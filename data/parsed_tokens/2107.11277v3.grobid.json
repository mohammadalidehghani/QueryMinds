{
  "title": [
    {
      "sentence": "Machine Learning with a Reject Option: A survey",
      "tokens": [
        "Machine",
        "Learning",
        "with",
        "a",
        "Reject",
        "Option",
        ":",
        "A",
        "survey"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "Machine learning models always make a prediction, even when it is likely to be inaccurate.",
      "tokens": [
        "Machine",
        "learning",
        "models",
        "always",
        "make",
        "a",
        "prediction",
        ",",
        "even",
        "when",
        "it",
        "is",
        "likely",
        "to",
        "be",
        "inaccurate",
        "."
      ]
    },
    {
      "sentence": "This behavior should be avoided in many decision support applications, where mistakes can have severe consequences.",
      "tokens": [
        "This",
        "behavior",
        "should",
        "be",
        "avoided",
        "in",
        "many",
        "decision",
        "support",
        "applications",
        ",",
        "where",
        "mistakes",
        "can",
        "have",
        "severe",
        "consequences",
        "."
      ]
    },
    {
      "sentence": "Albeit already studied in 1970, machine learning with rejection recently gained interest.",
      "tokens": [
        "Albeit",
        "already",
        "studied",
        "in",
        "1970",
        ",",
        "machine",
        "learning",
        "with",
        "rejection",
        "recently",
        "gained",
        "interest",
        "."
      ]
    },
    {
      "sentence": "This machine learning subfield enables machine learning models to abstain from making a prediction when likely to make a mistake.",
      "tokens": [
        "This",
        "machine",
        "learning",
        "subfield",
        "enables",
        "machine",
        "learning",
        "models",
        "to",
        "abstain",
        "from",
        "making",
        "a",
        "prediction",
        "when",
        "likely",
        "to",
        "make",
        "a",
        "mistake",
        "."
      ]
    },
    {
      "sentence": "This survey aims to provide an overview on machine learning with rejection.",
      "tokens": [
        "This",
        "survey",
        "aims",
        "to",
        "provide",
        "an",
        "overview",
        "on",
        "machine",
        "learning",
        "with",
        "rejection",
        "."
      ]
    },
    {
      "sentence": "We introduce the conditions leading to two types of rejection, ambiguity and novelty rejection, which we carefully formalize.",
      "tokens": [
        "We",
        "introduce",
        "the",
        "conditions",
        "leading",
        "to",
        "two",
        "types",
        "of",
        "rejection",
        ",",
        "ambiguity",
        "and",
        "novelty",
        "rejection",
        ",",
        "which",
        "we",
        "carefully",
        "formalize",
        "."
      ]
    },
    {
      "sentence": "Moreover, we review and categorize strategies to evaluate a model's predictive and rejective quality.",
      "tokens": [
        "Moreover",
        ",",
        "we",
        "review",
        "and",
        "categorize",
        "strategies",
        "to",
        "evaluate",
        "a",
        "model",
        "'s",
        "predictive",
        "and",
        "rejective",
        "quality",
        "."
      ]
    },
    {
      "sentence": "Additionally, we define the existing architectures for models with rejection and describe the standard techniques for learning such models.",
      "tokens": [
        "Additionally",
        ",",
        "we",
        "define",
        "the",
        "existing",
        "architectures",
        "for",
        "models",
        "with",
        "rejection",
        "and",
        "describe",
        "the",
        "standard",
        "techniques",
        "for",
        "learning",
        "such",
        "models",
        "."
      ]
    },
    {
      "sentence": "Finally, we provide examples of relevant",
      "tokens": [
        "Finally",
        ",",
        "we",
        "provide",
        "examples",
        "of",
        "relevant"
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "Introduction The canonical task in machine learning is to learn a predictive model that captures the relationship between a set of input variables and a target variable on the basis of training data.",
      "tokens": [
        "Introduction",
        "The",
        "canonical",
        "task",
        "in",
        "machine",
        "learning",
        "is",
        "to",
        "learn",
        "a",
        "predictive",
        "model",
        "that",
        "captures",
        "the",
        "relationship",
        "between",
        "a",
        "set",
        "of",
        "input",
        "variables",
        "and",
        "a",
        "target",
        "variable",
        "on",
        "the",
        "basis",
        "of",
        "training",
        "data",
        "."
      ]
    },
    {
      "sentence": "Machine-learned models are powerful because, after training, they offer the ability to make accurate predictions about future examples.",
      "tokens": [
        "Machine-learned",
        "models",
        "are",
        "powerful",
        "because",
        ",",
        "after",
        "training",
        ",",
        "they",
        "offer",
        "the",
        "ability",
        "to",
        "make",
        "accurate",
        "predictions",
        "about",
        "future",
        "examples",
        "."
      ]
    },
    {
      "sentence": "Since this enables automating a number of tasks that are difficult and/or time-consuming, such models are ubiquitously deployed.",
      "tokens": [
        "Since",
        "this",
        "enables",
        "automating",
        "a",
        "number",
        "of",
        "tasks",
        "that",
        "are",
        "difficult",
        "and/or",
        "time-consuming",
        ",",
        "such",
        "models",
        "are",
        "ubiquitously",
        "deployed",
        "."
      ]
    },
    {
      "sentence": "However, their key functionality of always returning a prediction for a given novel input is also a drawback.",
      "tokens": [
        "However",
        ",",
        "their",
        "key",
        "functionality",
        "of",
        "always",
        "returning",
        "a",
        "prediction",
        "for",
        "a",
        "given",
        "novel",
        "input",
        "is",
        "also",
        "a",
        "drawback",
        "."
      ]
    },
    {
      "sentence": "While the model may produce accurate predictions in general, in certain circumstances this may not be the case.",
      "tokens": [
        "While",
        "the",
        "model",
        "may",
        "produce",
        "accurate",
        "predictions",
        "in",
        "general",
        ",",
        "in",
        "certain",
        "circumstances",
        "this",
        "may",
        "not",
        "be",
        "the",
        "case",
        "."
      ]
    },
    {
      "sentence": "For instance, there could be certain regions of the feature space where the model struggles to differentiate among the different classes.",
      "tokens": [
        "For",
        "instance",
        ",",
        "there",
        "could",
        "be",
        "certain",
        "regions",
        "of",
        "the",
        "feature",
        "space",
        "where",
        "the",
        "model",
        "struggles",
        "to",
        "differentiate",
        "among",
        "the",
        "different",
        "classes",
        "."
      ]
    },
    {
      "sentence": "Or the current test example could be highly dissimilar to the data used to train the model.",
      "tokens": [
        "Or",
        "the",
        "current",
        "test",
        "example",
        "could",
        "be",
        "highly",
        "dissimilar",
        "to",
        "the",
        "data",
        "used",
        "to",
        "train",
        "the",
        "model",
        "."
      ]
    },
    {
      "sentence": "In certain application domains, such as medical diagnostics (Kotropoulos and Arce 2009) and engineering (Zou et al.",
      "tokens": [
        "In",
        "certain",
        "application",
        "domains",
        ",",
        "such",
        "as",
        "medical",
        "diagnostics",
        "(",
        "Kotropoulos",
        "and",
        "Arce",
        "2009",
        ")",
        "and",
        "engineering",
        "(",
        "Zou",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "2011) , mispredictions can have serious consequences.",
      "tokens": [
        "2011",
        ")",
        ",",
        "mispredictions",
        "can",
        "have",
        "serious",
        "consequences",
        "."
      ]
    },
    {
      "sentence": "Therefore, it would be beneficial for a model to be cautious in situations where it is uncertain about its predictions.",
      "tokens": [
        "Therefore",
        ",",
        "it",
        "would",
        "be",
        "beneficial",
        "for",
        "a",
        "model",
        "to",
        "be",
        "cautious",
        "in",
        "situations",
        "where",
        "it",
        "is",
        "uncertain",
        "about",
        "its",
        "predictions",
        "."
      ]
    },
    {
      "sentence": "The prediction task could be deferred to a human expert in these situations.",
      "tokens": [
        "The",
        "prediction",
        "task",
        "could",
        "be",
        "deferred",
        "to",
        "a",
        "human",
        "expert",
        "in",
        "these",
        "situations",
        "."
      ]
    },
    {
      "sentence": "One way to accomplish this is to use machine learning models with rejection.",
      "tokens": [
        "One",
        "way",
        "to",
        "accomplish",
        "this",
        "is",
        "to",
        "use",
        "machine",
        "learning",
        "models",
        "with",
        "rejection",
        "."
      ]
    },
    {
      "sentence": "Such models assess their confidence in each prediction and have the option to abstain from making a prediction when they are likely to make a mistake.",
      "tokens": [
        "Such",
        "models",
        "assess",
        "their",
        "confidence",
        "in",
        "each",
        "prediction",
        "and",
        "have",
        "the",
        "option",
        "to",
        "abstain",
        "from",
        "making",
        "a",
        "prediction",
        "when",
        "they",
        "are",
        "likely",
        "to",
        "make",
        "a",
        "mistake",
        "."
      ]
    },
    {
      "sentence": "This ability to abstain from making a prediction has several benefits.",
      "tokens": [
        "This",
        "ability",
        "to",
        "abstain",
        "from",
        "making",
        "a",
        "prediction",
        "has",
        "several",
        "benefits",
        "."
      ]
    },
    {
      "sentence": "First, by only making predictions when it is confident, it can result in improved performance for the retained examples (Pudil et al.",
      "tokens": [
        "First",
        ",",
        "by",
        "only",
        "making",
        "predictions",
        "when",
        "it",
        "is",
        "confident",
        ",",
        "it",
        "can",
        "result",
        "in",
        "improved",
        "performance",
        "for",
        "the",
        "retained",
        "examples",
        "(",
        "Pudil",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "1992) .",
      "tokens": [
        "1992",
        ")",
        "."
      ]
    },
    {
      "sentence": "Second, avoiding mispredictions can increase a user's trust in the system (El-Yaniv and Wiener 2010).",
      "tokens": [
        "Second",
        ",",
        "avoiding",
        "mispredictions",
        "can",
        "increase",
        "a",
        "user",
        "'s",
        "trust",
        "in",
        "the",
        "system",
        "(",
        "El-Yaniv",
        "and",
        "Wiener",
        "2010",
        ")",
        "."
      ]
    },
    {
      "sentence": "Third, it can still result in time savings by only requiring human interventions to make decisions in a small number of cases.",
      "tokens": [
        "Third",
        ",",
        "it",
        "can",
        "still",
        "result",
        "in",
        "time",
        "savings",
        "by",
        "only",
        "requiring",
        "human",
        "interventions",
        "to",
        "make",
        "decisions",
        "in",
        "a",
        "small",
        "number",
        "of",
        "cases",
        "."
      ]
    },
    {
      "sentence": "Fourth, avoiding strongly biased predictions helps build a more fair model (Lee et al.",
      "tokens": [
        "Fourth",
        ",",
        "avoiding",
        "strongly",
        "biased",
        "predictions",
        "helps",
        "build",
        "a",
        "more",
        "fair",
        "model",
        "(",
        "Lee",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "2021; Ruggieri et al.",
      "tokens": [
        "2021",
        ";",
        "Ruggieri",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "2023) .",
      "tokens": [
        "2023",
        ")",
        "."
      ]
    },
    {
      "sentence": "This machine learning subfield was already studied in 1970 by Chow (1970) and Hellman (1970) .",
      "tokens": [
        "This",
        "machine",
        "learning",
        "subfield",
        "was",
        "already",
        "studied",
        "in",
        "1970",
        "by",
        "Chow",
        "(",
        "1970",
        ")",
        "and",
        "Hellman",
        "(",
        "1970",
        ")",
        "."
      ]
    },
    {
      "sentence": "However, the proliferation of applications has resulted in renewed interest in this area.",
      "tokens": [
        "However",
        ",",
        "the",
        "proliferation",
        "of",
        "applications",
        "has",
        "resulted",
        "in",
        "renewed",
        "interest",
        "in",
        "this",
        "area",
        "."
      ]
    },
    {
      "sentence": "This survey aims to provide an overview of the subfield of machine learning with rejection, which we structure around eight key research questions.",
      "tokens": [
        "This",
        "survey",
        "aims",
        "to",
        "provide",
        "an",
        "overview",
        "of",
        "the",
        "subfield",
        "of",
        "machine",
        "learning",
        "with",
        "rejection",
        ",",
        "which",
        "we",
        "structure",
        "around",
        "eight",
        "key",
        "research",
        "questions",
        "."
      ]
    },
    {
      "sentence": "Q1.",
      "tokens": [
        "Q1",
        "."
      ]
    },
    {
      "sentence": "How can we formalize the conditions for which a model should abstain from making a prediction?",
      "tokens": [
        "How",
        "can",
        "we",
        "formalize",
        "the",
        "conditions",
        "for",
        "which",
        "a",
        "model",
        "should",
        "abstain",
        "from",
        "making",
        "a",
        "prediction",
        "?"
      ]
    },
    {
      "sentence": "Q2.",
      "tokens": [
        "Q2",
        "."
      ]
    },
    {
      "sentence": "How can we evaluate the performance of a model with rejection?",
      "tokens": [
        "How",
        "can",
        "we",
        "evaluate",
        "the",
        "performance",
        "of",
        "a",
        "model",
        "with",
        "rejection",
        "?"
      ]
    },
    {
      "sentence": "Q3.",
      "tokens": [
        "Q3",
        "."
      ]
    },
    {
      "sentence": "What architectures are possible for operationalizing (i.e., putting this into practice) the ability to abstain from making a prediction?",
      "tokens": [
        "What",
        "architectures",
        "are",
        "possible",
        "for",
        "operationalizing",
        "(",
        "i.e.",
        ",",
        "putting",
        "this",
        "into",
        "practice",
        ")",
        "the",
        "ability",
        "to",
        "abstain",
        "from",
        "making",
        "a",
        "prediction",
        "?"
      ]
    },
    {
      "sentence": "Q4.",
      "tokens": [
        "Q4",
        "."
      ]
    },
    {
      "sentence": "How do we learn models with rejection?",
      "tokens": [
        "How",
        "do",
        "we",
        "learn",
        "models",
        "with",
        "rejection",
        "?"
      ]
    },
    {
      "sentence": "Q5.",
      "tokens": [
        "Q5",
        "."
      ]
    },
    {
      "sentence": "What are the main pros and cons of using a specific architecture?",
      "tokens": [
        "What",
        "are",
        "the",
        "main",
        "pros",
        "and",
        "cons",
        "of",
        "using",
        "a",
        "specific",
        "architecture",
        "?"
      ]
    },
    {
      "sentence": "Q6.",
      "tokens": [
        "Q6",
        "."
      ]
    },
    {
      "sentence": "How can we combine multiple rejectors?",
      "tokens": [
        "How",
        "can",
        "we",
        "combine",
        "multiple",
        "rejectors",
        "?"
      ]
    },
    {
      "sentence": "Q7.",
      "tokens": [
        "Q7",
        "."
      ]
    },
    {
      "sentence": "Where does the need for machine learning with rejection methods arise in real-world applications?",
      "tokens": [
        "Where",
        "does",
        "the",
        "need",
        "for",
        "machine",
        "learning",
        "with",
        "rejection",
        "methods",
        "arise",
        "in",
        "real-world",
        "applications",
        "?"
      ]
    },
    {
      "sentence": "Q8.",
      "tokens": [
        "Q8",
        "."
      ]
    },
    {
      "sentence": "How does machine learning with rejection relate to other research areas?",
      "tokens": [
        "How",
        "does",
        "machine",
        "learning",
        "with",
        "rejection",
        "relate",
        "to",
        "other",
        "research",
        "areas",
        "?"
      ]
    },
    {
      "sentence": "In addition to the individual contributions of addressing each of these research questions, our major contribution is that we identify the main characteristics of machine learning models with rejection, allowing us to structure the methods in this research field.",
      "tokens": [
        "In",
        "addition",
        "to",
        "the",
        "individual",
        "contributions",
        "of",
        "addressing",
        "each",
        "of",
        "these",
        "research",
        "questions",
        ",",
        "our",
        "major",
        "contribution",
        "is",
        "that",
        "we",
        "identify",
        "the",
        "main",
        "characteristics",
        "of",
        "machine",
        "learning",
        "models",
        "with",
        "rejection",
        ",",
        "allowing",
        "us",
        "to",
        "structure",
        "the",
        "methods",
        "in",
        "this",
        "research",
        "field",
        "."
      ]
    },
    {
      "sentence": "By providing an overview of the research field as well as deeper insights into the various techniques, we aid in further advance this research area, as well as its adaptation to real-world applications.",
      "tokens": [
        "By",
        "providing",
        "an",
        "overview",
        "of",
        "the",
        "research",
        "field",
        "as",
        "well",
        "as",
        "deeper",
        "insights",
        "into",
        "the",
        "various",
        "techniques",
        ",",
        "we",
        "aid",
        "in",
        "further",
        "advance",
        "this",
        "research",
        "area",
        ",",
        "as",
        "well",
        "as",
        "its",
        "adaptation",
        "to",
        "real-world",
        "applications",
        "."
      ]
    },
    {
      "sentence": "The remainder of this paper is structured as follows.",
      "tokens": [
        "The",
        "remainder",
        "of",
        "this",
        "paper",
        "is",
        "structured",
        "as",
        "follows",
        "."
      ]
    },
    {
      "sentence": "In Section 2, we formalize the setting in which machine learning with rejection operates and identify the two main motivations to abstain from making a prediction (Q1).",
      "tokens": [
        "In",
        "Section",
        "2",
        ",",
        "we",
        "formalize",
        "the",
        "setting",
        "in",
        "which",
        "machine",
        "learning",
        "with",
        "rejection",
        "operates",
        "and",
        "identify",
        "the",
        "two",
        "main",
        "motivations",
        "to",
        "abstain",
        "from",
        "making",
        "a",
        "prediction",
        "(",
        "Q1",
        ")",
        "."
      ]
    },
    {
      "sentence": "Section 3 introduces the means to evaluate the performance of models with rejection (Q2).",
      "tokens": [
        "Section",
        "3",
        "introduces",
        "the",
        "means",
        "to",
        "evaluate",
        "the",
        "performance",
        "of",
        "models",
        "with",
        "rejection",
        "(",
        "Q2",
        ")",
        "."
      ]
    },
    {
      "sentence": "Sections 4, 5, and 6 provide a structured overview of the actionable techniques to reject based on the relevant literature.",
      "tokens": [
        "Sections",
        "4",
        ",",
        "5",
        ",",
        "and",
        "6",
        "provide",
        "a",
        "structured",
        "overview",
        "of",
        "the",
        "actionable",
        "techniques",
        "to",
        "reject",
        "based",
        "on",
        "the",
        "relevant",
        "literature",
        "."
      ]
    },
    {
      "sentence": "In these sections, we focus on describing the architecture (Q3), the rejector's learning (Q4), and the key pros and cons (Q5).",
      "tokens": [
        "In",
        "these",
        "sections",
        ",",
        "we",
        "focus",
        "on",
        "describing",
        "the",
        "architecture",
        "(",
        "Q3",
        ")",
        ",",
        "the",
        "rejector",
        "'s",
        "learning",
        "(",
        "Q4",
        ")",
        ",",
        "and",
        "the",
        "key",
        "pros",
        "and",
        "cons",
        "(",
        "Q5",
        ")",
        "."
      ]
    },
    {
      "sentence": "In Section 7 we explore how to combine multiple rejectors to allow different types of rejection (Q6) Section 8 discusses the main application fields (Q7), while Section 9 explores the relation of machine learning with rejection with other research areas (Q8).",
      "tokens": [
        "In",
        "Section",
        "7",
        "we",
        "explore",
        "how",
        "to",
        "combine",
        "multiple",
        "rejectors",
        "to",
        "allow",
        "different",
        "types",
        "of",
        "rejection",
        "(",
        "Q6",
        ")",
        "Section",
        "8",
        "discusses",
        "the",
        "main",
        "application",
        "fields",
        "(",
        "Q7",
        ")",
        ",",
        "while",
        "Section",
        "9",
        "explores",
        "the",
        "relation",
        "of",
        "machine",
        "learning",
        "with",
        "rejection",
        "with",
        "other",
        "research",
        "areas",
        "(",
        "Q8",
        ")",
        "."
      ]
    },
    {
      "sentence": "Finally, Section 10 summarizes our conclusions and lists the main open research questions.",
      "tokens": [
        "Finally",
        ",",
        "Section",
        "10",
        "summarizes",
        "our",
        "conclusions",
        "and",
        "lists",
        "the",
        "main",
        "open",
        "research",
        "questions",
        "."
      ]
    },
    {
      "sentence": "2 The learning with reject problem setting In the standard supervised setting, a learner has access to a training set D = {(x 1 , y 1 ), .",
      "tokens": [
        "2",
        "The",
        "learning",
        "with",
        "reject",
        "problem",
        "setting",
        "In",
        "the",
        "standard",
        "supervised",
        "setting",
        ",",
        "a",
        "learner",
        "has",
        "access",
        "to",
        "a",
        "training",
        "set",
        "D",
        "=",
        "{",
        "(",
        "x",
        "1",
        ",",
        "y",
        "1",
        ")",
        ",",
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ", (xn, yn)}, where each x i is a d dimensional vector and y i is the target.",
      "tokens": [
        ",",
        "(",
        "xn",
        ",",
        "yn",
        ")",
        "}",
        ",",
        "where",
        "each",
        "x",
        "i",
        "is",
        "a",
        "d",
        "dimensional",
        "vector",
        "and",
        "y",
        "i",
        "is",
        "the",
        "target",
        "."
      ]
    },
    {
      "sentence": "The training data is assumed to be independent and identically distributed (i.i.d.)",
      "tokens": [
        "The",
        "training",
        "data",
        "is",
        "assumed",
        "to",
        "be",
        "independent",
        "and",
        "identically",
        "distributed",
        "(",
        "i.i.d",
        ".",
        ")"
      ]
    },
    {
      "sentence": "according to some unknown probability measure P (with density p(X, Y )).",
      "tokens": [
        "according",
        "to",
        "some",
        "unknown",
        "probability",
        "measure",
        "P",
        "(",
        "with",
        "density",
        "p",
        "(",
        "X",
        ",",
        "Y",
        ")",
        ")",
        "."
      ]
    },
    {
      "sentence": "More generally, we denote the feature space as X and the target space as Y, which could be discrete Y = {1, 2, .",
      "tokens": [
        "More",
        "generally",
        ",",
        "we",
        "denote",
        "the",
        "feature",
        "space",
        "as",
        "X",
        "and",
        "the",
        "target",
        "space",
        "as",
        "Y",
        ",",
        "which",
        "could",
        "be",
        "discrete",
        "Y",
        "=",
        "{",
        "1",
        ",",
        "2",
        ",",
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ", K}, continuous Y = R, or even probabilistic Y = [0, 1].",
      "tokens": [
        ",",
        "K",
        "}",
        ",",
        "continuous",
        "Y",
        "=",
        "R",
        ",",
        "or",
        "even",
        "probabilistic",
        "Y",
        "=",
        "[",
        "0",
        ",",
        "1",
        "]",
        "."
      ]
    },
    {
      "sentence": "The assumption is that there is an unknown, non-deterministic function f : X → Y that maps the examples to their target value.",
      "tokens": [
        "The",
        "assumption",
        "is",
        "that",
        "there",
        "is",
        "an",
        "unknown",
        ",",
        "non-deterministic",
        "function",
        "f",
        ":",
        "X",
        "→",
        "Y",
        "that",
        "maps",
        "the",
        "examples",
        "to",
        "their",
        "target",
        "value",
        "."
      ]
    },
    {
      "sentence": "Given a hypothesis space H of functions h : X → Y, the goal of a learner is to find a good approximation to f .",
      "tokens": [
        "Given",
        "a",
        "hypothesis",
        "space",
        "H",
        "of",
        "functions",
        "h",
        ":",
        "X",
        "→",
        "Y",
        ",",
        "the",
        "goal",
        "of",
        "a",
        "learner",
        "is",
        "to",
        "find",
        "a",
        "good",
        "approximation",
        "to",
        "f",
        "."
      ]
    },
    {
      "sentence": "Typically, this can be done by finding a model h ∈ H with a small expected risk R which is usually approximated using the training data R(h) := X ×Y L(h(x), y)dP (x, y) ≈ n i=1 L(h(x i ), y i ) n , (1) where L is a suitable loss function such as the squared or zero-one loss.",
      "tokens": [
        "Typically",
        ",",
        "this",
        "can",
        "be",
        "done",
        "by",
        "finding",
        "a",
        "model",
        "h",
        "∈",
        "H",
        "with",
        "a",
        "small",
        "expected",
        "risk",
        "R",
        "which",
        "is",
        "usually",
        "approximated",
        "using",
        "the",
        "training",
        "data",
        "R",
        "(",
        "h",
        ")",
        ":",
        "=",
        "X",
        "×Y",
        "L",
        "(",
        "h",
        "(",
        "x",
        ")",
        ",",
        "y",
        ")",
        "dP",
        "(",
        "x",
        ",",
        "y",
        ")",
        "≈",
        "n",
        "i=1",
        "L",
        "(",
        "h",
        "(",
        "x",
        "i",
        ")",
        ",",
        "y",
        "i",
        ")",
        "n",
        ",",
        "(",
        "1",
        ")",
        "where",
        "L",
        "is",
        "a",
        "suitable",
        "loss",
        "function",
        "such",
        "as",
        "the",
        "squared",
        "or",
        "zero-one",
        "loss",
        "."
      ]
    }
  ]
}