{
  "title": [
    {
      "sentence": "On the computation of counterfactual explanations -A survey",
      "tokens": [
        "On",
        "the",
        "computation",
        "of",
        "counterfactual",
        "explanations",
        "-A",
        "survey"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "Due to the increasing use of machine learning in practice it becomes more and more important to be able to explain the prediction and behavior of machine learning models.",
      "tokens": [
        "Due",
        "to",
        "the",
        "increasing",
        "use",
        "of",
        "machine",
        "learning",
        "in",
        "practice",
        "it",
        "becomes",
        "more",
        "and",
        "more",
        "important",
        "to",
        "be",
        "able",
        "to",
        "explain",
        "the",
        "prediction",
        "and",
        "behavior",
        "of",
        "machine",
        "learning",
        "models",
        "."
      ]
    },
    {
      "sentence": "An instance of explanations are counterfactual explanations which provide an intuitive and useful explanations of machine learning models.",
      "tokens": [
        "An",
        "instance",
        "of",
        "explanations",
        "are",
        "counterfactual",
        "explanations",
        "which",
        "provide",
        "an",
        "intuitive",
        "and",
        "useful",
        "explanations",
        "of",
        "machine",
        "learning",
        "models",
        "."
      ]
    },
    {
      "sentence": "In this survey we review model-specific methods for efficiently computing counterfactual explanations of many different machine learning models and propose methods for models that have not been considered in literature so far.",
      "tokens": [
        "In",
        "this",
        "survey",
        "we",
        "review",
        "model-specific",
        "methods",
        "for",
        "efficiently",
        "computing",
        "counterfactual",
        "explanations",
        "of",
        "many",
        "different",
        "machine",
        "learning",
        "models",
        "and",
        "propose",
        "methods",
        "for",
        "models",
        "that",
        "have",
        "not",
        "been",
        "considered",
        "in",
        "literature",
        "so",
        "far",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "Introduction Due to recent advances in machine learning (ML), ML methods are increasingly use in real world scenarios [1] [2] [3] [4] .",
      "tokens": [
        "Introduction",
        "Due",
        "to",
        "recent",
        "advances",
        "in",
        "machine",
        "learning",
        "(",
        "ML",
        ")",
        ",",
        "ML",
        "methods",
        "are",
        "increasingly",
        "use",
        "in",
        "real",
        "world",
        "scenarios",
        "[",
        "1",
        "]",
        "[",
        "2",
        "]",
        "[",
        "3",
        "]",
        "[",
        "4",
        "]",
        "."
      ]
    },
    {
      "sentence": "Especially, ML technology is nowadays used in critical situations like predictive policing [5] and loan approval [6] .",
      "tokens": [
        "Especially",
        ",",
        "ML",
        "technology",
        "is",
        "nowadays",
        "used",
        "in",
        "critical",
        "situations",
        "like",
        "predictive",
        "policing",
        "[",
        "5",
        "]",
        "and",
        "loan",
        "approval",
        "[",
        "6",
        "]",
        "."
      ]
    },
    {
      "sentence": "In order to increase trust and acceptance of these kind of technology, it is important to be able to explain the behaviour and prediction of these models [7] -in particular answer questions like \"Why did the model do that?",
      "tokens": [
        "In",
        "order",
        "to",
        "increase",
        "trust",
        "and",
        "acceptance",
        "of",
        "these",
        "kind",
        "of",
        "technology",
        ",",
        "it",
        "is",
        "important",
        "to",
        "be",
        "able",
        "to",
        "explain",
        "the",
        "behaviour",
        "and",
        "prediction",
        "of",
        "these",
        "models",
        "[",
        "7",
        "]",
        "-in",
        "particular",
        "answer",
        "questions",
        "like",
        "``",
        "Why",
        "did",
        "the",
        "model",
        "do",
        "that",
        "?"
      ]
    },
    {
      "sentence": "And why not smth.",
      "tokens": [
        "And",
        "why",
        "not",
        "smth",
        "."
      ]
    },
    {
      "sentence": "else?\".",
      "tokens": [
        "else",
        "?",
        "``",
        "."
      ]
    },
    {
      "sentence": "This becomes even more important in view to legal regulations like the EU regulation on GDPR [8] , that grants the user a right to an explanation.",
      "tokens": [
        "This",
        "becomes",
        "even",
        "more",
        "important",
        "in",
        "view",
        "to",
        "legal",
        "regulations",
        "like",
        "the",
        "EU",
        "regulation",
        "on",
        "GDPR",
        "[",
        "8",
        "]",
        ",",
        "that",
        "grants",
        "the",
        "user",
        "a",
        "right",
        "to",
        "an",
        "explanation",
        "."
      ]
    },
    {
      "sentence": "A popular method for explaining models [7, [9] [10] [11] are counterfactual explanations (often just called counterfactuals) [12] .",
      "tokens": [
        "A",
        "popular",
        "method",
        "for",
        "explaining",
        "models",
        "[",
        "7",
        ",",
        "[",
        "9",
        "]",
        "[",
        "10",
        "]",
        "[",
        "11",
        "]",
        "are",
        "counterfactual",
        "explanations",
        "(",
        "often",
        "just",
        "called",
        "counterfactuals",
        ")",
        "[",
        "12",
        "]",
        "."
      ]
    },
    {
      "sentence": "A counterfactual explanation states changes to some features that lead to a different (specified) behaviour or prediction of the model.",
      "tokens": [
        "A",
        "counterfactual",
        "explanation",
        "states",
        "changes",
        "to",
        "some",
        "features",
        "that",
        "lead",
        "to",
        "a",
        "different",
        "(",
        "specified",
        ")",
        "behaviour",
        "or",
        "prediction",
        "of",
        "the",
        "model",
        "."
      ]
    },
    {
      "sentence": "Thus, counterfactual explanation can be interpreted as a recommendation what to do in order to achieve a requested goal.",
      "tokens": [
        "Thus",
        ",",
        "counterfactual",
        "explanation",
        "can",
        "be",
        "interpreted",
        "as",
        "a",
        "recommendation",
        "what",
        "to",
        "do",
        "in",
        "order",
        "to",
        "achieve",
        "a",
        "requested",
        "goal",
        "."
      ]
    },
    {
      "sentence": "This is why counterfactual explanations are that popular -they are intuitive and user-friendly [7, 12] .",
      "tokens": [
        "This",
        "is",
        "why",
        "counterfactual",
        "explanations",
        "are",
        "that",
        "popular",
        "-they",
        "are",
        "intuitive",
        "and",
        "user-friendly",
        "[",
        "7",
        ",",
        "12",
        "]",
        "."
      ]
    },
    {
      "sentence": "Counterfactual explanations are an instance of model-agnostic methods.",
      "tokens": [
        "Counterfactual",
        "explanations",
        "are",
        "an",
        "instance",
        "of",
        "model-agnostic",
        "methods",
        "."
      ]
    },
    {
      "sentence": "Therefore, counterfactuals are not tailored to a particular model but can be computed for all possible models (in theory).",
      "tokens": [
        "Therefore",
        ",",
        "counterfactuals",
        "are",
        "not",
        "tailored",
        "to",
        "a",
        "particular",
        "model",
        "but",
        "can",
        "be",
        "computed",
        "for",
        "all",
        "possible",
        "models",
        "(",
        "in",
        "theory",
        ")",
        "."
      ]
    },
    {
      "sentence": "Other instances of model-agnostic methods are feature interaction methods [13] , feature importance methods [14] , partial dependency plots [15] and local methods that approximates the model locally by an explainable model (e.g.",
      "tokens": [
        "Other",
        "instances",
        "of",
        "model-agnostic",
        "methods",
        "are",
        "feature",
        "interaction",
        "methods",
        "[",
        "13",
        "]",
        ",",
        "feature",
        "importance",
        "methods",
        "[",
        "14",
        "]",
        ",",
        "partial",
        "dependency",
        "plots",
        "[",
        "15",
        "]",
        "and",
        "local",
        "methods",
        "that",
        "approximates",
        "the",
        "model",
        "locally",
        "by",
        "an",
        "explainable",
        "model",
        "(",
        "e.g",
        "."
      ]
    },
    {
      "sentence": "a decisiontree) [16, 17] .",
      "tokens": [
        "a",
        "decisiontree",
        ")",
        "[",
        "16",
        ",",
        "17",
        "]",
        "."
      ]
    },
    {
      "sentence": "The nice thing about model-agnostic methods is that they (in theory) do not need access to model internals and/or training data -it is sufficient to have an interface where we can pass data points to the model and observe the output/predictions of the model.",
      "tokens": [
        "The",
        "nice",
        "thing",
        "about",
        "model-agnostic",
        "methods",
        "is",
        "that",
        "they",
        "(",
        "in",
        "theory",
        ")",
        "do",
        "not",
        "need",
        "access",
        "to",
        "model",
        "internals",
        "and/or",
        "training",
        "data",
        "-it",
        "is",
        "sufficient",
        "to",
        "have",
        "an",
        "interface",
        "where",
        "we",
        "can",
        "pass",
        "data",
        "points",
        "to",
        "the",
        "model",
        "and",
        "observe",
        "the",
        "output/predictions",
        "of",
        "the",
        "model",
        "."
      ]
    },
    {
      "sentence": "However, it turns out that efficiently computing high quality counterfactual explanations of black-box models can be very difficult [18] .",
      "tokens": [
        "However",
        ",",
        "it",
        "turns",
        "out",
        "that",
        "efficiently",
        "computing",
        "high",
        "quality",
        "counterfactual",
        "explanations",
        "of",
        "black-box",
        "models",
        "can",
        "be",
        "very",
        "difficult",
        "[",
        "18",
        "]",
        "."
      ]
    },
    {
      "sentence": "Therefore, it is beneficial to develop model-specific methods -that use model internals -for efficiently computing counterfactual explanations.",
      "tokens": [
        "Therefore",
        ",",
        "it",
        "is",
        "beneficial",
        "to",
        "develop",
        "model-specific",
        "methods",
        "-that",
        "use",
        "model",
        "internals",
        "-for",
        "efficiently",
        "computing",
        "counterfactual",
        "explanations",
        "."
      ]
    },
    {
      "sentence": "Whenever we have access to model internals, we can use the model-specific method over the model-agnostic method for efficiently computing counterfactual explanations.",
      "tokens": [
        "Whenever",
        "we",
        "have",
        "access",
        "to",
        "model",
        "internals",
        ",",
        "we",
        "can",
        "use",
        "the",
        "model-specific",
        "method",
        "over",
        "the",
        "model-agnostic",
        "method",
        "for",
        "efficiently",
        "computing",
        "counterfactual",
        "explanations",
        "."
      ]
    },
    {
      "sentence": "In this work we focus on such model-specific methods.",
      "tokens": [
        "In",
        "this",
        "work",
        "we",
        "focus",
        "on",
        "such",
        "model-specific",
        "methods",
        "."
      ]
    },
    {
      "sentence": "In particular, our contributions are: • We review model-specific methods for efficiently computing counterfactual explanations of different ML models.",
      "tokens": [
        "In",
        "particular",
        ",",
        "our",
        "contributions",
        "are",
        ":",
        "•",
        "We",
        "review",
        "model-specific",
        "methods",
        "for",
        "efficiently",
        "computing",
        "counterfactual",
        "explanations",
        "of",
        "different",
        "ML",
        "models",
        "."
      ]
    },
    {
      "sentence": "• We propose model-specific methods for efficiently computing counterfactual explanations of models that have not been considered in literature so far.",
      "tokens": [
        "•",
        "We",
        "propose",
        "model-specific",
        "methods",
        "for",
        "efficiently",
        "computing",
        "counterfactual",
        "explanations",
        "of",
        "models",
        "that",
        "have",
        "not",
        "been",
        "considered",
        "in",
        "literature",
        "so",
        "far",
        "."
      ]
    },
    {
      "sentence": "The remainder of this paper is structured as follows: First, we briefly review counterfactual explanations (section 2).",
      "tokens": [
        "The",
        "remainder",
        "of",
        "this",
        "paper",
        "is",
        "structured",
        "as",
        "follows",
        ":",
        "First",
        ",",
        "we",
        "briefly",
        "review",
        "counterfactual",
        "explanations",
        "(",
        "section",
        "2",
        ")",
        "."
      ]
    },
    {
      "sentence": "Then, in section 3 we review and propose model-specific methods for computing counterfactual explanations.",
      "tokens": [
        "Then",
        ",",
        "in",
        "section",
        "3",
        "we",
        "review",
        "and",
        "propose",
        "model-specific",
        "methods",
        "for",
        "computing",
        "counterfactual",
        "explanations",
        "."
      ]
    },
    {
      "sentence": "Finally, section 5 summarizes this papers.",
      "tokens": [
        "Finally",
        ",",
        "section",
        "5",
        "summarizes",
        "this",
        "papers",
        "."
      ]
    },
    {
      "sentence": "All derivations and mathematical details can be found in the appendix (section 6).",
      "tokens": [
        "All",
        "derivations",
        "and",
        "mathematical",
        "details",
        "can",
        "be",
        "found",
        "in",
        "the",
        "appendix",
        "(",
        "section",
        "6",
        ")",
        "."
      ]
    }
  ]
}