{
  "title": [
    {
      "sentence": "On-the-Fly Learning in a Perpetual Learning Machine",
      "tokens": [
        "On-the-Fly",
        "Learning",
        "in",
        "a",
        "Perpetual",
        "Learning",
        "Machine"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "Despite the promise of brain-inspired machine learning, deep neural networks (DNN) have frustratingly failed to bridge the deceptively large gap between learning and memory.",
      "tokens": [
        "Despite",
        "the",
        "promise",
        "of",
        "brain-inspired",
        "machine",
        "learning",
        ",",
        "deep",
        "neural",
        "networks",
        "(",
        "DNN",
        ")",
        "have",
        "frustratingly",
        "failed",
        "to",
        "bridge",
        "the",
        "deceptively",
        "large",
        "gap",
        "between",
        "learning",
        "and",
        "memory",
        "."
      ]
    },
    {
      "sentence": "Here, we introduce a Perpetual Learning Machine; a new type of DNN that is capable of brain-like dynamic 'on the fly' learning because it exists in a self-supervised state of Perpetual Stochastic Gradient Descent.",
      "tokens": [
        "Here",
        ",",
        "we",
        "introduce",
        "a",
        "Perpetual",
        "Learning",
        "Machine",
        ";",
        "a",
        "new",
        "type",
        "of",
        "DNN",
        "that",
        "is",
        "capable",
        "of",
        "brain-like",
        "dynamic",
        "'on",
        "the",
        "fly",
        "'",
        "learning",
        "because",
        "it",
        "exists",
        "in",
        "a",
        "self-supervised",
        "state",
        "of",
        "Perpetual",
        "Stochastic",
        "Gradient",
        "Descent",
        "."
      ]
    },
    {
      "sentence": "Thus, we provide the means to unify learning and memory within a machine learning framework.",
      "tokens": [
        "Thus",
        ",",
        "we",
        "provide",
        "the",
        "means",
        "to",
        "unify",
        "learning",
        "and",
        "memory",
        "within",
        "a",
        "machine",
        "learning",
        "framework",
        "."
      ]
    },
    {
      "sentence": "We also explore the elegant duality of abstraction and synthesis: the Yin and Yang of deep learning.",
      "tokens": [
        "We",
        "also",
        "explore",
        "the",
        "elegant",
        "duality",
        "of",
        "abstraction",
        "and",
        "synthesis",
        ":",
        "the",
        "Yin",
        "and",
        "Yang",
        "of",
        "deep",
        "learning",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "I.",
      "tokens": [
        "I",
        "."
      ]
    },
    {
      "sentence": "INTRODUCTION It is an embarassing fact that while deep neural networks (DNN) are frequently compared to the brain, and even their performance found to be similar in specific static tasks, there remains a critical difference; DNN do not exhibit the fluid and dynamic learning of the brain but are static once trained.",
      "tokens": [
        "INTRODUCTION",
        "It",
        "is",
        "an",
        "embarassing",
        "fact",
        "that",
        "while",
        "deep",
        "neural",
        "networks",
        "(",
        "DNN",
        ")",
        "are",
        "frequently",
        "compared",
        "to",
        "the",
        "brain",
        ",",
        "and",
        "even",
        "their",
        "performance",
        "found",
        "to",
        "be",
        "similar",
        "in",
        "specific",
        "static",
        "tasks",
        ",",
        "there",
        "remains",
        "a",
        "critical",
        "difference",
        ";",
        "DNN",
        "do",
        "not",
        "exhibit",
        "the",
        "fluid",
        "and",
        "dynamic",
        "learning",
        "of",
        "the",
        "brain",
        "but",
        "are",
        "static",
        "once",
        "trained",
        "."
      ]
    },
    {
      "sentence": "For example, to add a new class of data to a trained DNN it is necessary to add the respective new training data to the preexisting training data and re-train (probably from scratch) to account for the new class.",
      "tokens": [
        "For",
        "example",
        ",",
        "to",
        "add",
        "a",
        "new",
        "class",
        "of",
        "data",
        "to",
        "a",
        "trained",
        "DNN",
        "it",
        "is",
        "necessary",
        "to",
        "add",
        "the",
        "respective",
        "new",
        "training",
        "data",
        "to",
        "the",
        "preexisting",
        "training",
        "data",
        "and",
        "re-train",
        "(",
        "probably",
        "from",
        "scratch",
        ")",
        "to",
        "account",
        "for",
        "the",
        "new",
        "class",
        "."
      ]
    },
    {
      "sentence": "By contrast, learning is essentially additive in the brain -if we want to learn a new thing, we do.",
      "tokens": [
        "By",
        "contrast",
        ",",
        "learning",
        "is",
        "essentially",
        "additive",
        "in",
        "the",
        "brain",
        "-if",
        "we",
        "want",
        "to",
        "learn",
        "a",
        "new",
        "thing",
        ",",
        "we",
        "do",
        "."
      ]
    },
    {
      "sentence": "Thus, whilst there is little doubt that the learning of the brain and machine learning are essentially the same, the learning of the brain involves the emergent phenomenon of memory which has failed to emerge from machine learning.",
      "tokens": [
        "Thus",
        ",",
        "whilst",
        "there",
        "is",
        "little",
        "doubt",
        "that",
        "the",
        "learning",
        "of",
        "the",
        "brain",
        "and",
        "machine",
        "learning",
        "are",
        "essentially",
        "the",
        "same",
        ",",
        "the",
        "learning",
        "of",
        "the",
        "brain",
        "involves",
        "the",
        "emergent",
        "phenomenon",
        "of",
        "memory",
        "which",
        "has",
        "failed",
        "to",
        "emerge",
        "from",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "Indeed, recent machine-inspired approaches to 'memory' have involved explicit add-on storage facilities [e.g., 1] which explicitly discriminate between learning (training -i.e., of weights) and memory (storage -i.e., of data).",
      "tokens": [
        "Indeed",
        ",",
        "recent",
        "machine-inspired",
        "approaches",
        "to",
        "'memory",
        "'",
        "have",
        "involved",
        "explicit",
        "add-on",
        "storage",
        "facilities",
        "[",
        "e.g.",
        ",",
        "1",
        "]",
        "which",
        "explicitly",
        "discriminate",
        "between",
        "learning",
        "(",
        "training",
        "-i.e.",
        ",",
        "of",
        "weights",
        ")",
        "and",
        "memory",
        "(",
        "storage",
        "-i.e.",
        ",",
        "of",
        "data",
        ")",
        "."
      ]
    },
    {
      "sentence": "Thus, the problem has been brushed under the carpet.",
      "tokens": [
        "Thus",
        ",",
        "the",
        "problem",
        "has",
        "been",
        "brushed",
        "under",
        "the",
        "carpet",
        "."
      ]
    },
    {
      "sentence": "In this article, we describe a novel form of supervised learning model, which we call a Perpetual Learning Machine, which gives rise to the basic properties of memory.",
      "tokens": [
        "In",
        "this",
        "article",
        ",",
        "we",
        "describe",
        "a",
        "novel",
        "form",
        "of",
        "supervised",
        "learning",
        "model",
        ",",
        "which",
        "we",
        "call",
        "a",
        "Perpetual",
        "Learning",
        "Machine",
        ",",
        "which",
        "gives",
        "rise",
        "to",
        "the",
        "basic",
        "properties",
        "of",
        "memory",
        "."
      ]
    },
    {
      "sentence": "Our model involves two DNNs, one for storage and the other for recall.",
      "tokens": [
        "Our",
        "model",
        "involves",
        "two",
        "DNNs",
        ",",
        "one",
        "for",
        "storage",
        "and",
        "the",
        "other",
        "for",
        "recall",
        "."
      ]
    },
    {
      "sentence": "The storage DNN learns the classes of some training images.",
      "tokens": [
        "The",
        "storage",
        "DNN",
        "learns",
        "the",
        "classes",
        "of",
        "some",
        "training",
        "images",
        "."
      ]
    },
    {
      "sentence": "The recall DNN learns to synthesise the same images from the same classes.",
      "tokens": [
        "The",
        "recall",
        "DNN",
        "learns",
        "to",
        "synthesise",
        "the",
        "same",
        "images",
        "from",
        "the",
        "same",
        "classes",
        "."
      ]
    },
    {
      "sentence": "Together, the two networks hold, encoded, the training set.",
      "tokens": [
        "Together",
        ",",
        "the",
        "two",
        "networks",
        "hold",
        ",",
        "encoded",
        ",",
        "the",
        "training",
        "set",
        "."
      ]
    },
    {
      "sentence": "We then place these pair of DNNs in a selfsupervised and homeostatic state of Perpetual Stochastic Gradient Descent (PSGD).",
      "tokens": [
        "We",
        "then",
        "place",
        "these",
        "pair",
        "of",
        "DNNs",
        "in",
        "a",
        "selfsupervised",
        "and",
        "homeostatic",
        "state",
        "of",
        "Perpetual",
        "Stochastic",
        "Gradient",
        "Descent",
        "(",
        "PSGD",
        ")",
        "."
      ]
    },
    {
      "sentence": "During each step of PSGD, a random class is chosen and an image synthesised from the recall DNN.",
      "tokens": [
        "During",
        "each",
        "step",
        "of",
        "PSGD",
        ",",
        "a",
        "random",
        "class",
        "is",
        "chosen",
        "and",
        "an",
        "image",
        "synthesised",
        "from",
        "the",
        "recall",
        "DNN",
        "."
      ]
    },
    {
      "sentence": "This randomly synthesised image is then used in combination with the random class to train both DNNs via non-batch SGD.",
      "tokens": [
        "This",
        "randomly",
        "synthesised",
        "image",
        "is",
        "then",
        "used",
        "in",
        "combination",
        "with",
        "the",
        "random",
        "class",
        "to",
        "train",
        "both",
        "DNNs",
        "via",
        "non-batch",
        "SGD",
        "."
      ]
    },
    {
      "sentence": "I.e., the PSGD is driven by training data that is synthesised from memory according to random classes.",
      "tokens": [
        "I.e.",
        ",",
        "the",
        "PSGD",
        "is",
        "driven",
        "by",
        "training",
        "data",
        "that",
        "is",
        "synthesised",
        "from",
        "memory",
        "according",
        "to",
        "random",
        "classes",
        "."
      ]
    },
    {
      "sentence": "We next demonstrate that new classes may be learned on the fly by introducing them, via 'new experience' SGD steps, into the path of PSGD.",
      "tokens": [
        "We",
        "next",
        "demonstrate",
        "that",
        "new",
        "classes",
        "may",
        "be",
        "learned",
        "on",
        "the",
        "fly",
        "by",
        "introducing",
        "them",
        ",",
        "via",
        "'new",
        "experience",
        "'",
        "SGD",
        "steps",
        ",",
        "into",
        "the",
        "path",
        "of",
        "PSGD",
        "."
      ]
    },
    {
      "sentence": "Over time, new classes are assimilated without disruption of earlier learning and hence we demonstrate a machine which both learns and remembers.",
      "tokens": [
        "Over",
        "time",
        ",",
        "new",
        "classes",
        "are",
        "assimilated",
        "without",
        "disruption",
        "of",
        "earlier",
        "learning",
        "and",
        "hence",
        "we",
        "demonstrate",
        "a",
        "machine",
        "which",
        "both",
        "learns",
        "and",
        "remembers",
        "."
      ]
    }
  ]
}