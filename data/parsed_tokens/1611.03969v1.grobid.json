{
  "title": [
    {
      "sentence": "An Introduction to MM Algorithms for Machine Learning and Statistical Estimation",
      "tokens": [
        "An",
        "Introduction",
        "to",
        "MM",
        "Algorithms",
        "for",
        "Machine",
        "Learning",
        "and",
        "Statistical",
        "Estimation"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "MM (majorization-minimization) algorithms are an increasingly popular tool for solving optimization problems in machine learning and statistical estimation.",
      "tokens": [
        "MM",
        "(",
        "majorization-minimization",
        ")",
        "algorithms",
        "are",
        "an",
        "increasingly",
        "popular",
        "tool",
        "for",
        "solving",
        "optimization",
        "problems",
        "in",
        "machine",
        "learning",
        "and",
        "statistical",
        "estimation",
        "."
      ]
    },
    {
      "sentence": "This article introduces the MM algorithm framework in general and via three popular example applications: Gaussian mixture regressions, multinomial logistic regressions, and support vector machines.",
      "tokens": [
        "This",
        "article",
        "introduces",
        "the",
        "MM",
        "algorithm",
        "framework",
        "in",
        "general",
        "and",
        "via",
        "three",
        "popular",
        "example",
        "applications",
        ":",
        "Gaussian",
        "mixture",
        "regressions",
        ",",
        "multinomial",
        "logistic",
        "regressions",
        ",",
        "and",
        "support",
        "vector",
        "machines",
        "."
      ]
    },
    {
      "sentence": "Specific algorithms for the three examples are derived and numerical demonstrations are presented.",
      "tokens": [
        "Specific",
        "algorithms",
        "for",
        "the",
        "three",
        "examples",
        "are",
        "derived",
        "and",
        "numerical",
        "demonstrations",
        "are",
        "presented",
        "."
      ]
    },
    {
      "sentence": "Theoretical and practical aspects of MM algorithm design are discussed.",
      "tokens": [
        "Theoretical",
        "and",
        "practical",
        "aspects",
        "of",
        "MM",
        "algorithm",
        "design",
        "are",
        "discussed",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "Introduction Let X ∈ X ⊂ R p and Y ∈ Y ⊂ R q be random variables, which we shall refer to as the input and target variables, respectively.",
      "tokens": [
        "Introduction",
        "Let",
        "X",
        "∈",
        "X",
        "⊂",
        "R",
        "p",
        "and",
        "Y",
        "∈",
        "Y",
        "⊂",
        "R",
        "q",
        "be",
        "random",
        "variables",
        ",",
        "which",
        "we",
        "shall",
        "refer",
        "to",
        "as",
        "the",
        "input",
        "and",
        "target",
        "variables",
        ",",
        "respectively",
        "."
      ]
    },
    {
      "sentence": "We shall denote a sample of n independent and identically distributed (IID) pairs of variables D = {(X i , Y i )} n i=1 1 arXiv:1611.03969v1 [stat.CO] 12 Nov 2016 as the data, and D = {(x i , y i )} n i=1 as an observed realization of the data.",
      "tokens": [
        "We",
        "shall",
        "denote",
        "a",
        "sample",
        "of",
        "n",
        "independent",
        "and",
        "identically",
        "distributed",
        "(",
        "IID",
        ")",
        "pairs",
        "of",
        "variables",
        "D",
        "=",
        "{",
        "(",
        "X",
        "i",
        ",",
        "Y",
        "i",
        ")",
        "}",
        "n",
        "i=1",
        "1",
        "arXiv:1611.03969v1",
        "[",
        "stat.CO",
        "]",
        "12",
        "Nov",
        "2016",
        "as",
        "the",
        "data",
        ",",
        "and",
        "D",
        "=",
        "{",
        "(",
        "x",
        "i",
        ",",
        "y",
        "i",
        ")",
        "}",
        "n",
        "i=1",
        "as",
        "an",
        "observed",
        "realization",
        "of",
        "the",
        "data",
        "."
      ]
    },
    {
      "sentence": "Under the empirical risk minimization (ERM) framework of Vapnik (1998, Ch.",
      "tokens": [
        "Under",
        "the",
        "empirical",
        "risk",
        "minimization",
        "(",
        "ERM",
        ")",
        "framework",
        "of",
        "Vapnik",
        "(",
        "1998",
        ",",
        "Ch",
        "."
      ]
    },
    {
      "sentence": "1) or the extremum estimation (EE) framework of Amemiya (1985, Ch.",
      "tokens": [
        "1",
        ")",
        "or",
        "the",
        "extremum",
        "estimation",
        "(",
        "EE",
        ")",
        "framework",
        "of",
        "Amemiya",
        "(",
        "1985",
        ",",
        "Ch",
        "."
      ]
    },
    {
      "sentence": "4 ), a large number of machine learning and statistical estimation problems can be phrased as the computation of min θ∈Θ R θ; D or θ = arg min θ∈Θ R θ; D , (1) where R θ; D is a risk function defined over the observed data D and is dependent on some parameter θ ∈ Θ.",
      "tokens": [
        "4",
        ")",
        ",",
        "a",
        "large",
        "number",
        "of",
        "machine",
        "learning",
        "and",
        "statistical",
        "estimation",
        "problems",
        "can",
        "be",
        "phrased",
        "as",
        "the",
        "computation",
        "of",
        "min",
        "θ∈Θ",
        "R",
        "θ",
        ";",
        "D",
        "or",
        "θ",
        "=",
        "arg",
        "min",
        "θ∈Θ",
        "R",
        "θ",
        ";",
        "D",
        ",",
        "(",
        "1",
        ")",
        "where",
        "R",
        "θ",
        ";",
        "D",
        "is",
        "a",
        "risk",
        "function",
        "defined",
        "over",
        "the",
        "observed",
        "data",
        "D",
        "and",
        "is",
        "dependent",
        "on",
        "some",
        "parameter",
        "θ",
        "∈",
        "Θ",
        "."
      ]
    },
    {
      "sentence": "Common risk functions that are used in practice are the negative log-likelihood functions, which can be expressed as When Y = {-1, 1}, a common problem in machine learning is to construct a classification function f (x i ; θ) that minimizes the classification (0-1) risk R θ; D = - 1 n n i=1 log f (x i , y i ; θ) , R θ; D = 1 n n i=1 I {y i = f (x i ; θ)} , where f : X → Y and I {A} = 1 if proposition A is true and 0 otherwise.",
      "tokens": [
        "Common",
        "risk",
        "functions",
        "that",
        "are",
        "used",
        "in",
        "practice",
        "are",
        "the",
        "negative",
        "log-likelihood",
        "functions",
        ",",
        "which",
        "can",
        "be",
        "expressed",
        "as",
        "When",
        "Y",
        "=",
        "{",
        "-1",
        ",",
        "1",
        "}",
        ",",
        "a",
        "common",
        "problem",
        "in",
        "machine",
        "learning",
        "is",
        "to",
        "construct",
        "a",
        "classification",
        "function",
        "f",
        "(",
        "x",
        "i",
        ";",
        "θ",
        ")",
        "that",
        "minimizes",
        "the",
        "classification",
        "(",
        "0-1",
        ")",
        "risk",
        "R",
        "θ",
        ";",
        "D",
        "=",
        "-",
        "1",
        "n",
        "n",
        "i=1",
        "log",
        "f",
        "(",
        "x",
        "i",
        ",",
        "y",
        "i",
        ";",
        "θ",
        ")",
        ",",
        "R",
        "θ",
        ";",
        "D",
        "=",
        "1",
        "n",
        "n",
        "i=1",
        "I",
        "{",
        "y",
        "i",
        "=",
        "f",
        "(",
        "x",
        "i",
        ";",
        "θ",
        ")",
        "}",
        ",",
        "where",
        "f",
        ":",
        "X",
        "→",
        "Y",
        "and",
        "I",
        "{",
        "A",
        "}",
        "=",
        "1",
        "if",
        "proposition",
        "A",
        "is",
        "true",
        "and",
        "0",
        "otherwise",
        "."
      ]
    },
    {
      "sentence": "Unfortunately, the form of the classification risk is combinatorial and thus necessitates the use of surrogate classification risks of the form R θ; D = 1 n n i=1 ψ (x i , y i , f (x i ; θ)) , where ψ : R p ×{-1, 1} 2 → [0, ∞) and ψ (x, y, y) = 0 for all x and y [cf.",
      "tokens": [
        "Unfortunately",
        ",",
        "the",
        "form",
        "of",
        "the",
        "classification",
        "risk",
        "is",
        "combinatorial",
        "and",
        "thus",
        "necessitates",
        "the",
        "use",
        "of",
        "surrogate",
        "classification",
        "risks",
        "of",
        "the",
        "form",
        "R",
        "θ",
        ";",
        "D",
        "=",
        "1",
        "n",
        "n",
        "i=1",
        "ψ",
        "(",
        "x",
        "i",
        ",",
        "y",
        "i",
        ",",
        "f",
        "(",
        "x",
        "i",
        ";",
        "θ",
        ")",
        ")",
        ",",
        "where",
        "ψ",
        ":",
        "R",
        "p",
        "×",
        "{",
        "-1",
        ",",
        "1",
        "}",
        "2",
        "→",
        "[",
        "0",
        ",",
        "∞",
        ")",
        "and",
        "ψ",
        "(",
        "x",
        ",",
        "y",
        ",",
        "y",
        ")",
        "=",
        "0",
        "for",
        "all",
        "x",
        "and",
        "y",
        "[",
        "cf",
        "."
      ]
    },
    {
      "sentence": "Scholkopf & Smola (2002, Def.",
      "tokens": [
        "Scholkopf",
        "&",
        "Smola",
        "(",
        "2002",
        ",",
        "Def",
        "."
      ]
    },
    {
      "sentence": "3.1) ].",
      "tokens": [
        "3.1",
        ")",
        "]",
        "."
      ]
    },
    {
      "sentence": "An example of a machine learning algorithm that minimizes a surrogate classification risk is the support vector machine (SVM) of Cortes & Vapnik (1995) .",
      "tokens": [
        "An",
        "example",
        "of",
        "a",
        "machine",
        "learning",
        "algorithm",
        "that",
        "minimizes",
        "a",
        "surrogate",
        "classification",
        "risk",
        "is",
        "the",
        "support",
        "vector",
        "machine",
        "(",
        "SVM",
        ")",
        "of",
        "Cortes",
        "&",
        "Vapnik",
        "(",
        "1995",
        ")",
        "."
      ]
    },
    {
      "sentence": "The linear-basis SVM utilizes a surrogate risk function, where ψ (x, y, f (x; θ)) = max {0, 1yf (x; θ)}is the hinge loss function, f (x; θ) = α + β x, and θ = α, β ∈ Θ ⊂ R p+1 .",
      "tokens": [
        "The",
        "linear-basis",
        "SVM",
        "utilizes",
        "a",
        "surrogate",
        "risk",
        "function",
        ",",
        "where",
        "ψ",
        "(",
        "x",
        ",",
        "y",
        ",",
        "f",
        "(",
        "x",
        ";",
        "θ",
        ")",
        ")",
        "=",
        "max",
        "{",
        "0",
        ",",
        "1yf",
        "(",
        "x",
        ";",
        "θ",
        ")",
        "}",
        "is",
        "the",
        "hinge",
        "loss",
        "function",
        ",",
        "f",
        "(",
        "x",
        ";",
        "θ",
        ")",
        "=",
        "α",
        "+",
        "β",
        "x",
        ",",
        "and",
        "θ",
        "=",
        "α",
        ",",
        "β",
        "∈",
        "Θ",
        "⊂",
        "R",
        "p+1",
        "."
      ]
    },
    {
      "sentence": "The task of computing (1) may be complicated by various factors that fall outside the scope of the traditional calculus formulation for optimization [cf.",
      "tokens": [
        "The",
        "task",
        "of",
        "computing",
        "(",
        "1",
        ")",
        "may",
        "be",
        "complicated",
        "by",
        "various",
        "factors",
        "that",
        "fall",
        "outside",
        "the",
        "scope",
        "of",
        "the",
        "traditional",
        "calculus",
        "formulation",
        "for",
        "optimization",
        "[",
        "cf",
        "."
      ]
    },
    {
      "sentence": "Khuri (2003, Ch.",
      "tokens": [
        "Khuri",
        "(",
        "2003",
        ",",
        "Ch",
        "."
      ]
    },
    {
      "sentence": "7) ].",
      "tokens": [
        "7",
        ")",
        "]",
        "."
      ]
    },
    {
      "sentence": "Such factors include the lack of differentiability of R or difficulty in obtaining closed-form solutions to the first-order condition (FOC) equation ∇ θ R = 0, where ∇ θ is the gradient operator with respect to θ, and 0 is a zero vector.",
      "tokens": [
        "Such",
        "factors",
        "include",
        "the",
        "lack",
        "of",
        "differentiability",
        "of",
        "R",
        "or",
        "difficulty",
        "in",
        "obtaining",
        "closed-form",
        "solutions",
        "to",
        "the",
        "first-order",
        "condition",
        "(",
        "FOC",
        ")",
        "equation",
        "∇",
        "θ",
        "R",
        "=",
        "0",
        ",",
        "where",
        "∇",
        "θ",
        "is",
        "the",
        "gradient",
        "operator",
        "with",
        "respect",
        "to",
        "θ",
        ",",
        "and",
        "0",
        "is",
        "a",
        "zero",
        "vector",
        "."
      ]
    },
    {
      "sentence": "The MM (majorization-minimization) algorithm framework is a unifying paradigm for simplifying the computation of (1) when difficulties arise, via iterative minimization of surrogate functions.",
      "tokens": [
        "The",
        "MM",
        "(",
        "majorization-minimization",
        ")",
        "algorithm",
        "framework",
        "is",
        "a",
        "unifying",
        "paradigm",
        "for",
        "simplifying",
        "the",
        "computation",
        "of",
        "(",
        "1",
        ")",
        "when",
        "difficulties",
        "arise",
        ",",
        "via",
        "iterative",
        "minimization",
        "of",
        "surrogate",
        "functions",
        "."
      ]
    },
    {
      "sentence": "MM algorithms are particularly attractive due to the monotonicity and thus stability of their objective sequences as well as global convergence of their limits, in general settings.",
      "tokens": [
        "MM",
        "algorithms",
        "are",
        "particularly",
        "attractive",
        "due",
        "to",
        "the",
        "monotonicity",
        "and",
        "thus",
        "stability",
        "of",
        "their",
        "objective",
        "sequences",
        "as",
        "well",
        "as",
        "global",
        "convergence",
        "of",
        "their",
        "limits",
        ",",
        "in",
        "general",
        "settings",
        "."
      ]
    },
    {
      "sentence": "A comprehensive treatment on the theory and implementation of MM algorithms can be found in Lange (2016) .",
      "tokens": [
        "A",
        "comprehensive",
        "treatment",
        "on",
        "the",
        "theory",
        "and",
        "implementation",
        "of",
        "MM",
        "algorithms",
        "can",
        "be",
        "found",
        "in",
        "Lange",
        "(",
        "2016",
        ")",
        "."
      ]
    },
    {
      "sentence": "Summaries and tutorials on MM algorithms for various problems can be found in Becker et al.",
      "tokens": [
        "Summaries",
        "and",
        "tutorials",
        "on",
        "MM",
        "algorithms",
        "for",
        "various",
        "problems",
        "can",
        "be",
        "found",
        "in",
        "Becker",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "(1997) , Hunter & Lange (2004) , Lange (2013, Ch.",
      "tokens": [
        "(",
        "1997",
        ")",
        ",",
        "Hunter",
        "&",
        "Lange",
        "(",
        "2004",
        ")",
        ",",
        "Lange",
        "(",
        "2013",
        ",",
        "Ch",
        "."
      ]
    },
    {
      "sentence": "8) , Lange et al.",
      "tokens": [
        "8",
        ")",
        ",",
        "Lange",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "(2000) , Lange et al.",
      "tokens": [
        "(",
        "2000",
        ")",
        ",",
        "Lange",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "(2014) , McLachlan & Krishnan (2008, Sec.",
      "tokens": [
        "(",
        "2014",
        ")",
        ",",
        "McLachlan",
        "&",
        "Krishnan",
        "(",
        "2008",
        ",",
        "Sec",
        "."
      ]
    },
    {
      "sentence": "7 .7), Wu & Lange (2010), and Zhou et al.",
      "tokens": [
        "7",
        ".7",
        ")",
        ",",
        "Wu",
        "&",
        "Lange",
        "(",
        "2010",
        ")",
        ",",
        "and",
        "Zhou",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "(2010) .",
      "tokens": [
        "(",
        "2010",
        ")",
        "."
      ]
    },
    {
      "sentence": "Some theoretical analyses of MM algorithms can be found in de Leeuw & Lange (2009) , Lange (2013, Sec.",
      "tokens": [
        "Some",
        "theoretical",
        "analyses",
        "of",
        "MM",
        "algorithms",
        "can",
        "be",
        "found",
        "in",
        "de",
        "Leeuw",
        "&",
        "Lange",
        "(",
        "2009",
        ")",
        ",",
        "Lange",
        "(",
        "2013",
        ",",
        "Sec",
        "."
      ]
    },
    {
      "sentence": "12.4) , Mairal (2015), and Vaida (2005) .",
      "tokens": [
        "12.4",
        ")",
        ",",
        "Mairal",
        "(",
        "2015",
        ")",
        ",",
        "and",
        "Vaida",
        "(",
        "2005",
        ")",
        "."
      ]
    },
    {
      "sentence": "It is known that MM algorithms are generalizations of the EM (expectationmaximization) algorithms of Dempster et al.",
      "tokens": [
        "It",
        "is",
        "known",
        "that",
        "MM",
        "algorithms",
        "are",
        "generalizations",
        "of",
        "the",
        "EM",
        "(",
        "expectationmaximization",
        ")",
        "algorithms",
        "of",
        "Dempster",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "(1977) [cf.",
      "tokens": [
        "(",
        "1977",
        ")",
        "[",
        "cf",
        "."
      ]
    },
    {
      "sentence": "Lange (2013, Ch.",
      "tokens": [
        "Lange",
        "(",
        "2013",
        ",",
        "Ch",
        "."
      ]
    },
    {
      "sentence": "9) ].",
      "tokens": [
        "9",
        ")",
        "]",
        "."
      ]
    },
    {
      "sentence": "The recently established connection between MM algorithms and the successive upper-bound maximization (SUM) algorithms of Razaviyayn et al.",
      "tokens": [
        "The",
        "recently",
        "established",
        "connection",
        "between",
        "MM",
        "algorithms",
        "and",
        "the",
        "successive",
        "upper-bound",
        "maximization",
        "(",
        "SUM",
        ")",
        "algorithms",
        "of",
        "Razaviyayn",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "(2013) further shows that the MM algorithm framework also covers the concave-convex procedures [Yuille & Rangarajan (2003) ; CCCP], proximal algorithms (Parikh & Boyd, 2013) , forward-backward splitting algorithms [Combettes & Pesquet (2011) ; FBS], as well as various incarnations of iteratively-reweighed leastsquares algorithms (IRLS) such as those of Becker et al.",
      "tokens": [
        "(",
        "2013",
        ")",
        "further",
        "shows",
        "that",
        "the",
        "MM",
        "algorithm",
        "framework",
        "also",
        "covers",
        "the",
        "concave-convex",
        "procedures",
        "[",
        "Yuille",
        "&",
        "Rangarajan",
        "(",
        "2003",
        ")",
        ";",
        "CCCP",
        "]",
        ",",
        "proximal",
        "algorithms",
        "(",
        "Parikh",
        "&",
        "Boyd",
        ",",
        "2013",
        ")",
        ",",
        "forward-backward",
        "splitting",
        "algorithms",
        "[",
        "Combettes",
        "&",
        "Pesquet",
        "(",
        "2011",
        ")",
        ";",
        "FBS",
        "]",
        ",",
        "as",
        "well",
        "as",
        "various",
        "incarnations",
        "of",
        "iteratively-reweighed",
        "leastsquares",
        "algorithms",
        "(",
        "IRLS",
        ")",
        "such",
        "as",
        "those",
        "of",
        "Becker",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "(1997) and Lange et al.",
      "tokens": [
        "(",
        "1997",
        ")",
        "and",
        "Lange",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "(2000) ; see Hong et al.",
      "tokens": [
        "(",
        "2000",
        ")",
        ";",
        "see",
        "Hong",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "(2016) for details.",
      "tokens": [
        "(",
        "2016",
        ")",
        "for",
        "details",
        "."
      ]
    },
    {
      "sentence": "It is not possible to provide a complete list of applications of MM algorithms to machine learning, statistical estimation, and signal processing problems.",
      "tokens": [
        "It",
        "is",
        "not",
        "possible",
        "to",
        "provide",
        "a",
        "complete",
        "list",
        "of",
        "applications",
        "of",
        "MM",
        "algorithms",
        "to",
        "machine",
        "learning",
        ",",
        "statistical",
        "estimation",
        ",",
        "and",
        "signal",
        "processing",
        "problems",
        "."
      ]
    },
    {
      "sentence": "We present a comprehensive albeit incomplete summary of applications of MM algorithms in Table 1 .",
      "tokens": [
        "We",
        "present",
        "a",
        "comprehensive",
        "albeit",
        "incomplete",
        "summary",
        "of",
        "applications",
        "of",
        "MM",
        "algorithms",
        "in",
        "Table",
        "1",
        "."
      ]
    },
    {
      "sentence": "Further examples and references can be found in Hong et al.",
      "tokens": [
        "Further",
        "examples",
        "and",
        "references",
        "can",
        "be",
        "found",
        "in",
        "Hong",
        "et",
        "al",
        "."
      ]
    },
    {
      "sentence": "(2016) and Lange (2016) .",
      "tokens": [
        "(",
        "2016",
        ")",
        "and",
        "Lange",
        "(",
        "2016",
        ")",
        "."
      ]
    },
    {
      "sentence": "In this article, we will present the MM algorithm framework via applications to three examples that span the scope of statistical estimation and machine learning problems: Gaussian mixtures of regressions (GMR), multinomiallogistic regressions (MLR), and SVM estimations.",
      "tokens": [
        "In",
        "this",
        "article",
        ",",
        "we",
        "will",
        "present",
        "the",
        "MM",
        "algorithm",
        "framework",
        "via",
        "applications",
        "to",
        "three",
        "examples",
        "that",
        "span",
        "the",
        "scope",
        "of",
        "statistical",
        "estimation",
        "and",
        "machine",
        "learning",
        "problems",
        ":",
        "Gaussian",
        "mixtures",
        "of",
        "regressions",
        "(",
        "GMR",
        ")",
        ",",
        "multinomiallogistic",
        "regressions",
        "(",
        "MLR",
        ")",
        ",",
        "and",
        "SVM",
        "estimations",
        "."
      ]
    },
    {
      "sentence": "The three estimation prob-Table 1 : MM algorithm applications and references.",
      "tokens": [
        "The",
        "three",
        "estimation",
        "prob-Table",
        "1",
        ":",
        "MM",
        "algorithm",
        "applications",
        "and",
        "references",
        "."
      ]
    }
  ]
}