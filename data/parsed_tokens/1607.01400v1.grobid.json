{
  "title": [
    {
      "sentence": "An Aggregate and Iterative Disaggregate Algorithm with Proven Optimality in Machine Learning",
      "tokens": [
        "An",
        "Aggregate",
        "and",
        "Iterative",
        "Disaggregate",
        "Algorithm",
        "with",
        "Proven",
        "Optimality",
        "in",
        "Machine",
        "Learning"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "We propose a clustering-based iterative algorithm to solve certain optimization problems in machine learning, where we start the algorithm by aggregating the original data, solving the problem on aggregated data, and then in subsequent steps gradually disaggregate the aggregated data.",
      "tokens": [
        "We",
        "propose",
        "a",
        "clustering-based",
        "iterative",
        "algorithm",
        "to",
        "solve",
        "certain",
        "optimization",
        "problems",
        "in",
        "machine",
        "learning",
        ",",
        "where",
        "we",
        "start",
        "the",
        "algorithm",
        "by",
        "aggregating",
        "the",
        "original",
        "data",
        ",",
        "solving",
        "the",
        "problem",
        "on",
        "aggregated",
        "data",
        ",",
        "and",
        "then",
        "in",
        "subsequent",
        "steps",
        "gradually",
        "disaggregate",
        "the",
        "aggregated",
        "data",
        "."
      ]
    },
    {
      "sentence": "We apply the algorithm to common machine learning problems such as the least absolute deviation regression problem, support vector machines, and semi-supervised support vector machines.",
      "tokens": [
        "We",
        "apply",
        "the",
        "algorithm",
        "to",
        "common",
        "machine",
        "learning",
        "problems",
        "such",
        "as",
        "the",
        "least",
        "absolute",
        "deviation",
        "regression",
        "problem",
        ",",
        "support",
        "vector",
        "machines",
        ",",
        "and",
        "semi-supervised",
        "support",
        "vector",
        "machines",
        "."
      ]
    },
    {
      "sentence": "We derive model-specific data aggregation and disaggregation procedures.",
      "tokens": [
        "We",
        "derive",
        "model-specific",
        "data",
        "aggregation",
        "and",
        "disaggregation",
        "procedures",
        "."
      ]
    },
    {
      "sentence": "We also show optimality, convergence, and the optimality gap of the approximated solution in each iteration.",
      "tokens": [
        "We",
        "also",
        "show",
        "optimality",
        ",",
        "convergence",
        ",",
        "and",
        "the",
        "optimality",
        "gap",
        "of",
        "the",
        "approximated",
        "solution",
        "in",
        "each",
        "iteration",
        "."
      ]
    },
    {
      "sentence": "A computational study is provided.",
      "tokens": [
        "A",
        "computational",
        "study",
        "is",
        "provided",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "Introduction In this paper, we propose a clustering-based iterative algorithm to solve certain optimization problems in machine learning when data size is large and thus it becomes impractical to use out-of-the-box algorithms.",
      "tokens": [
        "Introduction",
        "In",
        "this",
        "paper",
        ",",
        "we",
        "propose",
        "a",
        "clustering-based",
        "iterative",
        "algorithm",
        "to",
        "solve",
        "certain",
        "optimization",
        "problems",
        "in",
        "machine",
        "learning",
        "when",
        "data",
        "size",
        "is",
        "large",
        "and",
        "thus",
        "it",
        "becomes",
        "impractical",
        "to",
        "use",
        "out-of-the-box",
        "algorithms",
        "."
      ]
    },
    {
      "sentence": "We rely on the principle of data aggregation and then subsequent disaggregations.",
      "tokens": [
        "We",
        "rely",
        "on",
        "the",
        "principle",
        "of",
        "data",
        "aggregation",
        "and",
        "then",
        "subsequent",
        "disaggregations",
        "."
      ]
    },
    {
      "sentence": "While it is standard practice to aggregate the data and then calibrate the machine learning algorithm on aggregated data, we embed this into an iterative framework where initial aggregations are gradually disaggregated to the extent that even an optimal solution is obtainable.",
      "tokens": [
        "While",
        "it",
        "is",
        "standard",
        "practice",
        "to",
        "aggregate",
        "the",
        "data",
        "and",
        "then",
        "calibrate",
        "the",
        "machine",
        "learning",
        "algorithm",
        "on",
        "aggregated",
        "data",
        ",",
        "we",
        "embed",
        "this",
        "into",
        "an",
        "iterative",
        "framework",
        "where",
        "initial",
        "aggregations",
        "are",
        "gradually",
        "disaggregated",
        "to",
        "the",
        "extent",
        "that",
        "even",
        "an",
        "optimal",
        "solution",
        "is",
        "obtainable",
        "."
      ]
    },
    {
      "sentence": "Early studies in data aggregation consider transportation problems [1, 10] , where either demand or supply nodes are aggregated.",
      "tokens": [
        "Early",
        "studies",
        "in",
        "data",
        "aggregation",
        "consider",
        "transportation",
        "problems",
        "[",
        "1",
        ",",
        "10",
        "]",
        ",",
        "where",
        "either",
        "demand",
        "or",
        "supply",
        "nodes",
        "are",
        "aggregated",
        "."
      ]
    },
    {
      "sentence": "Zipkin [31] studied data aggregation for linear programming (LP) and derived error bounds of the approximate solution.",
      "tokens": [
        "Zipkin",
        "[",
        "31",
        "]",
        "studied",
        "data",
        "aggregation",
        "for",
        "linear",
        "programming",
        "(",
        "LP",
        ")",
        "and",
        "derived",
        "error",
        "bounds",
        "of",
        "the",
        "approximate",
        "solution",
        "."
      ]
    },
    {
      "sentence": "There are also studies on data aggregation for 0-1 integer programming [8, 13] .",
      "tokens": [
        "There",
        "are",
        "also",
        "studies",
        "on",
        "data",
        "aggregation",
        "for",
        "0-1",
        "integer",
        "programming",
        "[",
        "8",
        ",",
        "13",
        "]",
        "."
      ]
    },
    {
      "sentence": "The reader is referred to Rogers et al [22] and Litvinchev and Tsurkov [16] for comprehensive literature reviews for aggregation techniques applied for optimization problems.",
      "tokens": [
        "The",
        "reader",
        "is",
        "referred",
        "to",
        "Rogers",
        "et",
        "al",
        "[",
        "22",
        "]",
        "and",
        "Litvinchev",
        "and",
        "Tsurkov",
        "[",
        "16",
        "]",
        "for",
        "comprehensive",
        "literature",
        "reviews",
        "for",
        "aggregation",
        "techniques",
        "applied",
        "for",
        "optimization",
        "problems",
        "."
      ]
    },
    {
      "sentence": "For support vector machines (SVM), there exist several works using the concept of clustering or data aggregation.",
      "tokens": [
        "For",
        "support",
        "vector",
        "machines",
        "(",
        "SVM",
        ")",
        ",",
        "there",
        "exist",
        "several",
        "works",
        "using",
        "the",
        "concept",
        "of",
        "clustering",
        "or",
        "data",
        "aggregation",
        "."
      ]
    },
    {
      "sentence": "Evgeniou and Pontil [11] proposed a clustering algorithm that creates large size clusters for entries surrounded by the same class and small size clusters for entries in the mixed-class area.",
      "tokens": [
        "Evgeniou",
        "and",
        "Pontil",
        "[",
        "11",
        "]",
        "proposed",
        "a",
        "clustering",
        "algorithm",
        "that",
        "creates",
        "large",
        "size",
        "clusters",
        "for",
        "entries",
        "surrounded",
        "by",
        "the",
        "same",
        "class",
        "and",
        "small",
        "size",
        "clusters",
        "for",
        "entries",
        "in",
        "the",
        "mixed-class",
        "area",
        "."
      ]
    },
    {
      "sentence": "The clustering algorithm is used to preprocess the data and the clustered data is used to solve the problem.",
      "tokens": [
        "The",
        "clustering",
        "algorithm",
        "is",
        "used",
        "to",
        "preprocess",
        "the",
        "data",
        "and",
        "the",
        "clustered",
        "data",
        "is",
        "used",
        "to",
        "solve",
        "the",
        "problem",
        "."
      ]
    },
    {
      "sentence": "The algorithm tends to create large size clusters for entries far from the decision boundary and small size clusters for the other case.",
      "tokens": [
        "The",
        "algorithm",
        "tends",
        "to",
        "create",
        "large",
        "size",
        "clusters",
        "for",
        "entries",
        "far",
        "from",
        "the",
        "decision",
        "boundary",
        "and",
        "small",
        "size",
        "clusters",
        "for",
        "the",
        "other",
        "case",
        "."
      ]
    },
    {
      "sentence": "Wang et al [26] developed screening rules for SVM to discard non-support vectors that do not affect the classifier.",
      "tokens": [
        "Wang",
        "et",
        "al",
        "[",
        "26",
        "]",
        "developed",
        "screening",
        "rules",
        "for",
        "SVM",
        "to",
        "discard",
        "non-support",
        "vectors",
        "that",
        "do",
        "not",
        "affect",
        "the",
        "classifier",
        "."
      ]
    },
    {
      "sentence": "Nath et al [19] and Doppa et al [9] proposed a second order cone programming (SOCP) formulation for SVM based on chance constraints and clusters.",
      "tokens": [
        "Nath",
        "et",
        "al",
        "[",
        "19",
        "]",
        "and",
        "Doppa",
        "et",
        "al",
        "[",
        "9",
        "]",
        "proposed",
        "a",
        "second",
        "order",
        "cone",
        "programming",
        "(",
        "SOCP",
        ")",
        "formulation",
        "for",
        "SVM",
        "based",
        "on",
        "chance",
        "constraints",
        "and",
        "clusters",
        "."
      ]
    },
    {
      "sentence": "The key idea of the SOCP formulations is to reduce the number of constraints (from the number of the entries to number of clusters) by defining chance constraints for clusters.",
      "tokens": [
        "The",
        "key",
        "idea",
        "of",
        "the",
        "SOCP",
        "formulations",
        "is",
        "to",
        "reduce",
        "the",
        "number",
        "of",
        "constraints",
        "(",
        "from",
        "the",
        "number",
        "of",
        "the",
        "entries",
        "to",
        "number",
        "of",
        "clusters",
        ")",
        "by",
        "defining",
        "chance",
        "constraints",
        "for",
        "clusters",
        "."
      ]
    },
    {
      "sentence": "After obtaining an approximate solution by solving the optimization problem with aggregated data, a natural attempt is to use less-coarsely aggregated data, in order to obtain a finer approximation.",
      "tokens": [
        "After",
        "obtaining",
        "an",
        "approximate",
        "solution",
        "by",
        "solving",
        "the",
        "optimization",
        "problem",
        "with",
        "aggregated",
        "data",
        ",",
        "a",
        "natural",
        "attempt",
        "is",
        "to",
        "use",
        "less-coarsely",
        "aggregated",
        "data",
        ",",
        "in",
        "order",
        "to",
        "obtain",
        "a",
        "finer",
        "approximation",
        "."
      ]
    },
    {
      "sentence": "In fact, we can do this iteratively: modify the aggregated data in each iteration based on the information at hand.",
      "tokens": [
        "In",
        "fact",
        ",",
        "we",
        "can",
        "do",
        "this",
        "iteratively",
        ":",
        "modify",
        "the",
        "aggregated",
        "data",
        "in",
        "each",
        "iteration",
        "based",
        "on",
        "the",
        "information",
        "at",
        "hand",
        "."
      ]
    },
    {
      "sentence": "This framework, which iteratively passes information between the original problem and the aggregated problem [22] , is known as Iterative Aggregation Disaggregation (IAD).",
      "tokens": [
        "This",
        "framework",
        ",",
        "which",
        "iteratively",
        "passes",
        "information",
        "between",
        "the",
        "original",
        "problem",
        "and",
        "the",
        "aggregated",
        "problem",
        "[",
        "22",
        "]",
        ",",
        "is",
        "known",
        "as",
        "Iterative",
        "Aggregation",
        "Disaggregation",
        "(",
        "IAD",
        ")",
        "."
      ]
    },
    {
      "sentence": "The IAD framework has been applied for several optimization problems such as LP [17, 24, 25] and network design [2] .",
      "tokens": [
        "The",
        "IAD",
        "framework",
        "has",
        "been",
        "applied",
        "for",
        "several",
        "optimization",
        "problems",
        "such",
        "as",
        "LP",
        "[",
        "17",
        ",",
        "24",
        ",",
        "25",
        "]",
        "and",
        "network",
        "design",
        "[",
        "2",
        "]",
        "."
      ]
    },
    {
      "sentence": "In machine learning, Yu et al [28, 29] used hierarchical micro clustering and a clustering feature tree to obtain an approximate solution for support vector machines.",
      "tokens": [
        "In",
        "machine",
        "learning",
        ",",
        "Yu",
        "et",
        "al",
        "[",
        "28",
        ",",
        "29",
        "]",
        "used",
        "hierarchical",
        "micro",
        "clustering",
        "and",
        "a",
        "clustering",
        "feature",
        "tree",
        "to",
        "obtain",
        "an",
        "approximate",
        "solution",
        "for",
        "support",
        "vector",
        "machines",
        "."
      ]
    },
    {
      "sentence": "In this paper, we propose a general optimization algorithm based on clustering and data aggregation, and apply it to three common machine learning problems: least absolute deviation regression (LAD), SVM, and semi-supervised support vector machines (S 3 VM).",
      "tokens": [
        "In",
        "this",
        "paper",
        ",",
        "we",
        "propose",
        "a",
        "general",
        "optimization",
        "algorithm",
        "based",
        "on",
        "clustering",
        "and",
        "data",
        "aggregation",
        ",",
        "and",
        "apply",
        "it",
        "to",
        "three",
        "common",
        "machine",
        "learning",
        "problems",
        ":",
        "least",
        "absolute",
        "deviation",
        "regression",
        "(",
        "LAD",
        ")",
        ",",
        "SVM",
        ",",
        "and",
        "semi-supervised",
        "support",
        "vector",
        "machines",
        "(",
        "S",
        "3",
        "VM",
        ")",
        "."
      ]
    },
    {
      "sentence": "The algorithm fits the IAD framework, but has additional properties shown for the selected problems in this paper.",
      "tokens": [
        "The",
        "algorithm",
        "fits",
        "the",
        "IAD",
        "framework",
        ",",
        "but",
        "has",
        "additional",
        "properties",
        "shown",
        "for",
        "the",
        "selected",
        "problems",
        "in",
        "this",
        "paper",
        "."
      ]
    },
    {
      "sentence": "The ability to report the optimality gap and monotonic convergence to global optimum are features of our algorithm for LAD and SVM, while our algorithm guarantees optimality for S 3 VM without monotonic convergence.",
      "tokens": [
        "The",
        "ability",
        "to",
        "report",
        "the",
        "optimality",
        "gap",
        "and",
        "monotonic",
        "convergence",
        "to",
        "global",
        "optimum",
        "are",
        "features",
        "of",
        "our",
        "algorithm",
        "for",
        "LAD",
        "and",
        "SVM",
        ",",
        "while",
        "our",
        "algorithm",
        "guarantees",
        "optimality",
        "for",
        "S",
        "3",
        "VM",
        "without",
        "monotonic",
        "convergence",
        "."
      ]
    },
    {
      "sentence": "Our work for SVM is distinguished from the work of Yu et al [28, 29] , as we iteratively solve weighted SVM and guarantee optimality, whereas they iteratively solve the standard unweighted SVM and thus find only an approximate solution.",
      "tokens": [
        "Our",
        "work",
        "for",
        "SVM",
        "is",
        "distinguished",
        "from",
        "the",
        "work",
        "of",
        "Yu",
        "et",
        "al",
        "[",
        "28",
        ",",
        "29",
        "]",
        ",",
        "as",
        "we",
        "iteratively",
        "solve",
        "weighted",
        "SVM",
        "and",
        "guarantee",
        "optimality",
        ",",
        "whereas",
        "they",
        "iteratively",
        "solve",
        "the",
        "standard",
        "unweighted",
        "SVM",
        "and",
        "thus",
        "find",
        "only",
        "an",
        "approximate",
        "solution",
        "."
      ]
    },
    {
      "sentence": "On the other hand, it is distinguished from Evgeniou and Pontil [11] , as our algorithm is iterative and guarantees global optimum, whereas they used clustering to preprocess data and obtain an approximate optimum.",
      "tokens": [
        "On",
        "the",
        "other",
        "hand",
        ",",
        "it",
        "is",
        "distinguished",
        "from",
        "Evgeniou",
        "and",
        "Pontil",
        "[",
        "11",
        "]",
        ",",
        "as",
        "our",
        "algorithm",
        "is",
        "iterative",
        "and",
        "guarantees",
        "global",
        "optimum",
        ",",
        "whereas",
        "they",
        "used",
        "clustering",
        "to",
        "preprocess",
        "data",
        "and",
        "obtain",
        "an",
        "approximate",
        "optimum",
        "."
      ]
    },
    {
      "sentence": "Nath et al [19] and Doppa et al [9] are different because we use the typical SVM formulation within an iterative framework, whereas they propose an SOCP formulation based on chance constraints.",
      "tokens": [
        "Nath",
        "et",
        "al",
        "[",
        "19",
        "]",
        "and",
        "Doppa",
        "et",
        "al",
        "[",
        "9",
        "]",
        "are",
        "different",
        "because",
        "we",
        "use",
        "the",
        "typical",
        "SVM",
        "formulation",
        "within",
        "an",
        "iterative",
        "framework",
        ",",
        "whereas",
        "they",
        "propose",
        "an",
        "SOCP",
        "formulation",
        "based",
        "on",
        "chance",
        "constraints",
        "."
      ]
    },
    {
      "sentence": "Our data disaggregation and cluster partitioning procedure is based on the optimality condition derived in this paper: relative location of the observations to the hyperplane (for LAD, SVM, S 3 VM) and labels of the observations (for SVM, S 3 VM).",
      "tokens": [
        "Our",
        "data",
        "disaggregation",
        "and",
        "cluster",
        "partitioning",
        "procedure",
        "is",
        "based",
        "on",
        "the",
        "optimality",
        "condition",
        "derived",
        "in",
        "this",
        "paper",
        ":",
        "relative",
        "location",
        "of",
        "the",
        "observations",
        "to",
        "the",
        "hyperplane",
        "(",
        "for",
        "LAD",
        ",",
        "SVM",
        ",",
        "S",
        "3",
        "VM",
        ")",
        "and",
        "labels",
        "of",
        "the",
        "observations",
        "(",
        "for",
        "SVM",
        ",",
        "S",
        "3",
        "VM",
        ")",
        "."
      ]
    },
    {
      "sentence": "For example, in the SVM case, if the separating hyperplane divides a cluster, the cluster is split.",
      "tokens": [
        "For",
        "example",
        ",",
        "in",
        "the",
        "SVM",
        "case",
        ",",
        "if",
        "the",
        "separating",
        "hyperplane",
        "divides",
        "a",
        "cluster",
        ",",
        "the",
        "cluster",
        "is",
        "split",
        "."
      ]
    },
    {
      "sentence": "The condition for S 3 VM is even more involved since a single cluster can be split into four clusters.",
      "tokens": [
        "The",
        "condition",
        "for",
        "S",
        "3",
        "VM",
        "is",
        "even",
        "more",
        "involved",
        "since",
        "a",
        "single",
        "cluster",
        "can",
        "be",
        "split",
        "into",
        "four",
        "clusters",
        "."
      ]
    },
    {
      "sentence": "In the computational experiment, we show that our algorithm outperforms the current state-of-the-art algorithms when the data size is large.",
      "tokens": [
        "In",
        "the",
        "computational",
        "experiment",
        ",",
        "we",
        "show",
        "that",
        "our",
        "algorithm",
        "outperforms",
        "the",
        "current",
        "state-of-the-art",
        "algorithms",
        "when",
        "the",
        "data",
        "size",
        "is",
        "large",
        "."
      ]
    },
    {
      "sentence": "The implementation of our algorithms is based on in-memory processing, however the algorithms work also when data does not fit entirely in memory and has to be read from disk in batches.",
      "tokens": [
        "The",
        "implementation",
        "of",
        "our",
        "algorithms",
        "is",
        "based",
        "on",
        "in-memory",
        "processing",
        ",",
        "however",
        "the",
        "algorithms",
        "work",
        "also",
        "when",
        "data",
        "does",
        "not",
        "fit",
        "entirely",
        "in",
        "memory",
        "and",
        "has",
        "to",
        "be",
        "read",
        "from",
        "disk",
        "in",
        "batches",
        "."
      ]
    },
    {
      "sentence": "The algorithms never require the entire data set to be processed at once.",
      "tokens": [
        "The",
        "algorithms",
        "never",
        "require",
        "the",
        "entire",
        "data",
        "set",
        "to",
        "be",
        "processed",
        "at",
        "once",
        "."
      ]
    },
    {
      "sentence": "Our contributions are summarized as follows.",
      "tokens": [
        "Our",
        "contributions",
        "are",
        "summarized",
        "as",
        "follows",
        "."
      ]
    },
    {
      "sentence": "1.",
      "tokens": [
        "1",
        "."
      ]
    },
    {
      "sentence": "We propose a clustering-based iterative algorithm to solve certain optimization problems, where an optimality condition is derived for each problem.",
      "tokens": [
        "We",
        "propose",
        "a",
        "clustering-based",
        "iterative",
        "algorithm",
        "to",
        "solve",
        "certain",
        "optimization",
        "problems",
        ",",
        "where",
        "an",
        "optimality",
        "condition",
        "is",
        "derived",
        "for",
        "each",
        "problem",
        "."
      ]
    },
    {
      "sentence": "The proposed algorithmic framework can be applied to other problems with certain structural properties (even outside of machine learning).",
      "tokens": [
        "The",
        "proposed",
        "algorithmic",
        "framework",
        "can",
        "be",
        "applied",
        "to",
        "other",
        "problems",
        "with",
        "certain",
        "structural",
        "properties",
        "(",
        "even",
        "outside",
        "of",
        "machine",
        "learning",
        ")",
        "."
      ]
    },
    {
      "sentence": "The algorithm is most beneficial when the time complexity of the original optimization problem is high.",
      "tokens": [
        "The",
        "algorithm",
        "is",
        "most",
        "beneficial",
        "when",
        "the",
        "time",
        "complexity",
        "of",
        "the",
        "original",
        "optimization",
        "problem",
        "is",
        "high",
        "."
      ]
    },
    {
      "sentence": "2.",
      "tokens": [
        "2",
        "."
      ]
    },
    {
      "sentence": "We present model specific disaggregation and cluster partitioning procedures based on the optimality condition, which is one of the keys for achieving optimality.",
      "tokens": [
        "We",
        "present",
        "model",
        "specific",
        "disaggregation",
        "and",
        "cluster",
        "partitioning",
        "procedures",
        "based",
        "on",
        "the",
        "optimality",
        "condition",
        ",",
        "which",
        "is",
        "one",
        "of",
        "the",
        "keys",
        "for",
        "achieving",
        "optimality",
        "."
      ]
    },
    {
      "sentence": "3.",
      "tokens": [
        "3",
        "."
      ]
    },
    {
      "sentence": "For the selected machine learning problems, i.e., LAD and SVM, we show that the algorithm monotonically converges to a global optimum, while providing the optimality gap in each iteration.",
      "tokens": [
        "For",
        "the",
        "selected",
        "machine",
        "learning",
        "problems",
        ",",
        "i.e.",
        ",",
        "LAD",
        "and",
        "SVM",
        ",",
        "we",
        "show",
        "that",
        "the",
        "algorithm",
        "monotonically",
        "converges",
        "to",
        "a",
        "global",
        "optimum",
        ",",
        "while",
        "providing",
        "the",
        "optimality",
        "gap",
        "in",
        "each",
        "iteration",
        "."
      ]
    },
    {
      "sentence": "For S 3 VM, we provide the optimality condition.",
      "tokens": [
        "For",
        "S",
        "3",
        "VM",
        ",",
        "we",
        "provide",
        "the",
        "optimality",
        "condition",
        "."
      ]
    },
    {
      "sentence": "We present the algorithmic framework in Section 2 and apply it to LAD, SVM, and S 3 VM in Section 3.",
      "tokens": [
        "We",
        "present",
        "the",
        "algorithmic",
        "framework",
        "in",
        "Section",
        "2",
        "and",
        "apply",
        "it",
        "to",
        "LAD",
        ",",
        "SVM",
        ",",
        "and",
        "S",
        "3",
        "VM",
        "in",
        "Section",
        "3",
        "."
      ]
    },
    {
      "sentence": "A computational study is provided in Section 4, followed by a discussion on the characteristic of the algorithm and how to develop the algorithm for other problems in Section 5.",
      "tokens": [
        "A",
        "computational",
        "study",
        "is",
        "provided",
        "in",
        "Section",
        "4",
        ",",
        "followed",
        "by",
        "a",
        "discussion",
        "on",
        "the",
        "characteristic",
        "of",
        "the",
        "algorithm",
        "and",
        "how",
        "to",
        "develop",
        "the",
        "algorithm",
        "for",
        "other",
        "problems",
        "in",
        "Section",
        "5",
        "."
      ]
    }
  ]
}