{
  "title": [
    {
      "sentence": "Representation Learning for Electronic Health Records",
      "tokens": [
        "Representation",
        "Learning",
        "for",
        "Electronic",
        "Health",
        "Records"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "Information in electronic health records (EHR), such as clinical narratives, examination reports, lab measurements, demographics, and other patient encounter entries, can be transformed into appropriate data representations that can be used for downstream clinical machine learning tasks using representation learning.",
      "tokens": [
        "Information",
        "in",
        "electronic",
        "health",
        "records",
        "(",
        "EHR",
        ")",
        ",",
        "such",
        "as",
        "clinical",
        "narratives",
        ",",
        "examination",
        "reports",
        ",",
        "lab",
        "measurements",
        ",",
        "demographics",
        ",",
        "and",
        "other",
        "patient",
        "encounter",
        "entries",
        ",",
        "can",
        "be",
        "transformed",
        "into",
        "appropriate",
        "data",
        "representations",
        "that",
        "can",
        "be",
        "used",
        "for",
        "downstream",
        "clinical",
        "machine",
        "learning",
        "tasks",
        "using",
        "representation",
        "learning",
        "."
      ]
    },
    {
      "sentence": "Learning better representations is critical to improve the performance of downstream tasks.",
      "tokens": [
        "Learning",
        "better",
        "representations",
        "is",
        "critical",
        "to",
        "improve",
        "the",
        "performance",
        "of",
        "downstream",
        "tasks",
        "."
      ]
    },
    {
      "sentence": "Due to the advances in machine learning, we now can learn better and meaningful representations from EHR through disentangling the underlying factors inside data and distilling large amounts of information and knowledge from heterogeneous EHR sources.",
      "tokens": [
        "Due",
        "to",
        "the",
        "advances",
        "in",
        "machine",
        "learning",
        ",",
        "we",
        "now",
        "can",
        "learn",
        "better",
        "and",
        "meaningful",
        "representations",
        "from",
        "EHR",
        "through",
        "disentangling",
        "the",
        "underlying",
        "factors",
        "inside",
        "data",
        "and",
        "distilling",
        "large",
        "amounts",
        "of",
        "information",
        "and",
        "knowledge",
        "from",
        "heterogeneous",
        "EHR",
        "sources",
        "."
      ]
    },
    {
      "sentence": "In this chapter, we first introduce the background of learning representations and reasons why we need good EHR representations in machine learning for medicine and healthcare in Section 1.",
      "tokens": [
        "In",
        "this",
        "chapter",
        ",",
        "we",
        "first",
        "introduce",
        "the",
        "background",
        "of",
        "learning",
        "representations",
        "and",
        "reasons",
        "why",
        "we",
        "need",
        "good",
        "EHR",
        "representations",
        "in",
        "machine",
        "learning",
        "for",
        "medicine",
        "and",
        "healthcare",
        "in",
        "Section",
        "1",
        "."
      ]
    },
    {
      "sentence": "Next, we explain the commonly-used machine learning and evaluation methods for representation learning using a deep learning approach in Section 2.",
      "tokens": [
        "Next",
        ",",
        "we",
        "explain",
        "the",
        "commonly-used",
        "machine",
        "learning",
        "and",
        "evaluation",
        "methods",
        "for",
        "representation",
        "learning",
        "using",
        "a",
        "deep",
        "learning",
        "approach",
        "in",
        "Section",
        "2",
        "."
      ]
    },
    {
      "sentence": "Following that, we review recent related studies of learning patient state representation from EHR for clinical machine learning tasks in Section 3.",
      "tokens": [
        "Following",
        "that",
        ",",
        "we",
        "review",
        "recent",
        "related",
        "studies",
        "of",
        "learning",
        "patient",
        "state",
        "representation",
        "from",
        "EHR",
        "for",
        "clinical",
        "machine",
        "learning",
        "tasks",
        "in",
        "Section",
        "3",
        "."
      ]
    },
    {
      "sentence": "Finally, in Section 4 we discuss more techniques, studies, and challenges for learning natural language representations when free texts, such as clinical notes, examination reports, or biomedical literature are used.",
      "tokens": [
        "Finally",
        ",",
        "in",
        "Section",
        "4",
        "we",
        "discuss",
        "more",
        "techniques",
        ",",
        "studies",
        ",",
        "and",
        "challenges",
        "for",
        "learning",
        "natural",
        "language",
        "representations",
        "when",
        "free",
        "texts",
        ",",
        "such",
        "as",
        "clinical",
        "notes",
        ",",
        "examination",
        "reports",
        ",",
        "or",
        "biomedical",
        "literature",
        "are",
        "used",
        "."
      ]
    },
    {
      "sentence": "We also discuss challenges and opportunities in these rapidly growing research fields.",
      "tokens": [
        "We",
        "also",
        "discuss",
        "challenges",
        "and",
        "opportunities",
        "in",
        "these",
        "rapidly",
        "growing",
        "research",
        "fields",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "Learning Representations for Medicine and Healthcare Medicine and healthcare has become one of the key applied machine learning research domains due to increasing adoption of electronic health records (EHR) and the increasing 1 MIT CSAIL, Cambridge, MA, USA.",
      "tokens": [
        "Learning",
        "Representations",
        "for",
        "Medicine",
        "and",
        "Healthcare",
        "Medicine",
        "and",
        "healthcare",
        "has",
        "become",
        "one",
        "of",
        "the",
        "key",
        "applied",
        "machine",
        "learning",
        "research",
        "domains",
        "due",
        "to",
        "increasing",
        "adoption",
        "of",
        "electronic",
        "health",
        "records",
        "(",
        "EHR",
        ")",
        "and",
        "the",
        "increasing",
        "1",
        "MIT",
        "CSAIL",
        ",",
        "Cambridge",
        ",",
        "MA",
        ",",
        "USA",
        "."
      ]
    },
    {
      "sentence": "Correspondence to: Wei-Hung Weng <ckbjimmy@mit.edu>.",
      "tokens": [
        "Correspondence",
        "to",
        ":",
        "Wei-Hung",
        "Weng",
        "<",
        "ckbjimmy",
        "@",
        "mit.edu",
        ">",
        "."
      ]
    },
    {
      "sentence": "power of computation (Charles et al., 2013; Topol, 2019) .",
      "tokens": [
        "power",
        "of",
        "computation",
        "(",
        "Charles",
        "et",
        "al.",
        ",",
        "2013",
        ";",
        "Topol",
        ",",
        "2019",
        ")",
        "."
      ]
    },
    {
      "sentence": "Researchers have framed various medical and healthcarerelated challenges as machine learning tasks and adopted various algorithms to tackle them with massive amounts of medical data (Topol, 2019) .",
      "tokens": [
        "Researchers",
        "have",
        "framed",
        "various",
        "medical",
        "and",
        "healthcarerelated",
        "challenges",
        "as",
        "machine",
        "learning",
        "tasks",
        "and",
        "adopted",
        "various",
        "algorithms",
        "to",
        "tackle",
        "them",
        "with",
        "massive",
        "amounts",
        "of",
        "medical",
        "data",
        "(",
        "Topol",
        ",",
        "2019",
        ")",
        "."
      ]
    },
    {
      "sentence": "Some examples of commonlyseen topics in machine learning for medicine and healthcare research include diagnosis support (Lipton et al., 2016; Choi et al., 2016c; Gulshan et al., 2016; Esteva et al., 2017) , outcome and risk prediction (Ghassemi et al., 2014; Futoma et al., 2015; Choi et al., 2016a; Xiao et al., 2018b) , patient phenotyping (Miotto et al., 2016; Baytas et al., 2017) , optimal decision making (Raghu et al., 2017; Weng et al., 2017a; Komorowski et al., 2018) , and workflow improvement (Horng et al., 2017; Chen et al., 2019a) .",
      "tokens": [
        "Some",
        "examples",
        "of",
        "commonlyseen",
        "topics",
        "in",
        "machine",
        "learning",
        "for",
        "medicine",
        "and",
        "healthcare",
        "research",
        "include",
        "diagnosis",
        "support",
        "(",
        "Lipton",
        "et",
        "al.",
        ",",
        "2016",
        ";",
        "Choi",
        "et",
        "al.",
        ",",
        "2016c",
        ";",
        "Gulshan",
        "et",
        "al.",
        ",",
        "2016",
        ";",
        "Esteva",
        "et",
        "al.",
        ",",
        "2017",
        ")",
        ",",
        "outcome",
        "and",
        "risk",
        "prediction",
        "(",
        "Ghassemi",
        "et",
        "al.",
        ",",
        "2014",
        ";",
        "Futoma",
        "et",
        "al.",
        ",",
        "2015",
        ";",
        "Choi",
        "et",
        "al.",
        ",",
        "2016a",
        ";",
        "Xiao",
        "et",
        "al.",
        ",",
        "2018b",
        ")",
        ",",
        "patient",
        "phenotyping",
        "(",
        "Miotto",
        "et",
        "al.",
        ",",
        "2016",
        ";",
        "Baytas",
        "et",
        "al.",
        ",",
        "2017",
        ")",
        ",",
        "optimal",
        "decision",
        "making",
        "(",
        "Raghu",
        "et",
        "al.",
        ",",
        "2017",
        ";",
        "Weng",
        "et",
        "al.",
        ",",
        "2017a",
        ";",
        "Komorowski",
        "et",
        "al.",
        ",",
        "2018",
        ")",
        ",",
        "and",
        "workflow",
        "improvement",
        "(",
        "Horng",
        "et",
        "al.",
        ",",
        "2017",
        ";",
        "Chen",
        "et",
        "al.",
        ",",
        "2019a",
        ")",
        "."
      ]
    },
    {
      "sentence": "Researchers have utilized various types of EHR data in addressing these tasks, such as lab measurements (Pivovarov et al., 2015) , claims data (Doshi-Velez et al., 2014; Pivovarov et al., 2015; Choi et al., 2016e) , clinical narratives (Pivovarov et al., 2015; Weng et al., 2017b) , medical images (Gulshan et al., 2016; Esteva et al., 2017; Bejnordi et al., 2017; Liu et al., 2017; Poplin et al., 2018; Nagpal et al., 2019) , as well as waveform signals (Lehman et al., 2018) .",
      "tokens": [
        "Researchers",
        "have",
        "utilized",
        "various",
        "types",
        "of",
        "EHR",
        "data",
        "in",
        "addressing",
        "these",
        "tasks",
        ",",
        "such",
        "as",
        "lab",
        "measurements",
        "(",
        "Pivovarov",
        "et",
        "al.",
        ",",
        "2015",
        ")",
        ",",
        "claims",
        "data",
        "(",
        "Doshi-Velez",
        "et",
        "al.",
        ",",
        "2014",
        ";",
        "Pivovarov",
        "et",
        "al.",
        ",",
        "2015",
        ";",
        "Choi",
        "et",
        "al.",
        ",",
        "2016e",
        ")",
        ",",
        "clinical",
        "narratives",
        "(",
        "Pivovarov",
        "et",
        "al.",
        ",",
        "2015",
        ";",
        "Weng",
        "et",
        "al.",
        ",",
        "2017b",
        ")",
        ",",
        "medical",
        "images",
        "(",
        "Gulshan",
        "et",
        "al.",
        ",",
        "2016",
        ";",
        "Esteva",
        "et",
        "al.",
        ",",
        "2017",
        ";",
        "Bejnordi",
        "et",
        "al.",
        ",",
        "2017",
        ";",
        "Liu",
        "et",
        "al.",
        ",",
        "2017",
        ";",
        "Poplin",
        "et",
        "al.",
        ",",
        "2018",
        ";",
        "Nagpal",
        "et",
        "al.",
        ",",
        "2019",
        ")",
        ",",
        "as",
        "well",
        "as",
        "waveform",
        "signals",
        "(",
        "Lehman",
        "et",
        "al.",
        ",",
        "2018",
        ")",
        "."
      ]
    },
    {
      "sentence": "Many efforts use multiple such modalities of available data.",
      "tokens": [
        "Many",
        "efforts",
        "use",
        "multiple",
        "such",
        "modalities",
        "of",
        "available",
        "data",
        "."
      ]
    },
    {
      "sentence": "For medical and healthcare applications, it is critical to develop robust techniques that can not only yield good performance on given tasks but also provide efficiency, reliability, and explainability (Szolovits & Pauker, 1978; Szolovits, 1982) , to improve the likelihood of their practical clinical deployment (Chen et al., 2019b) .",
      "tokens": [
        "For",
        "medical",
        "and",
        "healthcare",
        "applications",
        ",",
        "it",
        "is",
        "critical",
        "to",
        "develop",
        "robust",
        "techniques",
        "that",
        "can",
        "not",
        "only",
        "yield",
        "good",
        "performance",
        "on",
        "given",
        "tasks",
        "but",
        "also",
        "provide",
        "efficiency",
        ",",
        "reliability",
        ",",
        "and",
        "explainability",
        "(",
        "Szolovits",
        "&",
        "Pauker",
        ",",
        "1978",
        ";",
        "Szolovits",
        ",",
        "1982",
        ")",
        ",",
        "to",
        "improve",
        "the",
        "likelihood",
        "of",
        "their",
        "practical",
        "clinical",
        "deployment",
        "(",
        "Chen",
        "et",
        "al.",
        ",",
        "2019b",
        ")",
        "."
      ]
    },
    {
      "sentence": "For example, applying an attention mechanism or interpretable models give us better explainability of the model behavior or the prediction (Bahdanau et al., 2015; Ribeiro et al., 2016; Lundberg & Lee, 2017) .",
      "tokens": [
        "For",
        "example",
        ",",
        "applying",
        "an",
        "attention",
        "mechanism",
        "or",
        "interpretable",
        "models",
        "give",
        "us",
        "better",
        "explainability",
        "of",
        "the",
        "model",
        "behavior",
        "or",
        "the",
        "prediction",
        "(",
        "Bahdanau",
        "et",
        "al.",
        ",",
        "2015",
        ";",
        "Ribeiro",
        "et",
        "al.",
        ",",
        "2016",
        ";",
        "Lundberg",
        "&",
        "Lee",
        ",",
        "2017",
        ")",
        "."
      ]
    },
    {
      "sentence": "Designing models with a robust optimization to tolerate adversarial examples provides the model reliability (Madry et al., 2018) .",
      "tokens": [
        "Designing",
        "models",
        "with",
        "a",
        "robust",
        "optimization",
        "to",
        "tolerate",
        "adversarial",
        "examples",
        "provides",
        "the",
        "model",
        "reliability",
        "(",
        "Madry",
        "et",
        "al.",
        ",",
        "2018",
        ")",
        "."
      ]
    },
    {
      "sentence": "Preprocessing data appropriately and making better data representations for algorithms allow us to develop models with better performance and also interpretability.",
      "tokens": [
        "Preprocessing",
        "data",
        "appropriately",
        "and",
        "making",
        "better",
        "data",
        "representations",
        "for",
        "algorithms",
        "allow",
        "us",
        "to",
        "develop",
        "models",
        "with",
        "better",
        "performance",
        "and",
        "also",
        "interpretability",
        "."
      ]
    },
    {
      "sentence": "A good representation organizes the data in a way that machine learning algorithms can learn models with good performance from them.",
      "tokens": [
        "A",
        "good",
        "representation",
        "organizes",
        "the",
        "data",
        "in",
        "a",
        "way",
        "that",
        "machine",
        "learning",
        "algorithms",
        "can",
        "learn",
        "models",
        "with",
        "good",
        "performance",
        "from",
        "them",
        "."
      ]
    },
    {
      "sentence": "It also transforms the data into a form that provides human interpretability given a suitable model design.",
      "tokens": [
        "It",
        "also",
        "transforms",
        "the",
        "data",
        "into",
        "a",
        "form",
        "that",
        "provides",
        "human",
        "interpretability",
        "given",
        "a",
        "suitable",
        "model",
        "design",
        "."
      ]
    },
    {
      "sentence": "For example, the radial domain folding al-gorithm, an unsupervised multivariate clustering method developed by (Joshi & Szolovits, 2012) , abstracts the patient states and summarizes the patient physiology from vitals, labs, and clinical categorical data to a dense but rich representation using domain knowledge.",
      "tokens": [
        "For",
        "example",
        ",",
        "the",
        "radial",
        "domain",
        "folding",
        "al-gorithm",
        ",",
        "an",
        "unsupervised",
        "multivariate",
        "clustering",
        "method",
        "developed",
        "by",
        "(",
        "Joshi",
        "&",
        "Szolovits",
        ",",
        "2012",
        ")",
        ",",
        "abstracts",
        "the",
        "patient",
        "states",
        "and",
        "summarizes",
        "the",
        "patient",
        "physiology",
        "from",
        "vitals",
        ",",
        "labs",
        ",",
        "and",
        "clinical",
        "categorical",
        "data",
        "to",
        "a",
        "dense",
        "but",
        "rich",
        "representation",
        "using",
        "domain",
        "knowledge",
        "."
      ]
    },
    {
      "sentence": "The resulting model outperforms classical clinical scoring systems on the critical patient mortality prediction task while retaining human understandability of the representation.",
      "tokens": [
        "The",
        "resulting",
        "model",
        "outperforms",
        "classical",
        "clinical",
        "scoring",
        "systems",
        "on",
        "the",
        "critical",
        "patient",
        "mortality",
        "prediction",
        "task",
        "while",
        "retaining",
        "human",
        "understandability",
        "of",
        "the",
        "representation",
        "."
      ]
    },
    {
      "sentence": "A good representation may also be derived from multimodal data sources (Weng et al., 2019a) .",
      "tokens": [
        "A",
        "good",
        "representation",
        "may",
        "also",
        "be",
        "derived",
        "from",
        "multimodal",
        "data",
        "sources",
        "(",
        "Weng",
        "et",
        "al.",
        ",",
        "2019a",
        ")",
        "."
      ]
    },
    {
      "sentence": "(Suresh et al., 2017) preprocessed, transformed, and represented the raw data from different modalities (static variables such as demographics, time-varying variables like vital signs and labs, and clinical narrative notes) into a representation for clinical intervention prediction tasks.",
      "tokens": [
        "(",
        "Suresh",
        "et",
        "al.",
        ",",
        "2017",
        ")",
        "preprocessed",
        ",",
        "transformed",
        ",",
        "and",
        "represented",
        "the",
        "raw",
        "data",
        "from",
        "different",
        "modalities",
        "(",
        "static",
        "variables",
        "such",
        "as",
        "demographics",
        ",",
        "time-varying",
        "variables",
        "like",
        "vital",
        "signs",
        "and",
        "labs",
        ",",
        "and",
        "clinical",
        "narrative",
        "notes",
        ")",
        "into",
        "a",
        "representation",
        "for",
        "clinical",
        "intervention",
        "prediction",
        "tasks",
        "."
      ]
    },
    {
      "sentence": "They transformed the clinical notes into a low-dimensional vector of topic distributions to preserve the human interpretability of the representation.",
      "tokens": [
        "They",
        "transformed",
        "the",
        "clinical",
        "notes",
        "into",
        "a",
        "low-dimensional",
        "vector",
        "of",
        "topic",
        "distributions",
        "to",
        "preserve",
        "the",
        "human",
        "interpretability",
        "of",
        "the",
        "representation",
        "."
      ]
    },
    {
      "sentence": "Therefore, having appropriate representations is essential for modeling since it provides the fundamental organization of the data in both a machine and human understandable language (Bengio et al., 2013) .",
      "tokens": [
        "Therefore",
        ",",
        "having",
        "appropriate",
        "representations",
        "is",
        "essential",
        "for",
        "modeling",
        "since",
        "it",
        "provides",
        "the",
        "fundamental",
        "organization",
        "of",
        "the",
        "data",
        "in",
        "both",
        "a",
        "machine",
        "and",
        "human",
        "understandable",
        "language",
        "(",
        "Bengio",
        "et",
        "al.",
        ",",
        "2013",
        ")",
        "."
      ]
    }
  ]
}