{
  "title": [
    {
      "sentence": "Efficient Deep Learning on Multi-Source Private Data",
      "tokens": [
        "Efficient",
        "Deep",
        "Learning",
        "on",
        "Multi-Source",
        "Private",
        "Data"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "Machine learning models benefit from large and diverse datasets.",
      "tokens": [
        "Machine",
        "learning",
        "models",
        "benefit",
        "from",
        "large",
        "and",
        "diverse",
        "datasets",
        "."
      ]
    },
    {
      "sentence": "Using such datasets, however, often requires trusting a centralized data aggregator.",
      "tokens": [
        "Using",
        "such",
        "datasets",
        ",",
        "however",
        ",",
        "often",
        "requires",
        "trusting",
        "a",
        "centralized",
        "data",
        "aggregator",
        "."
      ]
    },
    {
      "sentence": "For sensitive applications like healthcare and finance this is undesirable as it could compromise patient privacy or divulge trade secrets.",
      "tokens": [
        "For",
        "sensitive",
        "applications",
        "like",
        "healthcare",
        "and",
        "finance",
        "this",
        "is",
        "undesirable",
        "as",
        "it",
        "could",
        "compromise",
        "patient",
        "privacy",
        "or",
        "divulge",
        "trade",
        "secrets",
        "."
      ]
    },
    {
      "sentence": "Recent advances in secure and privacy-preserving computation, including trusted hardware enclaves and differential privacy, offer a way for mutually distrusting parties to efficiently train a machine learning model without revealing the training data.",
      "tokens": [
        "Recent",
        "advances",
        "in",
        "secure",
        "and",
        "privacy-preserving",
        "computation",
        ",",
        "including",
        "trusted",
        "hardware",
        "enclaves",
        "and",
        "differential",
        "privacy",
        ",",
        "offer",
        "a",
        "way",
        "for",
        "mutually",
        "distrusting",
        "parties",
        "to",
        "efficiently",
        "train",
        "a",
        "machine",
        "learning",
        "model",
        "without",
        "revealing",
        "the",
        "training",
        "data",
        "."
      ]
    },
    {
      "sentence": "In this work, we introduce Myelin, a deep learning framework which combines these privacy-preservation primitives, and use it to establish a baseline level of performance for fully private machine learning.",
      "tokens": [
        "In",
        "this",
        "work",
        ",",
        "we",
        "introduce",
        "Myelin",
        ",",
        "a",
        "deep",
        "learning",
        "framework",
        "which",
        "combines",
        "these",
        "privacy-preservation",
        "primitives",
        ",",
        "and",
        "use",
        "it",
        "to",
        "establish",
        "a",
        "baseline",
        "level",
        "of",
        "performance",
        "for",
        "fully",
        "private",
        "machine",
        "learning",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "I.",
      "tokens": [
        "I",
        "."
      ]
    },
    {
      "sentence": "INTRODUCTION Machine learning (ML) has enabled a variety of applications from smart-homes to personal assistants.",
      "tokens": [
        "INTRODUCTION",
        "Machine",
        "learning",
        "(",
        "ML",
        ")",
        "has",
        "enabled",
        "a",
        "variety",
        "of",
        "applications",
        "from",
        "smart-homes",
        "to",
        "personal",
        "assistants",
        "."
      ]
    },
    {
      "sentence": "Such success is largely due to recent algorithmic breakthroughs, increased availability of computational resources, and access to vast quantities of data which enable training complex models.",
      "tokens": [
        "Such",
        "success",
        "is",
        "largely",
        "due",
        "to",
        "recent",
        "algorithmic",
        "breakthroughs",
        ",",
        "increased",
        "availability",
        "of",
        "computational",
        "resources",
        ",",
        "and",
        "access",
        "to",
        "vast",
        "quantities",
        "of",
        "data",
        "which",
        "enable",
        "training",
        "complex",
        "models",
        "."
      ]
    },
    {
      "sentence": "However, such datasets often contain sensitive information and therefore raise several privacy concerns.",
      "tokens": [
        "However",
        ",",
        "such",
        "datasets",
        "often",
        "contain",
        "sensitive",
        "information",
        "and",
        "therefore",
        "raise",
        "several",
        "privacy",
        "concerns",
        "."
      ]
    },
    {
      "sentence": "For instance, it has recently been demonstrated that personally identifying information can be inferred from even rough estimates of an ad campaign's audience size [29] .",
      "tokens": [
        "For",
        "instance",
        ",",
        "it",
        "has",
        "recently",
        "been",
        "demonstrated",
        "that",
        "personally",
        "identifying",
        "information",
        "can",
        "be",
        "inferred",
        "from",
        "even",
        "rough",
        "estimates",
        "of",
        "an",
        "ad",
        "campaign",
        "'s",
        "audience",
        "size",
        "[",
        "29",
        "]",
        "."
      ]
    },
    {
      "sentence": "Additionally, machine learning models can benefit from multiple providers' shared data.",
      "tokens": [
        "Additionally",
        ",",
        "machine",
        "learning",
        "models",
        "can",
        "benefit",
        "from",
        "multiple",
        "providers",
        "'",
        "shared",
        "data",
        "."
      ]
    },
    {
      "sentence": "Examples include clinical researchers training a model on patient information from several geographically distributed clinics, and banks pooling data to train a higher quality fraud detection model.",
      "tokens": [
        "Examples",
        "include",
        "clinical",
        "researchers",
        "training",
        "a",
        "model",
        "on",
        "patient",
        "information",
        "from",
        "several",
        "geographically",
        "distributed",
        "clinics",
        ",",
        "and",
        "banks",
        "pooling",
        "data",
        "to",
        "train",
        "a",
        "higher",
        "quality",
        "fraud",
        "detection",
        "model",
        "."
      ]
    },
    {
      "sentence": "In both cases, directly sharing data is unacceptable: the clinics must protect their patients' privacy and banks desire to protect their trade secrets.",
      "tokens": [
        "In",
        "both",
        "cases",
        ",",
        "directly",
        "sharing",
        "data",
        "is",
        "unacceptable",
        ":",
        "the",
        "clinics",
        "must",
        "protect",
        "their",
        "patients",
        "'",
        "privacy",
        "and",
        "banks",
        "desire",
        "to",
        "protect",
        "their",
        "trade",
        "secrets",
        "."
      ]
    },
    {
      "sentence": "Thus, protecting the confidentiality of the data, the model, and the computations on them requires a privacypreserving machine learning platform.",
      "tokens": [
        "Thus",
        ",",
        "protecting",
        "the",
        "confidentiality",
        "of",
        "the",
        "data",
        ",",
        "the",
        "model",
        ",",
        "and",
        "the",
        "computations",
        "on",
        "them",
        "requires",
        "a",
        "privacypreserving",
        "machine",
        "learning",
        "platform",
        "."
      ]
    },
    {
      "sentence": "Although it is currently possible to train fully private individual ML models, existing systems for privacy-preserving machine learning are unable to accommodate to the large-scale, highly flexible deep learning models which power modern ML services.",
      "tokens": [
        "Although",
        "it",
        "is",
        "currently",
        "possible",
        "to",
        "train",
        "fully",
        "private",
        "individual",
        "ML",
        "models",
        ",",
        "existing",
        "systems",
        "for",
        "privacy-preserving",
        "machine",
        "learning",
        "are",
        "unable",
        "to",
        "accommodate",
        "to",
        "the",
        "large-scale",
        ",",
        "highly",
        "flexible",
        "deep",
        "learning",
        "models",
        "which",
        "power",
        "modern",
        "ML",
        "services",
        "."
      ]
    },
    {
      "sentence": "For instance, federated learning [26] , designed to allow multiple users to jointly train a private model, has been shown to be vulnerable against certain privacy attacks [17] .",
      "tokens": [
        "For",
        "instance",
        ",",
        "federated",
        "learning",
        "[",
        "26",
        "]",
        ",",
        "designed",
        "to",
        "allow",
        "multiple",
        "users",
        "to",
        "jointly",
        "train",
        "a",
        "private",
        "model",
        ",",
        "has",
        "been",
        "shown",
        "to",
        "be",
        "vulnerable",
        "against",
        "certain",
        "privacy",
        "attacks",
        "[",
        "17",
        "]",
        "."
      ]
    },
    {
      "sentence": "Approaches based on direct cryptographic operation over models and data incur a performance penalty of 3 to 4 orders of magnitude.",
      "tokens": [
        "Approaches",
        "based",
        "on",
        "direct",
        "cryptographic",
        "operation",
        "over",
        "models",
        "and",
        "data",
        "incur",
        "a",
        "performance",
        "penalty",
        "of",
        "3",
        "to",
        "4",
        "orders",
        "of",
        "magnitude",
        "."
      ]
    },
    {
      "sentence": "Moreover, for those which depend on trusted hardware, supporting deep learning workloads requires including large libraries which were designed with performancenot privacy-as a main objective.",
      "tokens": [
        "Moreover",
        ",",
        "for",
        "those",
        "which",
        "depend",
        "on",
        "trusted",
        "hardware",
        ",",
        "supporting",
        "deep",
        "learning",
        "workloads",
        "requires",
        "including",
        "large",
        "libraries",
        "which",
        "were",
        "designed",
        "with",
        "performancenot",
        "privacy-as",
        "a",
        "main",
        "objective",
        "."
      ]
    },
    {
      "sentence": "In this work, we introduce Myelin, a system designed for efficient differentially-private and data-oblivious deep learning in trusted hardware enclaves.",
      "tokens": [
        "In",
        "this",
        "work",
        ",",
        "we",
        "introduce",
        "Myelin",
        ",",
        "a",
        "system",
        "designed",
        "for",
        "efficient",
        "differentially-private",
        "and",
        "data-oblivious",
        "deep",
        "learning",
        "in",
        "trusted",
        "hardware",
        "enclaves",
        "."
      ]
    },
    {
      "sentence": "Contributions We demonstrate the base performance of Myelin through benchmarks on practical ML models.",
      "tokens": [
        "Contributions",
        "We",
        "demonstrate",
        "the",
        "base",
        "performance",
        "of",
        "Myelin",
        "through",
        "benchmarks",
        "on",
        "practical",
        "ML",
        "models",
        "."
      ]
    },
    {
      "sentence": "This paper contributes a system for efficient, fully-private training of ML models in hardware enclaves.",
      "tokens": [
        "This",
        "paper",
        "contributes",
        "a",
        "system",
        "for",
        "efficient",
        ",",
        "fully-private",
        "training",
        "of",
        "ML",
        "models",
        "in",
        "hardware",
        "enclaves",
        "."
      ]
    },
    {
      "sentence": "We demonstrate stateof-the-art single-enclave performance through benchmarks on practical ML models.",
      "tokens": [
        "We",
        "demonstrate",
        "stateof-the-art",
        "single-enclave",
        "performance",
        "through",
        "benchmarks",
        "on",
        "practical",
        "ML",
        "models",
        "."
      ]
    },
    {
      "sentence": "Importantly, Myelin can be deployed on existing commodity hardware and offers a tool for both production applications as well as continued exploration of the problem space.",
      "tokens": [
        "Importantly",
        ",",
        "Myelin",
        "can",
        "be",
        "deployed",
        "on",
        "existing",
        "commodity",
        "hardware",
        "and",
        "offers",
        "a",
        "tool",
        "for",
        "both",
        "production",
        "applications",
        "as",
        "well",
        "as",
        "continued",
        "exploration",
        "of",
        "the",
        "problem",
        "space",
        "."
      ]
    }
  ]
}