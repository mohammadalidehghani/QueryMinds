{
  "title": "SUSTAINABLE FEDERATED LEARNING",
  "abstract": "Potential environmental impact of machine learning by large-scale wireless networks is a major challenge for the sustainability of future smart ecosystems. In this paper, we introduce sustainable machine learning in federated learning settings, using rechargeable devices that can collect energy from the ambient environment. We propose a practical federated learning framework that leverages intermittent energy arrivals for training, with provable convergence guarantees. Our framework can be applied to a wide range of machine learning settings in networked environments, including distributed and federated learning in wireless and edge networks. Our experiments demonstrate that the proposed framework can provide significant performance improvement over the benchmark energy-agnostic federated learning settings.",
  "introduction": "I. Introduction The environmental impact of machine learning matters. Modern machine learning systems consume massive amounts of energy. In fact, the computational resources needed to train a state-of-the-art deep learning model has increased by 300000x between 2012-2018 [1] . Today, it is estimated that training a single deep learning model can generate as much CO 2 as the total lifetime of five cars [2] . This impact will worsen with the emergence of machine learning in distributed and federated learning settings, where billions of devices are expected to train machine learning models on a regular basis. In this paper, we provide a first study for sustainable machine learning in the federated learning setting, through the use of compute devices that can generate energy from renewable sources in the ambient environment, such as solar, kinetic, ambient light, or ambient RF energy [3] - [5] . Federated learning is a communication-efficient and privacy-preserving distributed learning framework for training machine learning models over large volumes of data created and stored locally at millions of remote clients, such as the data generated at mobile or edge devices [6] - [10] . This is an iterative training process that is coordinated by a central server. The server maintains a global model and sends its current state to the clients at the beginning of each training iteration. During training, the data collected by the individual devices never leaves the device, instead, devices locally update the global model using their local dataset, creating a local model. The local models are then sent to the central server, who then aggregates the local models to update the global model. It has received significant attention in the recent years and has found a variety of applications from keyboard query recommendations to healthcare, from electrical load forecasting to traffic flow prediction [11] - [23] .",
  "body": "I. Introduction The environmental impact of machine learning matters. Modern machine learning systems consume massive amounts of energy. In fact, the computational resources needed to train a state-of-the-art deep learning model has increased by 300000x between 2012-2018 [1] . Today, it is estimated that training a single deep learning model can generate as much CO 2 as the total lifetime of five cars [2] . This impact will worsen with the emergence of machine learning in distributed and federated learning settings, where billions of devices are expected to train machine learning models on a regular basis. In this paper, we provide a first study for sustainable machine learning in the federated learning setting, through the use of compute devices that can generate energy from renewable sources in the ambient environment, such as solar, kinetic, ambient light, or ambient RF energy [3] - [5] . Federated learning is a communication-efficient and privacy-preserving distributed learning framework for training machine learning models over large volumes of data created and stored locally at millions of remote clients, such as the data generated at mobile or edge devices [6] - [10] . This is an iterative training process that is coordinated by a central server. The server maintains a global model and sends its current state to the clients at the beginning of each training iteration. During training, the data collected by the individual devices never leaves the device, instead, devices locally update the global model using their local dataset, creating a local model. The local models are then sent to the central server, who then aggregates the local models to update the global model. It has received significant attention in the recent years and has found a variety of applications from keyboard query recommendations to healthcare, from electrical load forecasting to traffic flow prediction [11] - [23] . arXiv:2102.11274v1 [cs.LG] 22 Feb 2021 Recent works have considered energy efficient training strategies for federated learning [24] , [25] . In these works, the primary focus is on either minimizing the total energy cost of training [24] , or minimizing the training loss within a given total energy budget [25] , where all of the energy is available at the beginning of training. In contrast, our focus is on federated learning when devices generate energy through an intermittent and non-homogeneous renewal process. Our goal is to build a scalable and practical federated learning framework with provable convergence guarantees, for networks with intermittent energy arrivals. Prior work has investigated client selection in the context of federated learning primarily for improving the convergence rate or reducing the communication overhead of training [26] - [30] . Such algorithms are designed with the underlying assumption that all clients are available to participate in training if selected. Then, the goal is to either sample a small number of clients uniformly at random to minimize the communication overhead per iteration, or to select the clients that maximize the convergence rate of training. In contrast, in our setting, whether or not a client can participate in training is determined by an underlying energy arrival process, which is intermittent and non-homogeneous across the clients. Several works have considered federated learning when clients may dropout from the system during training, however, in these setups, the main assumption is that the client dropouts occur uniformly at random, which does not bias the training process [7] , [31] . In this work, we consider a federated learning scenario with N clients and a server. Client i holds a local dataset D i . Clients wish to jointly train a machine learning model over the datasets D 1 , . . . , D N . Training is coordinated by the central server, who maintains a global model that is updated locally by the clients through an iterative process. More specially, at each training iteration, the server sends the current state of the global model to the clients. Then, clients locally update the global model, through multiple stochastic gradient descent (SGD) iterations over their local dataset, and send their local updates to the server. Finally, the server updates the global model by aggregating the local updates received from the clients, and sends the updated global model back to the clients, to be used in the next iteration. Unlike the conventional federated learning setting, we assume that clients only have intermittent energy availability, and can participate in the training process only when they have energy available. The energy generation process is not uniform across the devices, that is, some clients may have more frequent energy arrivals than others. One potential approach in this setting is to let each client to participate in training as soon as they generate enough energy to do so. However, as we demonstrate in our experiments, in this setting, conventional federated learning strategies may bias the global model towards clients with more frequent energy arrivals, causing a performance loss in the resulting accuracy. Another approach is to wait until all clients generate enough energy to participate in training before each iteration of the conventional federated learning scheme. Doing so, however, would require waiting for the clients with the slowest energy generation, therefore, even though the training is unbiased, the convergence rate can be very slow to reach a desired performance level. We propose a simple federated learning framework with provable convergence guarantees, for networks in which devices generate energy through an intermittent renewable energy source. The proposed framework consists of three main components, client scheduling, local training at the clients, and model update at the server. Client scheduling is performed at the client level, in other words, each client decides whether or not to participate at any given training iteration based solely on the local estimation of the energy arrival process. The client scheduling process requires no coordination between the clients, and is scalable to large networks. During the local training phase, clients who choose to participate at the current training iteration update the global model using their local datasets, and then send their local updates to the server. Upon receiving the local updates, the server updates the global model for the next iteration. In our experiments, we compare the performance of the proposed framework with benchmark federated learning settings that are agnostic to the energy-arrival process of the clients. The first benchmark is the federated learning setting in which clients participate in training as soon as they generate enough energy, and then wait for the next energy arrival. The second benchmark is the setting in which the server waits for all clients to have enough energy to participate in training before initiating a single training iteration. We show that the proposed framework can significantly outperform both benchmarks in terms of the test accuracy. This paper is a first study of sustainable federated learning, and we hope our work to open up new research directions in building sustainable federated and distributed learning schemes for large-scale networks, where millions of devices jointly train machine learning models over large volumes of data. Some of these research directions include, formalizing the fundamental performance limits of distributed training under stochastic and unknown energy arrival processes, model quantization and compression techniques that can adapt to the resource and energy arrival patterns, and characterizing the relationship between the energy renewal processes and training performance. II. Problem Formulation A. Federated Learning Setup We consider a distributed training setting with N clients. Client i has a local dataset D i with D i data points. The total number of data points across all clients is D = i∈[N ] D i . The clients are connected through a central server that coordinates the training. The goal is to train a model w to minimize a global loss function F (w) = 1 D N i=1 Di j=1 l(w, x ij ) (1) where l(w, x ij ) represents the loss of a single data point x ij in the local dataset D i of client i. By defining a local loss function F i (w) = 1 D i Di j=1 l(w, x ij ) (2) for client i, the global loss function in (1) can be written as F (w) = N i=1 p i F i (w) (3) where p i := Di D and thus, i∈[N ] p i = 1 (4) We next provide the details of training in the conventional federated learning setting [7] . In this setting, the server maintains a global model that is updated locally by the clients. The local updates are then aggregated at the server to update the global model. As such, the training process consists of local and global update iterations. Each iteration (local or global) is represented by a discrete time instant t ∈ {0, 1, 2, . . .}. It is assumed that a global update occurs at every T time instants, where T is the number of local training iterations that take place between two global updates. Without loss of generality, we assume that a global update occurs when t mod T = 0, and let T = {t : t mod T = 0} (5) denote the set of time instances at which a global update occurs, which we also refer to as synchronization steps. At the beginning of each global round t ∈ T , the server sends the current state of the global model to the clients, which is denoted by a vector w (t) ∈ R d of dimension d, where d is the model size. Then, all or a fraction of the clients update the global model w (t) through T local training iterations, using their local datasets. The set of clients that participate in training at a given iteration depends on the specifics of the client scheduling algorithm, which could range from all clients to a small fraction of clients. We let S t denote the set of participating clients at iteration t. Local training at the clients is performed through stochastic gradient descent (SGD), in which the model parameters are updated iteratively in the negative direction of the gradient evaluated over a random sample (or a minibatch) from the local dataset. To present the details of the local training process, we consider a synchronization step t ∈ T , at which the server sends the current estimation of the global model w (t) to the clients. We also let w (t) i denote the local estimation of the model parameters at client i at time t. Accordingly, we will call w (t) i the local model of client i at time t. When t ∈ T , client i ∈ [N ] sets its local model as, w (t) i ← w (t) . (6) In other words, at each synchronization step, clients synchronize their local models with the current state of the global model. Then, client i ∈ S t updates their local model through T SGD iterations, w (t+j+1) i = w (t+j) i -η t+j ∇F i (w (t+j) i , ξ (t+j) i ) (7) for j ∈ {0, . . . , T -1}, where w (t+0) i = w (t) , η t+j is the learning rate (step size), and ∇F i (w (t+j) i , ξ (t+j) i ) denotes the stochastic gradient of client i, with ξ (t) i representing a uniformly random sample (or a minibatch) from D i . The stochastic gradient is an unbiased estimator of the true gradient of client i, E[∇F i (w (t+j) i , ξ (t+j) i )] = ∇F i (w (t+j) i ) (8) where ∇F i (w (t+j) ) is the true gradient of client i, i.e., the gradient of the local loss function (2) evaluated at w (t+j) i . At the end of T local SGD operations, clients i ∈ S t+T -1 send their local updates w (t+T ) i from ( 7 ) to the server. For all clients not participating in the current global round, i.e., for clients i / ∈ S t+T -1 , it is assumed that w (t+T ) i = w (t) . Finally, the server updates the global model, w (t+T ) = i∈[N ] p i w (t+T ) i . ( 9 ) by aggregating the local models of the clients. After updating the global model, the server sends the updated global model w (t+T ) to the clients for the next iteration. We use the term global round to refer to the block of T time instances between two consecutive syncronization steps (global updates). In other words, global round t corresponds to the block of time instances t ∈ {t, . . . , t + T -1}. We also note that our focus is on the conventional synchronous federated learning setup, in which all clients participating at a given global round perform the same number of local training iterations and the global model is updated only at specified time instances t ∈ T . Asynchronous learning scenarios in which clients can perform varying number of local iterations and communicate their local models with the server at arbitrary time instances are interesting future directions, but are beyond our scope. B. Energy Profile of the Clients In this work, we consider devices that are powered by the small quantities of energy generated from the ambient environment, such as solar, kinetic, ambient light or RF energy [32] - [35] . Clients can participate in training only if they have available energy to do so. It is assumed that it takes E i global rounds for device i to generate enough energy to participate in one global round of training, which includes the energy cost of computing the T local updates from (7) and communicating it with the server. We call E i the energy renewal cycle of client i. As we demonstrate in our experiments, in this setting, i.e., when clients have intermittent energy arrivals, the conventional federated learning setup from Section II-A might bias the model towards clients with more frequent energy availability. This calls for an energy-aware client scheduling and training strategy which we study in this paper. Main Problem. Given the above energy arrival and training setup, the main problem we study in this work is, \"How to design a scalable federated learning framework for devices with intermittent energy availability?\". In the sequel, we provide a practical federated learning framework that takes into account the energy limitations of the clients during training, while ensuring theoretical convergence guarantees. III. Federated Learning with Intermittent Resource Arrivals We now introduce a practical federated learning framework for networks in which devices have intermittent energy availability. The overall procedure of our framework is provided in Algorithm 1. Our framework consists of three main components, client scheduling, local training at the clients, and global model update at the server. A. Client scheduling The first component of our framework is client scheduling for training. Client selection in conventional federated learning algorithms are primarily based on the assumption that all clients are inherently available to participate in training if chosen, or that client dropouts occur uniformly at random (which does not bias the training), and focus on selecting the clients to maximize the convergence rate or to reduce the communication overhead of training [7] , [26] , [28] , [30] , [31] . In contrast, in our setup, not all clients can participate in the training process at all rounds. In Algorithm 1 Federated Learning with Intermittent Resource Arrivals input Number of devices N , local dataset D i and energy renewal cycle E i of device i ∈ [N ], number of local training iterations T at each global round, total number of training iterations K where K T ×Ei ∈ Z + for i ∈ [N ]. output Global model w (K) . Initialization: 1: for client i = 1, . . . , N do 2: Initialize I t i ← 0 for t ∈ [K] and i ∈ [N ]. // Indicates whether client i participates at iteration t. Training: 3: for iteration t = 1, . . . , K do Clients: 4: for client i = 1, . . . , N do 5: if t mod T E i = 0 then // Client i has enough energy to participate in training. 6: Sample an integer J uniformly random from {0, . . . , E i -1}. 7: Update I t+JT +l i ← 1 for l ∈ {0, . . . , T -1}. // Client i is scheduled at global round t + JT . 8: if t mod T = 0 then 9: if I t i = 1 then // Client i locally updates the model. 10: Initialize the local model w (t) i ← w (t) 11: for iteration j = 0, . . . , T -1 do 12: Update the local model according to (7) . 13: Send the local update g (t) i from ( 12 ) to the server. Server: 14: if (t + 1) mod T = 0 then 15: Receive the local updates g (t+1) i from the clients in S t = {i : I t i = 1}. 16: Update the global model according to (13) , w (t+1) = w (t-T +1) + i∈St p i g (t+1) i (10) 17: Send the updated global model w (t+1) to the clients. particular, if a client has participated in one round, they may not have enough energy to participate in the next round. Moreover, the energy availability of the clients is non-uniform, i.e., some clients have less frequent energy arrivals than others. A naive approach for client scheduling is to schedule clients as soon as they have collected enough energy to participate in training. However, as we will demonstrate in our experiments, doing so can bias the trained model towards clients with better (more frequent) energy availability. Another approach is to wait until all clients become available for training, and then use a conventional client sampling algorithm. However, waiting for all clients to have enough energy can significantly increase the total training time needed to achieve a target performance level. Instead, we propose a simple client scheduling protocol that can be performed locally by the clients. In our protocol, clients participate in training through a stochastic process based on their energy profile. The details of this process is as follows. First, we note that it takes E i global rounds for client i to harvest enough energy to participate in one global round of training foot_0 . When t mod (E i T ) = 0, client i samples an integer J uniformly at random from the set {0, . . . , E i -1}. Then, within the E i global rounds starting at the time instances {t, t + T, . . . , t + (E i -1)T }, client i only participates during the global round that starts at t + JT , and does not participate in the remaining global rounds. We note that the client selection algorithm decides whether or not a client will participate at a given global round. If a client chooses to participate at a global round starting at some t ∈ T , then the client participates for the whole duration of that global round, i.e., for {t, . . . , t + T -1}, by computing the local model as in (7) . As such, for any global round starting at t ∈ T , the set of participating clients S t at time t, . . . , t + T -1 satisfy, S t = S t+1 = . . . = S t+T -1 , (11) i.e., the set of clients participating in a given global round stays the same throughout the duration of that global round. As we demonstrate in our theoretical analysis, the proposed client scheduling strategy provides provable convergence guarantees for the global model. B. Local training At the beginning of each global round, the server sends the current state of the global model to the clients. The clients then locally update the global model on their local datasets. The details of this local update process is as follows. Consider a global round starting at some t ∈ T . Then, the server sends the current state of the global model w (t) to the clients. Then, clients choose whether or not to participate in the current global round, based on the client scheduling process from Section III-A. Clients who choose to participate in the current global round then compute a local model, by updating the global model w (t) through T local SGD iterations as in (7) . After T local SGD iterations, client i ∈ S t+T -1 sends a local update to the server. The local update is defined as, g (t+T ) i E i (w (t+T ) i -w (t) ) (12) which is obtained by shifting w (t+E) i by w (t) and then scaling it with respect to the energy renewal cycle E i . C. Global model update After receiving the local updates in (12) from the participating clients, the server updates the global model as, w (t+T ) = w (t) + i∈S t+T -1 p i g (t+T ) i ( 13 ) and sends the updated model w (t+T ) back to the clients, for the next iteration. We note that the complexity of Algorithm 1 is the same as that of conventional federated learning, i.e., the federated averaging algorithm (FedAvg) from [7] . In the following, we demonstrate the theoretical convergence guarantees of our framework. IV. Convergence Analysis In this section, we provide the convergence guarantees of our framework. First, we review a few common technical assumptions [26] , [36] that will be useful in our further analysis. Assumption 1. (Strong-convexity) The local loss functions F i (w) for i ∈ [N ] are µ-strongly convex: F i (v) ≥ F i (w) + F i (w) T (v -w) + µ 2 ||w -v|| 2 (14) Assumption 2. (Smoothness) The local loss functions F i (w) for i ∈ [N ] are L-smooth: F i (v) ≤ F i (w) + F i (w) T (v -w) + L 2 ||w -v|| 2 (15) Assumption 3. (Variance bound) The stochastic gradient ∇F i (w (t+j) i , ξ (t+j) i ) has bounded variance for all i ∈ [N ] E[||∇F i (w (t+j) i , ξ (t+j) i ) -∇F i (w (t) )|| 2 ] ≤ σ 2 . ( 16 ) Assumption 4. (Bounded second moment) The stochastic gradient ∇F i (w (t+j) i , ξ (t+j) i ) has bounded expected squared norm for all i ∈ [N ], E[||∇F i (w (t+j) i , ξ (t+j) i )|| 2 ] ≤ G 2 . ( 17 ) Our convergence analysis is simple and follows along the lines of standard convergence analysis techniques for distributed SGD with local averaging [26] , [30] , [36] . We first represent the model update process in an equivalent but more tractable form. Note that in our original problem formulation, at any global round, only the clients that choose to participate in that global round perform the local update. To make the mathematical analysis simpler, one can instead assume that all clients perform local training at each global round, but the global model is updated by using only the local updates from the clients that were originally scheduled at that global round. Note that, mathematically, the two processes lead to the same global model. Hence, we will use the latter approach in the following, and represent the model update process from Algorithm 1 as, v (t+1) k = w (t) k -η t ∇F k (w (t) k , ξ (t) k ) (18) w (t+1) k = v (t+1) k t+1 / ∈ T w (t+1-T ) k + i∈St p i E i (v (t+1) i -w (t+1-T ) i ) t+1 ∈ T ( 19 ) for t ∈ [K] and k ∈ [N ]. Note that for t + 1 ∈ T , w (t+1-T ) k = w (t+1-T ) (20) for all k ∈ [N ], since t + 1 -T ∈ T whenever t + 1 ∈ T . We next define two virtual sequences that will be useful in our analysis: w (t+1) = k∈[N ] p k w (t+1) k (21) and v (t+1) = k∈[N ] p k v (t+1) k . (22) We next provide a key lemma. Lemma 1. (Unbiased client scheduling) For all t ∈ T , E w (t+1) = v (t+1) , (23) hence, the client scheduling process from Section III-A is unbiased. Proof. Define a binary random variable α t i such that: α t i = 1 if client i participates at iteration t 0 otherwise (24) According to the client scheduling algorithm from Section III-A, at t ∈ T , client i participates in one of the E i consecutive global rounds uniformly at random. Hence, among the global rounds starting at {t, t+T, . . . , t+(E i -1)T }, the probability of participating at a specific round is 1 Ei , from which we have, P [α t i = 1] = 1 E i . (25) Then, by defining α t (α t 1 , . . . , α t N ), we find that, E w (t+1) = k∈[N ] p k E w (t+1-T ) k + i∈S (t+1) E i p i (v (t+1) i -w (t+1-T ) i ) (26) = k∈[N ] p k w (t+1-T ) k + E i∈S (t+1) E i p i (v (t+1) i -w (t+1-T ) i ) (27) = k∈[N ] p k w (t+1-T ) k + E i∈[N ] α t i E i p i (v (t+1) i -w (t+1-T ) i ) (28) = k∈[N ] p k w (t+1-T ) k + i∈[N ] E[α t i E i p i (v (t+1) i -w (t+1-T ) i )] (29) = k∈[N ] p k w (t+1-T ) k + i∈[N ] 1 E i E i p i (v (t+1) i -w (t+1-T ) i ) (30) = w (t+1-T ) + k∈[N ] p k i∈[N ] p i v (t+1) i -w (t+1-T ) (31) = w (t+1-T ) + i∈[N ] p i v (t+1) i -w (t+1-T ) (32) = i∈[N ] p i v (t+1) i = v (t+1) (33) where ( 30 ) is from (25) , and ( 31 ) is from ( 20 ) and ( 4 ). Next, we provide another key lemma. Lemma 2. (Bounded variance for w (t+1) ) For all t ∈ T , by assuming a decreasing learning rate η t with η t ≤ 2η t+T for all t ≥ 0, we have E[ v (t+1) -w (t+1) 2 ] ≤ 4E 2 max G 2 η 2 t T 2 , ( 34 ) where E max = max i∈[N ] E i . Hence, the aggregate of the local models have bounded variance. Proof. From ( 21 ) and ( 22 ), we have that, E[ v (t+1) -w (t+1) 2 ] = E[ k∈[N ] p k v (t+1) k A - k∈[N ] p k w (t+1) k B 2 ] (35) The first term in (35) can be written as: A = k∈[N ] p k w (t+1-T ) k - t j=t+1-T η j ∇F k (w (j) k , ξ (j) k ) (36) = w (t+1-T ) - k∈[N ] t j=t+1-T p k η j ∇F k (w (j) k , ξ (j) k ) (37) where (36) follows from (18) , and (37) is from ( 4 ) and (20) . Similarly, the second term in (35) can be written as: B = k∈[N ] p k w (t+1-T ) k + i∈St E i p i (v (t+1) i -w (t+1-T ) i ) (38) = w (t+1-T ) + i∈St E i p i (w (t+1-T ) - t j=t+1-T η j ∇F i (w (j) i , ξ (j) i ) -w (t+1-T ) ) (39) = w (t+1-T ) - i∈St E i p i t j=t+1-T η j ∇F i (w (j) i , ξ (j) i ) (40) where (38) follows from (19) , (20) , and (4), whereas (39) is from (18) . By combining (40), (37) , and (35), we have, E[ k∈[N ] p k v (t+1) k - k∈[N ] p k w (t+1) k 2 ] = E[ - k∈[N ] t j=t+1-T p k η j ∇F k (w (j) k , ξ (j) k ) + i∈St E i p i t j=t+1-T η j ∇F i (w (j) i , ξ (j) i ) 2 ] (41) ≤ E[ i∈St E i p i t j=t+1-T η j ∇F i (w (j) i , ξ (j) i ) 2 ] (42) where (42 ) holds from E[(X -E[X]) 2 ] ≤ E[X 2 ] and that, E[ i∈St E i p i t j=t+1-T η j ∇F i (w (j) i , ξ (j) i )] = E[ i∈[N ] α t i E i p i t j=t+1-T η j ∇F i (w (j) i , ξ (j) i )] (43) = i∈[N ] 1 E i E i p i t j=t+1-T η j ∇F i (w (j) i , ξ (j) i ) (44) = k∈[N ] t j=t+1-T p k η j ∇F k (w (j) k , ξ (j) k ) (45) by defining α t (α t 1 , . . . , α t N ) as in (24) . Finally, by letting r j i ∇F i (w (j) i , ξ (j) i ), E[ i∈St E i p i t j=t+1-T η j ∇F i (w (j) i , ξ (j) i ) 2 ] = E[ i∈St i ∈St E i E i p i p i t j=t+1-T η j r j i , t j =t+1-T η j r j i ] (46) ≤ E[ i∈St i ∈St E i E i p i p i t j=t+1-T t j =t+1-T η j η j G 2 ] (47) ≤ E[ i∈[N ] i ∈[N ] α i α i E i E i p i p i t j=t+1-T t j =t+1-T η j η j G 2 ] ≤ i∈[N ] i ∈[N ] E[α i α i ]E i E i p i p i t j=t+1-T t j =t+1-T η j η j G 2 ≤ E 2 max T 2 η 2 t+1-T G 2 ≤ 4E 2 max T 2 η 2 t G 2 (48) where (47) follows from (17) and that, t j=t+1-T η j r j i , t j =t+1-T η j r j i = t j=t+1-T t j =t+1-T η j η j r j i , r j i (49) ≤ t j=t+1-T t j =t+1-T η j η j r j i r j i (50) ≤ t j=t+1-T t j =t+1-T η j η j 1 2 ( r j i 2 + r j i 2 ) (51) where ( 50 ) is from the Cauchy-Schwarz inequality, and (51) is from the AM-GM (arithmetic mean-geometric mean) inequality. Equation (48) follows from using a decreasing learning rate η t with t and η t ≤ 2η t+T . In equation (48), we define E max max i∈[N ] E i . We next define the degree of heterogeneity between the clients as in [26] , Γ = F * - i∈[N ] p i F * i ( 52 ) where F * and F * i denote the minimum of the global and local loss functions from ( 1 ) and (2), respectively. We are now ready to state our convergence guarantees. Theorem 1. For the federated learning problem from (1) over N clients and an energy renewal cycle E i for client i ∈ [N ], Algorithm 1 converges, E[F (w (T ) )] -F (w * ) ≤ 2κ γ + K B + C µ + 2L w (0) -w * 2 (53) in K iterations, where w * denotes the optimal model parameters that minimize the global loss function in (1), and C 4E 2 max T 2 η 2 t G 2 , (54) where E max max i∈[N ] E i , κ = L µ , γ = max{8κ, T }, learning rate η t = 2 µ(γ+t) , and B = σ 2 6LΓ + 8(T -1) 2 G 2 . Proof. The proof follows directly from Lemmas 1 and 2 along with standard steps in the convergence analysis of distributed SGD with local averaging [26] , [30] , [36] , e.g., from Section B.3 of [26] by replacing Lemmas 4 and 5 from [26] with Lemmas 1 and 2 from our work, respectively. V. Experiments We now demonstrate the convergence properties of Algorithm 1 compared to federated learning benchmarks that are agnostic to the energy availability of the clients. Network architecture. We consider an image classification task with 10 classes on the CIFAR-10 dataset [37] . Training is done using a convolutional neural network with the same architecture from [7] (about 10 6 parameters). Experiment Setup. We consider a network of N = 40 clients. The dataset is distributed in an i.i.d. fashion across the network, by shuffling the dataset and distributing it evenly across the clients. Clients use the ADAM optimizer [38] during training, and the number of local training iterations is set to T = 5. Energy Profile. In order to show the impact of non-homogeneous energy arrivals, clients are partitioned into 4 groups U 0 , . . . , U 3 of equal size, such that U k = {i : i mod 4 = k}. Then, the energy arrivals of clients in group U k are assigned as E i = τ k for all i ∈ U, where (τ 0 , τ 1 , τ 2 , τ 3 ) = (1, 5, 10, 20) . In other words, clients in group U 0 receive energy at every global round, whereas clients in groups U 1 , U 2 , and U 3 receive energy at every 5, 10, and 20 global rounds, respectively. Benchmarks. To evaluate the performance of Algorithm 1, we consider the conventional federated learning algorithm from Section II-A (known as FedAvg [7] ), but under the constraint that users receive energy according to the energy arrival process in Section II-B, and implement two benchmarks with respect to the specific client scheduling policy. Benchmark 1: In the first benchmark, each client participates in training as soon as they have enough energy, and then waits until the next energy arrival. More specifically, as soon as t mod T E i = 0, the client participates in the current global round, by updating the current state of the global model through T local training iterations as in (7) , and then sending the local update to the server. The server then updates the global model according to (9) . The client does not participate in training in the next E i -1 global rounds, until the next energy arrival. Benchmark 2: In the second benchmark, the global model is updated only when all clients have received energy, i.e., the server waits until all clients have energy available before initiating a global update. After all clients have received energy, the server sends the current state of the global model to the clients, the clients compute a local model as in (7) , and then the server aggregates the local models to update the global model as in (9) . Note that in this case, the server needs to wait for the slowest client, hence the global model is updated once in the duration of 20 global rounds. We evaluate the training performance in terms of the test accuracy with respect to the number of global rounds. Our results are given in Figure 1 . In our experiments, we also implement the original federated learning algorithm (FedAvg) from Section II-A without any resource limitations, which acts as an upper bound on the accuracy. We observe that Algorithm 1 achieves an accuracy of 77%, which is comparable to the accuracy of FedAvg, whereas the accuracy of the two benchmarks are 60% and 62%, respectively, within 1000 global rounds. This is caused by the fact that, in the first benchmark, the training algorithm favors clients with more frequent energy availability, which causes the global model to be biased. In the second benchmark, the server waits until all clients have energy available before each global update, which causes the convergence to be very slow even though the algorithm is unbiased. On the other hand, Algorithm 1 converges fast and significantly outperforms the benchmarks in terms of test accuracy. VI. Conclusion This paper proposes sustainable federated learning with the utilization of intermittently powered devices, where a large number of remote devices are expected to perform training on a daily basis. We demonstrate a simple and scalable federated learning strategy with provable convergence guarantees, for devices with intermittent energy availability, and show that the proposed framework can significantly improve the training performance compared to the energy-agnostic benchmarks. We hope our work to open up further research on sustainable learning in large-scale federated and decentralized settings. Fig. 1 . 1 Fig. 1. Test accuracy of Algorithm 1 compared to federated learning benchmarks for N = 40 clients on the CIFAR-10 dataset. For simplicity, we assume that when t = 0, all clients have enough energy to participate in one global round. Our results hold even if clients start at different time instances."
}