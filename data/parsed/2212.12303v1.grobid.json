{
  "title": "Introduction to Machine Learning for Physicians: A Survival Guide for Data Deluge",
  "abstract": "Many modern research fields increasingly rely on collecting and analysing massive, often unstructured, and unwieldy datasets. Consequently, there is growing interest in machine learning and artificial intelligence applications that can harness this 'data deluge'. This broad nontechnical overview provides a gentle introduction to machine learning with a specific focus on medical and biological applications. We explain the common types of machine learning algorithms and typical tasks that can be solved, illustrating the basics with concrete examples from healthcare. Lastly, we provide an outlook on open challenges, limitations, and potential impacts of machine-learning-powered medicine.",
  "introduction": "Machine learning (ML) is a discipline emerging from computer science [1] with close ties to statistics and applied mathematics. Its fundamental goal is the design of computer programs [2] , or algorithms, that learn to perform a certain task in an automated manner. Without explicit rules or knowledge, ML algorithms observe and possibly, interact with the surrounding world by the use of available data. Typically, as a result of learning, algorithms distil observations of complex phenomena into a general model which summarises the patterns, or regularities, discovered from the data. Modern ML algorithms regularly break records achieving impressive performance at a wide range of tasks, e.g. game playing [3] , protein structure prediction [4] , searching for particles in high-energy physics [5] , and forecasting precipitation [6] . The utility of machine learning methods for healthcare is apparent: it is often Artificial intelligence (AI) [25, 18] tackles the most general problem of building intelligent machines and is not restricted to a particular set of methods: both a simple expert system with a few hand-engineered rules and a logical inference engine [19] or a deep artificial neural network playing the board game of Go [3] could be seen as instances of artificial intelligence. On the other hand, ML is a subfield of AI [18] focusing on the machines that learn from experience, namely, from the given data. Deep learning (DL) [26, 27] refers to an even smaller subset of machine learning methods: it studies deep neural networks (DNNs), a family of ML techniques which learn many layers of complex, highly nonlinear concepts directly from the raw data, e.g. images, sound recordings, text, and videos. A well-informed reader might have noticed before that many ML methods rely on statistical reasoning and in some cases, ML and statistical models can be used for similar purposes [28] . A simplified, stereotypical delineation between the two fields, sufficient for the current overview, is that classical statistical models are probabilistic, focus on inference, and make strict structural assumptions; whereas ML methods offer an algorithmic solution to the prediction problem allowing for very general and complex relationships [24, 28] . Machine Learning Approaches and Tasks Three most common categories of machine learning methods are (i) supervised learning, (ii) unsupervised learning, and (iii) reinforcement learning [1, 29] (Figure 1 ). These approaches have been tailored towards principally different problem types, which will be outlined below. Regardless of the method, ultimately, a model that generalises well is desired, i.e. a model with good performance at the considered task across as many different unobserved settings as possible. In supervised learning [1, 29] , the goal is to learn a predictive relationship between a set of input variables, also called features, attributes, or covariates, and an output variable, also called response, target, or label. Following the example from Figure 1 (a), let us assume that we want to design a computer system to recognise objects, such as apples, bananas, or dogs from hand-drawn images. For this task, our features could be given by digital images stored on a personal computer, and labels could be verbal descriptions of the depicted objects, such as 'It's a dog', written down in a text file. Typically, we would use some learning algorithm to extract predictive patterns from the observed training data. The algorithm serves as a 'recipe' for distilling the raw data into a sufficiently abstract and general model. We would then apply the trained model to unseen test data to predict unobserved labels, and evaluate its performance, for example, in terms of accuracy. The setting where labels come from a finite number of un-ordered categories, as in the handdrawn image recognition example, is known as the classification task; whereas in the regression task, labels are usually real-valued. Note, that more generally, we could even learn relationships between input variables and multiple differently-valued outputs. Unsupervised learning [1, 29, 30] approach is not as well-defined as supervised learning and attempts to solve a more challenging open-ended problem: given only the input variables without labels, unsupervised learning algorithms typically seek to discover some 'interesting' structure in the data. For instance, we might want to stratify our dataset into groups of similar observations -this problem is known as clustering. Following the hand-drawn image example above, a clustering algorithm would group images of similar objects together, e.g. into groups of fruit and animals (Figure 1(b) ). Dimensionality reduction is another typical unsupervised task where usually for visualisation purposes, we reduce the data to two or three informative dimensions by combining the input features. Although it might seem that supervised and unsupervised learning solve completely disjoint sets of problems, there is a whole spectrum of practical settings in-between [31, 32] , for example, when the output variable is partially missing because it is too expensive to measure for all of the subjects or when the output does not correspond to the exact target, which is impossible or unethical to measure. Techniques that deal with such settings fall under the categories of semi-supervised [31] and weakly supervised [32] learning. In their simplest forms, both supervised and unsupervised learning usually assume that the model is trained on a set of examples collected prior to learning and that model's predictions or decisions do not affect each other. Reinforcement learning (RL) [1, 29, 33] ventures beyond these assumptions: the learning algorithm, in this context referred to as agent, interacts with the surrounding environment by observing it and performing sequences of actions in order to maximise the occasionally obtained reward. For example, a baby learning to walk and being praised by its parents or a robotic arm learning to place objects into a container (Figure 1(c) ) could be thought of as reinforcement learning scenarios. An important feature of this setting is the interactive and sequential nature of the learning process. While the three approaches discussed above have become active research areas in their own right, in practice, real-world applications often require a combination of different methods and solving multiple tasks at a time. In the following, we will focus on biomedical and healthcare applications of ML supplementing our discussion with examples of the current research. (a) Supervised learning (b) Unsupervised learning (c) Reinforcement learning",
  "body": "Machine learning (ML) is a discipline emerging from computer science [1] with close ties to statistics and applied mathematics. Its fundamental goal is the design of computer programs [2] , or algorithms, that learn to perform a certain task in an automated manner. Without explicit rules or knowledge, ML algorithms observe and possibly, interact with the surrounding world by the use of available data. Typically, as a result of learning, algorithms distil observations of complex phenomena into a general model which summarises the patterns, or regularities, discovered from the data. Modern ML algorithms regularly break records achieving impressive performance at a wide range of tasks, e.g. game playing [3] , protein structure prediction [4] , searching for particles in high-energy physics [5] , and forecasting precipitation [6] . The utility of machine learning methods for healthcare is apparent: it is often Artificial intelligence (AI) [25, 18] tackles the most general problem of building intelligent machines and is not restricted to a particular set of methods: both a simple expert system with a few hand-engineered rules and a logical inference engine [19] or a deep artificial neural network playing the board game of Go [3] could be seen as instances of artificial intelligence. On the other hand, ML is a subfield of AI [18] focusing on the machines that learn from experience, namely, from the given data. Deep learning (DL) [26, 27] refers to an even smaller subset of machine learning methods: it studies deep neural networks (DNNs), a family of ML techniques which learn many layers of complex, highly nonlinear concepts directly from the raw data, e.g. images, sound recordings, text, and videos. A well-informed reader might have noticed before that many ML methods rely on statistical reasoning and in some cases, ML and statistical models can be used for similar purposes [28] . A simplified, stereotypical delineation between the two fields, sufficient for the current overview, is that classical statistical models are probabilistic, focus on inference, and make strict structural assumptions; whereas ML methods offer an algorithmic solution to the prediction problem allowing for very general and complex relationships [24, 28] . Machine Learning Approaches and Tasks Three most common categories of machine learning methods are (i) supervised learning, (ii) unsupervised learning, and (iii) reinforcement learning [1, 29] (Figure 1 ). These approaches have been tailored towards principally different problem types, which will be outlined below. Regardless of the method, ultimately, a model that generalises well is desired, i.e. a model with good performance at the considered task across as many different unobserved settings as possible. In supervised learning [1, 29] , the goal is to learn a predictive relationship between a set of input variables, also called features, attributes, or covariates, and an output variable, also called response, target, or label. Following the example from Figure 1 (a), let us assume that we want to design a computer system to recognise objects, such as apples, bananas, or dogs from hand-drawn images. For this task, our features could be given by digital images stored on a personal computer, and labels could be verbal descriptions of the depicted objects, such as 'It's a dog', written down in a text file. Typically, we would use some learning algorithm to extract predictive patterns from the observed training data. The algorithm serves as a 'recipe' for distilling the raw data into a sufficiently abstract and general model. We would then apply the trained model to unseen test data to predict unobserved labels, and evaluate its performance, for example, in terms of accuracy. The setting where labels come from a finite number of un-ordered categories, as in the handdrawn image recognition example, is known as the classification task; whereas in the regression task, labels are usually real-valued. Note, that more generally, we could even learn relationships between input variables and multiple differently-valued outputs. Unsupervised learning [1, 29, 30] approach is not as well-defined as supervised learning and attempts to solve a more challenging open-ended problem: given only the input variables without labels, unsupervised learning algorithms typically seek to discover some 'interesting' structure in the data. For instance, we might want to stratify our dataset into groups of similar observations -this problem is known as clustering. Following the hand-drawn image example above, a clustering algorithm would group images of similar objects together, e.g. into groups of fruit and animals (Figure 1(b) ). Dimensionality reduction is another typical unsupervised task where usually for visualisation purposes, we reduce the data to two or three informative dimensions by combining the input features. Although it might seem that supervised and unsupervised learning solve completely disjoint sets of problems, there is a whole spectrum of practical settings in-between [31, 32] , for example, when the output variable is partially missing because it is too expensive to measure for all of the subjects or when the output does not correspond to the exact target, which is impossible or unethical to measure. Techniques that deal with such settings fall under the categories of semi-supervised [31] and weakly supervised [32] learning. In their simplest forms, both supervised and unsupervised learning usually assume that the model is trained on a set of examples collected prior to learning and that model's predictions or decisions do not affect each other. Reinforcement learning (RL) [1, 29, 33] ventures beyond these assumptions: the learning algorithm, in this context referred to as agent, interacts with the surrounding environment by observing it and performing sequences of actions in order to maximise the occasionally obtained reward. For example, a baby learning to walk and being praised by its parents or a robotic arm learning to place objects into a container (Figure 1(c) ) could be thought of as reinforcement learning scenarios. An important feature of this setting is the interactive and sequential nature of the learning process. While the three approaches discussed above have become active research areas in their own right, in practice, real-world applications often require a combination of different methods and solving multiple tasks at a time. In the following, we will focus on biomedical and healthcare applications of ML supplementing our discussion with examples of the current research. (a) Supervised learning (b) Unsupervised learning (c) Reinforcement learning Machine Learning for Healthcare In healthcare, ML methods are usually leveraged to extract patterns that correlate with medical conditions. They are applied to healthcare records and other patient data to support clinicians by predicting diagnosis, management, and outcome in an automated manner. There are a plethora of data types in healthcare that ML algorithms can be applied to: • clinical data from electronic health records (EHR) which contain demographics, laboratory test results, medication, allergies, vital signs, clinical reports [34, 35] , • imaging data from different modalities such as X-ray, retinal, mammography, dermoscopy, MR (magnetic resonance), CT (computerized tomography), and ultrasound (US) images and echocardiograms [36, 37, 38] , • sensors or mobile data from wearable devices or sensors recorded and stored as time series [39, 40] , • omics data which are complex and high-dimensional genomic, epigenomic, transcriptomic, metabolomic, exposomic, and proteomic measurements [41, 42] . An advantage of ML methods over conventional statistical modelling is their flexibility and scalability in exploiting diverse and complex data types. Table 1 summarises a few selected application examples in terms of their domain, type of data, ML approach, and task. Below we compile further recent works using various methods and types of data mentioned above. Supervised Learning Arguably, the most common ML approach in healthcare is supervised learning. Linear [43] and logistic [44] regression models and decision trees [45] are simple, reliable, and effective supervised learning algorithms used on a variety of datasets to this day. Some examples include the classification of sagittal gait patterns in neurology [46] , prediction of diabetes severity [47] , breast cancer survival prediction [48, 49] , diagnosis of acute appendicitis [50] using clinical data, activity classification [51] and fall detection in elderly people [52] from wearable sensors, and prediction of interactions between target genes and drugs [53] using omics data. However, simpler models often under-perform on data featuring nonlinear effects and interactions, and therefore, more flexible methods may be required, such as random forests [54] or gradient boosting ma-chines [55] . Some of the applications of random forests are the prediction of the risk of developing hypertension [56] , the severity and outcome of COVID-19 [57] , breast cancer recurrence [58] , identification of various diseases, such as hepatitis, Parkinson's [59, 40] or Type 2 Diabetes Mellitus [60] using clinical and wearable sensors data. Furthermore, applications based on omics data also exist, e.g. for improving hazard characterisation in microbial risk assessment [61] or identifying gene signatures for the diagnosis of tuberculosis [62] . In medical images, the most commonly used models are based on DNNs, applied to a number of different modalities including • X-ray images for predicting pneumonia [63] , tuberculosis [64] or other pathologies [38] , multi-organ segmentation [65] , image registration [66] , pathology localisation [67, 68, 69] ; • retinal images for predicting diabetic retinopathy grading [36, 70] , age-related macular degeneration [71] or retinopathy of prematurity [72] , simultaneous segmentation of retinal anatomical structures, such as retinal vessel and optic disc [73] , or pathologies, such as exudates, haemorrhages, microaneurysms, or retinal neovascularization [74, 75] ; • heart echocardiograms for cardiac image segmentation [76, 77, 78] , identification of local cardiac structures and estimation of cardiac function [79, 80, 81] , view classification [82] , and the reduction of user variability in data acquisition [83] ; • mammography images to improve breast cancer classification [84, 85] , lesion localisation [86, 87] , and risk assessment [88, 89] ; • dermoscopy images for classifying skin cancer [37, 90, 91] , skin lesion segmentation [92] , or detection and localisation of cutaneous vasculature [93] ; • MR images for brain tumour grading assessment [94] , classification of prostate cancer [95] , age estimation [96] or Alzheimer's disease detection [97] from brain images, cardiac multi-structures segmentation [98] or left ventricle segmentation in cardiac MRI [99] ; • CT images for liver tumour assessment [100] , classification of brain images for diagnosis of Alzheimer's disease [101] , haemorrhage detection [102, 103] , COVID-19 pneumonia classification [104] , abdominal [105] or urinary bladder [106] segmentation. There is accumulating evidence that DNNs have already led to improved accuracy for computer-aided applications in various medical imaging modalities. Moreover, interest and advances in deep learning are still developing rapidly in the ML for healthcare community, bringing the performance of ML methods to a level that is acceptable by the clinicians. Semi-supervised Learning The cost of acquiring raw medical images is often negligible in comparison to expert annotations, labels, or scores. Thus, instead of using expensive supervised learning, many authors leverage semi-supervised learning (SSL) approaches [31] , which rely on unsupervised learning techniques to work with a mixture of labelled and unlabelled data. For medical images, the scarcity of labelled data is often a limitation for both segmentation and classification tasks. To this end, SSL has been leveraged for X-ray [107] , MR [108, 109, 110] and CT [111] image, MS lesion [112] and gland [113] segmentation. For the classification task, SSL methods have been applied for cardiac abnormality classification in chest X-rays [114] , and skin lesion diagnosis [115] or gastric disease identification from endoscopic images [116] . Pulmonary nodule detection in CT scans [117] using SSL is also possible. Unsupervised Learning Unsupervised learning methods further loosen the burden of manual annotation by exploiting unlabelled data without any supervision. It might be helpful to find interesting patterns or structure in the data, which can be, for example, used for anomaly detection. Various problems in the healthcare setting can be solved using unsupervised learning: disease clustering and patient subgrouping using EHR [118] , fMRI time series [119] data or genomic makeup [120] , genomic segmentation [121] , dimensionality reduction prior to anomaly detection [122] or classification of mammography images [123] . Unsupervised learning has been applied to various imaging modalities, e.g. X-ray image retrieval [124] , blood vessel segmentation in retinal images [125] , breast density segmentation and scoring in mammography [126] , probabilistic atlas-based segmentation [127] and denoising of contrast-enhanced sequences in MR images [128] , and lung nodule characterisation in CT images [129] . Reinforcement Learning In RL, an agent learns from new experiences through a continuous trial-anderror process [130] . This approach has been used in different medical scenarios, e.g. for optimal and individualised treatment strategies for HIV infected patients [131] , for cancer trials [132] , and for sepsis patients [133] , forecasting the risk of diabetes [134] , segmenting transrectal US images to estimate location and volume of the prostate [135] , surgical decision-making [136] , predicting CpG islands in the human genome [137] , increasing the accuracy of biological sequence annotation [138] . The rapid progress in ML triggered considerable interest and created numerous opportunities for data-driven applications in healthcare, which in the future might lead to advancements in clinical practice like semiautomated and more accurate diagnosis or the development of novel and more personalised treatment strategies. Despite these reasons for cautious optimism, plenty of under-explored opportunities, unaddressed limitations and concerns exist. In the following, we elaborate on some open problems. Limitations, Challenges, and Opportunities While it is undoubted that ML can be instrumental in developing data-driven decision support systems, the use of machine learning and promises associated with it have come under scrutiny [7, 139, 140] . Machine learning is not a panacean magic crystal ball: it relies on large amounts of high-quality, representative, and unbiased data [7] and is not a substitute for rigorous study and data system design or causal inference [139] . Prior to applying ML methods to health data, we should be critical and ask ourselves whether there actually exists use cases for our ML model [140] , whether we possess a sufficiently large dataset representative of the population of interest, whether the features we will use are commonly available in practice, whether we would be able to validate the model externally, whether our model will be accepted by its target users [141, 142] . Some of the recent lines of work attempt to alleviate and address these and similar concerns. Below we discuss a few open challenges and areas of active research which could be of interest to both ML methodologists and practitioners working in healthcare. Lack of Data, Labels, and Annotations Data scarcity is a very important problem since data lie at the heart of any ML project. For most of the applications, in addition to data collection, the annotation is an expensive task. Furthermore, medical data are personal and accessing and labelling it has its own challenges. Moreover in case of rare diseases, class imbalance makes the use of ML algorithms more challenging. To overcome these problems, different terms for learning are proposed which do not entirely depend on manually labelled data: self-supervised learning, where the model leverages the underlying structure of the data [143] , semi-supervised learning using a small amount of labelled combined with a large amount of unlabelled data during training [31] , weakly-supervised learning using the supervision of noisy labels [32] , Personalised patient-centred decision-making [136] and few-shot learning for generalising from a small amount of labelled data without using any unlabelled data [144] . Learning across Domains, Tasks, and Modalities ML methods generally assume that the training and test sets feature similar patterns and relationships, which usually does not hold for healthcare applications. Domain adaptation is a promising solution and gets an increasing attention in recent years [145] . Furthermore, trained models usually suffer from overspecialising at individual tasks which tend to not generalise either [146] . As a response, multi-task learning was proposed, which is inspired by human learning and proposes to use shared concepts to extract the common ideas among a collection of related tasks [147, 148] . Moreover, clinicians typically make use of multiple data modalities in their decisionmaking, including imaging, time series data, such as ECG signals, clinical data, such as lab results, and non-structured data, such as clinical notes. Combining data from different modalities lies at the centre of multimodal learning [149, 150] . Data Sharing, Privacy, and Security Despite the spectacular advances in the ML domain, there is a concern regarding privacy and security in the proposed data-driven methods. This is traditionally quite a challenging issue in the healthcare setting due to the fact that ML models need to work with personal information [151] . The need for patient privacy while implementing ML methods using large datasets triggers the urge for automated models which respect privacy and security. The issue has recently been picked up by official authorities, e.g. in the EU the General Data Protection Regulation (GDPR) was implemented [152, 153] . This decision accelerated the field of secure and privacy-preserving ML research to bridge the gap between data protection and utilisation for clinical routine [154, 155] . Interpretable and Explainable Machine Learning Machine learning models are increasingly incorporated into high-stakes decision-making [142, 156] , including healthcare [157] . With methodological advances and empirical success of deep learning, ML models have become even more performant, yet larger and more complex. As a response, there is a surge of interest in designing ML systems that are transparent and trustworthy. Interpretable [158, 159, 156] and explainable [160] machine learning typically refer to models that are either directly comprehensible or can explain and present their decisions post hoc in terms understandable to the target user. Many interesting research questions originate from this line of work, pertinent to healthcare as well. For instance, does ML even need to be interpretable or explainable, what is a 'good' interpretation/explanation in the considered application, how can we make model's interpretations/explanations insightful and/or actionable? Fair Machine Learning The fact that ML methods are data-driven does not necessarily make their decisions fair, ethical, or moral [161] . Datasets and ML models are products of the larger sociotechnical system we live in and inevitably reflect the state of the society with all of its disparities [162] . Fairness [161, 163] has become an important principle for machine-learning-based algorithmic decision-making and given rise to many technical challenges, such as mitigating demographic disparities captured by ML models [164] , documenting and reporting ML models in a transparent manner [165] , and documenting datasets, their contents, characteristics, and intended uses [166] . Many of these considerations are equally applicable to ML for healthcare [163] where personalisation based on sensitive information could sometimes lead to undesirable disparate outcomes [161] . Towards Causally-informed Models Many clinical and scientific research questions inherently require causal reasoning [167] , e.g. treatment effect estimation or counterfactual outcome prediction. The 'big data' alone are meaningless, unless researchers are equipped with adequate tools that actually can address their questions [168] . Causality [169] is a field of study which formalises our reasoning about cause-and-effect relationships. In the recent years, it has been argued that many challenging open ML problems are closely related to causality and the inability of the naïve purely data-driven models to reason causally [170, 171, 172] . This realisation is an important step towards data collection and ML model development that are informed by the causal perspective. Naturally, causal considerations matter for healthcare applications of ML as well: causally-informed ML models tend to be more stable and avoid the pitfalls of a purely predictive approach. For example, when analysing medical imaging data [173] with highly heterogeneous anatomical and acquisition conditions, causality could help mitigate irrelevant correlations picked up by a predictive model due to confounding in the training data. 4 Conclusion: Quo Vadis? In this overview, we have introduced the basics of machine learning, types of tasks it is able to tackle, explained its relationships with other well-established fields, and illustrated its utility in healthcare with a variety of applied research. We have seen that opportunities for application are numerous: ML offers an algorithmic solution to the automated analysis of complex and unwieldy datasets. It is beyond doubt that ML and AI hold promises of automating routine clinical tasks [174] , reducing costs [175] , and improving healthcare access and quality [176] , especially, in developing economies. Some researchers have even optimistically proclaimed that deep learning will replace human specialists altogether, for example, in radiology [177, 38, 178] . Not surprisingly, their bold predictions have not come to pass yet, and a wide-spread, clinically meaningful adoption of ML 'in the wild' still stands as an ambitious task for both the research and industry. The next decades will show if and how these promises are delivered. Likely, it is by supporting, complementing, and relieving healthcare professionals of tedious routine (and not by replacing them) that ML and AI will 'make the difference'. To achieve this kind of harmony, we need an interdisciplinary collaboration among healthcare specialists, ML practitioners, and methodologists [142] . To facilitate a dialogue on equal terms, we should improve the overall digital, machine learning, and statistical literacy among medical students [179, 180] and disseminate subject matter knowledge among machine learning practitioners [181] . Lastly, to implement this ambitious project in practice, we have to develop regulatory frameworks and economic incentives [8] , establish large-scale data infrastructures [182] , and collect high-quality representative datasets [183] . While all of this requires a considerable initial investment, the machine-learning-powered medicine is a worthy cause. Figure 1 : 1 Figure 1: Types of machine learning approaches: (a) supervised, (b) unsupervised, and (c) reinforcement learning. (a) In supervised learning, an ML model extracts predictive patterns from labelled data. (b) In unsupervised learning, a model discovers structure from unlabelled data. (c) In reinforcement learning, an agent interacts with the surrounding environment by sequentially performing actions to maximise received reward. Table 1 : 1 A few selected healthcare application examples summarised in terms of the application domain, type of data, ML approach, and task. Description Application Domain Data Type ML Approach ML Task"
}