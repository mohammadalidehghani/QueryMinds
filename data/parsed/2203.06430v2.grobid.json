{
  "title": "Categories of Differentiable Polynomial Circuits for Machine Learning",
  "abstract": "Reverse derivative categories (RDCs) have recently been shown to be a suitable semantic framework for studying machine learning algorithms. Whereas emphasis has been put on training methodologies, less attention has been devoted to particular model classes: the concrete categories whose morphisms represent machine learning models. In this paper we study presentations by generators and equations of classes of RDCs. In particular, we propose polynomial circuits as a suitable machine learning model. We give an axiomatisation for these circuits and prove a functional completeness result. Finally, we discuss the use of polynomial circuits over specific semirings to perform machine learning with discrete values.",
  "introduction": "Introduction Reverse Derivative Categories [11] have recently been introduced as a formalism to study abstractly the concept of differentiable functions. As explored in [12] , it turns out that this framework is suitable to give a categorical semantics for gradient-based learning. In this approach, models-as for instance neural networks-correspond to morphisms in some RDC. We think of the particular RDC as a 'model class'-the space of all possible definable models. However, much less attention has been directed to actually defining the RDCs in which models are specified: existing approaches assume there is some chosen RDC and morphism, treating both essentially as a black box. In this paper, we focus on classes of RDCs which we call 'polynomial circuits', which may be thought of as a more expressive version of the boolean circuits of Lafont [17] , with wires carrying values from an arbitrary semiring instead of Z 2 . Because we ensure polynomial circuits have RDC structure, they are suitable as machine learning models, as we discuss in the second part of the paper. Our main contribution is to provide an algebraic description of polynomial circuits and their reverse derivative structure. More specifically, we build a presentation of these categories by operation and equations. Our approach will proceed in steps, by gradually enriching the algebraic structures considered, and culminate in showing that a certain presentation is functionally complete for the class of functions that these circuits are meant to represent. An important feature of our categories of circuits is that morphisms are specified in the graphical formalism of string diagrams. This approach has the benefit of making the model specification reflect its combinatorial structure. Moreover, at a computational level, the use of string diagrams makes available the principled mathematical toolbox of double-pushout rewriting, via an interpretation of string diagrams as hypergraphs [7, 8, 9] . Finally, the string diagrammatic presentation suggests a way to encode polynomial circuits into datastructures: an important requirement for being able to incorporate these models into tools analogous to existing deep learning frameworks such as TensorFlow [2] and Py-Torch [19] . Tool-building is not the only application of the model classes we define here. Recent neural networks literature [5, 10] proposes to improve model performance (e.g. memory requirements, power consumption, and inference time) by 'quantizing' network parameters. One categorical approach in this area is [23] , in which the authors define learning directly over boolean circuit models instead of training with real-valued parameters and then quantizing. The categories in our paper can be thought of as a generalisation of this approach to arbitrary semirings. This generalisation further yields another benefit: while neural networks literature focuses on finding particular 'architectures' (i.e. specific morphisms) that work well for a given problem, our approach suggests a new avenue for model design: changing the underlying semiring (and thus the corresponding notion of arithmetic). To this end, we conclude our paper with some examples of finite semirings which may yield new approaches to model design.",
  "body": "Introduction Reverse Derivative Categories [11] have recently been introduced as a formalism to study abstractly the concept of differentiable functions. As explored in [12] , it turns out that this framework is suitable to give a categorical semantics for gradient-based learning. In this approach, models-as for instance neural networks-correspond to morphisms in some RDC. We think of the particular RDC as a 'model class'-the space of all possible definable models. However, much less attention has been directed to actually defining the RDCs in which models are specified: existing approaches assume there is some chosen RDC and morphism, treating both essentially as a black box. In this paper, we focus on classes of RDCs which we call 'polynomial circuits', which may be thought of as a more expressive version of the boolean circuits of Lafont [17] , with wires carrying values from an arbitrary semiring instead of Z 2 . Because we ensure polynomial circuits have RDC structure, they are suitable as machine learning models, as we discuss in the second part of the paper. Our main contribution is to provide an algebraic description of polynomial circuits and their reverse derivative structure. More specifically, we build a presentation of these categories by operation and equations. Our approach will proceed in steps, by gradually enriching the algebraic structures considered, and culminate in showing that a certain presentation is functionally complete for the class of functions that these circuits are meant to represent. An important feature of our categories of circuits is that morphisms are specified in the graphical formalism of string diagrams. This approach has the benefit of making the model specification reflect its combinatorial structure. Moreover, at a computational level, the use of string diagrams makes available the principled mathematical toolbox of double-pushout rewriting, via an interpretation of string diagrams as hypergraphs [7, 8, 9] . Finally, the string diagrammatic presentation suggests a way to encode polynomial circuits into datastructures: an important requirement for being able to incorporate these models into tools analogous to existing deep learning frameworks such as TensorFlow [2] and Py-Torch [19] . Tool-building is not the only application of the model classes we define here. Recent neural networks literature [5, 10] proposes to improve model performance (e.g. memory requirements, power consumption, and inference time) by 'quantizing' network parameters. One categorical approach in this area is [23] , in which the authors define learning directly over boolean circuit models instead of training with real-valued parameters and then quantizing. The categories in our paper can be thought of as a generalisation of this approach to arbitrary semirings. This generalisation further yields another benefit: while neural networks literature focuses on finding particular 'architectures' (i.e. specific morphisms) that work well for a given problem, our approach suggests a new avenue for model design: changing the underlying semiring (and thus the corresponding notion of arithmetic). To this end, we conclude our paper with some examples of finite semirings which may yield new approaches to model design. Synopsis We recall the notion of RDC in Section 2, and then study presentations of RDCs by operations and equations in Section 3. We define categories of polynomial circuits in Section 4, before showing how they can be made functionally complete in Section 5. Finally, we close by discussing some case studies of polynomial circuits in machine learning, in Section 6. Reverse Derivative Categories We recall the notion of reverse derivative category [11] in two steps. First we introduce the simpler structure of cartesian left-additive categories. We make use of the graphical formalism of string diagrams [20] to represent morphisms in our categories. Definition 1. A Cartesian Left-Additive Category ( [11] , [6] ) is a cartesian category in which each object A is equipped with a commutative monoid and zero map: A A A A (1) so that = = = A ⊗ B A ⊗ B A ⊗ B = A B A A B B A ⊗ B = A B (2) Note that the category being cartesian means that: (I) it is symmetric monoidal, namely for each object A and B there are symmetries B A A B and identities A A satisfying the laws of symmetric monoidal categories [20] ; (II) each object A comes equipped with a copy and a discard map: A A A A (3) satisfying the axioms of commutative comonoids and natural with respect to the other morphisms in the category: = = = f = f f f = (4 x (f + g) = (x f ) + (x g) x 0 = 0 are represented by string diagrams f g x = f g x x x = and follow from Definition 1 thanks to the naturality of and , respectively. We refer to [6, Proposition 1.2.2 (iv)] for more details on the equivalence of the two definitions. Now, Reverse Derivative Categories, originally defined in [11] , are cartesian left-additive categories equipped with an operator R of the following type, and satisfying axioms RD.1 -RD.7 detailed in [11, Definition 13] . A f -→ B A × B -→ R[f ] A Intuitively, for a morphism f : A → B we think of its reverse derivative R[f ] : A × B → A as approximately computing the change of input to f required to achieve a given change in output. That is, if f is a function, we should have f (x) + δ y ≈ f (x + R[f ](x, δ y )) The authors of [11] go on to show that any reverse derivative category also admits a forward differential structure: i.e, it is also a Cartesian Differential Category (CDC). This means the existence of a forward differential operator D satisfying various axioms, and having the following type: A f -→ B A × A -→ D[f ] B In an RDC, the forward differential operator is defined in terms of R as the following string diagram, with R (n) denoting the n-fold application 3 of R: D[f ] := R (2) [f ] In contrast to the R operator, we think of D as computing a change in output from a given change in input, whence 'forward' and 'reverse' derivative: f (x + δ x ) ≈ f (x) + D[f ](x, δ x ) The final pieces we need to state our definition of RDCs are the (cartesian differential) notions of partial derivative and linearity defined in [11] . Graphically, the partial derivative of g : A × B → C with respect to B is defined as follows: D B [g] := D[g] A B B C Finally we say that g is linear in B when D B [g] = g A B C B and more generally that f : A → B is linear when D[f ] = f B B A 3 For example, R (2) [f ] denotes the map R[R[f ]]. We can now formulate the definition of RDCs. Note that in the following definition and proofs we treat D purely as a syntactic shorthand for its definition in terms of R. We avoid use of CDC axioms to prevent a circular definition, although one can derive them as corollaries of the RDC axioms. Definition 2. A Reverse Derivative Category is a cartesian left-additive category equipped with a reverse differential combinator R: A f -→ B A × B -→ R[f ] A satisfying the following axioms: [ARD.1] (Structural axioms, equivalent to RD.1, RD.3-5 in [11] ) R [ ] = R = R = R = R [ ] = R [ ] = R[f g] = f R[g] R[f ] R[f × g] = R[f ] R[g] [ARD.2] (Additivity of change, equivalent to RD.2 in [11] ) R[f ] = R[f ] R[f ] R[f ] = [ARD. 3] (Linearity of change, equivalent to RD.6 in [11] ) D B [R[f ]] = R[f ] [ARD.4] (Symmetry of partials, equivalent to RD.7 in [11] ) D (2) [f ] = D (2) [f ] Remark 2. Note that we may alternatively write axioms ARD.3 and ARD.4 directly in terms of the R operator by simply expanding the syntactic definition of D. Note that axioms ARD.1 and ARD.2 are quite different to that of [11] , while ARD.3 and ARD.4 are essentially direct restatements in graphical language of RD.6 and RD.7 respectively. The definition we provide best suits our purposes, although it is different than the standard one provided in [11, Definition 13] . We can readily verify that they are equivalent. Theorem 1. Definition 2 is equivalent to [11, Definition 13] . Proof. Axioms ARD.3-4 are direct statements of axioms RD.6-7, so it suffices to show that we can derive axioms ARD.1-2 from RD.1.5 and vice-versa. The structural axioms ARD.1 follow directly from RD.1 and RD.3-5. -For R [ ] use RD.3 directly. -For R , apply RD.4 to π 1 , π 0 -For R , apply RD.1 to π 0 + π 1 -For R [ ], apply RD.1 directly. -For R , apply RD.4 to id, id -For R [ ], apply RD.4 directly. -For composition f g, apply RD.5 directly -For tensor f × g, apply RD.4 to π 0 f, π 1 g In the reverse direction, we can obtain RD.1 and RD.3-5 by simply constructing each equation and showing it holds given the structural equations. For example, RD. R [0] = 0, which we can write graphically as: 1 says that R[f +g] = R[f ]+R[g] and R   f g   = R [f ] + R [g] and R [ ] = ARD.2 can be derived from RD.2 by setting a, b, c to appropriate projections, and in the reverse direction we can obtain RD.2 simply by applying ARD.2 to its left-hand-side and using naturality of . A main reason to give an alternative formulation of cartesian left-additive and reverse derivative categories is being able to work with a more 'algebraic' definition, which revolves around the interplay of operations , , , and . This perspective is particularly useful when one wants to show that the free category on certain generators and equations has RDC structure. We thus recall such free construction, referring to [24, Chapter 2] and [4, Section 5] for a more thorough exposition. Definition 3. Given a set Obj of generating objects, we may consider a set Σ of generating morphisms f : w → v, where the arity w ∈ Obj ⋆ and the coarity v ∈ Obj ⋆ of f are Obj -words. Cartesian left-additive Σ-terms are defined inductively: -Each f : w → v is a Σ-term. -For each A ∈ Obj , the generators (1) and (3) of the cartesian left-additive structure are Σ-terms. -If f : w → v, g : v → u, and h : w ′ → v ′ are Σ-terms, then f g : w → u and f ⊗ h : ww ′ → vv ′ are Σ-terms, represented as string diagrams f w v g u f w v h w ′ v ′ Let us fix Obj , Σ and a set E of equations between Σ-terms. The cartesian left-additive category C freely generated by (Obj , Σ, E) is the monoidal category with set of objects Obj ⋆ and morphisms the Σ-terms quotiented by the axioms of cartesian left-additive categories and the equations in E. The monoidal product in C is given on objects by word concatenation. Identities, monoidal product and sequential composition of morphisms are given by the corresponding Σ-terms and their constructors f ⊗ h and f g. One may readily see that C defined in this way is indeed cartesian leftadditive. We say that C is presented by generators (Obj , Σ) and equations E. Reverse Derivatives and Algebraic Presentations As we will see in Section 5, our argument for functional completeness relies on augmenting the algebraic presentation of polynomial circuits with an additional operation. To formulate such result, we first need to better understand how reverse differential combinators may be defined compatibly with the generators and equations presenting a category. Theorem 2. Let C be the cartesian left-additive category presented by generators (Obj , Σ) and equations E. If for each s ∈ Σ there is some R[s] which is well-defined (see Remark 3) with respect to E, and which satisfies axioms ARD.1-4, then C is a reverse derivative category. Proof. Observe that axioms ARD.1 fix the definition of R on composition, tensor product and the cartesian and left-additive structures. It therefore suffices to show that axioms ARD.2-4 are preserved by composition and tensor product. That is, for morphisms f, g of appropriate types, both f g and f ⊗ g preserve axioms ARD.2-4. Thus, any morphism constructed from generators must also satisfy the axioms ARD.1-4, and C must be an RDC. We provide the full graphical proofs that ARD.2-4 are preserved by composition and tensor product in Appendix A. Remark 3. In the statement of Theorem 2, strictly speaking s ∈ Σ is just a representative of the equivalence class of Σ-terms (modulo E plus the laws of left-additive cartesian categories) defining a morphism in C . Because of this, we require R[s] to be 'well-defined', in the sense that if s and t are representatives of the same morphisms of C , then the same should hold for R[s] and R[t]. In a nutshell, we are allowed to define R directly on Σ-terms, provided our definition is compatible with E and the laws of left-additive cartesian categories. An immediate consequence of Theorem 2 is that if we have a presentation of an RDC C , we can 'freely extend' it with an additional operation s, a chosen reverse derivative R[s], and equations E ′ , so long as R is well-defined with respect to E ′ and the axioms ARD.2-4 hold for R[s]. Essentially, this gives us a simple recipe for adding new 'gadgets' to existing RDCs and ensuring they retain RDC structure. One particularly useful such 'extension' is the addition of a multiplication morphism that distributes over the addition . We define categories with such a morphism as an extension of cartesian left-additive categories as follows: Definition 4. A Cartesian Distributive Category is a cartesian left-additive category such that each object A is equipped with a commutative monoid and unit which distributes over the addition . More completely, it is a category having generators satisfying the cartesianity equations (4), the left-additivity equations (2), the multiplicativity equations = = = (5) and the distributivity and annihilation equations = = (6) Just as for cartesian left-additive categories, one may construct cartesian distributive categories freely from a set of objects Obj , a signature Σ, and equations E, the difference being that Σ-term will be constructed using also and , and quotiented also by ( 5 )- (6) . The main example of cartesian distributive categories are Polynomial Circuits, which we define in Section 4 below. Reverse derivative categories define a reverse differential combinator on a left-additive cartesian structure. As cartesian distributive categories properly extend left-additive ones, it is natural to ask how we may extend the definition of the reverse differential combinator to cover the extra operations and . The following theorem provide a recipe, which we will use in the next section to study RDCs with a cartesian distributive structure. Note that the definition of R * below is a string diagrammatic version of the reverse derivative combinator defined on POLY in [11] . Theorem 3. Suppose C is a left-additive cartesian category presented by (Obj , Σ, E), and assume C is also an RDC, say with reverse differential combinator R. Then the cartesian distributive category C * presented by (Obj , Σ, E), with reverse differential combinator R * defined as R on the left-additive cartesian structure, and as follows R * = R * [ ] = (7) on the extra distributive structure, is also an RDC. Proof. It suffices to check that R is well-defined with respect to the additional equations of cartesian distributive categories, and that the new generators and satisfy axioms ARD.2-4. Polynomial Circuits Our motivating example of cartesian distributive categories is that of polynomial circuits, whose morphisms can be thought of as representing polynomials over a commutative semiring. We define them as follows: Definition 5. Let S be a commutative semiring. We define PolyCirc S as the cartesian distributive category presented by (I) one generating object 1, (II) for each s ∈ S, a generating morphism s : 0 → 1, (III) the 'constant' equations 0 = s t = s + t 1 = s t = s • t (8 ) for s, t ∈ S, intuitively saying that the generating morphisms respect addition and multiplication of S. Proposition 1. PolyCirc S is an RDC with R s = . Proof. The type of R s : 1 → 0 implies that there is only one choice of reverse derivative, namely the unique discard map . Furthermore, R is welldefined with respect to the constant equations ( 8 ) for the same reason. Finally, observe that the axioms ARD.2-4 hold for R s , precisely in the same way as for R [ ], and so PolyCirc S is an RDC. Although our Definition 5 of PolyCirc S requires that we add an axiom for each possible addition and multiplication of constants, for some significant choices of S an equivalent smaller finite axiomatisation is possible. We demonstrate this with some examples. Example 1. In the case of PolyCirc Z2 , the equations of Definition 5 reduce to the single equation = expressing that x + x = 0 for both elements of the field Z 2 . Example 2. In the case PolyCirc N of the semiring of natural numbers, with the usual addition and multiplication, no extra generating morphisms or equations are actually necessary: all those appearing in Definition 5 may be derived from the cartesian distributive structure. To see why, notice that we may define each constant s ∈ S as repeated addition: s := s where we define n inductively as 0 := n := n -1 The equations expressing addition and multiplication in N are then a consequence of those of cartesian distributive categories. In fact, from this observation we have that PolyCirc N is the free cartesian distributive category on one generating object. Example 3. In a straightforward generalization of PolyCirc Z2 , we can define PolyCirc Zn in the same way, but with the only additional equation as n = which says algebraically that (1 + n . . . + 1) • x = n • x = 0 • x = 0. It is important to note that PolyCirc S is isomorphic to the category POLY S , defined as follows: Definition 6. POLY S is the symmetric monoidal category with objects the natural numbers and arrows m → n the n-tuples of polynomials in m indeterminates: p 1 ( x), . . . , p n ( x) : m → n with each p i ∈ S[x 1 , . . . , x m ] where S[x 1 , . . . x m ] denotes the polynomial ring in m indeterminates over S. The isomorphism PolyCirc S ∼ = POLY S is constructed by using that homsets PolyCirc S (m, n) and POLY S (m, n) have the structure of the free module over the polynomial ring S[x 1 . . . x m ] n which yields a unique module isomorphism between them. We do not prove this isomorphism here, other than to say that it follows by the same argument as presented in [11, Appendix A]. Remark 4. Note in [11] POLY S is proven to be a reverse derivative category, meaning that we could have derived Proposition 1 as a corollary of the isomorphism PolyCirc S ∼ = POLY S . We chose to provide a 'native' definition of the reverse differential combinator of PolyCirc S because-as we will see shortly-we will need to extend it with an additional generator. The reason for this is to gain the property of 'functional completeness', which will allow us to express any function S m → S n . This new derived category will in general no longer be isomorphic to POLY S , and so we must prove it too is an RDC: we do this straightforwardly using Theorem 2. Remark 5. When S is a bonafide ring, we may account for its inverse by extending PolyCirc S with a 'negate' generating morphism , together with the additional equation = . Then Theorem 2 suggests us how to extend the reverse differential combinator of PolyCirc S to this new category: R [ ] := Functional Completeness We are now ready to consider the expressivity of the model class of polynomial circuits. More concretely, for a given commutative semiring S, we would like to be able to represent any function between sets S m → S n as a string diagram in PolyCirc S . This property, which we call 'functional completeness', is important for a class of machine learning models to satisfy because it guarantees that we may always construct an appropriate model for a given dataset. It has been studied, for instance, in the context of the various 'universal approximation' theorems for neural networks (see e.g. [16] , [18] ). To formally define functional completeness, let us fix a finite set S. Recall the cartesian monoidal category FinSet S , whose objects are natural numbers and a morphism m → n is a function of type S m → S n . Definition 7. We say a category C is functionally complete with respect to a finite set S when there a full identity-on-objects functor F : C → FinSet S . The intuition for Definition 7 is that we call a category C 'functionally complete' when it suffices as a syntax for FinSet S -that is, by fullness of F we may express any morphism in FinSet S . Note however that two distinct morphisms in C may represent the same function -F is not necessarily faithful. In general, PolyCirc S is not functionally complete with respect to S. Take for example the boolean semiring B with multiplication and addition as AND and OR respectively. It is well known [21] that one cannot construct every function of type B m → B n from only these operations. Nonetheless, we claim that in order to make PolyCirc S functionally complete it suffices to add to its presentation just one missing ingredient: the 'comparator' operation, which represents the following function: compare(x, y) = 1 if x = y 0 otherwise The following result clarifies the special role played by the comparator. Theorem 4. Let S be a finite commutative semiring. A category C is functionally complete with respect to S iff. there is a monoidal functor F : C → FinSet S in whose image are the following functions: - → s for each s ∈ S (constants) -x, y → x + y (addition) -x, y → x • y (multiplication) -compare Proof. Suppose C is functionally complete with respect to S, where S is a finite commutative semiring. Then by definition there is a functor F : C → FinSet S with each of the required functions in its image. Now in the reverse direction, we will show that any function can be constructed only from constants, addition, multiplication, and comparison. The idea is that because S is finite, we can simply encode the function table of any function f : S m → S as the following expression: x → s∈S m compare(s, x) • f (s) (9) Further, since C is cartesian, we may decompose any function f : S m → S n into an n-tuple of functions of type S m → S. More intuitively, for each of the n outputs, we simply look up the appropriate output in the encoded function table. It follows immediately that PolyCirc S is functionally complete with respect to S if and only if one can construct the compare function in terms of constants, additions, and multiplications. We illustrate one such case below. Example 4. PolyCirc Zp is functionally complete for prime p. To see why, recall Fermat's Little Theorem [13] , which states that a p-1 ≡ 1(mod p) for all a > 0. Consequently, we have that (p -1) • a p-1 + 1 = 1 if a = 0 0 otherwise We denote this function as δ(a) := (p -1) • a p-1 + 1 to evoke the dirac delta 'zero indicator' function. To construct the compare function is now straightforward: compare(x 1 , x 2 ) = s∈S δ(x 1 + s) • δ(x 2 + s) However, as we already observed, it is not possible in general to construct the compare function in terms of multiplication and addition. Therefore, to guarantee functional completeness we must extend the category of polynomial circuits with an additional comparison operation. Definition 8. We define by PolyCirc = S as the cartesian distributive category presented by the same objects, operations, and equations of PolyCirc S , with the addition of a 'comparator' operation = ( 10 ) and equations = s s = = s t = (11) for s, t ∈ S with s = t. To make PolyCirc = S a reverse derivative category, we can once again appeal to Theorem 2. However, we must choose an apropriate definition of R[compare] which is well-defined and satisfies axioms ARD.1-4. A suggestion for this choice comes from the machine learning literature. In particular, the use of the 'straight-through' estimator in quantized neural networks, as in e.g. [5] . Typically, these networks make use of the dirac delta function in the forward pass, but this causes a catastrophic loss of gradient information in the backwards pass since the gradient is zero almost everywhere. To fix this, one uses the straight-through estimator, which instead passes through gradients directly from deeper layers to shallower ones. In terms of reverse derivatives, this amounts to setting R[δ] = R[id]. Of course, we need to define R for the full comparator, not just the zero-indicator function δ, and so we make the following choice: Theorem 5. PolyCirc = S is an RDC with R as for PolyCirc S , and R = := Proof. R is well-defined with respect to the equations ( 11 ) since both sides of each equation must equal the unique discard morphism . Further, R = satisfies axioms ARD.2-4 in the same way that R does, and so by Theorem 2 PolyCirc = S is a reverse derivative category. From Theorem 4, we may derive: Corollary 1. PolyCirc = S is functionally complete with respect to S. Finally, note that we recover the dirac delta function by 'capping' one of the comparator's inputs with the zero constant: δ := = 0 whose reverse derivative is equivalent to the 'straight-through' estimator: R = 0 = = R [ ] 6 Polynomial Circuits in Machine Learning: Case Studies We now discuss the implications of some specific choices of semiring from a machine learning perspective. Let us begin with two extremes: neural networks, and the boolean circuit models of [23] . Neural Networks We may think of a neural network as a circuit whose wires carry values in R. Of course, in order to compute with such circuits we must make a finite approximation of the reals-typically using floating-point numbers. However, this approximation introduces two key issues. First, floating point arithmetic is significantly slower than integer arithmetic. Second, the floating point operations of addition and multiplication are not even associative, which introduces problems of numerical instability. Although attempts exist to address issues of floating point arithmetic (such as 'posits' [1] ), these still do not satisfy the ring axioms; to properly account for these approximations would require additional work. Boolean Circuits and Z 2 One may note that since we must always eventually deal with finite representations of values, we may as well attempt to define our model class directly in terms of them. This is essentially the idea of [23] : the authors use the category PolyCirc Z2 (which they call simply PolyCirc) as a model class since it is already functionally complete 4 and admits a reverse derivative operator. However, using a semiring of modular arithmetic in general introduces a different problem: one must be careful to construct models so that gradients do not 'wrap around'. Consider for example the model below, which can be thought of as two independent sub-models f 1 and f 2 using the same parameters foot_0 but applied to different parts of the input X 1 and X 2 f 1 f 2 P X 1 X 2 Y Since R = R , when we compute the gradient update for P we will sum the gradients of f 1 and f 2 . In the extreme case when the underlying semiring is Z 2 , then when the gradients of f 1 and f 2 are both 1, the result will 'wrap around' to 0 and P will not be updated. This is clearly undesirable: here we should prefer that 1 + 1 = 1 to 1 + 1 = 0. Saturating Arithmetic Another possible solution is to use the semiring Sat n as a model of saturating unsigned integer arithmetic for a given 'precision' n. The underlying set is simply the finite set n, with addition and multiplication defined as for the naturals, but 'truncated' to at most n -1. We define Sat n as follows, noting that it is equivalent to the semiring B(n, n-1) first defined in [3, Example 3] (see also [15] ). Definition 9. The semiring Sat n has as addition and multiplication the operations x 1 + x 2 := min(n -1, x 1 + x 2 ) x 1 • x 2 := min(n -1, x 1 • x 2 ) over the set n := {0 . . . n -1} Note that while Sat n is a commutative semiring, it is certainly not a ring: the introduction of inverses means that the associativity axiom of semirings is violated. Finally, note that for each of these choices of semiring S, in general PolyCirc S is not functionally complete. Thus, in order to obtain a model class which is functionally complete and is a reverse derivative category, we must use PolyCirc = S . Conclusions and Future Work In this paper, we studied in terms of algebraic presentations categories of polynomial circuits, whose reverse derivative structure makes them suitable for machine learning. Further, we showed how this class of categories is functionally complete for finite number representations, and therefore provides sufficient expressiveness. There remain however a number of opportunities for theoretical and empirical work. On the empirical side, we plan to use this work combined with data structures and algorithms like that of [22] as the basis for practical machine learning tools. Using these tools, we would like to experimentally verify that models built using semirings like those presented in Section 6 can indeed be used to develop novel model architectures for benchmark datasets. There also remains a number of theoretical avenues for research. First, we want to generalise our approach to functional completeness to the continuous case, and then to more abstract cases such as polynomial circuits over the Burnside semiring. Second, we want to extend the developments of Section 3 in order to provide a reverse derivative structure for circuits with notions of feedback and delay, such as the stream functions described in [14] . A Graphical Proofs of Extension Theorem We now prove Theorem 2. We split the proof into the following lemmas: 1. ARD.2 is preserved by composition 2. ARD.2 is preserved by tensor product 3. ARD.3/RD.6 is preserved by composition 4. ARD.3/RD.6 is preserved by tensor product 5. ARD.4/RD.7 is preserved by composition 6. ARD.4/RD.7 is preserved by tensor product In each case, when we say 'ARD.x is preserved by composition' we mean that if f and and g satisfy ARD.x, then so too does f g, and likewise for tensor product. Let us now address these lemmas in order. Lemma 1. ARD.2 is preserved by composition Proof. Assume that ARD.2 holds for f : A → B and g : B → C. For the zero case, apply the chain rule and use the hypothesis twice to obtain the result as follows: R[f g] = f R[g] R[f ] = f R[f ] = R[f ] = In the additive case we proceed similarly by expanding definitions, applying the hypothesis, and then using associativity and commutativity of to obtain the final result: R[f g] = f R[g] R[f ] = R[g] R[g] f R[f ] = R[g] R[g] f R[f ] R[f ] = R[g] R[g] R[f ] R[f ] f f = f R[g] R[f ] f R[g] R[f ] = R[f g] R[f g] Lemma 2. ARD.2 (RD.2) is preserved by tensr product For the zero case, R[f ⊗ g] = R[f ] R[g] = R[f ] R[g] = And now in the additive case,  3) [f ] R[f ⊗ g] = R[f ] R[g] = R[f ] R[g] = R[f ] R[f ] R[g] R[g] = R[f ] R[g] R[f ] R[g] = R[f ⊗ g] R[f ⊗ g] D C [R[f g]] = R (3) [f g] = R ( R (3) [g] f R[g] f = f R[g] f R[f ] R[g] = f R[f ] R[g] = R[f g] Note that in the first step, we must expand R (3) using repeated application of the chain rule-we have omitted much of this tedious calculation. In the second step where we apply the inductive hypothesis, then naturality of to finally obtain the result. D (2) [f g] = f D[f ] D (2) [g] D[f ] D (2) [f ] = f D[f ] D (2) [g] D[f ] D (2) [f ] = f D[f ] D (2) [g] D[f ] D (2) [f ] = f D[f ] D (2) [g] D[f ] D (2) [f ] = D (2) [f g] As with the proof for RD.6 we omit a great deal of tedious expansion and calculation from the first step of the proof, which is obtained simply by expanding D (2) [f g] in terms of R and using naturality of to simplify the result. In remaining steps, we apply of the assumption that ARD.4 holds for f and g, before finally using naturality of . Note that although the above derivation is written in terms of D, each step of the proof treats the D operator merely as a syntactic sugar for its definition in terms of R. Each step of the proof thus uses only axioms of RDCs, rather than the forward differential structure defined in terms of it. Lemma 6. ARD.4 (RD.7) is preserved by tensor product Proof. Assume that ARD.4 holds for f : A 1 → B 1 and g : A 2 → B 2 . Then we may calculate as follows, first expanding the definition of D, and then using the inductive hypothesis to obtain the result: D (2) [f ⊗ g] = D (2) [f ] D (2) [g] = D (2) [f ] D (2) [g] = D (2) [f ] D (2) [g] = D (2) [f ⊗ g] It is now straightforward to prove Theorem 2. ) Remark 1 . 1 Definition 1 is given differently than the standard definition of cartesian left-additive categories [11, Definition 1], which one may recover by letting addition of morphisms be f + g := f g , and the zero morphism be 0 := . Equations of cartesian left-additive categories as given in [11, Definition 1] Lemma 3 . 3 ARD.3 (RD.6) is preserved by compositionProof. Assume that ARD.3 holds for f : A → B and g : B → C. Now calculate: Lemma 4 . 4 ARD.3 (RD.6) is preserved by tensor productProof. Assume that ARD.4 holds for f : A → B and g : B → C. Now we can calculate as follows: This approach is called 'weight-tying' in neural networks literature."
}