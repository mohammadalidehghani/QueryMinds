{
  "title": "On the Conditions for Domain Stability for Machine Learning: a Mathematical Approach",
  "abstract": "This work proposes a mathematical approach that (re)defines a property of Machine Learning models named stability and determines sufficient conditions to validate it. Machine Learning models are represented as functions, and the characteristics in scope depend upon the domain of the function, what allows us to adopt topological and metric spaces theory as a basis. Finally, this work provides some equivalences useful to prove and test stability in Machine Learning models. The results suggest that whenever stability is aligned with the notion of function smoothness, then the stability of Machine Learning models primarily depends upon certain topological, measurable properties of the classification sets within the ML model domain.",
  "introduction": "Introduction In recent years, the study of Artificial Intelligence and related techniques, like Machine Learning, has attracted considerable attention from practitioners, engineers and researchers from many sectors. Such interest has been, in many respects, driven by questions and concerns raised and shared by the involved communities. In particular, it can be mentioned the need for safety of systems integrating AI algorithms and the possibility to achieve acceptable means for compliance, necessary for regulation and certification [3] [2] [1] . Despite autonomy is a well-known notion within the Systems, SW and HW engineering arenas, the usage of AI technology, (GenAI, LLMs, ML/DL) to carry out functions traditionally conducted under human supervision and control, induces new challenges [4] . Discussing referred challenges is out of the scope of this paper: notwithstanding the relevance of AI challenges and risks, they are currently under inspection and study by a variety of experts, following a plethora of approaches, ranging from conceptual to empirical/pragmatical [5] [10] . From the variety and heterogeneity of those studies, a consensus seems to emerge: despite the significant advances in AI technology, a considerable amount of requirements and properties still need to be ensured for the AI systems to be trustworthy and aligned with requirements. It is known that the lack of properties like robustness, generalization, and stability in ML models can have impacts at different system levels [11] . Several authors even highlight a lack of methods to validate and ensure referred properties [7] . In addition, the observed uncertainty of ML performance raise questions on the foundations of the AI algorithms. A basis for their sound design and validation seems necessary but still missing. This work aims to provide a preliminary mathematical basis to analyze ML models abstracted as functions. It mainly introduces a property named stability, which appears to be fundamental for ML classification. This preliminary work provides some equivalences which can be useful to prove stability. Topological and metric spaces [6] [9] were adopted as foundation to conduct this work which also relies on the theory of functional analysis [8] .",
  "body": "Introduction In recent years, the study of Artificial Intelligence and related techniques, like Machine Learning, has attracted considerable attention from practitioners, engineers and researchers from many sectors. Such interest has been, in many respects, driven by questions and concerns raised and shared by the involved communities. In particular, it can be mentioned the need for safety of systems integrating AI algorithms and the possibility to achieve acceptable means for compliance, necessary for regulation and certification [3] [2] [1] . Despite autonomy is a well-known notion within the Systems, SW and HW engineering arenas, the usage of AI technology, (GenAI, LLMs, ML/DL) to carry out functions traditionally conducted under human supervision and control, induces new challenges [4] . Discussing referred challenges is out of the scope of this paper: notwithstanding the relevance of AI challenges and risks, they are currently under inspection and study by a variety of experts, following a plethora of approaches, ranging from conceptual to empirical/pragmatical [5] [10] . From the variety and heterogeneity of those studies, a consensus seems to emerge: despite the significant advances in AI technology, a considerable amount of requirements and properties still need to be ensured for the AI systems to be trustworthy and aligned with requirements. It is known that the lack of properties like robustness, generalization, and stability in ML models can have impacts at different system levels [11] . Several authors even highlight a lack of methods to validate and ensure referred properties [7] . In addition, the observed uncertainty of ML performance raise questions on the foundations of the AI algorithms. A basis for their sound design and validation seems necessary but still missing. This work aims to provide a preliminary mathematical basis to analyze ML models abstracted as functions. It mainly introduces a property named stability, which appears to be fundamental for ML classification. This preliminary work provides some equivalences which can be useful to prove stability. Topological and metric spaces [6] [9] were adopted as foundation to conduct this work which also relies on the theory of functional analysis [8] . Defining Stability Definition 1. Let (S, d) a metric space, D i ⊂ S, i = 1 . . . m, a finite sequence of sets. M is a classifier on S for the sets {D i } if: i) M is a function defined on m i=1 D i ii) D i ∩ D j = ∅, ∀i = j iii) ∃y i ∈ M (D i ), ∀x ∈ D i ⇒ M (x) = y i , i = 1 . . . m iv) For y i , y j as in previous point, if i = j ⇒ y i = y j Note 1. Given a metric space (S, d) the following notation is used for the neighborhood of a point x o ∈ S: B(x o , δ) = {x ∈ S | d(x o , x) < δ} Note 2. In Definition 1, a point x ∈ D i , M (x) = y i is denoted by x y i . The assignation M (x y i ) = y i can also be denoted by x y i M --→ y i . Definition 2. Let (S, d) a metric space, D ⊂ S and M a classifier for D and D c . x y ∈ D is said a stable point of M in D if it is satisfied: i) M (x y ) = y ii) ∃δ > 0, ∀x ∈ B(x y , δ) ⇒ x ∈ D, M (x) = y iii) For δ as in point ii), ∀δ α ≤ δ ∃x ∈ B(x y , δ α ), x = x y Practically, the existence of stable points for a classifier M implemented in a programming language, relies upon the limited/finite precision of computers. Indeed, the precision of a machine can be approximated, for instance, by an iterative algorithm taking ε o > 0 as input and computing ε n+1 = ε n /2 n at each iteration n. The stopping criterion is when 1 + ε n = 1. Then, a candidate for δ is any number k-times bigger than ε n . i.e. δ := kε n . The Definition 2 helps to identify cases where classifiers are unable to smoothly classify subsets within its domain, as can be seen in the following example. Example 1. Let M be a classifier in the interval S = [0, 1], with the 1euclidean metrics for the sets D 1 = I ∩ S and D 2 = Q ∩ S. Given that D 1 and D 2 are dense, then the set of stable points of M in D i is empty. Dense sets and Implications for Stability The implications of dense sets regarding the existence (absence) of stable points is formalized in this subsection. [6] . Let's assume there is x j ∈ S such that x j ∈ D j , j = k, is a stable point for M . Then M (x j ) = j and ∃δ > 0 such that B(x j , δ) ⊂ D j . However, since D k is dense in S, then B(x j , δ) ∩ D k = ∅. Then for any point x ∈ B(x j , δ) ∩ D k , it occurs that M (x) = j and M (x) = k, and x ∈ D j ∩ D k which contradicts Definition 1 i), ii), iv) and Definition 2, ii). QED. Definition 3. Let (S, d) a metric space. A set D ⊂ S is said dense in S if ∀x ∈ S, ∀δ > 0, B(x, δ) ∩ D = ∅ [9], Alternatives to Prove Stability Some equivalences are provided as alternatives to prove stability. [⇒] Let's assume x y ∈ D is a stable point of M . It will be proved that x y is an accumulation point of D. Let's consider ε > 0 arbitrary but fixed. Then since x y ∈ D is a stable point of M , M (x y ) = y and ∃δ > 0 such that B(x y , δ) ⊂ D and ∀δ α ≤ δ, ∃x ∈ B(x y , δ α ), x = x y . The following cases exist: If ε < δ: then B(x y , ε) ⊂ B(x y , δ) ⊂ D, since ∃x ∈ B(x y , ε), x = x y , it follows that x ∈ D, which leads directly to B(x y , ε) ∩ D\\{x y } = ∅. If ε > δ: since x y ∈ D is stable point of M , then ∃x ∈ B(x y , δ) ⊂ B(x y , ε), x = x If ε < δ: then B(x y , ε) ⊂ D and B(x y , ε) ∩ D c = ∅ what is a contra- diction If ε > δ: then B(x y , δ) ⊂ B(x y , ε) ⊂ D, what conflicts with the as- sumption ∀δ α < δ, B(x y , δ α ) ∩ D c = ∅ Therefore ∃δ α < δ such that B(x y , δ α )∩D c = ∅ what implies B(x y , δ α ) ⊂ D, thus ∀x ∈ B(x y , δ α ) ⇒ M (x) = y. QED. Accumulation series As shown in previous subsection, a classifier M defined over an open set is stable for every accumulation point therein. The equivalence provided in the following lemma provides further means to prove stability. if ∀{x n } series, such that lim n→∞ x n = x y , x n = x y , ∃{s k } sub-series of {x n } such that ∃k o , k ≥ k o , ⇒ s k ∈ D, s k = x y , lim k→∞ s k = x y . [⇒] Let's assume x y is a stable point of M . Let {x n } be a series such that lim n→∞ x n = x y , x n = x y , then ∃δ > 0 such that B(x y , δ) ⊂ D. For such δ, ∃n o such that ∀n > n o , d(x y , x n ) < δ, what means that ∀n > n o , x n ∈ B(x y , δ) ⊂ D, then M (x n ) = y, x n = x y . Then, we can define the sub-series of {x n } as {s k } = {x n } ∩ B(x y , δ) ∩ D\\{x y } = ∅. Thus, by its construction, {s k } satisfies ∃k o , k ≥ k o , ⇒ s k ∈ D, s k = x y , lim k→∞ s k = x y . [⇐] Let δ > 0. Then, if lim n→∞ x n = x y , x n = x y , and ∃{s k } a sub-series of {x n } such that ∃k o , k ≥ k o , ⇒ s k ∈ D, s k = x y , lim k→∞ s k = x y , let ε = d(s ko , x y ). The following cases exist: If ε < δ: ∀k > k o , ⇒ s k ∈ B(x y , ε) ⊂ B(x y , δ) and s k ∈ D, s k = x y , therefore ∀k > k o , s k ∈ D ∩ B(x y , δ)\\{x y } = ∅. If ε > δ: since lim k→∞ s k = x y , then for the given δ, ∃k 1 such that ∀k ≥ k 1 , d(x y , s k ) < δ. If k 2 = max{k o , k 1 }, then ∀k > k 2 , s k ∈ B(x y , δ) ⊂ B(x y , ε) and s k ∈ D, s k = x y , therefore ∀k > k 2 , s k ∈ D ∩ B(x y , δ)\\{x y } = ∅. Thus, in any case x y is an accumulation point. Then by lemma 3, the conclusion follows. QED. Discussion Machine Learning models and their respective implementations include some uncertainties due to singularity regions. As such, the abstraction provided in this paper named classifier (Definition 1) is indeed a rough approximation of ML models. Nonetheless, the results obtained mostly rely upon properties of the domain of the ML model and not in the classifier itself. An important claim in this approach is that the conditions for ML stability depend, in a first place, upon certain topological and measurable properties of the space, namely density, accumulation and openness. Overall, open and bounded sets are suitable candidates sets for stable classification. As it is shown, if such topological/metric properties are not ensured, classifiers cannot ensure a stable operation. This approach shall be leveraged, by adapting the notion of classifier so as to consider the uncertainty of classifiers. This is left as a future work. The equivalence between stability and the so named accumulation series is intended to facilitate the specification of algorithms to test (absence of) stability. Whereas accumulation points and the density of sets are simple notions, they can be hard to verify on complex, high dimension domains. Then the notion of accumulation series seeks for a discrete solution, more adapted to finite/limited precision of computers. A description of such discrete algorithms was barely sketched but not formally defined. Conclusions This work aims to provide further understanding regarding foundational aspects of Machine Learning models. The first part of this paper introduces a definition for stability, a property that appears fundamental for the proper operation of classifiers which are defined as a function that abstracts the uncertainty of real Machine Learning models. Secondly, some limits of classifiers were explained which appear whenever one or more classification sets are dense. Indeed, it was proved that the stability of classifiers demands the absence of dense sets in the domain of classification (also called Operational Design Domain) (Lemmas 1, 2). Some basic but representative examples were provided to illustrate such limitations. The last part of this work provides alternatives to prove stability in the form of equivalences: Lemma 3 provides conditions for equivalence between stability and accumulation points, then, Lemma 4 proves the equivalence between accumulation points and so named accumulation series, also introduced in this paper. The resulting equivalence between stability and accumulation series provides the possibility to define finite, discrete algorithms to prove stability. The definition of referred algorithms is not included in this paper and will be addressed as a continuation of this work. Lemma 1 . 1 Let (S, d) a metric space and M a classifier for D ⊂ S and D c . If D c is dense in S then the set of stable points in D is empty. First, S = D ∪ D c . Let's assume x o ∈ D a stable point of M , then ∃δ > 0 such that B(x o , δ) ⊂ D. Since D c is dense in S, then B(x o , δ) ∩ D c = ∅. However, if x ∈ B(x o , δ) ∩ D c then x ∈ D c and by definition 2, ii) x ∈ D what contradicts the assumption. QED. By exchanging roles between D and D c in previous lemma, the following corollary is proved. Corollary 1. Let (S, d) a metric space and M a classifier for D ⊂ S and D c . If D is dense, then D c does not have any stable point. Corollary 2. Let S ⊂ R a (non-empty) interval, then there is no classifier M able to classify S ∩ I and S ∩ Q. Indeed, since (S ∩ Q) = (S ∩ I) c and S ∩ I = (S ∩ Q) c are both dense, by lemma 1 and Corollary 1 the conclusion follows. QED. The previous results, which hold particularly for intervals in R, are generalized in the following lemma.Lemma 2. Let (S, d) a metric space and M a classifier for a collection of sets D 1 . . . D n ⊂ S such that S = ∪ n i=1 D i . If there is D k dense in S then there is no stable point for M in any of the sets D i for i = k. 4. 1 1 Accumulation Points Definition 4. Let (S, d) a metric space. Given a set D ⊂ S, a point x ∈ S is an accumulation point of D if ∀δ > 0 then B(x, δ) ∩ D\\{x} = ∅ [9] [6]. Lemma 3. Let (S, d) a metric space and M a classifier for D and D c , with both D and D c not dense in S and D an open set. Then x y ∈ D is a stable point for M if and only if x y is an accumulation point of D. y and x ∈ D, what also leads to B(x y , ε) ∩ D\\{x y } = ∅. [⇐] Now, let's assume x y is an accumulation point of D, an open set. It will be proved that x y ∈ D is a stable point of M . By definition, ∀δ > 0, B(x y , δ) ∩ D\\{x y } = ∅. Let δ > 0 arbitrary but fixed. Then, since ∀δ α ≤ δ, B(x y , δ α ) ∩ D\\{x y } = ∅, this implies that ∃x α ∈ B(x y , δ α ) ∩ D, x α = x y . Therefore, M (x α ) = y since x α ∈ D and M classifier for D and D c . Previous statement holds for any δ α ≤ δ. Let's assume ∀δ α < δ, B(x y , δ α ) ∩ D c = ∅. Since D is open and x y ∈ D, then ∃ε > 0 such that B(x y , ε) ⊂ D. The following cases exist: Lemma 4 . 4 Let (S, d) a metric space and M a classifier for D and D c , with both D and D c not dense in S and D an open set. x y is a stable point of M if and only"
}