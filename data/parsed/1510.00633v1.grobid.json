{
  "title": "Distributed Multitask Learning",
  "abstract": "We consider the problem of distributed multi-task learning, where each machine learns a separate, but related, task. Specifically, each machine learns a linear predictor in high-dimensional space, where all tasks share the same small support. We present a communication-efficient estimator based on the debiased lasso and show that it is comparable with the optimal centralized method.",
  "introduction": "Introduction Learning multiple tasks simultaneously allows transferring information between related tasks and for improved performance compared to learning each tasks separately [Caruana, 1997] . It has been successfully exploited in, e.g., spam filtering [Weinberger et al., 2009] , web search [Chapelle et al., 2010] , disease prediction [Zhou et al., 2013] and eQTL mapping [Kim and Xing, 2010] . Tasks could be related to each other in a number of ways. In this paper, we focus on the high-dimensional multi-task setting with joint support where a few variables are related to all tasks, while others are not predictive [Turlach et al., 2005; Obozinski et al., 2011; Lounici et al., 2011] . The standard approach is to use the mixed ℓ 1 /ℓ 2 or ℓ 1 /ℓ ∞ penalty, as such penalties encourage selection of variables that affect all tasks. Using a mixed norm penalty leads to better performance in terms of prediction, estimation and model selection compared to using the ℓ 1 norm penalty, which is equivalent to considering each task separately. Shared support multi-task learning is generally considered in a centralized setting where data from all tasks is available on a single machine, and the estimator is computed using a standard single-thread algorithm. With the growth of modern massive data sets, there is a need to revisit multi-task learning in a distributed setting, where tasks and data are distributed across machines and communication is expensive. In particular, we consider a setting where each machine holds one \"task\" and its related data. We develop an efficient distributed algorithm for multi-task learning that exploits shared sparsity between tasks. Our algorithm (DSML) requires only one round of communication between the workers and the central node, involving each machine sending a vector to the central node and receiving back a support set. Despite the limited communication, our algorithm enjoys the same theoretical guarantees, in terms of the leading term in reasonable regimes and mild conditions, as the centralized approach. Table 1 summarizes our support recovery guarantees compared to the centralized (group lasso) and local (lasso) approaches, while",
  "body": "Introduction Learning multiple tasks simultaneously allows transferring information between related tasks and for improved performance compared to learning each tasks separately [Caruana, 1997] . It has been successfully exploited in, e.g., spam filtering [Weinberger et al., 2009] , web search [Chapelle et al., 2010] , disease prediction [Zhou et al., 2013] and eQTL mapping [Kim and Xing, 2010] . Tasks could be related to each other in a number of ways. In this paper, we focus on the high-dimensional multi-task setting with joint support where a few variables are related to all tasks, while others are not predictive [Turlach et al., 2005; Obozinski et al., 2011; Lounici et al., 2011] . The standard approach is to use the mixed ℓ 1 /ℓ 2 or ℓ 1 /ℓ ∞ penalty, as such penalties encourage selection of variables that affect all tasks. Using a mixed norm penalty leads to better performance in terms of prediction, estimation and model selection compared to using the ℓ 1 norm penalty, which is equivalent to considering each task separately. Shared support multi-task learning is generally considered in a centralized setting where data from all tasks is available on a single machine, and the estimator is computed using a standard single-thread algorithm. With the growth of modern massive data sets, there is a need to revisit multi-task learning in a distributed setting, where tasks and data are distributed across machines and communication is expensive. In particular, we consider a setting where each machine holds one \"task\" and its related data. We develop an efficient distributed algorithm for multi-task learning that exploits shared sparsity between tasks. Our algorithm (DSML) requires only one round of communication between the workers and the central node, involving each machine sending a vector to the central node and receiving back a support set. Despite the limited communication, our algorithm enjoys the same theoretical guarantees, in terms of the leading term in reasonable regimes and mild conditions, as the centralized approach. Table 1 summarizes our support recovery guarantees compared to the centralized (group lasso) and local (lasso) approaches, while Distributed Learning and Optimization With the increase in the volume of data used for machine learning, and the availability of distributed computing resources, distributed learning and the use of distributed optimization for machine learning has received much attention. Most work on distributed optimization focuses on \"consensus problems\", where each machine holds a different objective f i (β) and the goal is to communicate between the machines so as to jointly optimize the average objective 1/m i f i (β), that is, to find a single vector β that is good for all local objectives [Boyd et al., 2011] . The difficulty of consensus problems is that the local objectives might be rather different, and, as a result, one can obtain lower bounds on the amount of communication that must be exchanged in order to reach a joint optimum. In particular, the problem becomes harder as more machines are involved. The consensus problem has also been studied in the stochastic setting [Ram et al., 2010] , in which each machine receive stochastic estimates of its local objective. Thinking of each local objective as a generalization error w.r.t. a local distribution, we obtain the following distributed learning formulation [Balcan et al., 2012] : each machine holds a different source distribution D i from which it can sample, and this distribution corresponds to a different local generalization error f i = E (X,y)∼D i [loss(β, X, y)]. The goal is to find a single predictor β that minimizes the average generalization error, based on samples sampled at the local nodes. Again, the problem becomes harder when more machines are involved and one can obtain lower bounds on the amount of communication required- [Balcan et al., 2012] carry out such an analysis for several hypothesis classes. A more typical situation in machine learning is one in which there is only a single source distribution D, and data from this single source is distributed randomly across the machines (or equivalently, each machine has access to the same source distribution D i = D). Such a problem can be reduced to a consensus problem by performing consensus optimization of the empirical errors at each machine. However, such an approach ignores several issues: first, the local empirical objectives are not arbitrarily different, but rather quite similar, which can and should be taken advantage of in optimization [Shamir et al., 2014] . Second, since each machine has access to the source distribution, there is no lower bound on communication-an entirely \"local\" approach is possible, were each machine completely ignores other machines and just uses its own data. In fact, increasing the number of machines only makes the problem easier (in that it can reduce the runtime or number of samples per machine required to achieve target performance), as additional machines can always be ignored. In such a setting, the other relevant baseline is the \"centralized\" approach, where all data is communicated to a central machine which computes a predictor centrally. The goal here is then to obtain performance close to that of the \"centralized\" approach (and much better than the \"local\" approach), using roughly the same number of samples, but with low communication and computation costs. Such single-source distributed problems have been studied both in terms of predictive performance [Shamir and Srebro, 2014; Jaggi et al., 2014] and parameter estimation [Zhang et al., 2013b,a; Lee et al., 2015] . In this paper we suggest a novel setting that combines aspects of the above two extremes. On one hand, we assume that each machine has a different source distributions D i (X, y), corresponding to a different task, as in consensus problems and in [Balcan et al., 2012] . For example, each machine serves a different geographical location, or each is at a different hospital or school with different characteristics. But if indeed there are differences between the source distributions, it is natural to learn different predictors β i for each machine, so that β i is good for the distribution typical to that machine. In this regard, our distributed multi-task learning problem is more similar to single-source problems, in that machines could potentially learn on their own given enough samples and enough time. Furthermore, availability of other machines just makes the problem easier by allowing transfer between the machine, thus reducing the sample complexity and runtime. The goal, then, is to leverage as much transfer as possible, while limiting communication and runtime. As with single-source problems, we compare our method to the two baselines, where we would like to be much better than the \"local\" approach, achieving performance nearly as good as the \"centralized\" approach, but with minimal communication and efficient runtime. To the best of our knowledge, the only previous discussion of distributed multi-task learning is [Dinuzzo et al., 2011] , which considered a different setting with an almost orthogonal goal: a client-server architecture, where the server collects data from different clients, and send sufficient information that might be helpful for each client to solve its own task. Their emphasis is on preserving privacy, but their architecture is communication-heavy as the entire data set is communicated to the central server, as in the \"centralized\" bases line. On the other hand, we are mostly concerned with communication costs, but, for the time being, do not address privacy concerns. Preliminaries We consider the following multi-task linear regression model with m tasks: y t = X t β * t + t , t = 1, . . . , m, (1) where X t ∈ R nt×p , y t ∈ R nt , and t ∼ N (0, σ 2 t I) ∈ R nt is a noise vector, and β * t is the unknown vector of coefficients for the task t. For notation simplicity we assume each task has equal sample size and the same noise level, that is, we assume, n 1 = n 2 = . . . = n and σ 1 = σ 2 = . . . = σ. We will be working in a high-dimensional regime with p possibly larger than n, however, we will assume that each β * t is sparse, that is, few components of β * t are different from zero. Furthermore, we assume that the support between the tasks is shared. In particular, let S t = support(β * t ) = {j ∈ [p] : β tj = 0}, with S 1 = S 2 = . . . = S and s = |S| n. Suppose the data sets (X 1 , y 1 ), . . . , (X m , y m ) are distributed across machines, our goal is to estimate {β * t } m t=1 as accurately as possible, while maintaining low communication cost. The lasso estimate for each task t is given by: βt = arg min βt 1 n y t -X t β t 2 2 + λ t β t 1 . (2) The multi-task estimates are given by the joint optimization: { βt } m t=1 = arg min {βt} m t=1 1 mn t=1 y t -X t β t 2 2 + λpen({β t } m t=1 ), (3) where pen({β t } m t=1 ) is the regularizaton that promote group sparse solutions. For example, the group lasso penalty uses pen( {β t } m t=1 ) = j∈[p] t∈m β 2 tj [Yuan and Lin, 2006] , while the iCAP uses pen( Zhao et al., 2009] . In a distributed setting, one could potentially minimize (3) using a distributed consensus procedure (see Section 2), but such an approach would generally require multiple round of communication. Our procedure, described in the next section, lies in between the local lasso (2) and centralized estimate (3), requiring only one round of communication to compute, while still ensuring much of the statistical benefits of using group regularization. {β t } m t=1 ) = j∈[p] max t=1,...,m |β tj | [ Methodology In this section, we detail our procedure for performing estimation under model in ( 16 ). Algorithm 1 provides an outline of the steps executed by the worker nodes and the master node, which are explained in details below. Recall that each worker node contains data for one task. That is, a node t contains data (X t , y t ). In the first step, each worker node solves a lasso problem locally, that is, a node t minimizes the program in (2) and obtains βt . Next, a worker node constructs a debiased lasso estimator βu t by performing one Newton step update on the loss function, starting at the estimated value βt : βu t = βt + n -1 M t X T t (y t -X t βt ), (4) Algorithm 1: DSML:Distributed debiased Sparse Multi-task Lasso. Workers: for t = 1, 2, . . . , m do Each worker obtains βt as a solution to a local lasso in (2); Each worker obtains βu t the debiased lasso estimate in (17) and sends it to the master; if Receive Ŝ(Λ) from the master then Calculate final estimate βt in (6). end end Master: if Receive { βu t } m t=1 from all workers then Compute Ŝ(Λ) by group hard thresholding in( 5 ) and send the result back to every worker. end where n -1 X T t (y t -X t βt ) is a subgradient of the ℓ 1 norm and the matrix M t ∈ R p×p serves as an approximate inverse of the Hessian. The idea of debiasing the lasso estimator was introduced in the recent literature on statistical inference in high-dimensions [Zhang and Zhang, 2013; van de Geer et al., 2014; Javanmard and Montanari, 2014] . By removing the bias introduced through the ℓ 1 penalty, one can estimate the sampling distribution of a component of βu t and make inference about the unknown parameter of interest. In our paper, we will also utilize the sampling distribution of the debiased estimator, however, with a different goal in mind. The above mentioned papers proposed different techniques to construct the matrix M . Here, we adopt the approach proposed in [Javanmard and Montanari, 2014] , as it leads to weakest assumption on the model in ( 16 ): each machine uses a matrix M t = ( mtj ) p j=1 with rows: mtj = arg min m j ∈R p m T j Σt m j subject to Σt m j -e j ∞ ≤ µ. where e j is the vector with j-th component equal to 1 and 0 otherwise and Σt = n -1 X T t X t . After each worker obtains the debiased estimator βu t , it sends it to the central machine. After debiasing, the estimator is no longer sparse and as a result each worker communicates p numbers to the master node. It is at the master where shared sparsity between the task coefficients gets utilized. The master node concatenates the received estimators into a matrix B = ( βu 1 , βu 2 , ..., βu m ). Let Bj be the j-th row of B. The master performs the hard group thresholding to obtain an estimate of S as Ŝ(Λ) = {j | Bj 2 > Λ}. (5) The estimated support Ŝ(Λ) is communicated back to each worker, which then use the estimate of the support to filter their local estimate. In particular, each worker produces the final estimate: βtj = βu tj if j ∈ Ŝ(Λ) 0 otherwise. ( 6 ) Extension to multitask classification. DSML can be generalized to estimate multitask generalized linear models. We be briefly outline how to extend DSML to a multi-task logistic regression model, where y tk ∈ {-1, 1} and: P (y tk |X tk ) = exp 1 2 y tk X tk β * t exp -1 2 y tk X tk β * t + exp 1 2 y tk X tk β * t , ∀k = 1, . . . , n, t = 1, . . . , m. (7) First, each worker solves the ℓ 1 -regularized logistic regression problem βt = arg min βt 1 n k∈[n] log(1 + exp(-y tk X tk β t )) + λ t β t 1 . Let W t ∈ R n×n be a diagonal weighting matrix, with a k-th diagonal element W t(kk) = 1 1 + exp(-X tk βt ) • exp(-X tk βt ) 1 + exp(-X tk βt ) , which will be used to approximately invert the Hessian matrix of the logistic loss. The matrix M t = ( mtj ) p j=1 , which serves as an approximate inverse of the Hessian, in the case of logistic regression can be obtained as a solution to the following optimization problem: mtj = arg min m tj ∈R p m T tj X t T W t X t m tj subject to n -1 X T t W t X t m tj -e j ∞ ≤ µ. Finally, the debiased estimator is obtained as βu t = βt + n -1 M t X t T 1 2 (y t + 1) -1 + exp(-X t βt ) -1 , and then communicated to the master node. The rest of procedure is as described before. Theoretical Analysis In this section, we present our main theoretical results for the DSML procedure described in the previous section. We start by describing assumptions that we make on the model in ( 16 ). Our results are based on the random design analysis, and we also discuss fixed design case in appendix. Let the data X t for t-task are drawn from a subgaussian random vector with covariance matrix E[n -1 X T t X t ] = Σ t . We assume the subguassian random vectors for every task have bounded subgaussian norm: max t max k X tk ψ 2 ≤ σ X [Vershynin, 2012] . Let λ min (Σ) to be the minimal eigenvalue of Σ, and λ max (Σ) be its maximal eigenvalue. Let λ min = min t∈[m] λ min (Σ t ) and λ max = max t∈[m] λ max (Σ t ) be the bound on the eigenvalues of these covariance matrices. Let K be the maximal diagonal elements of the inverse convariance matrices: K = max t∈[m] max j∈[p] (Σ -1 t ) jj , The following theorem is our main result, which is proved in appendix. Theorem 1. Suppose λ in (2) was chosen as λ t = 4σ log p n . Furthermore, suppose that the multi-task coefficients in (16) satisfy the following bound on the signal strength min j∈S t∈[m] (β * tj ) 2 ≥ 6Kσ m + log p n + Cσ 4 X λ 1/2 max σ|S| √ m log p λ 3/2 min n := 2Λ * , (8) where C < 5000. Then the support estimated by the master node satisfies Ŝ(Λ * ) = S with probability at least 1 -mp -1 . Let us compare the minimal signal strength to that required by the lasso and group lasso. Let B = [β 1 , β 2 , . . . , β m ] ∈ R p×m be the matrix of true coefficients. Simplifying (8), we have that our procedure requires the minimum signal strength to satisfy min j∈S 1 √ m B j 2 1 n 1 + log p m + |S| log p n , (9) where a(n) b(n) means that for some c, N , a(n) > c • b(n), ∀n > N . For the centralized group lasso, the standard analysis assumes a stronger condition on the data, namely that the design matrix satisfies mutual incoherence with parameter α and sparse eigenvalue condition. Mutual incoherence is a much stronger conditions on the design in comparison to the generalized coherence condition required by DSML. Group lasso recovers the support if [Corollary 5.2 of Lounici et al., 2011] : min j∈S 1 √ m B j 2 ≥ 4 √ 2C α,κ σ √ n 1 + 2.5 log p m 1 n 1 + log p m . ( 10 ) where C α,κ is some constant depend on the mutual incoherence and sparse eigenvalue parameters. Under the irrepresentable condition on the design (which is weaker than the mutual incoherence), the lasso requires the signal to satisfy [Bunea, 2008; Wainwright, 2009] : min t∈[m] min j∈S |β * tj | ≥ C γ,κ σ log p n log p n (11) for some constant C γ,κ of the mutual coherence parameter γ and of κ. Ignoring for the moment the differences in the conditions on the design matrix, there are two advantages of the multitask group lasso over the local lasso: relaxing the signal strength requirement to a requirement on the average strength across tasks, and a reduction by a factor of m on the log p term. Similarly to the group lasso, DSML requires a lower bound only on the average signal strength, not on any individual coefficient. And as long as m n, or more precisely n m|S| 2 (log p) 2 κ 2 (m+log p) enjoys the same linear reduction in the dominant term of the required signal strength, match the leading term of the group lasso bound. Based on Theorem 1, we have the following corollary that characterizes estimation error and prediction risk of DSML, with the proof given in the appendix. Corollary 2. Suppose the conditions of Theorem 1 hold. With probability at least 1mp -1 , we have p j=1 Bj -B j 2 ≤ 6K|S|σ m + log p n + Cσ 4 X λ 1/2 max σ|S| 2 √ m log p λ 3/2 min n and 1 nm m t=1 (E Xt (X T t βt -X T t β * t )) 2 ≤ 36K 2 |S|σ 2 n 1 + log p m + C 2 σ 8 X λ max σ 2 |S| 3 (log p) 2 λ 3 min n 2 . Let us compare these guarantees for to the group lasso. For DSML Corollary 2 yields: 1 √ m p j=1 Bj -B j 2 |S| √ n 1 + log p m + |S| 2 log p n , (12) When using the group lasso, the restricted eigenvalue condition is sufficient for obtaining error bounds and following holds for the group lasso [Corollary 4.1 of Lounici et al., 2011] : 1 √ m p j=1 Bj -B j 2 ≤ 32 √ 2σ|S| κ √ n 1 + 2.5 log p m |S| √ n 1 + log p m , (13) which is min-max optimal (up to a logarithmic factor). Albeit with the stronger generalized coherence condition, DSML matches this bound when n m|S| 2 (log p) 2 (m+log p) . Similarly for prediction DSML attains: 1 nm m t=1 (E Xt (X T t βt -X T t β * t )) 2 |S|σ 2 n 1 + log p m + σ 2 |S| 3 (log p) 2 n 2 , ( 14 ) which in the same regime matches the group lasso minimax optimal rate: 1 nm m t=1 (E Xt (X T t βt -X T t β * t )) 2 ≤ 128|S|σ 2 κn 1 + 2.5 log p m |S|σ 2 n 1 + log p m . (15) In both cases, as long as m is not too large, we have a linear improvement over Lasso, which corresponds to ( 13 ) and ( 15 ) with m = 1. Experimental results Our first set of experiments is on simulated data. We generated synthetic data according to the model in ( 16 ) and in (7). Rows of X t are sampled from a mean zero multivariate normal with the covariance matrix Σ = (Σ ab ) a,b∈[p] , Σ ab = 2 -|a-b| . The data dimension p is set to 200, while the number of true relevant variables s is set to 10. Non-zero coefficients of β are generated uniformly in [0, 1]. Variance σ 2 is set to 1. Our simulation results are averaged over 200 independent runs. We investigate how performance of various procedures changes as a function of problem parameters (n, p, m, s). We compare the following procedures: i) local lasso, ii) group lasso, iii) refitted group lasso, where a worker node performs ordinary least squares on the selected support, iv) iCAP, and v) DSML. The parameters for local lasso, group lasso and iCAP were tuned to achieve the minimal Hamming error in variable selection. For DSML, to debias the output of local lasso estimator, we use µ = log p/n. The thresholding parameter Λ is also optimized to achive the best variable selection performance. The simulation results for regression are shown in Figure 1 . In terms of support recovery (measured by Hamming distance), Group lasso, iCAP, and DSML all perform similarly and significantly better than the local lasso. In terms of estimation error, lasso perform the worst, while DSML and refitted group lasso perform the best. This might be a result of bias removal introduced by regularization. Since the group lasso recovers the true support in most cases, refitting on it yields the maximum likelihood estimator on the true support. It is remarkable that DSML performs almost as well as this oracle estimator. Figure 2 shows the simulation results for classification. Similar with the regression case, we make the following observations: • The group sparsity based approaches, including DSML, significantly outperform the individual lasso. • In terms of Hamming variable selection error, DSML performs slightly worse than group lasso and iCAP. While in terms of estimation error and prediction error, DSML performs much better than group lasso and icap. Given the fact that group lasso recovers the true support in most cases, refitted group lasso is equivalent to oracle maximum likelihood estimator. It is remarkable that DSML only performs slightly worse than refitted group lasso. • The advantage of DSML, as well as group lasso over individual lasso, becomes more and more significant with the increase in number of tasks. We also evaluated DSML on the following benchmark data sets considered in previous investigations of shared support multi-task School. This is a widely used dataset for multi-task learning [Argyriou et al., 2008] . The goal is to predict the students' performance at London's secondary schools. There are 27 attributes for each student. The tasks are naturally divided according to different schools. We only considered schools with at least 200 students, which results in 11 tasks. Protein. The task is to predict the protein secondary structure [Sander and Schneider, 1991] . We considered three binary classification tasks here: coil vs helix, helix vs strand, strand vs coil. The dataset consists of 24,387 instances in total, each with 357 features. OCR. We consider the optical character recognition problem. Data were gathered by Rob Kassel at the MIT Spoken Language Systems Group foot_0 . Following [Obozinski et al., 2010] , we consider the following 9 binary classification task: c vs e, g vs y, g vs s, m vs n, a vs g, i vs j, a vs o, f vs t, h vs n. Each image is represented by 8 × 16 binary pixels. MNIST. This is a handwritten digit recognition dataset foot_1 , the ata consists of images that represent digits. Each image is represented by 784 pixels. We considered the following 5 binary classification task: 2 vs 4, 0 vs 9, 3 vs 5, 1 vs 7, 6 vs 8. USPS. This dataset consists handwritten images from envelopes by the U.S. Postal Service. We considere the following 5 binary classification task: 2 vs 4, 0 vs 9, 3 vs 5, 1 vs 7, 6 vs 8. Each image is represented by 256 pixels. Vehicle. We considered the vehicle classification problem in distributed sensor networks [Duarte and Hu, 2004] . We considered the following 3 binary classification task: AAV vs DW, AAV vs noise, DW vs noise. There are 98,528 instances in total, each instances is described by 50 acoustic features and 50 seismic features. In addition to the procedures used in the previous section, we also compare against the dirty model Jalali et al. [2010] , as well as the centralized approach that first debiases 0.1 0.2 0.3 0.4 0.5 Training Ratio 0.010 0.012 0.014 0.016 0.018 0.020 0.022 0.024 Averaged Classification Error 0.1 0.2 0.3 0.4 0.5 Training Ratio 0.070 0.075 0.080 0.085 0.090 0.095 Averaged classification error 0.1 0.2 0.3 0.4 0.5 Training Ratio 0.21 0.22 0.23 0.24 0.25 0.26 0.27 0.28 0.29 Averaged Classification Error USPS OCR Protein 0.1 0.2 0.3 0.4 0.5 Training Ratio 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24 0.25 Averaged nMSE Lasso Group lasso Debiased group lasso + HT iCAP DSML Dirty 0.1 0.2 0.3 0.4 0.5 Training Ratio 0.019 0.020 0.021 0.022 0.023 0.024 0.025 0.026 0.027 0.028 Averaged classification error 0.1 0.2 0.3 0.4 0.5 Training Ratio 0.130 0.135 0.140 0.145 0.150 0.155 0.160 0.165 0.170 Averaged classification error School MNIST Vehicle the group lasso and then performs group hard thresholding as in ( 5 ). Regularization and thresholding parameters were tuned on a held-out set consisting of 20% of the data. In Figure 3 we report results of training on 10%, 30% and, 50% of the total data set size. The multi-task methods clearly preform better than the local lasso, with DSML achieving similar error as the centralized methods. Discussion We introduced and studied a shared-sparsity distributed multi-task learning problem. We presented a novel communication-efficient approach that required only one round of communication and achieves provable guarantees that compete with the centralized approach to leading order up to a generous bound on the number of machines. Our analysis was based on Restricted Eigenvalue and Generalized Coherence conditions. Such conditions, or other similar conditions, are required for support recovery, but much weaker conditions are sufficient for obtaining low prediction error with the lasso or group lasso. An interesting open question is whether there exists a communication efficient method for distributed multi-task learning that requires sample complexity n = O(|S| + (log p)/m), like the group lasso, even without Restricted Eigenvalue and Generalized Coherence conditions, or whether beating the n = O(|S| + log p) sample complexity of the lasso in a more general setting inherently requires large amounts of communication. Our methods, certainly, rely on these stronger conditions. DSML can be easily extended to other types of structured sparsity, including sparse group lasso [Friedman et al., 2010] , tree-guided group lasso [Kim and Xing, 2010 ] and the dirty model [Jalali et al., 2010] . Going beyond shared sparsity, shared subspace (i.e. low rank) and other matrix-factorization and feature-learning methods are also commonly and successfully used for multi-task learning, and it would be extremely interesting to understand distributed multi-task learning in these models. Appendix A Proof of Theorem 1 We first introduce the following lemma. Lemma 3. When the rows of X 1 , . . . , X t are independent subgaussian random vectors, with mean zero, covariance Σ 1 , ..., Σ t , respectively. Let C M = max t∈[m] max j∈[p] M T t X T t X t n M t jj . Then with probability at least 1 -2mp exp (-cn) -2mp -2 for some constant c, we have C M ≤ 2 max t∈[m] max j∈[p] (Σ -1 t ) jj . Proof. As shown in Theorem 2.4 of [Javanmard and Montanari, 2014] , Σ -1 t will be a feasible solution for the problem of estimating M t . Since we're minimizing (M T t Σt M t ) jj , we must have max j∈[p] (M T t Σt M t ) jj ≤ max j∈[p] (Σ -1 t Σt Σ -1 t ) jj . Based on the concentration results of sub-exponential random variable [Vershynin, 2012] , also Lemma 3.3 of [Lee et al., 2015] , we know with probability at least 1 -2p exp (-cn) for some constant c, we have max j∈[p] (Σ -1 t Σt Σ -1 t ) jj ≤ 2 max j∈[p] (Σ -1 t ) jj . Take an union bound over t ∈ [m], we obtain with probability at least 1-2mp exp (-cn), C M ≤ max t∈[m] max j∈[p] (M T t Σt M t ) jj ≤ max t∈[m] max j∈[p] (Σ -1 t Σt Σ -1 t ) jj ≤ 2 max t∈[m] max j∈[p] (Σ -1 t ) jj . Now we are ready to prove Theorem 1, recall the model assumption y t = X t β * t + t , t = 1, . . . , m, (16) and the debiased estimation βu t = βt + n -1 M t X T t (y t -X t βt ), (17) we have βu t = βt + 1 n M t X T t (X t β * t -X t βt ) + 1 n M t X T t t =β * t + (M t Σt -I)(β * t -βt ) + 1 n M t X T t t . For the term (M t Σt -I)(β * t -βt ), define C µ = 10eσ 4 X λ max λ min , we have the following bound (M t Σt -I)(β * t -βt ) ∞ ≤ max j Σt m tj -e j ∞ β * t -βt 1 ≤ P C µ log p n • 16A κ σ|S| log p n = 16AC µ σ|S| log p κn . (18) Noticed that n -1 M t X T t t ∼ N 0, σ 2 M t Σt M t T n . Our next step uses a result on the concentration of χ 2 random variables. For any coordinate j, we have m i=1 n -1 e T j M t X T t 2 ≤ C 2 M σ 2 n m i=1 ξ 2 i , where (ξ i ) i∈[m] are standard normal random variables. Using Lemma 6 with a weight vector v = C 2 M σ 2 n , C 2 M σ 2 n , . . . , C 2 M σ 2 n and choosing t = √ m + log p √ m , we have P    C 2 M σ 2 n m i=1 ξ 2 i √ 2m C 2 M σ 2 n - m 2 > √ m + log p √ m    ≤ 2 exp   - √ m + log p √ m 2 2 + 2 √ 2(1 + log p m )    . A union bound over all j ∈ [p] gives us that with probability at least 1 -p -1 i∈[m] n -1 e T j M t X T t 2 ≤ 3m C 2 M σ 2 n + √ 2 log p C 2 M σ 2 n , ∀j ∈ [p]. (19) Combining ( 18 ) and ( 19 ), we get the following estimation error bound: Bj -B j 2 = i∈[m] [M t Σt -I)(β * t -βt )] j + n -1 M t X T t t j 2 ≤ i∈[m] 2 [M t Σt -I)(β * t -βt )] 2 j + n -1 M t X T t t 2 j ≤ i∈[m] 512A 2 C 2 µ σ 2 |S| 2 (log p) 2 κ 2 n 2 + 6m C 2 M σ 2 n + 2 √ 2 log p C 2 M σ 2 n = σ √ n 512A 2 C 2 µ m|S| 2 (log p) 2 κ 2 n + 6C 2 M m + 2 √ 2C 2 M log p ≤ 91C µ σ|S| √ m log p κn + 3C M σ m + log p n , (20) where the first inequality uses the fact (a + b) 2 ≤ 2a 2 + 2b 2 , and the second inequality uses ( 18 ) and ( 19 )), the last inequality uses the fact that √ a + b ≤ √ a + √ b. For every variable j ∈ S, we have Bj 2 ≤ 91C µ σ|S| √ m log p κn + 3C M σ m + log p n . plug in κ ≥ 1 2 λ min , C µ = 10eσ 4 X λmax λ min , C M ≤ 2K, we obtain Bj 2 ≤ 1820eσ 4 X λ 1/2 max σ|S| √ m log p λ 3/2 min n + 6Kσ m + log p n . From (20) and the choice of Λ * , we see that all variables not in S will be excluded from Ŝ as well. For every variable j ∈ S, we have Bj 2 ≥ B j 2 -Bj -B j 2 ≥ 2Λ * -Λ * = Λ * . Therefore, all variables in S will correctly stay in Ŝ after the group hard thresholding. B Proof of Corollary From Theorem 2 we have that Ŝ(Λ * ) = S and Bj -B j 2 ≤ 1820eσ 4 X λ 1/2 max σ|S| √ m log p λ 3/2 min n + 6Kσ m + log p n , (21) with high probability. Summing over j ∈ S, we obtain the ℓ 1 /ℓ 2 estimation error bound. For the prediction risk bound, we have 1 nm m t=1 X t ( βt -β * t ) 2 2 ≤ λ max m m i=1 βt -β * t 2 2 = λ max m p j=1 Bj -B j 2 2 . Using ( 21 ) and the fact that B -B is row-wise |S|-sparse, we obtain the prediction risk bound. C Collection of known results For completeness, we first give the definition of subgaussian norm, details could be found at [Vershynin, 2012] . Definition 4 (Subgaussian norm). The subgaussian norm X ψ 2 of a subgaussian pdimensional random vector X, is defined as X ψ 2 = sup x∈S p-1 sup q>1 q -1/2 (E| X, x | q ) 1/q , where S p-1 is the p-dimensional unit sphere. We then define the restricted set C(|S|, 3) as C(|S|, 3) = {∆ ∈ R p | ∆ U c 1 ≤ 3 ∆ U 1 , U ⊂ [p], |U | ≤ |S|}. The following proposition is a simple extension of Theorem 6.2 in [Bickel et al., 2009] . Proof. Using Theorem 6.2 in [Bickel et al., 2009] and take an union bound over 1, . . . , m we obtain the result. Lemma 6 (Equation ( 27 ) in [Cavalier et al., 2002] ; Lemma B.1 in [Lounici et al., 2011] ). Let ξ 1 , ξ 2 , ...ξ m be i.i.d. standard normal random variables, let v = (v 1 , ..., v m ) = 0, η v = 1 √ 2 v 2 m i=1 (ξ 2 i -1)v i and m(v) = v ∞ v 2 . We have, for all t > 0, that P (|η v | > t) ≤ 2 exp - t 2 2 + 2 √ 2tm(v) . The next lemma relies on the generalized coherence parameter: Definition 7 (Generalized Coherence). For matrices X ∈ R n×p and M = (m 1 , . . . , m p ) ∈ R p×p , let µ(X, M ) = max j∈[p] Σm j -e j ∞ be the generalized coherence parameter between X and M , where Σ = n -1 X T X. Furthermore, let µ * = min t∈[m] min M ∈R p×p µ(X t , M ) be the minimum generalized coherence. Lemma 8 (Theorem 2.4 in [Javanmard and Montanari, 2014] ). When X t are drawn from subgaussian random vectors with covariance matrix Σ t , and X t Σ -1/2 t has bounded subgaussian norm X t Σ -1/2 t ψ 2 ≤ σ X . When n ≥ 24 log p, then with probability at least 1 -2p -2 , we have µ(X t , Σ -1 t ) < 10eσ 4 X λ max λ min log p n . For subgaussian design, we also have the following restricted eigenvalue condition [Rudelson and Zhou, 2013; Lee et al., 2015] . Lemma 9. When X t are drawn from subguassian random vectors with covariance matrix Σ t , and bounded subgaussian norm σ X . When n ≥ 4000s σ X log 60 √ 2ep s where s = 1 + 30000 λmax λ min |S|, and p > s , then with probability at least 1 -2 exp (-n/4000C 4 κ ) , for any vector ∆ ∈ C(|S|, 3) where we have ∆ T X T t X t n ∆ ≥ 1 2 λ min ∆ S 2 2 . Figure 1 : 1 Figure 1: Hamming distance, estimation error, and prediction error for multi-task regression with p = 200. Top row: the number of tasks m = 10. Sample size per tasks is varied. Bottom row: Sample size n = 50. Number of tasks m varied. Figure 2 : 2 Figure 2: Hamming distance, estimation error, and prediction error for multi-task classification with p = 200. Top row: the number of tasks m = 10. Sample size per tasks is varied. Bottom row: Sample size n = 150. Number of tasks m varied. Figure 3 : 3 Figure 3: Comparison on real world datasets. regularization parameter in lasso. With probability at least 1 -mp 1-A 2 /8 , the minimum restricted eigenvalue of design matrix X 1 , . . . , X m : Table 1 : 1 Table 2 compares the parameter and prediction error guarantees. Lower Approach Communication Assumptions Min signal strength Strength type Lasso 0 Mutual Incoherence Sparse Eigenvalue log p n Element-wise Group lasso O(np) Mutual Incoherence Sparse Eigenvalue 1 n 1 + log p m Row-wise DSML O(p) Generalized Coherence Restricted Eigenvalue 1 n 1 + log p m + |S| log p n Row-wise bound on coefficients required to ensure support recovery with p variables, m tasks, n samples per task and a true support of size |S|. Table 2 : 2 Comparison of parameter estimation errors and prediction errors. The DSML guarantees improve over Lasso and have the same leading term as the Group lasso as long as m < n/(|S| 2 log p). Approach Assumptions ℓ1/ℓ2 estimation error Prediction error Lasso Restricted Eigenvalue |S| 2 log p n |S| log p n Group lasso Restricted Eigenvalue |S| √ n 1 + log p m |S| n 1 + log p m DSML Generalized Coherence Restricted Eigenvalue |S| √ n 1 + log p m + |S| 2 log p n |S| n 1 + log p m + |S| 3 (log p) 2 n 2 http://www.seas.upenn.edu/~taskar/ocr/ http://yann.lecun.com/exdb/mnist/"
}