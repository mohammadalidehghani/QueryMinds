<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distributed Multi-Task Learning with Shared Representation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2016-03-07">7 Mar 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jialei</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Chicago Chicago</orgName>
								<address>
									<postCode>60637</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mladen</forename><surname>Kolar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Booth School of Business</orgName>
								<orgName type="institution">University of Chicago Chicago</orgName>
								<address>
									<postCode>60637</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Srebro</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Toyota Technological Institute at Chicago Chicago</orgName>
								<address>
									<postCode>60637</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distributed Multi-Task Learning with Shared Representation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-03-07">7 Mar 2016</date>
						</imprint>
					</monogr>
					<idno type="MD5">66C193F0E1B0DB3F44C6B45F98343419</idno>
					<idno type="arXiv">arXiv:1603.02185v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study the problem of distributed multitask learning with shared representation, where each machine aims to learn a separate, but related, task in an unknown shared low-dimensional subspaces, i.e. when the predictor matrix has low rank. We consider a setting where each task is handled by a different machine, with samples for the task available locally on the machine, and study communication-efficient methods for exploiting the shared structure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Multi-task learning is widely used learning framework in which similar tasks are considered jointly for the purpose of improving performance compared to learning the tasks separately <ref type="bibr">[13]</ref>. By transferring information between related tasks it is hoped that samples will be better utilized, leading to improved generalization performance. Multi-task learning has been successfully applied, for example, in natural language understanding <ref type="bibr">[15]</ref>, speech recognition <ref type="bibr">[32]</ref>, remote sensing <ref type="bibr">[44]</ref>, image classification <ref type="bibr">[25]</ref>, spam filtering <ref type="bibr">[43]</ref>, web search <ref type="bibr">[14]</ref>, disease prediction <ref type="bibr">[49]</ref>, and eQTL mapping <ref type="bibr">[23]</ref> among other applications.</p><p>Here, we study multi-task learning in a distributed setting, where each task is handled by a different machine and communication between machines is expensive. That is, each machine has access to data for a different task and needs to learn a predictor for that task, where machines communicate with each other in order to leverage the relationship between the tasks. This situation lies between a homogeneous distributed learning setting <ref type="bibr">[e.g. 36]</ref>, where all machines have data from the same source distribution, and inhomogeneous consensus problems <ref type="bibr">[e.g. 30, 11, 6]</ref> where the goal is to reach a single consensus predictor or iterate which is the same on all machines. The main argument for this setting is that if each machine indeed has access to different data (e.g. from a different geographical region or different types of users), as in the consensus problems studied by <ref type="bibr">Balcan et al. [6]</ref>, then we should allow a different predictor for each distribution, instead of insisting on a single consensus predictor, while still trying to leverage the relationship and similarity between data distributions, as in classical multi-task learning. As was recently pointed out by <ref type="bibr">Wang et al. [41]</ref>, allowing separate predictors for each task instead of insisting on a consensus predictor changes the fundamental nature of the distributed learning problem, allows for different optimization methods, and necessitates a different analysis approach, more similar to homogeneous distributed learning as studied by <ref type="bibr">Shamir and Srebro [36]</ref>.</p><p>The success of multi-task learning relies on the relatedness between tasks. While <ref type="bibr">Wang et al. [41]</ref> studied tasks related through shared sparsity, here we turn to a more general, powerful and empirically more successful model of relatedness, where the predictors for different tasks lie in some (a-priori unknown) shared lowdimensional subspace and so the matrix of predictors is of low rank <ref type="bibr">[3,</ref><ref type="bibr">2,</ref><ref type="bibr">45,</ref><ref type="bibr">4]</ref>. In a shared sparsity model, information from all tasks is used to learn a subset of the input features which are then used by all tasks. In contrast, in a shared subspace model, novel features, which are linear functions of the input features, are learned. The model can thus be viewed as a two-layer neural network, with the bottom layer learned jointly across tasks and the top layer task-specific. Being arguably the most complex multi-layer network that we can fully analyze, studying such models can also serve as a gateway to using deeper networks for learning shared representations.</p><p>Multi-task learning with a shared subspace is wellstudied in a centralized setting, where data for all tasks are on the same machine, and some global centralized procedure is used to find a good predictor for each task. In such a situation, nuclear norm regularization is often used to leverage the low rank structure [e.g. 4, 2] and learning guarantees are known <ref type="bibr">([28]</ref> and see also Section 2). With the growth of modern massive data sets, where tasks and data often too big to handle on a single machine, it is important to develop methods also for the distributed setting. Unfortunately, the distributed multi-task setting is largely unexplored and we are not aware of any prior for on distributed multi-task learning with shared subspaces.</p><p>In this paper we focus on methods with efficient communication complexity (i.e. with as small as possible communication between machines), that can still leverage most of the statistical benefit of sharedsubspace multi-task learning. Although all our methods are also computationally tractable and can be implemented efficiently, we are less concerned here with minimizing the runtime on each machine separately, considering communication, instead, as the main bottleneck and the main resource to be minimized <ref type="bibr">[8]</ref>. This is similar to the focus in distributed optimization approaches such as ADMM <ref type="bibr">[11]</ref> and DANE <ref type="bibr">[37]</ref> where optimization within each machine is taken as an atomic step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contribution</head><p>The main contributions of this article are:</p><p>• Present and formalize the shared-subspace multitask learning <ref type="bibr">[4]</ref> in the novel distributed multitask setting, identifying the relevant problems and possible approaches. We analyze two baselines, several representative first-order distributed optimization methods, with careful sample and communication complexity analysis.</p><p>• We proposed and analyzed two subspace pursuit approaches which learns the shared representation in a greedy fashion, which leverage the lowdimensional predictive structure in a communication efficient way.</p><p>• We conducted comprehensive experimental comparisons of the discussed approaches on both simulated and real datasets, where we demonstrated that the proposed approaches are more communication efficient than first-order convex optimization methods.</p><p>Table <ref type="table">1</ref> summarized the approaches studied in this paper, which will be discussed in detail in the following sections.</p><p>Homogeneous, Inhomogeneous and Multi-Task Distributed Learning. We briefly review the relationship between homogeneous, inhomogeneous and multi-task learning, as recently presented by <ref type="bibr">Wang et al. [41]</ref>.</p><p>A typical situation considered in the literature is one in which data on different machines are all drawn i.i.d from the same source distribution. In this setting, tasks on different machines are all the same, which should be taken advantage of in optimization <ref type="bibr">[37]</ref>. Furthermore, as each machine has access to samples from the source distribution it can perform computations locally, without ever communicating with other machines. While having zero communication cost, this approach does not compare favorably with the centralized approach, in which all data are communicated to the central machine and used to obtain one predictor, when measured in terms of statistical efficiency. The goal in this setting is to obtain performance close to that of the centralized approach, using the same number of samples, but with low communication and computation costs <ref type="bibr">[36,</ref><ref type="bibr">20,</ref><ref type="bibr">48,</ref><ref type="bibr">47,</ref><ref type="bibr">26]</ref>. Another setting considered in the distributed optimization literature is that of consensus optimization. Here each machine has data from a different distribution and the goal is to find one vector of coefficients that is good for all the separate learning or optimization problems <ref type="bibr">[11,</ref><ref type="bibr">30,</ref><ref type="bibr">6]</ref>.</p><p>The difficulty of consensus problems is that the local objectives might be rather different, and, as a result, one can obtain lower bounds on the amount of communication that must be exchanged in order to reach a joint optimum.</p><p>In this paper we suggest a novel setting that combines aspects of the above two settings. On one hand, we assume that each machine has a different source distributions D j , corresponding to a different task, as in consensus problems. For example, each machine serves a different geographical location, or each is at a different hospital or school with different characteristics. But if indeed there are differences between the source distributions, it is natural to learn different predictors w j for each machine, so that w j is good for the distribution typical to that machine. In this regard, our distributed multi-task learning problem is more similar to single-source problems, in that machines could potentially learn on their own given enough samples and enough time. Furthermore, availability of other machines just makes the problem easier by allowing</p><p>Approach Samples Rounds Communication Worker Comp. Master Comp.</p><formula xml:id="formula_0">Local A 2 ε 2 1 0 ERM 0 Centralize A 2 ǫ 2 r m + r p 1 A 2 ǫ 2 r m + r p 0 Nuclear Norm Minimization ProxGD A 2 ǫ 2 r m + r p mHA 2 ε 2 • p Gradient Comp. SV Shrinkage AccProxGD A 2 ǫ 2 r m + r p mHA 2 ε 2 • p Gradient Comp. SV Shrinkage ADMM A 2 ǫ 2 r m + r p mA 2 ε 3 • p ERM SV Shrinkage DFW A 2 ǫ 2 r m + r p mHA 2 ε 2 • p Gradient Comp. Leading SV Comp. DGSP - mHA 2 ε 2 • p ERM Leading SV Comp. DNSP - - 2 • p ERM Leading SV Comp.</formula><p>Table 1: Summary of resources required by different approaches to distributed multi-task learning with shared representations (for squared loss), in units of vector operations/communications, ignoring log-factors.</p><p>transfer between the machine, thus reducing the sample complexity and potentially runtime. The goal, then, is to leverage as much transfer as possible, while limiting communication and runtime. As with singlesource problems, we compare our method to the two baselines, where we would like to be much better than the local approach, achieving performance nearly as good as the centralized approach, but with minimal communication and efficient runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Setting, Formulation and Baselines</head><p>We consider a setting with m tasks, each characterized by a source distribution D j (X, Y ) over feature vectors X ∈ R p and associated labels Y , and out goal is to find linear predictors w 1 , . . . , w m ∈ R p minimizing the overall expected loss (risk) across tasks:</p><formula xml:id="formula_1">L(W ) = 1 m m j=1 E (Xj ,Yj)∼Dj ℓ(w T j X j , Y j ) , (2.1)</formula><p>where for convenience we denote W ∈ R p×m for the matrix with columns w i , and ℓ(•, •) is some specified instantaneous loss function.</p><p>In the learning setting, we cannot observe L(W ) directly and only have access to i.i.d. sample {x ji , y ji } nj i=1</p><p>from each distribution D j , j = 1, . . . , m. For simplicity of presentation, we will assume that n j = n, j = 1, . . . , m, throughout the paper. We will denote the empirical loss L n (W ) =<ref type="foot" target="#foot_0">foot_0</ref> m m j=1 L nj (w j ) where</p><formula xml:id="formula_2">L nj (w j ) = 1 n n i=1 ℓ(w T j x ji , y ji )</formula><p>is the local (per-task) empirical loss.</p><p>We consider a distributed setting, where each task is handled on one of m separate machines, and each machine j has access only to the samples drawn from D j . Communication between the machines is by sending real-valued vectors. Our methods work either in a broadcast communication setting, where at each iteration each machine sends a vector which is received by all other machines, or in a master-at-the-center topology where each machine sends a vector to the master node, whom in turn performs some computation and broadcasts some other vectors to all machines. Either way, we count to total number of vectors communicated.</p><p>As in standard agnostic-PAC type analysis, our goal will be to obtain expected loss L(W ) which is not much larger then the expected loss of some (unknown) reference predictor 1 W * , and we will measure the excess error over this goal. To allow obtaining such guarantees we will assume:</p><p>Assumption 2.1. The loss function ℓ(•) is 1-Lipschitz and bounded 2 by 1, be twice differentiable and Hsmooth, that is</p><formula xml:id="formula_3">|ℓ ′ (a, c) -ℓ ′ (b, c)| ≤ H|a -b|, ∀a, b, c ∈ R.</formula><p>All the data points are bounded by unit length, i.e.</p><formula xml:id="formula_4">||x ji || 2 ≤ 1, ∀i, j,</formula><p>and the reference predictors have bounded norm:</p><formula xml:id="formula_5">max j∈[m] ||w * j || 2 2 ≤ A 2 for some A &lt; ∞.</formula><p>The simplest approach, which we refer to as Local, is to learn a linear predictor on each machine independently of other machines. This single task learning approach ignores the fact that the tasks are related and that sharing information between them could improve statistical performance. However, the communication cost for this procedure is zero, and with enough samples it can still drive the excess error to zero. However, compared to procedures discussed later, sample complexity (number of samples n required to achieve small excess error) is larger. A standard Rademacher complexity argument <ref type="bibr">[7]</ref> gives the following generalization guarantee, which is an extension of Theorem 26.12 in Shalev-Shwartz and Ben-David [33].</p><p>Proposition 2.2. Suppose Assumption 2.1 holds.</p><p>Then with probability at least 1δ,</p><formula xml:id="formula_6">L( W local ) -L(W * ) ≤ 2A √ n + 2 ln(2m/δ) n ,</formula><p>where</p><formula xml:id="formula_7">W local = [ w 1 , . . . , w m ] with w j = arg min ||w||≤A L nj (w).</formula><p>That is, in order to ensure ǫ excess error, we need</p><formula xml:id="formula_8">n = O A 2 ǫ 2</formula><p>samples from each task.</p><p>At the other extreme, if we ignore all communication costs, and, e.g. communicate all data to a single machine, we can significantly leverage the shared subspace. To understand this, we will first need to introduce two assumptions: one about the existence of a shared subspace (i.e. that the reference predictor is indeed low-rank), and the other about the spread of the data:</p><formula xml:id="formula_9">Assumption 2.3. rank(W * ) ≤ r Assumption 2.4. There is a constant p, such that 1 m m j=1 E (Xj ,Yj)∼Dj X j X T j 2 ≤ 1 p .</formula><p>Since the data is bounded, we always have 1 ≤ p ≤ p, with p being a measure of how spread out the data is in different direction. A value of 1 = p indicates the data is entirely contained in a one-dimensional line. In this case, the predictor matrix will also always be rankone, imposing a low-rank structure is meaningless and we can't expect to gain from it. However, when p is close to p, or at least high, the data is spread in many directions and the low-rank assumption is meaningful. We can think of p as the "effective dimensionality" of the data, and hope to gain when r ≪ p.</p><p>With these two assumptions in hand, we can think of minimizing the empirical error subject to a rank constraint on W . This is a hard and non-convex optimization task, but we can instead use the nuclear norm (aka trace-norm) ||W || * as a convex surrogate for the rank. This is because if Assumptions 2.1 and 2.3 hold, then we also have:</p><formula xml:id="formula_10">||W * || * ≤ √ rmA. (2.2)</formula><p>With this in mind, we can define the following centralized predictor:</p><formula xml:id="formula_11">W centralize = arg min ||W || * ≤ √ rmA L n (W ) (2.3)</formula><p>which achieves the improved excess error guarantee:</p><p>Proposition 2.5. (Theorem 1 in <ref type="bibr">Maurer and Pontil [28]</ref>) Suppose Assumptions 2.1, 2.3 and 2.4 hold.</p><p>Then with probability at least 1δ,</p><formula xml:id="formula_12">L( W centralize ) ≤L(W * ) + 2 ln(2/δ) nm + 2 √ rA 1 pn + 5 ln(mn) + 1 mn</formula><p>The sample complexity per task, up to logarithmic factors, is thus only:</p><formula xml:id="formula_13">n = O A 2 ǫ 2 r m + r p</formula><p>When p ≫ m, this is a reduction by a factor of r/m. That is, it is as if we needed to only learn r linear predictors instead of m.</p><p>The problem is that a naive computation of W centralize requires collecting all data on a single machine, i.e. communicating O(n</p><formula xml:id="formula_14">) = O A 2 ǫ 2 r m + r</formula><p>p samples per machine. In the next Sections, we aim at developing methods of approximating W centralized using communication efficient methods, or computing an alternate predictor with similar statistical properties but using much less communication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Distributed Convex Optimization</head><p>In this section, we study how to obtain the sharing benefit of the centralized approach using distributed convex optimization techniques, while keeping the communication requirements at low.</p><p>To enjoy the benefit of nuclear-norm regularization while avoid heavy communication cost of Centralize, a flexible strategy is to solve the convex objective (2.3) via distributed optimization techniques. Let W (t) be the solution at t-iteration for some iterative distributed optimization algorithm for the following constrained objective:</p><formula xml:id="formula_15">min ||W || * ≤ √ rmA L n (W ). (3.1)</formula><p>By the generalization error decompsition [10], t) will have the generalization error of order O(ǫ). Therefore in order to study the generalization performance, we will study how the optimization error decreases as the function of the number of iterations t.</p><formula xml:id="formula_16">L(W (t) ) -L(W * ) ≤2ǫ + ǫ opt , Suppose W (t) satisfying L n (W (t) ) ≤ L n ( W ) + O(ǫ opt ) with ǫ opt = O(ǫ). Then W (</formula><p>Constrained vs Regularized Objective Note that the constrained objective (3.1) is equivalent to the following regularized objective with a proper choice of λ:</p><formula xml:id="formula_17">min W L n (W ) + λ||W || * . (3.2)</formula><p>Though they are equivalent, specific optimization algorithms might sometimes be more suitable for one particular type of objectives<ref type="foot" target="#foot_1">foot_1</ref> . For convenience in the following discussion we didn't distinguish between these two formulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Distributed Proximal Gradient</head><p>Maybe the simplest distributed optimization algorithm for (3.2) is the proximal gradient descent. It is not hard to see that computation of the gradient ∇L n (W ) can be easily done in a distributed way as the losses are decomposable across machines:</p><formula xml:id="formula_18">∇L n (W ) = ∇L n1 (w 1 ), . . . , ∇L nm (w m )</formula><p>where</p><formula xml:id="formula_19">∇L nj (w j ) = 1 nm n i=1 ℓ ′ ( w j , x ji , y ji )x ji .</formula><p>Thus each machine j needs to compute the gradient ∇L nj (w j ) on the local dataset and send it to the master. The master concatenates the gradient vectors to form the gradient matrix ∇L n (W ). Finally, the master computes the proximal step</p><formula xml:id="formula_20">W (t+1) = arg min W ||W -(W (t) -η∇L n (W (t) ))|| 2 F + λ||W || * , (3.3)</formula><p>which has the following closed form solution [12]: let</p><formula xml:id="formula_21">W (t) -η∇L n (W (t) ) = U ΣV T be the SVD of W (t) - η∇L n (W (t) ), then W (t+1) = U (Σ -0.5λI) + V T with (x) + = max{0, x} applied element-wise.</formula><p>The algorithm is summarized in Algorithm 4 (in Appendix), which has well established convergence rates [5]:</p><formula xml:id="formula_22">L n (W (t) ) -L n ( W ) ≤ mHA 2 2t .</formula><p>To obtain ε-generalization error, the distributed proximal gradient descent requires O mHA 2 ε rounds of communication, with a total O mHA 2 p ε bits communications per machine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Distributed Accelerated Gradient</head><p>It is also possible to use Nesterov's acceleration idea <ref type="bibr">[29]</ref> to improve the convergence of the proximal gradient algorithm from O 1 t to O 1 t 2 [22]. Using the distributed accelerated proximal gradient descent, one needs O mHA 2 ε rounds of communication with a total O mHA 2 ε</p><p>• p bits communicated per machine to achieve ε-generalization error. The algorithm is summarized in Algorithm 5 (in Appendix), where the master maintains two sequences: W and Z. First, a proximal gradient update of W is done based on Z</p><formula xml:id="formula_23">W (t+1) = arg min Z ||Z -(Z (t) -η∇L n (Z (t) ))|| 2 F + λ||Z|| * (3.4)</formula><p>and then Z is updated based on a combination of the current W and the difference with previous W</p><formula xml:id="formula_24">Z (t+1) = W (t+1) + γ t (W (t+1) -W (t) ). (3.5)</formula><p>ADMM and DFW We also discuss the implementation and guarantees for two other popular optimization methods: ADMM and Frank-Wolfe, which are presented in the Appendix A and B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Greedy Representation Learning</head><p>In this section we propose two distributed algorithms which select the subspaces in a greedy fashion, instead of solving the nuclear norm regularized convex program.</p><p>Algorithm 1: DGSP: Distributed Gradient Subspace Pursuit.</p><p>for t = 1, 2, . . . do Workers:</p><p>for j = 1, 2, . . . , m do Each worker compute the its gradient direction ∇L nj (w Solve the projected ERM problem: Our greedy approach is inspired by the methods used for sparse signal reconstruction <ref type="bibr">[39,</ref><ref type="bibr">34]</ref>. Under the assumption that the optimal model W * is low-rank, say rank r, we can write W * as a sum of r rank-1 matrices:</p><formula xml:id="formula_25">v j = arg min vj L nj (U v j ); Update w (t+1) j = U v j .</formula><formula xml:id="formula_26">W * = r i=1 a i u i v T i = U V T ,</formula><p>where</p><formula xml:id="formula_27">a i ∈ R, u i ∈ R p , v i ∈ R m , and ||u i || 2 = ||v i || 2 = 1.</formula><p>In the proposed approach, the projection matrix U is learned in a greedy fashion. At every iteration, a new one-dimensional subspace is identified that leads to an improvement in the objective. This subspace is then included into the existing projection matrix. Using the new expanded projection matrix as the current feature representation, we refit the model to obtain the coefficient vectors V . In the distributed setting, there is a master that gathers local gradient information from each task. Based on this information, it then computes the subspace to be added to the projection matrix and sends it to each machine. The key step in the distributed greedy subspace pursuit algorithm is the addition of the subspace. One possible choice is the principle component of the gradient direction; after the master collected the gradient matrix ∇L n (W (t) ), it computes the top left and right singular vectors of ∇L n (W (t) ). Let (u, v) = SV(∇L n (W (t) )) be the largest singular vectors of ∇L n (W (t) ). The left singular vector u is used as a new subspace to be added to the projection matrix U . This vector is sent to each machine, which then concatenate it to the projection matrix and refit the model with the new representation. Algorithm 1 details the steps.</p><p>Distributed gradient subspace pursuit (DGSP), detailed in Algorithm 1, creates subspaces that are orthogonal to each other, as shown in the following proposition which is proved in Appendix D:</p><p>Proposition 4.1. At every iteration of Algorithm 1, the columns of U are orthonormal.</p><p>Both the distributed gradient subspace pursuit and the distributed Frank-Wolfe use the leading singular vector of the gradient matrix iteratively. Moreover, leading singular vectors of the gradient matrix have been used in greedy selection procedures for solving low-rank matrix learning problems <ref type="bibr">[35,</ref><ref type="bibr">42]</ref>. However, DGSP utilize the learned subspace in a very different way: GECO [35] re-fit the low-rank matrix under a larger subspace which is spanned by all left and right singular vectors; while OR1MP [42] only adjust the linear combination parameters {a i } r i=1 of the rank-1 matrices. The DGSP algorithm do not restrict on the joint subspaces {u i v T i }, but focused on the low-dimensional subspace induced the projection matrix U , and estimate the task specific predictors V based on the learned representation.</p><p>Next, we present convergence guarantees for the distributed gradient subspace pursuit. First, note that the smoothness of ℓ(•) implies the smoothness property for any rank-1 update.</p><p>Proposition 4.2. Suppose Assumption 2.1 holds. Then for any W and unit length vectors u ∈ R p and v ∈ R m , we have</p><formula xml:id="formula_28">L n (W + ηuv T ) ≤ L n (W ) + u T ∇L n (W )v + Hη 2 2 .</formula><p>We defer the proof in Appendix E. The following theorem states the number of iterations needed for the distributed gradient subspace pursuit to find an εsuboptimal solution.</p><p>Theorem 4.3. Suppose Assumption 2.1 holds. Then the distributed gradient subspace pursuit finds</p><formula xml:id="formula_29">W (t) such that L n (W (t) ) ≤ L n (W * ) + ε when t ≥ 4HmA 2 ε .</formula><p>We defer the proof in Appendix F. Theorem 4.3 tells us that for the distributed gradient subspace pursuit requires O mHA 2 ε iterations to reach ǫ accuracy. Since each iteration requires communicating p number, the communication cost per machine is O mHA 2 ε • p . In some applications this communication cost might be still too high and in order to improve it we will try to reduce the number of rounds of communication.</p><p>To that end, we develop a procedure that utilizes the second-order information to improve the convergence. Algorithm 6 describes the Distributed Newton Subspace Pursuit algorithm (DNSP). Note that distributed optimization with second-order information have been studied recently to achieve communication efficiency <ref type="bibr">[37,</ref><ref type="bibr">46]</ref>. Compared to the gradient based methods, the DNSP algorithm uses second-order information to find subspaces to work with. At each iteration, each machine computes the Newton direction</p><formula xml:id="formula_30">∆Lnj(wj ) =[∇ 2 Lnj (wj)] -1 ∇Lnj (wj) = 1 mn n i=1 ℓ ′′ (w T j xji, yji)xjix T ji -1 ∇Lnj (wj),</formula><p>based on the current solution and sends it to the master. The master computes the overall Newton direction by concatenating the Newton direction for each task ∆L n (W ) = [∆L n1 (w 1 ), ∆L n2 (w 2 ), . . . , ∆L nm (w m )] and computes the top singular vectors of ∆L n (W ). The top left singular vector u is is sent back to every machine, which is then concatenated to the current projection matrix. Each machine re-fits the predictors using the new representation. Note that at every iteration a Gram-Schmidt step is performed to ensure that the learned basis are orthonormal.</p><p>DNSP is a Newton-like method which uses second-order information, thus its generic analysis is not immediately apparent. However empirical results in the next section illustrate good performance of the proposed DNSP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We first illustrate performance of different procedures on simulated data. We generate data according to</p><formula xml:id="formula_31">y ji | x ji ∼ N (w T j x ji , 1)</formula><p>for regression problems and</p><formula xml:id="formula_32">y ji | x ji ∼ Bernoulli 1 + exp(-w T j x ji ) -1</formula><p>for classification problems. We generate the lowrank W * as follows. We first generate two matrices A ∈ R p×r , B ∈ R m×r with entries sampled independently from a standard normal distribution. Then we extract the left and right singular vectors of AB T , denoted as U, V . Finally, we set W * = U SV T , where S is a diagonal matrix with exponentially decaying entries: diag(S) = [1, 1/1.5, 1/(1.5) 2 , . . . , 1/(1.5) r ].</p><p>The feature vectors x ji are sampled from a mean zero multivariate normal with the covariance matrix Σ = (Σ ab ) a,b∈[p] , Σ ab = 2 -|a-b| . The regularization parameters for all approaches were optimized to give the best prediction performance over a held-out validation dataset. For ProxGD and AccProxGD, we initialized the solution from Local. Our simulation results are averaged over 10 independent runs.</p><p>We investigate how the performance of various procedures changes as a function of problem parameters (n, p, m, r). We compare the following procedures: i) Local, where each machine solves an empirical risk minimization problem (ordinary least squares or logistic regression) . ii) Nuclear-norm regularization: which is a popular Centralize approach: all machines send their data to the master, the master solves a nuclear-norm regularized loss minimization problem. iii) Learning with the best representation (BestRep): which assumes the true projection matrix U is known, and just fit ordinal least squares or logistic regression model in the projected low-dimensional subspace . Note that this is not a practical approach since in practice we do not know the best low-dimensional representations of the data. iv) Convex optimization approach which runs distributed optimization algorithms over the nuclear norm-regularized objective: here we implemented and compared the following algorithms: distributed proximal gradient (ProxGD); distributed accelerated proximal gradient, (AccProxGD); distributed alternating direction method of multipliers (ADMM); distributed Frank-Wolfe (DFW) . Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 Classification, (n,p,m,r) = (1000,100,50,5) LR Nuclear BestRep ProxGD AccProxGD ADMM DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 0 0.01 0.02 0.03 0.04 0.05 0.06 Classification, (n,p,m,r) = (2000,100,500,5) LR Nuclear BestRep ProxGD AccProxGD ADMM DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 Classification, (n,p,m,r) = (2000,200,200,5) LR Nuclear BestRep ProxGD AccProxGD ADMM DGSP DNSP Figure 2: Excess prediction error for multi-task classification.</p><p>the shared representation in multi-task learning.</p><p>• ADMM and AccProxGD perform reasonably well , especially ADMM. One reason for the effectiveness of ADMM is that for the problem of nuclear norm regularized multi-task learning considered here, the ADMM update solves regularized ERM problems at every iteration. ADMM and AccProxGD clearly outperform ProxGD.</p><p>• ProxGD and DGSP perform similarly. DGSP usually becomes worse as the iterations increases , while ProxGD converges to a global optimum of the nuclear norm regularized objective.</p><p>• DNSP is the most communication-efficient method, and usually converges to a solution that is slightly better compared to the optimum of the nuclear regularization. This shows that second-order information helps a lot in reducing the communication cost.</p><p>• The DFW performs the worst in most cases, even though DFW shares some similarity with DGSP in learning the subspace. The empirical results suggest the re-fitting step in DGSP is very important.</p><p>One-shot SVD truncation A natural question to ask is whether there exists a one-shot communication method for the shared representation problem considered here, that still matches the performance of centralized methods. One reasonable solution is to consider the following SVD truncation approach, which is based on the following derivation: consider the following well specified linear regression model:</p><formula xml:id="formula_33">y ji = x ji , w * j + ǫ ji ,</formula><p>where ǫ ji is drawn from mean-zero Gaussian noise. It is easy to verify the following equation for OLS estimation:</p><formula xml:id="formula_34">w local(j) = w * j + i x ji x T ji -1 i ǫ ji x ji .</formula><p>Since W local is just W * plus some mean-zero Gaussian noise, it is natural to consider the following low-rank matrix denoising estimator:</p><formula xml:id="formula_35">min W || W local -W || 2 F s.t. rank(W ) = r.</formula><p>where the solution is a simple SVD truncation, and can be implemented in a one-shot way: each worker send its Local solution to the master, which then performs an SVD truncation step to maintain the top-r components and send the resulting estimation back to each worker, where U r , S r , V r are top-r components of U, S, V . Though this approach might work well for some simple scenarios, but will generally fail when the features are highly correlated: although the Local solution W local can output normal estimation of W * , the estimation noise i x ji x T ji -1 ( i ǫ ji x ji ) might be highly correlated (depend on the correlation between features), which makes the SVD truncation estimation not reliable. To illustrate this, consider a more complex simulation which follows the same setup as above setting, except that now the feature vectors x ji are sampled from a higher correlation matrix Σ = (Σ ab ) a,b∈[p] , Σ ab = 2 -0.1|a-b| . The regression simulation results are shown in Figure <ref type="figure" target="#fig_3">3</ref>, where we see that the one-shot SVD truncation approach does not significantly outperforms Local, sometimes even slightly worse.</p><formula xml:id="formula_36">W svd = U r S r V T r , where U SV T = SVD( W local ),</formula><p>Besides simulation, we also conducted extensive experiments on real world datasets, which are presented in Appendix H due to space limitation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We studied the problem of distributed representation learning for multiple tasks, discussed the implementation and guarantees for distributed convex optimization methods, and presented two novel algorithms to learn low-dimensional projection in a greedy way, which can be communication more efficient than distributed convex optimization approaches. All approaches are extensively evaluated on simulation and real world datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Distributed Frank-Wolfe Method</head><p>Another approach we consider is the distributed <ref type="bibr">19,</ref><ref type="bibr">9)</ref>. This methods does not require performing SVD, which might bring additional computational advantages. Instead of directly minimizing the nuclear norm regularized objective, the Frank-Wolfe algorithm considers the equivalent constrained minimization problem min</p><formula xml:id="formula_37">W L n (W ) subject to ||W || * ≤ R.</formula><p>At each step, Frank-Wolfe algorithm considers the following direction to update</p><formula xml:id="formula_38">Z (t) = arg min ||Z|| * ≤R ∇L n (W (t) ), Z = -R • uv T , where (u, v) = SV(∇L n (W (t)</formula><p>)) is the leading singular vectors of ∇L n (W (t) ). The next iterate is obtained as</p><formula xml:id="formula_39">W (t+1) = (1 -γ)W (t) + γZ (t) ,</formula><p>where γ is a step size parameter. To implement this algorithm in a distributed way, the master first collects the gradient matrix ∇L n (W (t) ) and computes u and v.</p><p>The vector v j u is sent to j-th machine, which performs the following update:</p><formula xml:id="formula_40">w (t+1) j = (1 -γ)w (t) j -γRv j u. (B.1)</formula><p>The algorithm is summarized in Algorithm 3. Similar to the distributed (accelerated) proximal gradient descent, the distributed Frank-Wolfe only requires communication of two p-dimensional vectors per round. Though computationally cheaper compared to other methods considered in this section, the distributed Frank-Wolfe algorithm enjoys similar convergence guarantees to the distributed proximal gradient descent (19), that is, after O mHA 2 ε iterations, the solution will be ε suboptimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Pseudocode of the algorithms D Proof of Proposition 4.1</head><p>Proof. It is sufficient to prove that at every iteration, the current projection matrix U and the subspace to be added u are orthogonal to each other. Note that by the optimality condition:</p><formula xml:id="formula_41">∇ V L n (U V T ) = U T ∇L n (W (t) ) = 0.</formula><p>Since u is the leading left singular vector of ∇L n (W (t) ), we have U T u = 0. Each column of U has unit length, since it is a left singular vector of some matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Proof of Proposition 4.2</head><p>Proof. It is sufficient to prove that the largest eigenvalue of ∇ 2 L n (W ) does not exceed H. Since ∇ 2 L n (W ) is a block diagonal matrix, it is sufficient to show that for every block j ∈ [m], the largest eigenvalue of the block ∇ 2 L nj (w j ) is not larger than H. This is true by the H-smoothness of ℓ(•) and the fact that the data points have bounded length:</p><formula xml:id="formula_42">||∇ 2 L nj (w j )|| 2 ≤ H • max i,j ||x ji || 2 ≤ H.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Proof of Theorem 4.3</head><p>Proof. By the smoothness of L n , we know</p><formula xml:id="formula_43">L n (W (t+1) ) ≤ min b L n (W (t) + buv T ) ≤L n (W (t) ) + b uv T , ∇L n (W (t) ) + Hb 2 2 ≤L n (W (t) ) + b W * , ∇L n (W (t) ) ||W * || F + Hb 2 2 . (F.1) Let W (t) = U V T . Since V is a mini- mizer of L n (U V T ) with respect to V , we have U T ∇L n (W (t) )</formula><p>= 0 and therefore W (t) , ∇L n (W (t) ) = trace(V U T ∇L n (W (t) )) = 0. From convexity of L n (•), we have</p><formula xml:id="formula_44">W * , ∇L n (W (t) ) = W * -W (t) , ∇L n (W (t) ) ≤L n (W * ) -L n (W (t) ).</formula><p>Combining with the display above</p><formula xml:id="formula_45">L n (W (t) ) -L n (W (t+1) ) ≥ b(L n (W (t) ) -L n (W * )) ||W * || F - Hb 2 2 . By choosing b = L n (W (t) ) -L n (W * ) H||W * || F we have L n (W (t) ) -L n (W (t+1) ) ≥ L n (W (t) ) -L n (W * ) 2 2H||W * || 2 F ≥ L n (W (t) ) -L n (W * ) 2 2mHA 2 .</formula><p>Using Lemma G.1 in Appendix we know that after</p><formula xml:id="formula_46">t ≥ 2mHA 2 ε iterations, we have L n (W (t) ) ≤ L n (W * ) + ε.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G An auxiliary lemma</head><p>Lemma G.1. (Lemma B.2 of Shalev-Shwartz et al.</p><p>(34)) Let x &gt; 0 and let ε 0 , ε 1 , ... be a sequence such that ε ≤ ε trε 2 t for all t. Let ε be a positive scalar and t be a positive integer such that t ≥ ⌈ 1 xε ⌉. Then ε t ≤ ε.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Evaluation on Real World Datasets</head><p>We also evaluate discussed algorithms on several real world data sets, with 20% of the whole dataset as training set, 20% as held-out validation, then report the testing performance on the remaining 60%. For the real data, we have observed that adding ℓ 2 regularization usually helps improving the generalization performance. For the Local procedure we added an ℓ 2 regularization term (leads to ridge regression or ℓ 2 regularized logistic regression). For DGSP and DNSP, we also add an ℓ 2 regularization in finding the subspaces and refitting . We have worked on the following multitask learning datasets:</p><p>School. 5 The dataset consists of examination scores of students from London's secondary schools during the years <ref type="bibr">1985, 1986, 1987.</ref> There are 27 schoolspecific and student-specific features to describe each student.</p><p>The instances are divided by different schools, and the task is to predict the students' performance. We only considered schools with at least 100 records, which results in 72 tasks in total. The maximum number of records for each individual school is 260.</p><p>Computer Survey. The data is taken from a conjoint analysis experiment (27) which surveyed 180 persons about the probability of purchasing 20 kinds of personal computers. There are 14 variables for each computer, the response is an integer rating with scale 0 -10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ATP. 6</head><p>The task here is to predict the airline ticket price (38). We are interested in the minimum prices next day for some specific observation date and departure date pairs. Each case is described by 411 features, and there are 6 target minimum prices for different airlines to predict. The sample size is 337.</p><p>Protein. Given the amino acid sequence, we are interested predicting the protein secondary structure (31). We tackle the problem by considering the following three binary classification tasks: coil vs helix, helix vs</p><p>5 <ref type="url" target="http://cvn.ecp.fr/personnel/andreas/code/mtl/index.html">http://cvn.ecp.fr/personnel/andreas/code/mtl/index.html</ref> 6 <ref type="url" target="http://mulan.sourceforge.net/datasets.html">http://mulan.sourceforge.net/datasets.html</ref> Rounds of Communication 0 5 10 15 20 25 30 Averaged RMSE 2 3 4 5 6 7 8 Regression, Computer Survey(20,14,190) OLS Nuclear AltMin ProxGD AccProxGD ADMM DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 Averaged RMSE 10.5 11 11.5 12 12.5 13 13.5 14 14.5 15 15.5 Regression, School(260,27,72) OLS Nuclear AltMin ProxGD AccProxGD ADMM DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 Averaged RMSE 60 80 100 120 140 160 180 200 220 Regression, ATP(337,411,6) OLS Nuclear AltMin ProxGD AccProxGD ADMM DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 1 -Averaged AUC 0.14 0.16 0.18 0.2 0.22 0.24 0.26 Classification, Protein(13701,357,3) LR Nuclear AltMin ProxGD AccProxGD ADMM DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 1 -Averaged AUC 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 Classification, Landmine(690,10,19) LR Nuclear AltMin ProxGD AccProxGD ADMM DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 1 -Averaged AUC 0.35 0.4 0.45 0.5 0.55 Classification, Cal500(502,68,78) LR Nuclear AltMin ProxGD AccProxGD ADMM DGSP DNSP Figure 4: Prediction Error on real data. Algorithm 2: ADMM: Distributed ADMM for Multi-Task Learning. for t = 1, 2, . . . do Workers: for j = 1, 2, . . . , m do Each worker solves the regularized ERM problem as (A.1) to get w (t+1) j , and send it to the master; Wait; Receive z (t+1) j , q (t+1) j from master. end Master: if Receive w (t+1) j from all workers then Concatenate the current solutions w (t+1) j Landmine. The data is collected from 19 landmine detection tasks (44). Each landmine field is represented by a 9-dimensional vector extracted from radar images, containing moment-based, correlation-based, energy ratio, and spatial variance features. The sample size for each task varies from 445 to 690. Cal500. 7 This music dataset (40) consists of 502 songs, where for each song 68 features are extracted. Each task is to predict whether a particular musically relevant semantic keyword should be an annotation for the song. We only consider tags with at least 50 times apperance, which results in 78 prediction tasks.</p><p>We compared various approaches as in the simulation study, except the BestRep as the best low-dimensional representation is unknown. We also compared with AltMin, which learns low-rank prediction matrix using the alternating minimization (21). The results are shown in Figure <ref type="figure">4</ref>. Since the labels for the real world classification datasets are often unbalanced, we report averaged area under the curve (AUC) instead of classification accuracy. We have the following observations:</p><p>• The distributed first-order approaches converge much slower than in simulations, especially on Algorithm 6: DNSP: Distributed Newton Subspace Pursuit. for t = 1, 2, . . . do Workers: for j = 1, 2, . . . , m do Each worker computes the Newton direction ∆L nj (w (t) t ) = ∇ 2 L nj (w (t) t ) -1 ∇L nj (w (t) t ) and sends it to the master. end if Receive u from the master then Perform Gram-Schmidt orthogonalization: u ← u -t-1 k=1 U k , u ; Normalize u = u/||u|| 2 ; Update the projection matrix U = [U u]; Solve the projected ERM problem: v j = arg min vj 1 n n i=1 ℓ( v j , U T X ji , y ji ); Update w (t+1) j = U v j . end Master: if Receive ∆L nj (w (t) t ) from all workers then Concatenate the Newton vectors, and compute the largest singular vectors: (u, v) = SV(∆L n (W (t) )); Send u to all workers. end end Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 Classification, (n,p,m,r) = (500,50,50,5) LR Nuclear BestRep ProxGD AccProxGD ADMM DFW DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 0 0.02 0.04 0.06 0.08 0.1 0.12 Classification, (n,p,m,r) = (500,100,50,5) Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 0 0.05 0.1 0.15 0.2 0.25 Classification, (n,p,m,r) = (500,100,50,10) Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 Classification, (n,p,m,r) = (1000,100,50,5) Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 0 0.02 0.04 0.06 0.08 0.1 0.12 Classification, (n,p,m,r) = (2000,100,500,5) Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 Classification, (n,p,m,r) = (2000,200,200,5) Figure 6: Excess prediction error for multi-task classification. Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 10 -2 10 0 10 2 10 4 10 6 Regression, (n,p,m,r) = (500,100,50,5) OLS SVD Nuclear BestRep ProxGD AccProxGD ADMM DFW DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 10 -2 10 -1 10 0 10 1 10 2 10 3 10 4 Regression, (n,p,m,r) = (500,100,50,10) Rounds of Communication 0 5 10 15 20 25 30 Excess Prediction Error 10 -3 10 -2 10 -1 10 0 10 1 10 2 10 3 Regression, (n,p,m,r) = (1000,100,50,5) Figure 7: Excess prediction error for multi-task regression, with highly correlated features. Rounds of Communication 5 10 15 20 25 30 Averaged RMSE Regression, Computer Survey(20,14,190) OLS Nuclear AltMin ProxGD AccProxGD ADMM DFW DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 Averaged RMSE 10 11 12 13 14 15 16 17 18 Regression, School(260,27,72) OLS Nuclear AltMin ProxGD AccProxGD ADMM DFW DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 Averaged RMSE 60 80 100 120 140 160 180 200 220 Regression, ATP(337,411,6) OLS Nuclear AltMin ProxGD AccProxGD ADMM DGSP DNSP Rounds of Communication 5 10 15 20 25 30 1 -Averaged AUC 0.14 0.16 0.18 0.2 0.22 0.24 0.26 Classification, Protein(13701,357,3) LR Nuclear AltMin ProxGD AccProxGD ADMM DFW DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 1 -Averaged AUC 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 Classification, Landmine(690,10,19) LR Nuclear AltMin ProxGD AccProxGD ADMM DFW DGSP DNSP Rounds of Communication 0 5 10 15 20 25 30 1 -Averaged AUC 0.4 0.45 0.5 0.55 0.6 0.65 Classification, Cal500(502,68,78) LR Nuclear AltMin ProxGD AccProxGD ADMM DFW DGSP DNSP Figure 8: Prediction Error on real data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>and send it to the master end if Receive u from the master then Update the projection matrix U = [U u];</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>Receive ∇L nj (w (t) j ) from all workers then Concatenate the gradient vectors, and compute the largest singular vectors: (u, v) = SV(∇L n (W (t) )); Send u to all workers. end end 4.1 Distributed Greedy Subspace Pursuit</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>•Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Excess prediction error for multi-task regression.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Excess prediction error for multi-task regression, with highly correlated features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>vs coil. Each sequence is described by 357 features. There are 24,387 instances in total.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>end 6 ifSetFigure 5 :Figure 6 :Figure 7 :Figure 8 :</head><label>65678</label><figDesc>Figure 5: Excess prediction error for multi-task regression.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Despite the notation, W * need not be the minimizer of the expected loss. We can think of it as the minimizer inside some restricted hypothesis class, though all analysis and statements hold for any chosen reference predictor W * .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>e.g. ADMM for regularized objective and Frank-Wolfe for constrained objective. Gradient descent methods can be adopted for both, leads to proximal and projected methods, respectively.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>For better visualization, here we omit the plot for DFW as its performance is significantly worse than others.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>ε rounds of communication are needed to obtain ε-generalization error.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A Distributed Alternating Direction Methods of Multipliers</head><p>The Alternating Direction Methods of Multipliers (ADMM) is also a popular method for distributed optimization <ref type="bibr">(11)</ref> and can be used to solve the distributed low-rank multi-task learning problem. We first write the objective (2.3) as arg min</p><p>By introducing the Lagrangian and augmented terms, we get the following unconstrained problem:</p><p>where ρ is a parameter controlling the augmentation level. Note that except for Z, the augmented Lagrangian objective are decomposable across tasks. To implement the distributed ADMM algorithm, we let the workers maintain the data and W , while the master maintains Z and Q. At round t, each machine separately solves</p><p>which is minimizing the local loss plus a regularization term. Next, each worker sends their solution to the master, which performs the following updates for Z and Q</p><p>which have closed-form solutions.</p><p>The algorithm ADMM is summarized in Algorithm 2. Note that compared to methods discussed before, ADMM needs to communicate three p-dimensional vectors between each worker and the master at each round, while the proximal gradient approaches only communicate two p-dimensional vectors per round. ATP and Cal500. We suspect this is because in the simulation study, the generated data are usually well conditioned, which makes faster convergence possible for such methods (1, 18). On real data, the condition number can be much worse.</p><p>• In most case, DNSP is the best in terms of communication-efficiency. DGSP also has reasonable performance with fewer round of communications compared to distributed first-order approaches.</p><p>• Among the first-order distributed convex optimization methods, AccProxGD is overall the most communication-efficient, while DFW is the worst, though it might have some advantages in terms of computation. Also, we observed significant zigzag behavior of the DFW algorithm, as discussed in (24).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I Full experimental results with Distributed Frank-Wolfe</head><p>Algorithm 4: ProxGD: Distributed Proximal Gradient.</p><p>1 for t = 1, 2, . . . do   </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast global convergence of gradient methods for highdimensional statistical recovery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Negahban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2452" to="2482" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Uncovering shared structures in multiclass classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A framework for learning predictive structures from multiple tasks and unlabeled data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1817" to="1853" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Convex multi-task feature learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="272" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimization with sparsity-inducing penalties</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="106" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distributed learning, communication complexity and privacy</title>
		<author>
			<persName><forename type="first">M.-F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR W&amp;CP 23: COLT 2012</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="26" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rademacher and gaussian complexities: Risk bounds and structural results</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mendelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="463" to="482" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Scaling up machine learning: Parallel and distributed approaches</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bekkerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bilenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A distributed frank-wolfe algorithm for communication-efficient sparse learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Garakani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="478" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The tradeoffs of large scale learning</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="161" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="122" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A singular value thresholding algorithm for matrix completion</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1956" to="1982" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="75" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-task learning for boosting with application to web search ranking</title>
		<author>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shivaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vadrevu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1189" to="1198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An algorithm for quadratic programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval research logistics quarterly</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="95" to="110" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the o(1/n) convergence rate of the douglas-rachford alternating direction method</title>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="700" to="709" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">On the linear convergence of the alternating direction method of multipliers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-Q</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1208.3922</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Revisiting frank-wolfe: Projection-free sparse convex optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="427" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Communication-efficient distributed dual coordinate ascent</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takác</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Terhorst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3068" to="3076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Low-rank matrix completion using alternating minimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Netrapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sanghavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="665" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An accelerated gradient method for trace norm minimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tree-guided group lasso for multi-task regression with structured sparsity</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="543" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the global linear convergence of frank-wolfe optimization variants</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="496" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scalable multitask representation learning for scene classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lapin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1434" to="1441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Communication-efficient sparse regression: a oneshot approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.04337</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hierarchical bayes conjoint analysis: Recovery of partworth heterogeneity from reduced experimental designs</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="191" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Excess risk bounds for multitask learning with trace norm regularization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="55" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A method of solving a convex programming problem with convergence rate ≀(1/k 2 )</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Soviet Mathematics Doklady</title>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="372" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributed stochastic subgradient projection algorithms for convex optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Veeravalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of optimization theory and applications</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="516" to="545" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Database of homologyderived protein structures and the structural meaning of sequence alignment</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="page" from="56" to="68" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multi-task learning in deep neural networks for improved phoneme recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Seltzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Droppo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="6965" to="6969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Understanding machine learning: From theory to algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Trading accuracy for sparsity in optimization problems with sparsity constraints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2807" to="2832" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Largescale convex minimization with a low-rank constraint</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Distributed stochastic optimization and learning</title>
		<author>
			<persName><forename type="first">O</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Allerton</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="850" to="857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Communication efficient distributed optimization using an approximate newton-type method</title>
		<author>
			<persName><forename type="first">O</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1000" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Multi-target regression via input space expansion: Treating targets as inputs</title>
		<author>
			<persName><forename type="first">E</forename><surname>Spyromitros-Xioufis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Groves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vlahavas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1211.6581</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Greed is good: Algorithmic results for sparse approximation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEEit</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2231" to="2242" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Semantic annotation and retrieval of music and sound effects</title>
		<author>
			<persName><forename type="first">D</forename><surname>Turnbull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Barrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="467" to="476" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Distributed multitask learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kolar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.00633</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Orthogonal rank-one matrix pursuit for low rank matrix completion</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Davulcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="488" to="A514" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Feature hashing for large scale multitask learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Attenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1113" to="1120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multi-task learning for classification with dirichlet process priors</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Krishnapuram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="35" to="63" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dimension reduction and coefficient estimation in multivariate linear regression</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ekici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monteiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="346" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Communication-efficient distributed optimization of self-concordant empirical loss</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.00263</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Communication-efficient algorithms for statistical optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1502" to="1510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Information-theoretic lower bounds for distributed statistical estimation with communication constraints</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2328" to="2336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Modeling disease progression via multi-task learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neu-roImage</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="233" to="248" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
