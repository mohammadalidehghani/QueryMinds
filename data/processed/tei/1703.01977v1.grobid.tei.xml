<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Linear, Machine Learning and Probabilistic Approaches for Time Series Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Pavlyshenko</surname></persName>
							<email>b.pavlyshenko@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Ivan Franko National University of Lviv</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Linear, Machine Learning and Probabilistic Approaches for Time Series Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">45BF3E8D60B7CB3B85E57C4FAC2F76ED</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>time series</term>
					<term>ARIMA</term>
					<term>forecasting</term>
					<term>predictive analytics</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we study different approaches for time series modeling. The forecasting approaches using linear models, ARIMA alpgorithm, XGBoost machine learning algorithm are described. Results of different model combinations are shown. For probabilistic modeling the approaches using copulas and Bayesian inference are considered.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Time series analysis, especially forecasting, is an important problem of modern predictive analytics. The goal of this study is to consider different aproaches for time series modeling. For our analysis, we used stores sales historical data from Kaggle competition "Rossmann Store Sales" <ref type="bibr" target="#b0">[1]</ref>. These data represent the sales time series of Rossmann stores. For time series forecasting such approaches as linear models and ARIMA algorithm are widely used. Machine lerning algorithm make it possible to find patterns in the time series. Sometimes we need to forecast not only more probable values of sales but also their distribution. Especially we need it in the risk analysis for assessing different risks related to sales dynamics. In this case, we need to take into account sales distributions and dependencies between sales time series features (e.g. day of week, month, average sales, etc.) and external factors such as promo, distance to competitors, etc. One can consider sales as a stochastic variable with some marginal distributions. If we have sales distribution, we can calculate value at risk (VaR) which is one of risk assessment features. In probabilistic analysis of sales, we can use copulas which allows us to analyze the dependence between sales and different factors. To find distributions of model parameters Bayesian inference approach can be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. LINEAR MODELS AND MACHINE LEARNING APPROACHES</head><p>For our analysis, we used stores sales historical data.</p><p>To compare different forecasting approaches we used two last months of the historical data as validation data for accuracy scoring using root mean squared error (RMSE). For the comparison, we used the following methods: ARIMA using R package "forecast" <ref type="bibr" target="#b1">[2]</ref>, linear regression with LASSO regularization using R package "lars" <ref type="bibr" target="#b2">[3]</ref>, conditional inference trees with linear regression on the leaf using mob() function from R package "party" <ref type="bibr" target="#b3">[4]</ref>, gradient boosting XGBoost model using R package "xgboost" <ref type="bibr" target="#b4">[5]</ref>. Package "xgboost" (short term for eXtreme Gradient Boosting) is an efficient and scalable implementation of gradient boosting framework <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. The package includes efficient linear model solver and tree learning algorithm. We also used combined approaches such as linear blending ARIMA and gradient boosting model, stacking with the use of linear regression on the first step and gradient boosting on the second step. We used two ways of classifications -the first way is based on the time series approach and the second one is based on the independent and identically distributed variables. We consider sales in the natural logarithmic scale. Figure <ref type="figure" target="#fig_0">1</ref> shows typical time series of store sales.  We also studied the case of time series forecasting using XGBoost model with time series approach and xgboost model based on independent and identically distributed variables. For arbitrary chosen store (Store 95) we received RMSE=0.138 for XGBoost model with time series approach and RMSE=0.118 for XGBoost model with i.i.d approach. The obtained results show that for different stores the best accuracy is released by different approaches. For each type of time series, we may develop an optimized approach which can be based on the combination of different predictive models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. COPULAS APPROACH FOR MODELING</head><p>A copula is a multivariate probability distribution for which the marginal probability distribution of each variable is uniform. Copulas are used to describe the dependence between random variables. Sklar's Theorem states that any multivariate joint distribution can be written in terms of univariate marginal distribution functions and a copula, which describes the dependence structure between the variables. The copula contains all information on the dependence structure between the variables, whereas the marginal cumulative distribution functions contain all information on the marginal distributions. For the case study, we use the same sales time series, which represent sales in the stores network. We used "copula" R package <ref type="bibr" target="#b7">[8]</ref> for modeling. We consider sales in the natural logarithmic scale. For our analysis, we take such features as sales (variable logSales), previous day sales (variable prevLogSales), number of customers that visited a store (variable Customers). First of all we take one sales time series for one arbitrary store.</p><p>Marginal distributions and dependencies with correlation coefficient are shown on the figure 3. On the figures 4,5 the pseudo observations of investigated features are shown. These figures represent stochastic dependencies of investigated variable. Our next objective is to find such copulas, which will approximate these dependencies. We chose t-copula for modeling. Using maximum likelihood method, one can find fitting parameters for copula. The probability density function for calculated fitted t-copula is shown on the figure <ref type="figure" target="#fig_6">6</ref>.    Having fitted copula and marginal distributions, we can generate pseudo-random samples of investigated variables by applying inverse marginal comulative distribution function (CDF) to each dimensional variable of fitted copula. To construct multivariate distribution of dependent variables, we chose gamma distribution for marginal distributions of logSales and Customers variables. Having fitted copula and finding parameters for these gamma distributions from historical data, we generate pseudo-random samples with the probability density function (PDF), shown on the figure <ref type="figure">7</ref>.</p><p>Figure <ref type="figure">7</ref>. The PDF of generated pseudo-random samples using fitted t-copula and marginal distributions.</p><p>If we need to analyze multivariate dependences with more than two variables, it is effective to use vine copulas, which enable us to construct complex multivariate copula using bivariate ones. For studying vine copula, we used CDVine R package <ref type="bibr" target="#b8">[9]</ref>. Let us consider such features of sales time series as sales (variable logSales), mean sales per day for store (variable meanLogSales) and promo action (variable Promo). In this case, we analyze sales for stores chain.</p><p>To analyze the stochastic dependence we used canonical vine copula. First tree for fitted canonical vine copula with Kendall's tau values is shown on the figure <ref type="figure" target="#fig_7">8</ref>. We chose a t-copula for the logSales-Promo dependency and a normal for the logSales-meanLogSales dependency. The pseudo observations for constructed canonical vine copula are shown on the figure <ref type="figure" target="#fig_8">9</ref> in the dimension of logSales and meanLogSales . As the case study shows, the use of copula make it possible to model stochastic dependencies between different factors of sales time series separately from their marginal distributions. This can be considered as an additional approach in the sales time series analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. BAYESIAN INFERENCE</head><p>For Bayesian inference case study, we take such features as promo, seasonality factors (week day, month day, month of year). As well as in the previous studies, we consider sales in the natural logarithmic scale. As the example we take one sales time series for one arbitrary store. For Bayesian inference, we used Markov Chain Monte Carlo (MCMC) algorithm from MCMCpack R package <ref type="bibr" target="#b9">[10]</ref>. For time series modeling, we used the linear regression with Gaussian errors. Trace plots of samples vs the simulation index can be very useful in assessing convergence. The trace plot for promo coefficient is shown on the figure <ref type="figure" target="#fig_9">10</ref>. The trace plot demonstrates the stationary process, which means good convergence and sufficient burn-in period in the MCMC algorithm. The similar trace plots were received for other coefficients in the linear regression. The density of distributions of some regression coefficients for chosen arbitrary store are shown on the figure <ref type="figure" target="#fig_10">11</ref>. The figure <ref type="figure" target="#fig_11">12</ref> shows the examples for box plots for some regression coefficients Sales time series can have outliers and it is important to take into account this fact using heavy tails distributions instead of Gaussian distribution. For the linear regression with variables with different type of distributions we used Bayesian hierarchical model. We conducted the case study using JAGS sampler <ref type="bibr" target="#b10">[11]</ref> software with "rjags" R package. For modeling, we take into account mean sales for the store, sales, and promo. We consider sales and mean sales for the store in the natural logarithmic scale. For mean sales for stores, we used Gaussian distribution, for sales -Student distribution, and for promo -Bernoulli distribution. In this model, we consider sales as an independent and identically distributed random variable without separating sales for different stores.</p><p>Info about the store is represented by mean sales for the store values. Mean sales for the store (variable meanLogSales) vs sales (variable logSales) obtained for considered Bayesian model are shown on the figure <ref type="figure" target="#fig_3">13</ref>.</p><p>Figure <ref type="figure" target="#fig_3">13</ref>. Mean sales for the store (variable meanLogSales) vs sales (variable logSales) obtained for fitted Bayesian model.</p><p>As the case study shows, the use of Bayesian approach allows us to model stochastic dependencies between different factors of sales time series and receive the distributions for model parameters. Such an approach can be useful for assessing different risks related to sales dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In our cases study we showed different approaches for time series modeling. Forecasting with using linear models, ARIMA algorithm, xgboost machine learning algorithm are described. The results of different models combinations are shown. For probabilistic modeling, the approach with using copulas is shown. The Bayesian inference was applied for time series linear regression case. For time series forecasting the different models combinations technics can give better RMSE accuracy comparing to single algorithms. The probabilistic approach for time series modeling is important in the risk assessment problems. The copula approach gives one the ability to model probabilistic dependence between target values and extreme factors which is useful when a target variable has non Gausian probability density function with heavy tails. Bayesian models can be used to find distributions of coefficients in the linear model of time series. Having model parameters distributions one can find the distribution of target values using Monte-Carlo approaches. For each type of time series, one can develop an optimized approach, which can be based on the combination of different predictive models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Typical time series of store sales.</figDesc><graphic coords="1,316.08,446.40,231.12,116.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2 shows the example of time series forecasting by different methods with RMSE error metric. Let us consider the case of time series forecasting using linear blending of ARIMA and XGBoost models. For arbitrary chosen store (Store 285) we received RMSE=0.11 for ARIMA model, RMSE=0.107 for XGBoost model and RMSE=0.093 for linear blending of ARIMA and XGBoost models. Let us consider the case of using stacking with linear regression on the first step and xgboost on the second step. For arbitrary chosen store (Store 95) we received RMSE=0.122 for XGBoost model and RMSE=0.117 for stacking model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Time series forecastings by different methods.</figDesc><graphic coords="2,97.20,134.88,402.00,203.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Marginal distributions and correlation coefficient.</figDesc><graphic coords="2,316.08,380.16,246.24,275.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Pseudo observations for logSales and prevLogSales variables.</figDesc><graphic coords="3,79.92,264.48,180.00,199.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Pseudo observations for logSales and Customers variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. The probability density function for fitted t-copula.</figDesc><graphic coords="3,315.84,506.88,223.44,223.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. The tree for fitted canonical vine copula with Kendall's tau values.</figDesc><graphic coords="3,57.12,447.36,225.12,252.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Pseudo-observations for constructed canonical vine copula.</figDesc><graphic coords="4,57.12,123.84,184.80,184.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Trace plot for promo coefficient.</figDesc><graphic coords="4,61.68,546.72,214.08,149.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Density of distributions of regression coefficients.</figDesc><graphic coords="4,316.08,146.16,256.32,183.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Box plots for regression coefficients.</figDesc><graphic coords="4,316.08,385.20,241.44,172.56" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rossmann Store Sales</title>
		<ptr target="http://www.kaggle.com/c/rossmann-store-sales" />
	</analytic>
	<monogr>
		<title level="j">Kaggle.Com</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic Time Series Forecasting: The forecast Package for R</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hyndman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Khandakar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Least angle regression</title>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><surname>Johnstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of statistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="407" to="499" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model-based recursive partitioning</title>
		<author>
			<persName><forename type="first">Achim</forename><surname>Zeileis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Hothorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Hornik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="492" to="514" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">XGBoost: A Scalable Tree Boosting System</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.02754</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Stochastic gradient boosting</title>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="367" to="378" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Enjoy the joy of copulas: with a package copula</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modeling dependence with Cand D-vine copulas: The R-package CDVine</title>
		<author>
			<persName><forename type="first">Eike</forename><surname>Brechmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Christian</surname></persName>
		</author>
		<author>
			<persName><surname>Schepsmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">MCMCpack: Markov chain Monte Carlo in R</title>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">M</forename><surname>Quinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Park</forename><surname>Hee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>II</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Martyn</forename><surname>Plummer</surname></persName>
		</author>
		<ptr target="http://sourceforge.net/projects/mcmc-jags/files/Manuals/3.x/jags_user_manual.pdf" />
		<title level="m">JAGS Version 3.4.0 user manual</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
