<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Human-Like Active Learning: Machines Simulating the Human Learning Process</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-11-07">7 Nov 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jaeseo</forename><surname>Lim</surname></persName>
							<email>jaeseolim@snu.ac</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Interdisciplinary Program in Cognitive Science</orgName>
								<orgName type="institution" key="instit2">Seoul National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hwiyeol</forename><surname>Jo</surname></persName>
							<email>hwiyeolj@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computer Technology</orgName>
								<orgName type="institution">Seoul National University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Byoung-Tak</forename><surname>Zhang</surname></persName>
							<email>btzhang@bi.snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Interdisciplinary Program in Cognitive Science</orgName>
								<orgName type="institution" key="instit2">Seoul National University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Seoul National University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">SNU AI Institute</orgName>
								<orgName type="institution">Seoul National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jooyong</forename><surname>Park</surname></persName>
							<email>jooypark@snu.ac</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Interdisciplinary Program in Cognitive Science</orgName>
								<orgName type="institution" key="instit2">Seoul National University</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="laboratory">34th Conference on Neural Information Processing Systems</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<addrLine>NeurIPS 2020)</addrLine>
									<settlement>Vancouver</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Human-Like Active Learning: Machines Simulating the Human Learning Process</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11-07">7 Nov 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">258979F71378CCD9F36D577AE275043B</idno>
					<idno type="arXiv">arXiv:2011.03733v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Although the use of active learning to increase learners' engagement has recently been introduced in a variety of methods, empirical experiments are lacking. In this study, we attempted to align two experiments in order to (1) make a hypothesis for machine and (2) empirically confirm the effect of active learning on learning. In Experiment 1,we compared the effect of a passive form of learning to active form of learning. The results showed that active learning had a greater learning outcomes than passive learning. In the machine experiment based on the human result, we imitated the human active learning as a form of knowledge distillation. The active learning framework performed better than the passive learning framework. In the end, we showed not only that we can make build better machine training framework through the human experiment result, but also empirically confirm the result of human experiment through imitated machine experiments; human-like active learning have crucial effect on learning performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The current educational environment often utilizes passive teaching methods that simply delivers information since it requires students to learn a large amount of knowledge at a limited amount of time. Although passive learning have the advantage of being able to deliver a lot of knowledge, such characteristic this does not directly lead to learners' achievement. Rather, there are many studies that show the problems of passive form of learning.</p><p>Psychologists have perceived that, although learners can learn from receiving knowledge passively, they perform much better by learning actively. Active learning is defined by educational researchers as learning that requires students to engage cognitively and meaningfully with the learning materials <ref type="bibr" target="#b0">[1]</ref>. As students become more active in learning, they get to move in class, or really think about what they learn by analyzing, synthesizing, and evaluating materials rather than just passively receiving it <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>In this paper, the advantages of active learning are outlined, along with the problems of passive learning. Furthermore, through human-like active learning in machine experimentation, we empirically explored the benefits of active learning.</p><p>The Necessity of Active Learning As an alternative to passive learning, various methods have been researched to increase learners' participation. They are called active learning, which requires learner's cognitive intervention <ref type="bibr" target="#b0">[1]</ref>. According to <ref type="bibr" target="#b12">[13]</ref>, the main constructs of active learning are students' engagement with concrete learning experiences, knowledge construction through meaningful activities, and some degree of interaction between students during the learning process. Therefore, active learning eagers innovative learner-centered instructional approach that dynamically involves learners in the learning process.</p><p>As a segmentation for active learning, Chi and colleagues <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b2">3]</ref> proposed the 'Interactive-Constructive-Active-Passive (ICAP)' framework. The ICAP framework classifies active learning into three stages, interactive, constructive, and active, according to the learner's level of cognitive engagement. The passive mode generally refers to a situations where learners listen to lectures, while in active modes learners physically manipulate the information such as learning materials in educational settings. In constructive modes, learners make better efforts to gain knowledge and proceed with the action of making the study material their own by drawing diagrams or asking questions. In interactive modes, two or more colleagues cooperate and co-construct through the process of asking questions and responding to one another during their conversation. Therefore, learners' academic achievement was lowest at P, then increased at A, C, and I in the ascending order. These research demonstrate that active learning, when used appropriately, can enhance learning to a greater extent than passive learning performed in the same amount of time. <ref type="bibr" target="#b10">[11]</ref> Present Study: Human-like Active Learning In recent years, active learning has also been frequently used in machines Åctive learning in machine learning which query the datasets to be labeled for training by an oracle may get higher accuracy. Usually, most active learning in machine learning method focused on mechanism for choosing queries, or only on its high performance. In other words, it has become a learning method for machines, not essentially human's active learning.</p><p>This study aims to identify the effectiveness of active learning based on the ICAP framework and its impact on learners' learning performance. Accordingly, we compared performances of students who learn actively with those of students who learn passively. Thus, the lecture group was set up as a condition for passive learning. On the other hand, the discussion groups was set up as a condition for active learning.</p><p>On the next step, we simulate results of human-like active learning by using machine learning. The machine can complement the limitation of human experiment such as sampling bias, and human subjectivity. Therefore, we intended to maximize the effectiveness of human experimentation through the validation of machine experiments. Therefore, in order to form a form of active learning in human, we have set up teacher models and student models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experiment 1: Humans</head><p>Experiment 1 sought to find out which learning method produces better performance. Here, passive learning was defined as listening to lectures, a traditional learning method, whereas active learning was set as engaging in discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Methodology</head><p>Participants and Design. Fifty-four undergraduate students in selective university participated in this experiment. Participants were assigned to each group randomly: the lecture group (L group, n=25), a passive form of learning and the discussion group (D group, n=29, #groups=9), a active form of learning. Three or four students formed a discussion group. Procedure. The participants first took a background knowledge questionnaire. The L groups watched the video lecture and studied the provided written learning material by themselves without any physical manipulation for 36 minutes. Students of D groups studied the written learning materials by themselves for 18 minutes and then, discussed in groups of three or four for another 18 minutes. In fact, the total amount of learning time for both groups was the same. Lastly, all two groups took a 20 minutes test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Result and Discussion</head><p>Analysis of covariance (ANCOVA) was conducted to examine the differences between the two groups for the three type of test questions (see Appendix). The results revealed that the total means of the D group (M = 38.41, SD = 4.74) was significantly higher than that of L group (M = 27.52, SD = 5.03), F (1, 52) = 61.31, p &lt; .001, η<ref type="foot" target="#foot_0">foot_0</ref> = .55. For the transfer type items, the D group (M = 12.21, SD = 2.76) scored higher than the L group (M = 7.16, SD = 2.73), F (1, 52) = 42.62, p &lt; .001, η 2 = .46. For the paraphrased type questions, the D group (M = 18.93, SD = 3.14) scored significantly higher than the L group (M = 15.40, SD = 2.69), F (1, 52) = 15.74, p &lt; .001, η 2 = .24. Lastly, for the verbatim type questions, the D group (M = 7.35, SD = 1.20) scored significantly higher than the L group (M = 4.96, SD = 1.46), F (1, 52) = 40.60, p &lt; .001, η 2 = .45. The average and standard deviation of the test scores are provided in Figure 1.</p><p>In line with our hypothesis, the D group scored much higher than the L group in all of test question types. Discussions, active learning, promoted greater learning outcome than lectures, passive learning. Consistent with the ICAP framework, the findings showed the learning benefits of active learning. Subsequently, we compared active and passive learning in machines, in order to further validate the out results of human-like active learning.</p><p>3 Experiment 2: Machines</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Methodology</head><p>Datasets and Classifiers. We used five publicly open text classification datasets. 2 Three are topic classification datasets: DBpedia ontology (DBpedia) <ref type="bibr" target="#b9">[10]</ref>, YahooAnswers (Yahoo) <ref type="bibr" target="#b1">[2]</ref>, AGNews and the other two are sentiment classification datasets: Yelp reviews (Yelp) <ref type="bibr" target="#b13">[14]</ref>, IMDB <ref type="bibr" target="#b11">[12]</ref>. Next, we used TextCNN <ref type="bibr" target="#b7">[8]</ref> and LSTM <ref type="bibr" target="#b6">[7]</ref> as classifiers, but we made a difference on model capacity between passive learning and active learning. Passive learning required a teacher model (M T ), which is able to learn from the data fully. On the other hand, student models (M S ) only represent novice learners. Thus, M T has more deep and complex architecture whereas M S has shallow and simple architecture. The details of architecture of TextCNN and LSTM will be described in Appendix. We optimize their loss (see Figure <ref type="figure" target="#fig_1">2</ref>) using Adam <ref type="bibr" target="#b8">[9]</ref>. The other hyperparameters (e.g., learning rate=1e-3, batch size=64) were the same. Implementation. Knowledge transfer was implemented by knowledge distillation <ref type="bibr" target="#b5">[6]</ref>. The method did not use training data directly but it used other models to train a model. That is, a model can learn the other models' prediction scores on the training data. The transfer is implemented by mean squared error loss between two model predictions. By using the idea, the training frameworks were illustrated in Figure <ref type="figure" target="#fig_1">2</ref>. Passive learning (b) used a teacher model (M T ) and a student model (M S ). Both models are trained on the conventional training framework (see (a)) and then knowledge transfer occurred from M T to M S ; it imitates "the teacher provides knowledge to the student." Lastly, (c) imitates active learning used in Experiment 1. Limiting the time (36 mins in passive learning vs. 18 mins in active learning) in Experiment 1 corresponds to constraint the training capacity for machine. Therefore, we used two M S , which is much smaller than M T . Beside, in order to implement discussion, we simply made the knowledge transfer (distillation) in bidirectional ways. Overall method in (c) then imitates that "students use their knowledge (inter)actively to make better results."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Result and Discussion</head><p>The performance of the passive learning framework and the active learning framework are presented in Table <ref type="table">1</ref>. When we compared the result between the passive and the active, the active learning performed better in most of the datasets. These results support our hypothesis that Classifier Methods IMDB Yelp AGNews Yahoo DBpedia CNN x → MT 76.61±.73 56.36±.17 88.85±.38 65.45±.30 98.04±.11 x → MS 78.70±.13 56.31±.25 89.54±.12 67.92±.25 98.01±.03 Passive 78.89±.37 56.60±.08 89.68±.28 66.01±.36 97.85±.12 Active 79.04±.28 56.79±.15 90.21±.13 68.69±.10 98.14±.03 LSTM x → MT 77.05±.13 58.94±.19 89.38±.34 72.23±.20. 98.43±.05 x → MS 77.10±.25 58.26±.24 89.45±.47 71.63±.75 98.26±.06 Passive 77.55±.82 58.90±.20 89.74±.06 72.93±.78 98.33±.02 Active 77.58±.16 59.00±.14 90.53±.23 74.44±.55 98.67±.06</p><p>active learning enhances performance, as observed in Experiment 1. We also investigated that the performance of the passive learning framework were on par with the conventional learning framework (x → M S ), and even were better on several datasets. The reason might be that the teacher model enabled to capture a higher level of representation, and the knowledge is transferred to the student model. Moreover, in some datasets the teacher model might be overfitted to the training data, so their performance on the test data was worse than the student model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this study, we conducted two experiments in order to investigate the effect of active learning on performance. Active learning are generally expected to enhance learners' performance better than passive learning. Because actively participating in learning process allows the learners to activate relevant knowledge, thereby allowing the learners to assimilate novel information to fill in the knowledge gaps, whereas passive learning only allows to store novel information for a while <ref type="bibr" target="#b12">[13]</ref>.</p><p>With this expectation, in Experiment 1, we compared two conditions: lecture (passive learning) and discussion (active learning). As a result, the discussion group scored higher than the lecture group in all types of questions, as expected. These findings also correspond with the ICAP framework that learning performance would be greater in active learning than in passive learning.</p><p>In Experiment 2, we compared performance of active learning with passive learning in machines. Like in the human experiment, machines also increased their performance when they performed human-like active learning. In other words, the two student models exchanged opinions was more efficient than the well-learned teacher model transferring knowledge. We believe that these cognitive processes based approach would help the researchers to build better architectures.</p><p>A Appendix. Samples of three types of test questions: verbatim, paraphrased, and transfer items</p><p>(1) Examples of verbatim item: Given that there is no one who filed an accusation against a crime subject for prosecution, prosecutors must designate a person who can file the complaint within ( ) days upon the request of the stakeholders.</p><p>(Answer: 10)</p><p>(2) Examples of paraphrased items: Explain who the entitled person with the right to file a complaint is.</p><p>(Answer: Provided that there is no one to make the accusation (in case of an offense subject to complaint), prosecutors shall designate the person with the right to file a complaint within 10 days upon request by stakeholders)</p><p>(3) Examples of transfer items: 17. The under-aged victim (V) accused the offender (D) of contempt, and then withdrew his accusation on July 26th, 2017. Afterwards V's mother (M), the legal representative of V, accused D on August 3rd, 2017. D was charged with contempt and was found guilty on the first trial. However, D made an appeal claiming M's complaint is not valid because V has already withdrawn his complaint, and thus, the prosecutor's indictment is against the provisions of the law. Will the Court of Appeals accept D's claim? (Answer: A legal representative of an under-aged victim can independently file a complaint regardless of whether the victim's complaint is nullified. Such complaint can even go against the victim's stated will. Thus, even if victim V withdraws his accusation, the complaint of V's legal representative M is still effective. In conclusion, the Court of Appeals will reject D's claim)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Appendix. The details of Teacher Model and Student Model</head><p>In TextCNN, teacher model (M T ) consisted of 2 convolution layers, which had 32 and 16 channels, respectively. We also utilized multi-kernel approaches, which kernel sizes were 2, 3, 4, and 5. On the other hand, student model M S consisted of 1 convolution layer, which had 32 channels only. Moreover, its kernel size were 2 and 3 only. Likewise, in LSTM, the teacher model architecture consisted of forward and backward LSTM layers (i.e., bidirectional) with 300 hidden nodes. In contrast, the student model architectures had forward LSTM layers only with 150 hidden nodes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Mean scores for the total and the three different question types. (a) total score; (b) transfer type questions; (c) paraphrased type questions; (d) verbatim type questions. Gender and age were adjusted. ***ps &lt; .001. Error bars indicate ±2SE.</figDesc><graphic coords="3,108.00,72.00,396.00,79.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of the training frameworks. (a) the conventional training framework. Pretrained means the model is trained like (a) before using it. (b) passive learning using knowledge distillation (in this case, transfer), which minimizes the loss between the prediction scores of the two models instead of the loss between the prediction scores and the true labels. (c) implementation to imitate active learning.Table 1: The performance of training frameworks on the text classification. x denotes training data, M T denotes the teacher model, which had larger model capacity than the student model (M S ). The arrows (→ and ↔) describe the flow of knowledge transfer. Passive and Active can be symbolized as [x → M T ] → M S and [x → M S ] ↔ [x → M S ], respectively.</figDesc><graphic coords="4,129.78,87.94,62.35,121.57" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Experiment 1 is actually open-ended QA tasks, but for simplicity we use the basic tasks.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<author>
			<persName><forename type="first">C</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">A</forename><surname>Bonwell</surname></persName>
		</author>
		<author>
			<persName><surname>Eison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Active Learning: Creating Excitement in the Classroom. 1991 ASHE-ERIC Higher Education Reports</title>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Importance of semantic representation: Dataless classification</title>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lev-Arie</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="830" to="835" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Active-constructive-interactive: A conceptual framework for differentiating learning activities</title>
		<author>
			<persName><forename type="first">Chi</forename><surname>Michelene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in cognitive science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="105" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The icap framework: Linking cognitive engagement to active learning outcomes</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Michelene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruth</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><surname>Wylie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational psychologist</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="219" to="243" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The role of cognitive engagement in classroom learning and motivation</title>
		<author>
			<persName><forename type="first">Lyn</forename><surname>Corno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><forename type="middle">B</forename><surname>Mandinach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational psychologist</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="88" to="108" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1997</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dbpedia-a largescale, multilingual knowledge base extracted from wikipedia</title>
		<author>
			<persName><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anja</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Morsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Van Kleef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="195" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Active learning through discussion: Icap framework for education in health professions</title>
		<author>
			<persName><forename type="first">Jaeseo</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunwoong</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Won</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songeui</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seunghee</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myung-Sun</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungjoon</forename><surname>Ihm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jooyong</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Medical Education</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning word vectors for sentiment analysis</title>
		<author>
			<persName><forename type="first">Raymond</forename><forename type="middle">E</forename><surname>Andrew L Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">T</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies</title>
		<meeting>the 49th annual meeting of the association for computational linguistics: Human language technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="142" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Differentiated overt learning activities for effective instruction in engineering classrooms</title>
		<author>
			<persName><forename type="first">Muhsin</forename><surname>Menekse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glenda</forename><forename type="middle">S</forename><surname>Stump</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michelene Th</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Engineering Education</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="346" to="374" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="649" to="657" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
