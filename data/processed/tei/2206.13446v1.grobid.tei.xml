<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Edinburgh</roleName><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5274D1940D9DF5A5F18975486D0F5F6B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We may have all heard the saying "use it or lose it". We experience it when we feel rusty in a foreign language or sports that we have not practised in a while. Practice is important to maintain skills but it is also key when learning new ones. This is a reason why many textbooks and courses feature exercises. However, the solutions to the exercises feel often overly brief, or are sometimes not available at all. Rather than an opportunity to practice the new skills, the exercises then become a source of frustration and are ignored. This book contains a collection of exercises with detailed solutions. The level of detail is, hopefully, sufficient for the reader to follow the solutions and understand the techniques used. The exercises, however, are not a replacement of a textbook or course on machine learning. I assume that the reader has already seen the relevant theory and concepts and would now like to deepen their understanding through solving exercises.</p><p>While coding and computer simulations are extremely important in machine learning, the exercises in the book can (mostly) be solved with pen and paper. The focus on penand-paper exercises reduced length and simplified the presentation. Moreover, it allows the reader to strengthen their mathematical skills. However, the exercises are ideally paired with computer exercises to further deepen the understanding.</p><p>The exercises collected here are mostly a union of exercises that I developed for the courses "Unsupervised Machine Learning" at the University of Helsinki and "Probabilistic Modelling and Reasoning" at the University of Edinburgh. The exercises do not comprehensively cover all of machine learning but focus strongly on unsupervised methods, inference and learning. I am grateful to my students for providing feedback and asking questions. Both helped to improve the quality of the exercises and solutions. I am further grateful to both universities for providing the research and teaching environment.</p><p>My hope is that the collection of exercises will grow with time. I intend to add new exercises in the future and welcome contributions from the community. Latex source code is available at <ref type="url" target="https://github.com/michaelgutmann/ml-pen-and-paper-exercises">https://github.com/michaelgutmann/ml-pen-and-paper-exercises</ref>. Please use GitHub's issues to report mistakes or typos, and please get in touch if you would like to make larger contributions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contents</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Gram-Schmidt orthogonalisation</head><p>(a) Given two vectors a 1 and a 2 in R n , show that</p><formula xml:id="formula_0">u 1 = a 1 (1.1)</formula><formula xml:id="formula_1">u 2 = a 2 - u 1 a 2 u 1 u 1 u 1 (1.2)</formula><p>are orthogonal to each other.</p><p>Solution. Two vectors u 1 and u 2 of R n are orthogonal if their inner product equals zero. Computing the inner product u 1 u 2 gives</p><formula xml:id="formula_2">u 1 u 2 = u 1 (a 2 - u 1 a 2 u 1 u 1 u 1 ) (S.1.1) = u 1 a 2 - u 1 a 2 u 1 u 1 u 1 u 1 (S.1.2) = u 1 a 2 -u 1 a 2 (S.1.3) = 0. (S.1.4)</formula><p>Hence the vectors u 1 and u 2 are orthogonal.</p><p>If a 2 is a multiple of a 1 , the orthogonalisation procedure produces a zero vector for u 2 . To see this, let a 2 = αa 1 for some real number α. We then obtain</p><formula xml:id="formula_3">u 2 = a 2 - u 1 a 2 u 1 u 1 u 1 (S.1.5) = αu 1 - αu 1 u 1 u 1 u 1 u 1 (S.1.6)</formula><p>= αu 1 -αu 1 (S.1.7) = 0. (S.1.8) (b) Show that any linear combination of (linearly independent) a 1 and a 2 can be written in terms of u 1 and u 2 .</p><p>Solution. Let v be a linear combination of a 1 and a 2 , i.e. v = αa 1 + βa 2 for some real numbers α and β. Expressing u 1 and u 2 in term of a 1 and a 2 , we can write v as v = αa 1 + βa 2 (S.1.9)</p><formula xml:id="formula_4">= αu 1 + β(u 2 + u 1 a 2 u 1 u 1 u 1 ) (S.1.10) = αu 1 + βu 2 + β u 1 a 2 u 1 u 1 u 1 (S.1.11) = (α + β u 1 a 2 u 1 u 1</formula><p>)u 1 + βu 2 , (S.1.12)</p><p>Since α + β((u 1 a 2 )/(u 1 u 1 )) and β are real numbers, we can write v as a linear combination of u 1 and u 2 . Overall, this means that any vector in the span of {a 1 , a 2 } can be expressed in the orthogonal basis {u 1 , u 2 }.</p><p>(c) Show by induction that for any k ≤ n linearly independent vectors a 1 , . . . , a k , the vectors u i , i = 1, . . . k, are orthogonal, where</p><formula xml:id="formula_5">u i = a i - i-1 j=1</formula><p>u j a i u j u j u j .</p><p>(1.</p><p>3)</p><p>The calculation of the vectors u i is called Gram-Schmidt orthogonalisation.</p><p>Solution. We have shown above that the claim holds for two vectors. This is the base case for the proof by induction. Assume now that the claim holds for k vectors. The induction step in the proof by induction then consists of showing that the claim also holds for k + 1 vectors.</p><p>Assume that u 1 , u 2 , . . . , u k are orthogonal vectors. The linear independence assumption ensures that none of the u i is a zero vector. We then have for u k+1</p><formula xml:id="formula_6">u k+1 = a k+1 - u 1 a k+1 u 1 u 1 u 1 - u 2 a k+1 u 2 u 2 u 2 -. . . - u k a k+1 u k u k u k , (S.1.13)</formula><p>and for all i = 1, 2, . . . , k</p><formula xml:id="formula_7">u i u k+1 = u i a k+1 - u 1 a k+1 u 1 u 1 u i u 1 -. . . - u k a k+1 u k u k u i u k . (S.1.14)</formula><p>By assumption u i u j = 0 if i = j, so that</p><formula xml:id="formula_8">u i u k+1 = u i a k+1 -0 -. . . - u i a k+1 u i u i u i u i -0 . . . -0 (S.1.15)</formula><p>= u i a k+1 -u i a k+1 (S.1.16) = 0, (S.1.17) which means that u k+1 is orthogonal to u 1 , . . . , u k .</p><p>(d) Show by induction that any linear combination of (linear independent) a 1 , a 2 , . . . , a k can be written in terms of u 1 , u 2 , . . . , u k .</p><p>Solution. The base case of two vectors was proved above. Using induction, we assume that the claim holds for k vectors and we will prove that it then also holds for k + 1 vectors: Let v be a linear combination of a 1 , a 2 , . . . , a k+1 , i.e. v = α 1 a 1 + α 2 a 2 + . . . + α k a k + α k+1 a k+1 for some real numbers α 1 , α 2 , . . . , α k+1 . Using the induction assumption, v can be written as v = β 1 u 1 + β 2 u 2 + . . . + β k u k + α k+1 a k+1 , (S.1.18) for some real numbers β 1 , β 2 , . . . , β k Furthermore, using equation (S.1.13), v can be written as</p><formula xml:id="formula_9">v = β 1 u 1 + . . . + β k u k + α k+1 u k+1 + α k+1 u 1 a k+1 u 1 u 1 u 1 (S.1.19) + . . . + α k+1 u k a k+1 u k u k u k . (S.1.20)</formula><p>With γ i = β i + α k+1 (u i a k+1 )/(u i u i ), v can thus be written as v = γ 1 u 1 + γ 2 u 2 + . . . + γ k u k + α k+1 u k+1 , (S.1.21) which completes the proof. Overall, this means that the u 1 , u 2 , . . . , u k form an orthogonal basis for span(a 1 , . . . , a k ), i.e. the set of all vectors that can be obtained by linearly combining the a i .</p><p>(e) Consider the case where a 1 , a 2 , . . . , a k are linearly independent and a k+1 is a linear combination of a 1 , a 2 , . . . , a k . Show that u k+1 , computed according to (1.3), is zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution.</head><p>Starting with (1.3), we have</p><formula xml:id="formula_10">u k+1 = a k+1 - k j=1 u j a k+1 u j u j u j . (S.1.22)</formula><p>By assumption, a k+1 is a linear combination of a 1 , a 2 , . . . , a k . By the previous question, it can thus also be written as a linear combination of the u 1 , . . . , u k . This means that there are some β i so that</p><formula xml:id="formula_11">a k+1 = k i=1 β i u i (S.1.23)</formula><p>holds. Inserting this expansion into the equation above gives</p><formula xml:id="formula_12">u k+1 = k i=1 β i u i - k j=1 k i=1 β i u j u i u j u j u j (S.1.24) = k i=1 β i u i - k i=1 β i u i u i u i u i u i (S.1.25)</formula><p>because u j u i = 0 if i = j. We thus obtain the desired result:</p><formula xml:id="formula_13">u k+1 = k i=1 β i u i - k i=1 β i u i (S.1.26) = 0 (S.1.27)</formula><p>This property of the Gram-Schmidt process in (1.3) can be used to check whether a list of vectors a 1 , a 2 , . . . , a d is linearly independent or not. If, for example, u k+1 is zero, a k+1 is a linear combination of the a 1 , . . . , a k . Moreover, the result can be used to extract a sublist of linearly independent vectors: We would remove a k+1 from the list and restart the procedure in (1.3) with a k+2 taking the place of a k+1 . Continuing in this way constructs a list of linearly independent a j and orthogonal u j , j = 1, . . . , r, where r is the number of linearly independent vectors among the a 1 , a 2 , . . . , a d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Linear transforms</head><p>(a) Assume two vectors a 1 and a 2 are in R 2 . Together, they span a parallelogram. Use Exercise 1.1 to show that the squared area S 2 of the parallelogram is given by S 2 = (a T 2 a 2 )(a T 1 a 1 ) -(a T 2 a 1 ) 2  (1.4)</p><formula xml:id="formula_14">Solution.</formula><p>Let a 1 and a 2 be the vectors that span the parallelogram. From geometry we know that the area of parallelogram is base times height, which is equivalent to the length of the base vector times the length of the height vector. Denote this by</p><formula xml:id="formula_15">S 2 = ||a 1 || 2 ||u 2 || 2 ,</formula><p>where is a 1 is the base vector and u 2 is the height vector which is orthogonal to the base vector. Using the Gram-Schmidt process for the vectors a 1 and a 2 in that order, we obtain the vector u 2 as the second output.</p><formula xml:id="formula_16">u 2 a 1 a 2 a T 1 a 2 a T 1 a 1 a 1 Therefore ||u 2 || 2 equals ||u 2 || 2 = u 2 u 2 (S.1.28) = a 2 - a 1 a 2 a 1 a 1 a 1 a 2 - a 1 a 2 a 1 a 1 a 1 (S.1.29) = a 2 a 2 - (a 1 a 2 ) 2 a 1 a 1 - (a 1 a 2 ) 2 a 1 a 1 + a 1 a 2 a 1 a 1 2 a 1 a 1 (S.1.30) = a 2 a 2 - (a 1 a 2 ) 2 a 1 a 1 . (S.1.31)</formula><p>Thus, S 2 is:</p><formula xml:id="formula_17">S 2 = ||a 1 || 2 ||u 2 || 2 (S.1.32) = (a 1 a 1 )(u 2 u 2 ) (S.1.33) = (a 1 a 1 ) a 2 a 2 - (a 1 a 2 ) 2 a 1 a 1 (S.1.34)</formula><p>= (a 2 a 2 )(a 1 a 1 ) -(a 1 a 2 ) 2 . (S.1.35) (b) Form the matrix A = (a 1 a 2 ) where a 1 and a 2 are the first and second column vector, respectively. Show that</p><formula xml:id="formula_18">S 2 = (det A) 2 .</formula><p>(1.5)</p><p>Solution. We form the matrix A, A = a 1 a 2 = a 11 a 12 a 21 a 22 . (S.1.36) The determinant of A is det A = a 11 a 22 -a 12 a 21 . By multiplying out (a 2 a 2 ), (a 1 a 1 ) and (a 1 a 2 ) 2 , we get a 2 a 2 = a 2 12 + a 2 22 (S.1.37) a 1 a 1 = a 2 11 + a 2 21 (S.1.38) (a 1 a 2 ) 2 = (a 11 a 12 + a 21 a 22 ) 2 = a 2 11 a 2 12 + a 2 21 a 2 22 + 2a 11 a 12 a 21 a 22 . (S.1.39) Therefore the area equals S 2 = (a 2 12 + a 2 22 )(a 2 11 + a 2 21 ) -(a 1 a 2 ) 2 (S.1.40) = a 2 12 a 2 11 + a 2 12 a 2 21 + a 2 22 a 2 11 + a 2 22 a 2 21 -(a 2 12 a 2 11 + a 2 21 a 2 22 + 2a 11 a 12 a 21 a 22 ) (S.1.41) = a 2 12 a 2 21 + a 2 22 a 2 11 -2a 11 a 12 a 21 a 22 (S.1.42) = (a 11 a 22 -a 12 a 21 ) 2 , (S.1.43) which equals (det A) 2 .</p><p>(c) Consider the linear transform y = Ax where A is a 2 × 2 matrix. Denote the image of the rectangle</p><formula xml:id="formula_19">U x = [x 1 x 1 + 1 ] × [x 2 x 2 + 2 ] under the transform A by U y .</formula><p>What is U y ? What is the area of U y ?</p><p>Solution. U y is parallelogram that is spanned by the column vectors a 1 and a 2 of A, when A = (a 1 a 2 ).</p><p>A rectangle with the same area as U x is spanned by vectors (∆ 1 , 0) and (0, ∆ 2 ). Under the linear transform A these spanning vectors become ∆ 1 a 1 and ∆ 2 a 2 . Therefore a parallelogram with the same area as U y is spanned by ∆ 1 a 1 and ∆ 2 a 2 as shown in the following figure.</p><p>U x</p><p>x 2</p><p>x 1 + ∆ 1</p><p>x 2 + ∆ 2</p><p>x 1</p><p>x 1</p><p>x 1 + ∆ 1</p><formula xml:id="formula_20">x 2 + ∆ 2 x 2 a 1 a 2 U y</formula><p>From the previous question, the A Uy of U y equals the absolute value of the determinant of the matrix (∆ 1 a 1 ∆ 2 a 2 ): where A is such that U x is an axis-aligned (hyper-) rectangle as in the previous question.</p><formula xml:id="formula_21">A Uy = | det ∆ 1 a 11 ∆ 2 a 12 ∆ 1 a 21 ∆</formula><p>Solution. We can think that, loosely speaking, the two integrals are limits of the following two sums</p><formula xml:id="formula_22">y i ∈Uy f (y i )vol(∆ y i ) x i ∈Ux f (Ax i )| det A|vol(∆ x i ) (S.1.48)</formula><p>where x i = A -1 y i , which means that x and y are related by y = Ax. The set of function values f (y i ) and f (Ax i ) that enter the two sums are exactly the same. The volume vol(∆ x i ) of a small axis-aligned hypercube (in d dimensions) equals d i=1 ∆ i . The image of this small axis-aligned hypercube under A is a parallelogram ∆ y i with volume vol(∆ y i ) = | det A|vol(∆ x i ). Hence</p><formula xml:id="formula_23">y i ∈Uy f (y i )vol(∆ y i ) = x i ∈Ux f (Ax i )| det A|vol(∆ x i ).</formula><p>(S.1.49)</p><p>We must have the term | det A| to compensate for the fact that the volume of U x and U y are not the same. For example, let A be a diagonal matrix diag(10, 100) so that U x is much smaller than U y . The determinant det A = 1000 then compensates for the fact that the x i values are more condensed than the y i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Eigenvalue decomposition</head><p>For a square matrix A of size n × n, a vector u i = 0 which satisfies</p><formula xml:id="formula_24">Au i = λ i u i (1.7)</formula><p>is called a eigenvector of A, and λ i is the corresponding eigenvalue. For a matrix of size n × n, there are n eigenvalues λ i (which are not necessarily distinct).</p><p>(a) Show that if u 1 and u 2 are eigenvectors with λ 1 = λ 2 , then u = αu 1 + βu 2 is also an eigenvector with the same eigenvalue.</p><p>Solution. We compute Au = αAu 1 + βAu 2 (S.1.50)</p><p>= αλu 1 + βλu 2 (S.1.51)</p><p>= λ(αu 1 + βu 2 ) (S.1.52)</p><p>= λu, (S.1.53) so u is an eigenvector of A with the same eigenvalue as u 1 and u 2 .</p><p>(b) Assume that none of the eigenvalues of A is zero. Denote by U the matrix where the column vectors are linearly independent eigenvectors u i of A. Verify that (1.7) can be written in matrix form as AU = UΛ, where Λ is a diagonal matrix with the eigenvalues λ i as diagonal elements.</p><p>Solution. By basic properties of matrix multiplication, we have</p><formula xml:id="formula_25">AU = (</formula><p>Au 1 Au 2 . . . Au n ) (S.1.54) With Au i = λ i u i for all i = 1, 2, . . . , n, we thus obtain AU = (λ 1 u 1 λ 2 u 2 . . . λ n u n ) (S.1.55) = UΛ. (S.1.56) (c) Show that we can write, with</p><formula xml:id="formula_26">V T = U -1 , A = UΛV , A = n i=1 λ i u i v T i ,<label>(1.8)</label></formula><formula xml:id="formula_27">A -1 = UΛ -1 V , A -1 = n i=1 1 λ i u i v i ,<label>(1.9)</label></formula><p>where v i is the i-th column of V.</p><p>Solution.</p><p>(i) Since the columns of U are linearly independent, U is invertible. Because AU = UΛ, multiplying from the right with the inverse of U gives A = UΛU -1 = UΛV . (ii) Denote by u [i] the ith row of U, v (j) the jth column of V and v [j] the jth row of V and denote B = n i=1 λ i u i v i . Let e [i] be a row vector with 1 in the ith place and 0 elsewhere and e (j) be a column vector with 1 in the jth place and 0 elsewhere. Notice that because A = UΛV , the element in the ith row and jth column is (j)  (S.1.57)</p><formula xml:id="formula_28">A ij = u [i] Λv</formula><p>= u [i] Λv [j]  (S.1.58)</p><formula xml:id="formula_29">= u [i]    λ 1 V j1 . . . λ n V jn    (S.1.59) = n k=1 λ k V jk U ik . (S.1.60)</formula><p>On the other hand, for matrix B the element in the ith row and jth column is</p><formula xml:id="formula_30">B ij = n k=1</formula><p>λ k e [i] u k v k e (j) (S.1.61)</p><formula xml:id="formula_31">= n k=1 λ k U ik V jk , (S.1.62)</formula><p>which is the same as A ij . Therefore A = B.</p><p>(iii) Since Λ is a diagonal matrix with no zeros as diagonal elements, it is invertible. We have thus</p><p>A -1 = (UΛU -1 ) -1 (S.1.63) = (ΛU -1 ) -1 U -1 (S.1.64)</p><p>= UΛ -1 U -1 (S.1.65)</p><p>= UΛ -1 V . (S.1.66)</p><p>(iv) This follows from A = UΛV = i u i λ i v i , when λ i is replaced with 1/λ i .</p><p>1.4 Trace, determinants and eigenvalues where, in the last line, we have used that the determinant of a diagonal matrix is the product of its elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Eigenvalue decomposition for symmetric matrices</head><p>(a) Assume that a matrix A is symmetric, i.e. A = A. Let u 1 and u 2 be two eigenvectors of A with corresponding eigenvalues λ 1 and λ 2 , with λ 1 = λ 2 . Show that the two vectors are orthogonal to each other.</p><p>Solution. Since Au 2 = λ 2 u 2 , we have</p><formula xml:id="formula_32">u 1 Au 2 = λ 2 u 1 u 2 .</formula><p>(S.1.76)</p><p>Taking the transpose of u 1 Au 2 gives</p><formula xml:id="formula_33">(u 1 Au 2 ) = (Au 2 ) (u 1 ) = u 2 A u 1 = u 2 Au 1 (S.1.77) = λ 1 u 2 u 1 (S.1.78)</formula><p>because A is symmetric and Au 1 = λ 1 u 1 . On the other hand, the same operation gives</p><formula xml:id="formula_34">(u 1 Au 2 ) = (λ 2 u 1 u 2 ) = λ 2 u 2 u 1 (S.1.79)</formula><p>Therefore λ 1 u 2 u 1 = λ 2 u 2 u 1 , which is equivalent to u 2 u 1 (λ 1 -λ 2 ) = 0. Because λ 1 = λ 2 , the only possibility is that u 2 u 1 = 0. Therefore u 1 and u 2 are orthogonal to each other.</p><p>The result implies that the eigenvectors of a symmetric matrix A with distinct eigenvalues λ i forms an orthogonal basis. The result extends to the case where some of the eigenvalues are the same (not proven).</p><p>(b) A symmetric matrix A is said to be positive definite if v T Av &gt; 0 for all non-zero vectors v. Show that positive definiteness implies that λ i &gt; 0, i = 1, . . . , M . Show that, vice versa, λ i &gt; 0, i = 1 . . . M implies that the matrix A is positive definite. Conclude that a positive definite matrix is invertible.</p><p>Solution. Assume that v Av &gt; 0 for all v = 0. Since eigenvectors are not zero vectors, the assumption holds also for eigenvector u k with corresponding eigenvalue λ k . Now</p><formula xml:id="formula_35">u k Au k = u k λ k u k = λ k (u k u k ) = λ k ||u k || &gt; 0 (S.1.80)</formula><p>and because ||u k || &gt; 0, we obtain λ k &gt; 0.</p><p>Assume now that all the eigenvalues of A, λ 1 , λ 2 , . . . , λ n , are positive and nonzero. We have shown above that there exists an orthogonal basis consisting of eigenvectors u 1 , u 2 , . . . , u n and therefore every vector v can be written as a linear combination of those vectors (we have only shown it for the case of distinct eigenvalues but it holds more generally). Hence for a nonzero vector v and for some real numbers α 1 , α 2 , . . . , α n , we have</p><formula xml:id="formula_36">v Av = (α 1 u 1 + + . . . + α n u n ) A(α 1 u 1 + . . . + α n u n ) (S.1.81) = (α 1 u 1 + . . . + α n u n ) (α 1 Au 1 + . . . + α n Au n ) (S.1.82) = (α 1 u 1 + . . . + α n u n ) (α 1 λ 1 u 1 + . . . + α n λ n u n ) (S.1.83) = i,j</formula><p>α i u i α j λ j u j (S.1.84)</p><formula xml:id="formula_37">= i α i α i λ i u i u i (S.1.85) = i (α i ) 2 ||u i || 2 λ i , (S.1.86)</formula><p>where we have used that u T i u j = 0 if i = j, due to orthogonality of the basis. Since (α i ) 2 &gt; 0, ||u i || 2 &gt; 0 and λ i &gt; 0 for all i, we find that v Av &gt; 0.</p><p>Since every eigenvalue of A is nonzero, we can use Exercise 1.3 to conclude that inverse of A exists and equals i 1/λ i u i u i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.6">Power method</head><p>We here analyse an algorithm called the "power method". The power method takes as input a positive definite symmetric matrix Σ Σ Σ and calculates the eigenvector that has the largest eigenvalue (the "first eigenvector"). For example, in case of principal component analysis, Σ Σ Σ is the covariance matrix of the observed data and the first eigenvector is the first principal component direction.</p><p>The power method consists in iterating the update equations where Λ is the diagonal matrix with eigenvalues λ i of Σ Σ Σ as diagonal elements. Let the eigenvalues be ordered λ 1 &gt; λ 2 &gt; . . . &gt; λ n &gt; 0 (and, as additional assumption, all distinct).</p><formula xml:id="formula_38">v k+1 = Σ Σ Σw k , w k+1 = v k+1 ||v k+1 || 2 , (<label>1</label></formula><p>(b) Let ṽk = U T v k and wk = U T w k . Write the update equations of the power method in terms of ṽk and wk . This means that we are making a change of basis to represent the vectors w k and v k in the basis given by the eigenvectors of Σ Σ Σ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution.</head><p>With</p><formula xml:id="formula_39">v k+1 = Σ Σ Σw k (S.1.88) = UΛU w k (S.1.89)</formula><p>we obtain</p><formula xml:id="formula_40">U v k+1 = ΛU w k . (S.1.90)</formula><p>Hence ṽk+1 = Λ wk . The norm of ṽk+1 is the same as the norm of v k+1 :</p><formula xml:id="formula_41">||ṽ k+1 || 2 = ||U v k+1 || 2 (S.1.91) = (U v k+1 ) (U v k+1 ) (S.1.92) = v k+1 UU v k+1 (S.1.93) = v k+1 v k+1 (S.1.94) = ||v k+1 || 2 . (S.1.95)</formula><p>Hence, the update equation, in terms of ṽk and wk , is</p><formula xml:id="formula_42">ṽk+1 = Λ wk , wk+1 = ṽk+1 ||ṽ k+1 || . (S.1.96) (c)</formula><p>Assume you start the iteration with w0 . To which vector w * does the iteration converge to?</p><formula xml:id="formula_43">Solution. Let w0 = α 1 α 2 . . . α n . Since Λ is a diagonal matrix, we obtain ṽ1 =      λ 1 α 1 λ 2 α 2 . . . λ n α n      = λ 1 α 1      1 α 2 α 1 λ 2 λ 1 . . . αn α 1 λn λ 1      (S.1.97)</formula><p>and therefore</p><formula xml:id="formula_44">w1 = λ 1 α 1 c 1      1 α 2 α 1 λ 2 λ 1 . . . αn α 1 λn λ 1      , (S.1.98)</formula><p>where c 1 is a normalisation constant such that w1 = 1 (i.e. c 1 = ṽ1 ). Hence, for wk it holds that</p><formula xml:id="formula_45">wk = ck        1 α 2 α 1 λ 2 λ 1 k . . . αn α 1 λn λ 1 k        , (S.1.99)</formula><p>where ck is again a normalisation constant such that || wk || = 1.</p><p>As λ 1 is the dominant eigenvalue, |λ j /λ 1 | &lt; 1 for j = 2, 3, . . . , n, so that</p><formula xml:id="formula_46">lim k→∞ λ j λ 1 k = 0, j = 2, 3, . . . , n, (S.1.100)</formula><p>and hence</p><formula xml:id="formula_47">lim k→∞        1 α 2 α 1 λ 2 λ 1 k . . . αn α 1 λn λ 1 k        =      1 0 . . . 0      . (S.1.101)</formula><p>For the normalisation constant ck , we obtain</p><formula xml:id="formula_48">ck = 1 1 + n i=2 α i α 1 2 λ i λ 1 2k , (S.1.102)</formula><p>and therefore</p><formula xml:id="formula_49">lim k→∞ ck = 1 1 + n i=2 α i α 1 2 lim k→∞ λ i λ 1 2k (S.1.103) = 1 1 + n i=2 α i α 1 2 • 0 (S.1.104) = 1. (S.1.105)</formula><p>The limit of the product of two convergent sequences is the product of the limits so that</p><formula xml:id="formula_50">lim k→∞ wk = lim k→∞ ck lim k→∞        1 α 2 α 1 λ 2 λ 1 k . . . αn α 1 λn λ 1 k        =      1 0 . . . 0      .</formula><p>(S.1.106) (d) Conclude that the power method finds the first eigenvector.</p><p>Solution. Since w k = U wk , we obtain</p><formula xml:id="formula_51">lim k→∞ w k = U      1 0 . . . 0      = u 1 , (S.1.107)</formula><p>which is the eigenvector with the largest eigenvalue, i.e. the "first" or "dominant" eigenvector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Gradient of vector-valued functions</head><p>For a function J that maps a column vector w ∈ R n to R, the gradient is defined as</p><formula xml:id="formula_52">∇J(w) =     ∂J(w) ∂w 1 . . . ∂J(w) ∂wn     ,<label>(2.1)</label></formula><p>where ∂J(w)/∂w i are the partial derivatives of J(w) with respect to the i-th element of the vector w = (w 1 , . . . , w n ) (in the standard basis). Alternatively, it is defined to be the column vector ∇J(w) such that</p><formula xml:id="formula_53">J(w + h) = J(w) + (∇J(w)) h + O( 2 ) (2.2)</formula><p>for an arbitrary perturbation h. This phrases the derivative in terms of a first-order, or affine, approximation to the perturbed function J(w + h). The derivative ∇J is a linear transformation that maps h ∈ R n to R (see e.g. Rudin, 1976, Chapter 9, for a formal treatment of derivatives).</p><p>Use either definition to determine ∇J(w) for the following functions where a ∈ R n , A ∈ R n×n and f : R → R is a differentiable function.</p><p>(a) J(w) = a w.</p><p>Solution. First method:</p><formula xml:id="formula_54">J(w) = a w = n k=1 a k w k =⇒ ∂J(w) ∂w i = a i (S.2.1) Hence ∇J(w) =      a 1 a 2 . . . a n      = a. (S.2.2)</formula><p>Second method:</p><formula xml:id="formula_55">J(w + h) = a (w + h) = a w J(w) + a h ∇J h (S.2.3)</formula><p>Hence we find again ∇J(w) = a.</p><p>(b) J(w) = w Aw.</p><p>Solution. First method: We start with</p><formula xml:id="formula_56">J(w) = w Aw = n i=1 n j=1 w i A ij w j (S.2.4) Hence, ∂J(w) ∂w k = n j=1 A kj w j + n i=1 w i A ik (S.2.5) = n j=1 A kj w j + n i=1 w i (A ) ki (S.2.6) = m j=1 A kj + (A ) kj w j (S.2.7)</formula><p>where we have used that the entry in row i and column k of the matrix A equals the entry in row k and column i of its transpose A . It follows that</p><formula xml:id="formula_57">∇J(w) =    n j=1 A 1j + (A ) 1j w j . . . n j=1 A nj + (A ) nj w j    (S.2.8) = (A + A )w, (S.2.9)</formula><p>where we have used that sums like j B ij w j are equal to the i-th element of the matrix-vector product Bw.</p><p>Second method:</p><formula xml:id="formula_58">J(w + h) = (w + h) A(w + h) (S.2.10) = w Aw + w A( h) + h Aw + h A h O( 2 ) (S.2.11) = w Aw + (w Ah + w A h) + O( 2 ) (S.2.12) = w Aw J(w) + (w A + w A ∇J(w) )h + O( 2 ) (S.2.13)</formula><p>where we have used that h Aw is a scalar so that h Aw = (h Aw) = w A h.</p><formula xml:id="formula_59">Hence ∇J(w) = w A + w A = w (A + A ) (S.2.14) and ∇J(w) = (A + A )w. (S.2.15) (c) J(w) = w w.</formula><p>Solution. The easiest way to calculate the gradient of J(w) = w w is to use the previous question with A = I (the identity matrix). Therefore</p><formula xml:id="formula_60">∇J(w) = Iw + I w = w + w = 2w. (S.2.16) (d) J(w) = ||w|| 2 .</formula><p>Solution. Note that ||w|| 2 = √ w w.</p><p>First method: We use the chain rule</p><formula xml:id="formula_61">∂J(w) ∂w k = ∂ √ w w ∂w w ∂w w ∂w k (S.2.17) and that ∂ √ w w ∂w w = 1 2 √ w w (S.2.18)</formula><p>The derivatives ∂w w/∂w k were calculated in the question above so that</p><formula xml:id="formula_62">∇J(w) = 1 2 √ w w 2w = w ||w|| 2 (S.2.19)</formula><p>Second method: Let f (w) = w w. From the previous question, we know that</p><formula xml:id="formula_63">f (w + h) = f (w) + 2w h + O( 2 ). (S.2.20) Moreover, z + u + O( 2 ) = √ z + 1 2 √ z ( u + O( 2 )) + O( 2 ) (S.2.21) = √ z + 1 2 √ z u + O( 2 ) (S.2.22)</formula><p>With z = f (w) and u = 2w h, we thus obtain</p><formula xml:id="formula_64">J(w + h) = f (w + h) (S.2.23) = f (w) + 1 2 f (w) 2w h + O( 2 ) (S.2.24) = f (w) + w f (w) h + O( 2 ) (S.2.25) = J(w) + w ||w|| 2 h + O( 2 ) (S.2.26) so that ∇J(w) = w ||w|| 2 . (S.2.27) (e) J(w) = f (||w|| 2 ).</formula><p>Solution. Either the chain rule or the approach with the Taylor expansion can be used to deal with the outer function f . In any case:</p><formula xml:id="formula_65">∇J(w) = f (||w|| 2 )∇||w|| 2 = f (||w|| 2 ) w ||w|| 2 , (S.2.28)</formula><p>where f is the derivative of the function f .</p><p>(f) J(w) = f (w a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution.</head><p>We have seen that ∇ w a w = a. Using the chain rule then yields</p><formula xml:id="formula_66">∇J(w) = f (w a)∇(w a) (S.2.29)</formula><p>=f (w a)a (S.2.30)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Newton's method</head><p>Assume that in the neighbourhood of w 0 , a function J(w) can be described by the quadratic approximation</p><formula xml:id="formula_67">f (w) = c + g (w -w 0 ) + 1 2 (w -w 0 ) H(w -w 0 ),<label>(2.3)</label></formula><p>where c = J(w 0 ), g is the gradient of J with respect to w, and H a symmetric positive definite matrix (e.g. the Hessian matrix for J(w) at w 0 if positive definite).</p><p>(a) Use Exercise 2.1 to determine ∇f (w).</p><p>Solution. We first write f as</p><formula xml:id="formula_68">f (w) = c + g (w -w 0 ) + 1 2 (w -w 0 ) T H(w -w 0 ) (S.2.31) = c -g w 0 + 1 2 w 0 Hw 0 + g w + 1 2 w Hw - 1 2 w 0 Hw - 1 2 w Hw 0 (S.2.32)</formula><p>Using now that w Hw 0 is a scalar and that H is symmetric, we have w Hw 0 = (w Hw 0 ) = w 0 H w = w 0 Hw (S.2.33) and hence</p><formula xml:id="formula_69">f (w) = const + (g -w 0 H)w + 1 2 w Hw (S.2.34)</formula><p>With the results from Exercise 2.1 and the fact that H is symmetric, we thus obtain</p><formula xml:id="formula_70">∇f (w) = g -H w 0 + 1 2 (H w + Hw) (S.2.35) = g -Hw 0 + Hw (S.2.36)</formula><p>The expansion of f (w) due to the ww 0 terms is a bit tedious. It is simpler to note that gradients define a linear approximation of the function. We can more efficiently deal with ww 0 by changing the coordinates and determine the linear approximation of f as a function of v = ww 0 , i.e. locally around the point w 0 .</p><p>We then have</p><formula xml:id="formula_71">f (v) = f (v + w 0 ) (S.2.37) = c + g v + 1 2 v Hv (S.2.38)</formula><p>With Exercise 2.1, the derivative is</p><formula xml:id="formula_72">∇ v f (v) = g + Hv (S.2.39)</formula><p>and the linear approximation becomes</p><formula xml:id="formula_73">f (v + h) = c + (g + Hv) h + O( 2 ) (S.2.40)</formula><p>The linear approximation for f determines a linear approximation of f around w 0 , i.e.</p><formula xml:id="formula_74">f (w + h) = f (w -w 0 + h) = c + (g + H(w -w 0 )) h + O( 2 ) (S.2.41)</formula><p>so that the derivative for f is</p><formula xml:id="formula_75">∇ w f (w) = g + H(w -w 0 ) = g -Hw 0 + Hw, (S.2.42)</formula><p>which is the same result as before.</p><p>(b) A necessary condition for w being optimal (leading either to a maximum, minimum or a saddle point) is ∇f (w) = 0. Determine w * such that ∇f (w) w=w * = 0. Provide arguments why w * is a minimiser of f (w).</p><p>Solution. We set the gradient to zero and solve for w:</p><formula xml:id="formula_76">g + H(w -w 0 ) = 0 ↔ w -w 0 = -H -1 g (S.2.43) so that w * = w 0 -H -1 g. (S.2.44)</formula><p>As we assumed that H is positive definite, the inverse H exists (and is positive definite too).</p><p>Let us consider f as a function of v around w * , i.e. w = w * +v. With w * +v -w 0 = -H -1 g + v, we have</p><formula xml:id="formula_77">f (w * + v) = c + g (-H -1 g + v) + 1 2 (-H -1 g + v) H(-H -1 g + v) (S.2.45)</formula><p>Since H is positive definite, we have that (-</p><formula xml:id="formula_78">H -1 g + v) H(-H -1 g + v) &gt; 0 for all v.</formula><p>Hence, as we move away from w * , the function increases quadratically, so that w * minimises f (w).</p><p>(c) In terms of Newton's method to minimise J(w), what do w 0 and w * stand for?</p><p>Solution. The equation</p><formula xml:id="formula_79">w * = w 0 -H -1 g. (S.2.46)</formula><p>corresponds to one update step in Newton's method where w 0 is the current value of w in the optimisation of J(w) and w * is the updated value. In practice rather than determining the inverse H -1 , we solve Hp = g (S.2.47) for p and then set w * = w 0 -p. The vector p is the search direction, and it is possible include a step-length α so that the update becomes w * = w 0 -αp. The value of α may be set by hand or can be determined via line-search methods (see e.g. Nocedal and Wright, 1999).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Gradient of matrix-valued functions</head><p>For functions J that map a matrix W ∈ R n×m to R, the gradient is defined as</p><formula xml:id="formula_80">∇J(W) =     ∂J(W) ∂W 11 . . . ∂J(W) ∂W 1m . . . . . . . . . ∂J(W) ∂W n1 . . . ∂J(W) ∂Wnm     .</formula><p>(2.4)</p><p>Alternatively, it is defined to be the matrix ∇J such that</p><formula xml:id="formula_81">J(W + H) = J(w) + tr(∇J H) + O( 2 ) (2.5) = J(w) + tr(∇JH ) + O( 2 ) (2.6)</formula><p>This definition is analogue to the one for vector-valued functions in (2.2). It phrases the derivative in terms of a linear approximation to the perturbed objective J(W + H) and, more formally, tr ∇J is a linear transformation that maps H ∈ R n×m to R (see e.g. <ref type="bibr" target="#b34">Rudin, 1976</ref>, Chapter 9, for a formal treatment of derivatives).</p><p>Let e (i) be column vector which is everywhere zero but in slot i where it is 1. Moreover let e [j] be a row vector which is everywhere zero but in slot j where it is 1. The outer product e (i) e [j] is then a matrix that is everywhere zero but in row i and column j where it is one. For H = e (i) e [j] , we obtain</p><formula xml:id="formula_82">J(W + e (i) e [j] ) = J(W) + tr((∇J) e (i) e [j] ) + O( 2 ) (2.7) = J(W) + e [j] (∇J) e (i) + O( 2 ) (2.8) = J(W) + e [i] ∇Je (j) + O( 2 ) (2.9)</formula><p>Note that e [i] ∇Je (j) picks the element of the matrix ∇J that is in row i and column j, i.e. e [i] ∇Je (j) = ∂J/∂W ij .</p><p>Use either of the two definitions to find ∇J(W) for the functions below, where</p><formula xml:id="formula_83">u ∈ R n , v ∈ R m , A ∈ R n×m , and f : R → R is differentiable. (a) J(W) = u Wv. Solution. First method: With J(W) = n i=1 m j=1 u i W ij v j we have ∂J(W) W kl = u k v l = (uv ) kl (S.2.48)</formula><p>and hence ∇J(W) = uv (S.2.49)</p><p>Second method:</p><formula xml:id="formula_84">J(W + H) = u (W + H)v (S.</formula><p>2.50) = J(W) + u Hv (S.2.51) = J(W) + tr(u Hv) (S.2.52) = J(W) + tr(vu H) (S.2.53) Hence:</p><formula xml:id="formula_85">∇J(W) = uv (S.2.54) (b) J(W) = u (W + A)v.</formula><p>Solution. Expanding the objective function gives J(W) = u Wv + u Av. The second term does not depend on W. With the previous question, the derivative thus is</p><formula xml:id="formula_86">∇J(W) = uv (S.2.55) (c) J(W) = n f (w n v)</formula><p>, where w n are the rows of the matrix W.</p><p>Solution. First method:</p><formula xml:id="formula_87">∂J(W) ∂W ij = n k=1 ∂ ∂W ij f (w k v) (S.2.56) = f (w i v) ∂ ∂W ij w i v m j=1 W ij v j (S.2.57) = f (w i v)v j (S.2.58) Hence ∇J(W) = f (Wv)v , (S.2.59)</formula><p>where f operates element-wise on the vector Wv.</p><p>Second method:</p><formula xml:id="formula_88">J(W) = n k=1 f (w k v) (S.2.60) = n k=1 f (e [k] Wv), (S.2.61)</formula><p>where e [k] is the unit row vector that is zero everywhere but for element k which equals one. We now perform a perturbation of W by H.</p><formula xml:id="formula_89">J(W + H) = n k=1 f (e [k] (W + H)v) (S.2.62) = n k=1 f (e [k] Wv + e [k] Hv) (S.2.63) = n k=1 (f (e [k] Wv) + f (e [k] Wv)e [k] Hv + O( 2 ) (S.2.64) = J(W) + n k=1 f (e [k] Wv)e [k] Hv + O( 2 ) (S.2.65)</formula><p>The term f (e [k] Wv)e [k] is a row vector that equals (0, . . . , 0, f (e [k] Wv), 0, . . . , 0). Hence, we have</p><formula xml:id="formula_90">n k=1 f (e [k] Wv)e [k] ) = f (Wv) (S.2.66)</formula><p>where f operates element-wise on the column vector Wv. The perturbed objective function thus is</p><formula xml:id="formula_91">J(W + H) = J(W) + f (Wv) Hv + O( 2 ) (S.2.67) = J(W) + tr f (Wv) Hv + O( 2 ) (S.2.68) = J(W) + tr vf (Wv) H + O( 2 ) (S.2.69)</formula><p>Hence, the gradient is the transpose of vf (Wv) , i.e.</p><formula xml:id="formula_92">∇J(W) = f (Wv)v (S.2.70) (d) J(W) = u W -1 v (Hint: (W + H) -1 = W -1 -W -1 HW -1 + O( 2 ).)</formula><p>Solution. We first verify the hint:</p><formula xml:id="formula_93">W -1 -W -1 HW -1 + O( 2 ) (W + H) = I + W -1 H -W -1 H + O( 2 ) (S.2.71) = I + O( 2 ) (S.2.72)</formula><p>Hence the identity holds up to terms smaller than 2 , which is sufficient we do not care about terms of order 2 and smaller in the definition of the gradient in (2.5).</p><p>Let us thus make a first-order approximation of the perturbed objective J(W + H):</p><formula xml:id="formula_94">J(W + H) = u (W + Hv) -1 v (S.2.73) hint = u (W -1 -W -1 HW -1 + O( 2 ))v (S.2.74) = u W -1 v -u W -1 HW -1 v + O( 2 ) (S.2.75) = J(W) -tr u W -1 HW -1 v + O( 2 ) (S.2.76) = J(W) -tr W -1 vu W -1 H + O( 2 ) (S.2.77)</formula><p>Comparison with (2.5) gives</p><formula xml:id="formula_95">∇J = -W -1 vu W -1 (S.2.78)</formula><p>and hence</p><formula xml:id="formula_96">∇J = -W -uv W -, (S.2.79)</formula><p>where W -is the transpose of the inverse of W.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Gradient of the log-determinant</head><p>The goal of this exercise is to determine the gradient of</p><formula xml:id="formula_97">J(W) = log | det(W)|.</formula><p>(2.10) (a) Show that the n-th eigenvalue λ n can be written as</p><formula xml:id="formula_98">λ n = v n Wu n ,<label>(2.11)</label></formula><p>where u n is the nth eigenvector and v n the nth column vector of U -1 , with U being the matrix with the eigenvectors u n as columns.</p><p>Solution. As in Exercise 1.3, let UΛV be the eigenvalue decomposition of W (with V = U -1 ). Then Λ = V WU and</p><formula xml:id="formula_99">λ n = e [n] Λe (n) (S.2.80) = e [n] V WUe (n) (S.2.81) = (Ve (n) ) WUe (n) (S.2.82) = v n Wu n , (S.2.83)</formula><p>where e (n) is the standard basis (unit) vector with a 1 in the n-th slot and zeros elsewhere, and e [n] is the corresponding row vector.</p><p>(b) Calculate the gradient of λ n with respect to W, i.e. ∇λ n (W).</p><p>Solution. With Exercise 2.3, we have (ii) If W is a matrix with real entries, then Wu = λu implies Wū = λū, i.e. if λ is a complex eigenvalue, then λ (the complex conjugate of λ) is also an eigenvalue.</p><formula xml:id="formula_100">∇ W λ n (W) = ∇ W v n Wu n = v n u n . (S.</formula><p>Since</p><formula xml:id="formula_101">|λ| 2 = λ λ, | det(W)| =   λ i ∈C λ i     λ j ∈R |λ j |   . (S.2.85)</formula><p>Now we can write J(W) in terms of the eigenvalues:</p><formula xml:id="formula_102">J(W) = log | det(W)| (S.2.86) = log   λ i ∈C λ i     λ j ∈R |λ j |   (S.2.87) = log   λ i ∈C λ i   + log   λ j ∈R |λ j |   (S.2.88) = λ i ∈C log λ i + λ j ∈R log |λ j |. (S.2.89)</formula><p>Assume that the real-valued λ j are non-zero so that</p><formula xml:id="formula_103">∇ W log |λ j | = 1 |λ j | ∇ W |λ j | (S.2.90) = 1 |λ j | sign(λ j )∇ W λ j (S.2.91) Hence ∇J(W) = λ i ∈C ∇ W log λ i + λ j ∈R ∇ W log |λ j | (S.2.92) = λ i ∈C 1 λ i ∇ W λ i + λ i ∈R 1 |λ i | sign(λ i )∇ W λ i (S.2.93) = λ i ∈C v i u i λ i + λ i ∈R sign(λ i )v i u i |λ i | (S.2.94) = λ i ∈C v i u i λ i + λ i ∈R v i u i λ i (S.2.95) = i v i u i λ i . (S.2.96) (d) Show that ∇J(W) = (W -1 ) .</formula><p>(2.12)</p><p>Solution. This follows from Exercise 1.3 where we have found that</p><formula xml:id="formula_104">W -1 = i 1 λ i u i v i .</formula><p>(S.2.97) Indeed:</p><formula xml:id="formula_105">∇J(W) = i v i u i λ i = i 1 λ i (u i v i ) = W -1 . (S.2.98)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Descent directions for matrix-valued functions</head><p>Assume we would like to minimise a matrix valued function J(W) by gradient descent, i.e. the update equation is</p><formula xml:id="formula_106">W ← W -∇J(W),<label>(2.13)</label></formula><p>where is the step-length. The gradient ∇J(W) was defined in Exercise 2.3. It was there pointed out that the gradient defines a first order approximation to the perturbed objective function J(W + H). With (2.5),</p><formula xml:id="formula_107">J(W -∇J(W)) = J(W) -tr(∇J(W) ∇J(W)) + O( 2 ) (2.14)</formula><p>For any (nonzero) matrix M, it holds that</p><formula xml:id="formula_108">tr(M M) = i (M M) ii (2.15) = i j (M ) ij (M) ji (2.16) = i j M ji M ji (2.17) = ij (M ji ) 2 (2.18) &gt; 0,<label>(2.19)</label></formula><p>which means that tr(∇J(W) ∇J(W)) &gt; 0 if the gradient is nonzero, and hence</p><formula xml:id="formula_109">J(W -∇J(W)) &lt; J(W) (2.20)</formula><p>for small enough . Consequently, ∇J(W) is a descent direction. Show that A A∇J(W)BB for non-zero matrices A and B is also a descent direction or leaves the leaves the objective invariant.</p><p>Solution. As in the introduction to the question, we appeal to (2.5) to obtain</p><formula xml:id="formula_110">J(W -∇J(W)A ABB ) = J(W) -tr(∇J(W) A A∇J(W)BB ) + O( 2 ) (S.2.99) = J(W) -tr(B ∇J(W) A A∇J(W)B) + O(</formula><p>2 ), (S.2.100) where tr(B ∇J(W) A A∇J(W)B) takes the form tr(M M) with M = A∇J(W)B. With (2.19), we thus have tr(B ∇J(W) A A∇J(W)B) &gt; 0 if A∇J(W)B is non-zero, and hence J(W -A A∇J(W)BB ) &lt; J(W) (S.2.101) for small enough . We have equality if A∇J(W)B = 0, e.g. if the columns of B are all in the null space of ∇J. Chapter 3 Directed Graphical Models Exercises 3.1 Directed graph concepts . . . . . . . . . . . . . . . . . . . . . . . 3.2 Canonical connections . . . . . . . . . . . . . . . . . . . . . . . . . 3.3 Ordered and local Markov properties, d-separation . . . . . . . 3.4 More on ordered and local Markov properties, d-separation . 3.5 Chest clinic (based on Barber, 2012, Exercise 3.3) . . . . . . . 3.6 More on the chest clinic (based on Barber, 2012, Exercise 3.3) 3.7 Hidden Markov models . . . . . . . . . . . . . . . . . . . . . . . . 3.8 Alternative characterisation of independencies . . . . . . . . . . 3.9 More on independencies . . . . . . . . . . . . . . . . . . . . . . . 3.10 Independencies in directed graphical models . . . . . . . . . . . 3.11 Independencies in directed graphical models . . . . . . . . . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Directed graph concepts</head><p>Consider the following directed graph: a z q e h (a) List all trails in the graph (of maximal length)</p><p>Solution. We have (a, q, e) (a, q, z, h) (h, z, q, e)</p><p>and the corresponding ones with swapped start and end nodes.</p><p>(b) List all directed paths in the graph (of maximal length)</p><p>Solution. (a, q, e) (z, q, e) (z, h) Solution. nondesc(q) = {a, z, h, e} \ {e} = {a, z, h} (e) Which of the following orderings are topological to the graph?</p><p>• (a,z,h,q,e)</p><p>• (a,z,e,h,q)</p><p>• (z,a,q,h,e)</p><p>• (z,q,e,a,h)</p><p>Solution.</p><p>• (a,z,h,q,e): yes</p><p>• (a,z,e,h,q): no (q is a parent of e and thus has to come before e in the ordering)</p><p>• (z,a,q,h,e): yes</p><p>• (z,q,e,a,h): no (a is a parent of q and thus has to come before q in the ordering)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Canonical connections</head><p>We here derive the independencies that hold in the three canonical connections that exist in DAGs, shown in Figure <ref type="figure" target="#fig_14">3</ref>.1.</p><p>x z y (a) For the serial connection, use the ordered Markov property to show that x ⊥ ⊥ y | z. Solution. The only topological ordering is x, z, y. The predecessors of y are pre y = {x, z} and its parents pa y = {z}. The ordered Markov property y ⊥ ⊥ (pre y \ pa y ) | pa y (S.3.1) thus becomes y ⊥ ⊥ ({x, z} \ z) | z. Hence we have y ⊥ ⊥ x | z, (S.3.2) which is the same as x ⊥ ⊥ y | z since the independency relationship is symmetric.</p><p>This means that if the state or value of z is known (i.e. if the random variable z is "instantiated"), evidence about x will not change our belief about y, and vice versa. We say that the z node is "closed" and that the trail between x and y is "blocked" by the instantiated z. In other words, knowing the value of z blocks the flow of evidence between x and y.</p><p>(b) For the serial connection, show that the marginal p(x, y) does generally not factorise into p(x)p(y), i.e. that x ⊥ ⊥ y does not hold.</p><p>Solution. There are several ways to show the result. One is to present an example where the independency does not hold. Consider for instance the following model</p><formula xml:id="formula_111">x ∼ N (x; 0, 1) (S.3.3) z = x + n z (S.3.4) y = z + n y (S.3.5)</formula><p>where n z ∼ N (n z ; 0, 1) and n y ∼ N (n y ; 0, 1), both being statistically independent from x. Here N (•; 0, 1) denotes the Gaussian pdf with mean 0 and variance 1, and x ∼ N (x; 0, 1) means that we sample x from the distribution N (x; 0, 1). Hence p(z|x) = N (z; x, 1), p(y|z) = N (y; z, 1) and p(x, y, z) = p(x)p(z|x)p(y|z) = N (x; 0, 1)N (z; x, 1)N (y; z, 1).</p><p>Whilst we could manipulate the pdfs to show the result, it's here easier to work with the generative model in Equations (S.3.3) to (S.3.5). Eliminating z from the equations, by plugging the definition of z into (S.3.5) we have</p><formula xml:id="formula_112">y = x + n z + n y , (S.3.6)</formula><p>which describes the marginal distribution of (x, y). We see that E[xy] is</p><formula xml:id="formula_113">E[xy] = E[x 2 + xn z + xn y ] (S.3.7) = E[x 2 ] + E[x]E[n z ] + E[x]E[n y ] (S.3.8) = 1 + 0 + 0 (S.3.9)</formula><p>where we have use the linearity of expectation, that x is independent from n z and n y , and that x has zero mean. If x and y were independent (or only uncorrelated), we had</p><formula xml:id="formula_114">E[xy] = E[x]E[y] = 0. However, since E[xy] = E[x]E[y],</formula><p>x and y are not independent.</p><p>In plain English, this means that if the state of z is unknown, then evidence or information about x will influence our belief about y, and the other way around.</p><p>Evidence can flow through z between x and y. We say that the z node is "open" and the trail between x and y is "active". As in the serial connection, if the state or value z is known, evidence about x will not change our belief about y, and vice versa. Knowing z closes the z node, which blocks the trail between x and y.</p><p>(d) For the diverging connection, show that the marginal p(x, y) does generally not factorise into p(x)p(y), i.e. that x ⊥ ⊥ y does not hold.</p><p>Solution. As for the serial connection, it suffices to give an example where x ⊥ ⊥ y does not hold. We consider the following generative model z ∼ N (z; 0, 1) (S.3.12)</p><formula xml:id="formula_115">x = z + n x (S.3.13) y = z + n y (S.3.14)</formula><p>where n x ∼ N (n x ; 0, 1) and n y ∼ N (n y ; 0, 1), and they are independent of each other and the other variables. We have</p><formula xml:id="formula_116">E[x] = E[z + n x ] = E[z] + E[n x ] = 0.</formula><p>On the other hand</p><formula xml:id="formula_117">E[xy] = E[(z + n x )(z + n y )] (S.3.15) = E[z 2 + z(n x + n y ) + n x n y ] (S.3.16) = E[z 2 ] + E[z(n x + n y )] + E[n x n y ] (S.3.17) = 1 + 0 + 0 (S.3.18)</formula><p>Hence, E[xy] = E[x]E[y] and we do not have that x ⊥ ⊥ y holds.</p><p>In a diverging connection, as in the serial connection, if the state of z is unknown, then evidence or information about x will influence our belief about y, and the other way around. Evidence can flow through z between x and y. We say that the z node is open and the trail between x and y is active.</p><p>(e) For the converging connection, show that x ⊥ ⊥ y.</p><p>Solution. We can here again use the ordered Markov property with the ordering y, x, z. Since pre x = {y} and pa x = ∅, we have</p><formula xml:id="formula_118">x ⊥ ⊥ (pre x \ pa x ) | pa x = x ⊥ ⊥</formula><p>y. (S.3.19) Alternatively, we can use the basic definition of directed graphical models, i.e. p(x, y, z) = k(x)k(y)k(z | x, y) (S.3.20) together with the result that the kernels (factors) are valid (conditional) pdfs/pmfs and equal to the conditionals/marginals with respect to the joint distribution p(x, y, z), i.e. k(x) = p(x) (S.3.21) k(y) = p(y) (S.3.22) k(z|x, y) = p(z|x, y) (not needed in the proof below) (S.3.23) Integrating out z gives p(x, y) = p(x, y, z)dz (S.3.24) = k(x)k(y)k(z | x, y)dz (S.3.25) = k(x)k(y) k(z | x, y)dz 1 (S.3.26) = p(x)p(y) (S.3.27)</p><p>Hence p(x, y) factorises into its marginals, which means that x ⊥ ⊥ y.</p><p>Hence, when we do not have evidence about z, evidence about x will not change our belief about y, and vice versa. For the converging connection, if no evidence about z is available, the z node is closed, which blocks the trail between x and y.</p><p>(f) For the converging connection, show that x ⊥ ⊥ y | z does generally not hold.</p><p>Solution. We give a simple example where x ⊥ ⊥ y | z does not hold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consider</head><p>x ∼ N (x; 0, 1) (S.3.28) y ∼ N (y; 0, 1) (S.3.29)</p><formula xml:id="formula_119">z = xy + n z (S.3.30)</formula><p>where n z ∼ N (n z ; 0, 1), independent from the other variables. From the last equation, we have xy = z -n z (S.3.31)</p><p>We thus have</p><formula xml:id="formula_120">E[xy | z] = E[z -n z | z] (S.3.32) = z -0 (S.3.33)</formula><p>On the other hand,</p><formula xml:id="formula_121">E[xy] = E[x]E[y] = 0. Since E[xy | z] = E[xy], x ⊥ ⊥ y | z cannot hold.</formula><p>The intuition here is that if you know the value of the product xy, even if subject to noise, knowing the value of x allows you to guess the value of y and vice versa.</p><p>More generally, for converging connections, if evidence or information about z is available, evidence about x will influence the belief about y, and vice versa. We say that information about z opens the z-node, and evidence can flow between x and y.</p><p>Note: information about z means that z or one of its descendents is observed, see exercise 3.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ordered and local Markov properties, d-separation</head><p>We continue with the investigation of the graph from Exercise 3.1 shown below for reference.</p><p>a z q e h (a) The ordering (z, h, a, q, e) is topological to the graph. What are the independencies that follow from the ordered Markov property?</p><p>Solution. A distribution that factorises over the graph satisfies the independencies</p><formula xml:id="formula_122">x i ⊥ ⊥ (pre i \ pa i ) | pa i for all i</formula><p>for all orderings of the variables that are topological to the graph. The ordering comes into play via the predecessors pre i = {x 1 , . . . , x i-1 } of the variables x i ; the graph via the parent sets pa i .</p><p>For the graph and the specified topological ordering, the predecessor sets are pre z = ∅, pre h = {z}, pre a = {z, h}, pre q = {z, h, a}, pre e = {z, h, a, q}</p><p>The parent sets only depend on the graph and not the topological ordering. They are:</p><formula xml:id="formula_123">pa z = ∅, pa h = {z}, pa a = ∅, pa q = {a, z}, pa e = {q},</formula><p>The ordered Markov property reads x i ⊥ ⊥ (pre i \ pa i ) | pa i where the x i refer to the ordered variables, e.g.</p><formula xml:id="formula_124">x 1 = z, x 2 = h, x 3 = a, etc.</formula><p>With pre h \ pa h = ∅ pre a \ pa a = {z, h} pre q \ pa q = {h} pre e \ pa e = {z, h, a} we thus obtain</p><formula xml:id="formula_125">h ⊥ ⊥ ∅ | z a ⊥ ⊥ {z, h} q ⊥ ⊥ h | {a, z} e ⊥ ⊥ {z, h, a} | q</formula><p>The relation h ⊥ ⊥ ∅ | z should be understood as "there is no variable from which h is independent given z" and should thus be dropped from the list. Note that we can possibly obtain more independence relations for variables that occur later in the topological ordering. This is because the set pre \ pa can only increase when the predecessor set pre becomes larger.</p><p>(b) What are the independencies that follow from the local Markov property?</p><p>Solution. The non-descendants are nondesc(a) = {z, h} nondesc(z) = {a} nondesc(h) = {a, z, q, e} nondesc(q) = {a, z, h} nondesc(e) = {a, q, z, h}</p><p>With the parent sets as before, the independencies that follow from the local Markov property are</p><formula xml:id="formula_126">x i ⊥ ⊥ (nondesc(x i ) \ pa i ) | pa i , i.e. a ⊥ ⊥ {z, h} z ⊥ ⊥ a h ⊥ ⊥ {a, q, e} | z q ⊥ ⊥ h | {a, z} e ⊥ ⊥ {a, z, h} | q (c)</formula><p>The independency relations obtained via the ordered and local Markov property include q ⊥ ⊥ h | {a, z}. Verify the independency using d-separation.</p><p>Solution. The only trail from q to h goes through z which is in a tail-tail configuration. Since z is part of the conditioning set, the trail is blocked and the result follows.</p><p>(d) Use d-separation to check whether a ⊥ ⊥ h | e holds.</p><p>Solution. The trail from a to h is shown below in red together with the default states of the nodes along the trail.</p><formula xml:id="formula_127">a z q e h closed open</formula><p>Conditioning on e opens the q node since q in a collider configuration on the path.</p><formula xml:id="formula_128">a z q e h open open</formula><p>The trail from a to h is thus active, which means that the relationship does not hold because a ⊥ ⊥ h | e for some distributions that factorise over the graph.</p><p>(e) Assume all variables in the graph are binary. How many numbers do you need to specify, or learn from data, in order to fully specify the probability distribution?</p><p>Solution. The graph defines a set of probability mass functions (pmf) that factorise as p(a, z, q, h, e) = p(a)p(z)p(q|a, z)p(h|z)p(e|q)</p><p>To specify a member of the set, we need to specify the (conditional) pmfs on the right-hand side. The (conditional) pmfs can be seen as tables, and the number of elements that we need to specified in the tables are: -1 for p(a) -1 for p(z) -4 for p(q|a, z) -2 for p(h|z) -2 for p(e|q) In total, there are 10 numbers to specify. This is in contrast to 2 5 -1 = 31 for a distribution without independencies. Note that the number of parameters to specify could be further reduced by making parametric assumptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">More on ordered and local Markov properties, d-separation</head><p>We continue with the investigation of the graph below a z q e h (a) Why can the ordered or local Markov property not be used to check whether a ⊥ ⊥ h | e may hold?</p><p>Solution. The independencies that follow from the ordered or local Markov property require conditioning on parent sets. However, e is not a parent of any node so that the above independence assertion cannot be checked via the ordered or local Markov property.</p><p>(b) The independency relations obtained via the ordered and local Markov property include a ⊥ ⊥ {z, h}. Verify the independency using d-separation.</p><p>Solution. All paths from a to z or h pass through the node q that forms a headhead connection along that trail. Since neither q nor its descendant e is part of the conditioning set, the trail is blocked and the independence relation follows.</p><p>(c) Determine the Markov blanket of z.</p><p>Solution. The Markov blanket is given by the parents, children, and co-parents. Hence: MB(z) = {a, q, h}.</p><p>(d) Verify that q ⊥ ⊥ h | {a, z} holds by manipulating the probability distribution induced by the graph.</p><formula xml:id="formula_129">Solution. A basic definition of conditional statistical independence x 1 ⊥ ⊥ x 2 | x 3 is that the (conditional) joint p(x 1 , x 2 |</formula><p>x 3 ) equals the product of the (conditional) marginals p(x 1 | x 3 ) and p(x 2 | x 3 ). In other words, for discrete random variables,</p><formula xml:id="formula_130">x 1 ⊥ ⊥ x 2 | x 3 ⇐⇒ p(x 1 , x 2 | x 3 ) = x 2 p(x 1 , x 2 | x 3 ) x 1 p(x 1 , x 2 | x 3 ) (S.3.34)</formula><p>We thus answer the question by showing that (use integrals in case of continuous random variables) p(q, h|a, z) = h p(q, h|a, z) q p(q, h|a, z) (S.3.35)</p><p>First, note that the graph defines a set of probability density or mass functions that factorise as p(a, z, q, h, e) = p(a)p(z)p(q|a, z)p(h|z)p(e|q)</p><p>We then use the sum-rule to compute the joint distribution of (a, z, q, h), i.e. the distribution of all the variables that occur in p(q, h|a, z) p(a, z, q, h) = e p(a, z, q, h, e) (S.</p><p>3.36) = e p(a)p(z)p(q|a, z)p(h|z)p(e|q) (S.3.37) = p(a)p(z)p(q|a, z)p(h|z) e p(e|q) 1 (S.3.38) = p(a)p(z)p(q|a, z)p(h|z), (S.3.39) where e p(e|q) = 1 because (conditional) pdfs/pmfs are normalised so that the integrate/sum to one. We further have p(a, z) = q,h p(a, z, q, h) (S.3.40) = q,h p(a)p(z)p(q|a, z)p(h|z) (S.3.41) = p(a)p(z) q p(q|a, z) h p(h|z) (S.3.42) = p(a)p(z) (S.3.43) so that p(q, h|a, z) = p(a, z, q, h) p(a, z) (S.3.44) = p(a)p(z)p(q|a, z)p(h|z) p(a)p(z) (S.3.45) = p(q|a, z)p(h|z). (S.3.46)</p><p>We further see that p(q|a, z) and p(h|z) are the marginals of p(q, h|a, z), i.e.</p><p>p(q|a, z) = h p(q, h|a, z) (S.3.47) p(h|z) = q p(q, h|a, z). (S.3.48) This means that p(q, h|a, z) = h p(q, h|a, z) q p(q, h|a, z) , (S.3.49) which shows that q ⊥ ⊥ h|a, z.</p><p>We see that using the graph to determine the independency is easier than manipulating the pmf/pdf.</p><p>3.5 Chest clinic (based on Barber, 2012, Exercise 3.3)</p><p>The directed graphical model in Figure <ref type="figure" target="#fig_14">3</ref>.2 is about the diagnosis of lung disease (t=tuberculosis or l=lung cancer). In this model, a visit to some place "a" is thought to increase the probability of tuberculosis.</p><p>(a) Explain which of the following independence relationships hold for all distributions that factorise over the graph.</p><p>1. t ⊥ ⊥ s | d x d e t l b a s Positive X-ray Dyspnea (shortness of breath) Either tuberculosis or lung cancer Tuberculosis Lunc cancer Bronchitis Visited place a Smoker Solution.</p><p>• There are two trails from t to s: (t, e, l, s) and (t, e, d, b, s).</p><p>• The trail (t, e, l, s) features a collider node e that is opened by the conditioning variable d. The trail is thus active and we do not need to check the second trail because for independence all trails needed to be blocked. • The independence relationship does thus generally not hold.  (a) Explain which of the following independence relationships hold for all distributions that factorise over the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">a ⊥ ⊥ s | l</head><p>Solution.</p><p>• There are two trails from a to s: (a, t, e, l, s) and (a, t, e, d, b, s)</p><p>• The trail (a, t, e, l, s) features a collider node e that blocks the trail (the trail is also blocked by l). • The trail (a, t, e, d, b, s) is blocked by the collider node d.</p><p>• All trails are blocked so that the independence relation holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">a ⊥ ⊥ s | l, d</head><p>Solution.</p><p>• There are two trails from a to s: (a, t, e, l, s) and (a, t, e, d, b, s)</p><p>• The trail (a, t, e, l, s) features a collider node e that is opened by the conditioning variable d but the l node is closed by the conditioning variable l: the trail is blocked</p><p>• The trail (a, t, e, d, b, s) features a collider node d that is opened by conditioning on d. On this trail, e is not in a head-head (collider) configuration) so that all nodes are open and the trail active. • Hence, the independence relation does generally not hold. (b) Let g be a (deterministic) function of x and t. Is the expected value E[g(x, t) | l, b] equal to E[g(x, t) | l]?</p><p>Solution. The question boils down to checking whether x, t ⊥ ⊥ b | l. For the independence relation to hold, all trails from both x and t to b need to be blocked by l.</p><p>• For x, we have the trails </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Hidden Markov models</head><p>This exercise is about directed graphical models that are specified by the following DAG:</p><formula xml:id="formula_131">y 1 y 2 y 3 y 4 x 1 x 2 x 3 x 4</formula><p>These models are called "hidden" Markov models because we typically assume to only observe the y i and not the x i that follow a Markov model.</p><p>(a) Show that all probabilistic models specified by the DAG factorise as</p><formula xml:id="formula_132">p(x 1 , y 1 , x</formula><p>2 , y 2 , . . . , x 4 , y 4 ) = p(x 1 )p(y 1 |x 1 )p(x 2 |x 1 )p(y 2 |x 2 )p(x 3 |x 2 )p(y 3 |x 3 )p(x 4 |x 3 )p(y 4 |x 4 ) Solution. From the definition of directed graphical models it follows that p(x 1 , y 1 , x 2 , y 2 , . . . , x 4 , y 4 ) = 4 i=1 p(x i |pa(x i )) 4 i=1 p(y i |pa(y i )).</p><p>The result is then obtained by noting that the parent of y i is given by x i for all i, and that the parent of x i is x i-1 for i = 2, 3, 4 and that x 1 does not have a parent (pa(x 1 ) = ∅).</p><p>(b) Derive the independencies implied by the ordered Markov property with the topological ordering (x 1 , y 1 , x 2 , y 2 , x 3 , y 3 , x 4 , y 4 )</p><p>Solution.</p><formula xml:id="formula_133">y i ⊥ ⊥ x 1 , y 1 , . . . , x i-1 , y i-1 | x i x i ⊥ ⊥ x 1 , y 1 , . . . , x i-2 , y i-2 , y i-1 | x i-1 (c)</formula><p>Derive the independencies implied by the ordered Markov property with the topological ordering (x 1 , x 2 , . . . , x 4 , y 1 , . . . , y 4 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution.</head><p>For the x i , we use that for i ≥ 2: pre</p><formula xml:id="formula_134">(x i ) = {x 1 , . . . , x i-1 } and pa(x i ) = x i-1 .</formula><p>For the y i , we use that pre(y 1 ) = {x 1 , . . . , x 4 }, that pre(y i ) = {x 1 , . . . , x 4 , y 1 , . . . , y i-1 } for i &gt; 1, and that pa(y i ) = x i . The ordered Markov property then gives:</p><formula xml:id="formula_135">x 3 ⊥ ⊥ x 1 | x 2 x 4 ⊥ ⊥ {x 1 , x 2 } | x 3 y 1 ⊥ ⊥ {x 2 , x 3 , x 4 } | x 1 y 2 ⊥ ⊥ {x 1 , x 3 , x 4 , y 1 } | x 2 y 3 ⊥ ⊥ {x 1 , x 2 , x 4 , y 1 , y 2 } | x 3 y 4 ⊥ ⊥ {x 1 , x 2 , x 3 , y 1 , y 2 , y 3 } | x 4 (d) Does y 4 ⊥ ⊥ y 1 | y 3 hold?</formula><p>Solution. The trail y 1 -x 1 -x 2 -x 3 -x 4 -y 4 is active: none of the nodes is in a collider configuration, so that their default state is open and conditioning on y 3 does not block any of the nodes on the trail.</p><p>While x 1 -x 2 -x 3 -x 4 forms a Markov chain, where e.g. x 4 ⊥ ⊥ x 1 | x 3 holds, this not so for the distribution of the y's.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Alternative characterisation of independencies</head><p>We The characterisation in Equation (3.2) is particularly important for undirected graphical models.</p><p>Solution. We first show the equivalence of p(x, y|z) = p(x|z)p(y|z) and p(x, y, z) = p(x|z)p(y|z)p(z): By the product rule, we have p(x, y, z) = p(x, y|z)p(z).</p><p>If p(x, y|z) = p(x|z)p(y|z), it follows that p(x, y, z) = p(x|z)p(y|z)p(z). To show the opposite direction assume that p(x, y, z) = p(x|z)p(y|z)p(z) holds. By comparison with the decomposition in the product rule, it follows that we must have p(x, y|z) = p(x|z)p(y|z) whenever p(z) &gt; 0 (it suffices to consider this case because for z where p(z) = 0, p(x, y|z) may not be uniquely defined in the first place). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.9">More on independencies</head><p>This exercise is on further properties and characterisations of statistical independence. We have to show that x ⊥ ⊥ y|z and x ⊥ ⊥ w|z. For simplicity, we assume that the variables are discrete valued. If not, replace the sum below with an integral.</p><p>To show that x ⊥ ⊥ y|z, we marginalise p(x, y, w|z) over w to obtain p(x, y|z) = which means that x ⊥ ⊥ y|z.</p><p>To show that x ⊥ ⊥ w|z, we similarly marginalise p(x, y, w|z) over y to obtain p(x, w|z) = p(x|z)p(w|z), which means that x ⊥ ⊥ w|z.</p><p>(b) For the directed graphical model below, show that the following two statements hold without using d-separation:</p><p>x ⊥ ⊥ y and (3.3)</p><formula xml:id="formula_136">x ⊥ ⊥ y | w (3.4) x z w y</formula><p>The exercise shows that not only conditioning on a collider node but also on one of its descendents activates the trail between x and y. You can use the result that x ⊥ ⊥ y|w ⇔ p(x, y, w) = a(x, w)b(y, w) for some non-negative functions a(x, w) and b(y, w).</p><p>Solution. The graphical model corresponds to the factorisation p(x, y, z, w) = p(x)p(y)p(z|x, y)p(w|z).</p><p>For the marginal p(x, y) we have to sum (integrate) over all (z, w) p(x, y) = </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.10">Independencies in directed graphical models</head><p>Consider the following directed acyclic graph.</p><p>x 1</p><p>x 2</p><p>x 3</p><p>x 4</p><p>x 5</p><p>x 6</p><p>x 7</p><p>x 8</p><p>x 9</p><p>For each of the statements below, determine whether it holds for all probabilistic models that factorise over the graph. Provide a justification for your answer.</p><p>(a) p(x 7 |x 2 ) = p(x 7 )</p><p>Solution. Yes, it holds. x 2 is a non-descendant of x 7 , pa(x 7 ) = ∅, and hence, by the local Markov property,</p><formula xml:id="formula_137">x 7 ⊥ ⊥ x 2 , so that p(x 7 |x 2 ) = p(x 7 ). (b) x 1 ⊥ ⊥ x 3</formula><p>Solution. No, does not hold. x 1 and x 3 are d-connected, which only implies independence for some and not all distributions that factorise over the graph. The graph generally only allows us to read out independencies and not dependencies.</p><formula xml:id="formula_138">(c) p(x 1 , x 2 , x 4 ) ∝ φ 1 (x 1 , x 2 )φ 2 (x 1 , x 4</formula><p>) for some non-negative functions φ 1 and φ 2 .</p><p>Solution. Yes, it holds. The statement is equivalent to x 2 ⊥ ⊥ x 4 | x 1 . There are three trails from x 2 to x 4 , which are all blocked:</p><p>1. x 2 -x 1 -x 4 : this trail is blocked because x 1 is in a tail-tail connection and it is observed, which closes the node.</p><p>2. x 2 -x 3 -x 6 -x 5 -x 4 : this trail is blocked because x 3 , x 6 , x 5 is in a collider configuration, and x 6 is not observed (and it does not have any descendants).</p><p>3. x 2 -x 3 -x 6 -x 8 -x 7 -x 4 : this trail is blocked because x 3 , x 6 , x 8 is in a collider configuration, and x 6 is not observed (and it does not have any descendants).</p><p>Hence, by the global Markov property (d-separation), the independency holds.</p><formula xml:id="formula_139">(d) x 2 ⊥ ⊥ x 9 | {x 6 , x 8 } Solution.</formula><p>No, does not hold. Conditioning on x 6 opens the collider node x 4 on the trail x 2 -x 1 -x 4 -x 7 -x 9 , so that the trail is active.</p><p>(e) x 8 ⊥ ⊥ {x 2 , x 9 } | {x 3 , x 5 , x 6 , x 7 } Solution. Yes, it holds. {x 3 , x 5 , x 6 , x 7 } is the Markov blanket of x 8 , so that x 8 is independent of remaining nodes given the Markov blanket.</p><formula xml:id="formula_140">(f) E[x 2 • x 3 • x 4 • x 5 • x 8 | x 7 ] = 0 if E[x 8 | x 7 ] = 0</formula><p>Solution. Yes, it holds. {x 2 , x 3 , x 4 , x 5 } are non-descendants of x 8 , and x 7 is the parent of x 8 , so that</p><formula xml:id="formula_141">x 8 ⊥ ⊥ {x 2 , x 3 , x 4 , x 5 } | x 7 . This means that E[x 2 • x 3 • x 4 • x 5 • x 8 | x 7 ] = E[x 2 • x 3 • x 4 • x 5 | x 7 ]E[x 8 | x 7 ] = 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.11">Independencies in directed graphical models</head><p>Consider the following directed acyclic graph:</p><formula xml:id="formula_142">m 1 s 1 u 1 v 1 x 1 y 1 θ 1 m 2 s 2 u 2 v 2 x 2 y 2 θ 2</formula><p>For each of the statements below, determine whether it holds for all probabilistic models that factorise over the graph. Provide a justification for your answer.</p><formula xml:id="formula_143">(a) x 1 ⊥ ⊥ x 2 Solution. Does not hold. The trail x 1 -θ 1 -θ 2 -x 2 is active (unblocked) because none of the nodes is in a collider configuration or in the conditioning set. (b) p(x 1 , y 1 , θ 1 , u 1 ) ∝ φ A (x 1 , θ 1 , u 1 )φ B (y 1 , θ 1 , u 1 )</formula><p>for some non-negative functions φ A and φ B Solution. Holds. The statement is equivalent to x 1 ⊥ ⊥ y 1 | {θ 1 , u 1 }. The conditioning set {θ 1 , u 1 } blocks all trails from x 1 to y 1 because they are both only in serial configurations in all trails from x 1 to y 1 , hence the independency holds by the global Markov property. Alternative justification: the conditioning set is the Markov blanket of x 1 , and x 1 and y 1 are not neighbours which implies the independency.</p><formula xml:id="formula_144">(c) v 2 ⊥ ⊥ {u 1 , v 1 , u 2 , x 2 } | {m 2 , s 2 , y 2 , θ 2 }</formula><p>Solution. Holds. The conditioning set is the Markov blanket of v 2 (the set of parents, children, and co-parents): the set of parents is pa(v 2 ) = {m 2 , s 2 }, y 2 is the only child of v 2 , and θ 2 is the only other parent of y 2 . And v 2 is independent of all other variables given its Markov blanket.</p><formula xml:id="formula_145">(d) E[m 2 | m 1 ] = E[m 2 ]</formula><p>Solution. Holds. There are four trails from m 1 to m 2 , namely via x 1 , via y 1 , via x 2 , via y 2 . In all trails the four variables are in a collider configuration, so that each of the trails is blocked. By the global Markov property (d-separation), this means that</p><formula xml:id="formula_146">m 1 ⊥ ⊥ m 2 which implies that E[m 2 | m 1 ] = E[m 2 ].</formula><p>Alternative justification 1: m 2 is a non-descendent of m 1 and pa(m 2 ) = ∅. By the directed local Markov property, a variable is independent from its non-descendents given the parents, hence m 2 ⊥ ⊥ m 1 .</p><p>Alternative justification 2: We can choose a topological ordering where m 1 and m 2 are the first two variables. Moreover, their parent sets are both empty. By the directed ordered Markov, we thus have</p><formula xml:id="formula_147">m 1 ⊥ ⊥ m 2 .</formula><p>Chapter 4</p><p>Undirected Graphical Models </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Visualising and analysing Gibbs distributions via undirected graphs</head><p>We here consider the Gibbs distribution</p><formula xml:id="formula_148">p(x 1 , . . . , x 5 ) ∝ φ 12 (x 1 , x 2 )φ 13 (x 1 , x 3 )φ 14 (x 1 , x 4 )φ 23 (x 2 , x 3 )φ 25 (x 2 , x 5 )φ 45 (x 4 , x 5 )</formula><p>(a) Visualise it as an undirected graph.</p><p>Solution. We draw a node for each random variable x i . There is an edge between two nodes if the corresponding variables co-occur in a factor.</p><p>x 1</p><p>x 2</p><p>x 3</p><p>x 4</p><p>x 5</p><p>(b) What are the neighbours of x 3 in the graph?</p><p>Solution. The neighbours are all the nodes for which there is a single connecting edge. Thus: ne(x 3 ) = {x 1 , x 2 }. (Note that sometimes, we may denote ne(x 3 ) by ne 3 .) (c) Do we have</p><formula xml:id="formula_149">x 3 ⊥ ⊥ x 4 | x 1 , x 2 ?</formula><p>Solution. Yes. The conditioning set {x 1 , x 2 } equals ne 3 , which is also the Markov blanket of x 3 . This means that x 3 is conditionally independent of all the other variables given {x 1 , x 2 }, i.e.</p><formula xml:id="formula_150">x 3 ⊥ ⊥ x 4 , x 5 | x 1 , x 2 , which implies that x 3 ⊥ ⊥ x 4 | x 1 , x 2 .</formula><p>(One can also use graph separation to answer the question.)</p><formula xml:id="formula_151">(d) What is the Markov blanket of x 4 ?</formula><p>Solution. The Markov blanket of a node in a undirected graphical model equals the set of its neighbours: MB(x 4 ) = ne(x 4 ) = ne 4 = {x 1 , x 5 }. This implies, for example, that</p><formula xml:id="formula_152">x 4 ⊥ ⊥ x 2 , x 3 | x 1 , x 5 .</formula><p>(e) On which minimal set of variables A do we need to condition to have</p><formula xml:id="formula_153">x 1 ⊥ ⊥ x 5 | A?</formula><p>Solution. We first identify all trails from x 1 to x 5 . There are three such trails: (x 1 , x 2 , x 5 ), (x 1 , x 3 , x 2 , x 5 ), and (x 1 , x 4 , x 5 ). Conditioning on x 2 blocks the first two trails, conditioning on x 4 blocks the last. We thus have:</p><formula xml:id="formula_154">x 1 ⊥ ⊥ x 5 | x 2 , x 4 , so that A = {x 2 , x 4 }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Factorisation and independencies for undirected graphical models</head><p>Consider the undirected graphical model defined by the graph in Figure <ref type="figure">4</ref>.1.</p><p>x 1</p><p>x 2</p><p>x 3</p><p>x 4</p><p>x 5</p><p>x 6 (a) What is the set of Gibbs distributions that is induced by the graph?</p><p>Solution. The graph in Figure <ref type="figure">4</ref>.1 has four maximal cliques:</p><formula xml:id="formula_155">(x 1 , x 2 , x 4 ) (x 1 , x 3 , x 4 ) (x 3 , x 4 , x 5 ) (x 4 , x 5 , x 6 )</formula><p>The Gibbs distributions are thus</p><formula xml:id="formula_156">p(x 1 , . . . , x 6 ) ∝ φ 1 (x 1 , x 2 , x 4 )φ 2 (x 1 , x 3 , x 4 )φ 3 (x 3 , x 4 , x 5 )φ 4 (x 4 , x 5 , x 6 ) (b)</formula><p>Let p be a pdf that factorises according to the graph. Does p(x 3 |x 2 , x 4 ) = p(x 3 |x 4 ) hold?</p><formula xml:id="formula_157">Solution. p(x 3 |x 2 , x 4 ) = p(x 3 |x 4 ) means that x 3 ⊥ ⊥ x 2 | x 4 .</formula><p>We can use the graph to check whether this generally holds for pdfs that factorise according to the graph. There are multiple trails from x 3 to x 2 , including the trail (x 3 , x 1 , x 2 ), which is not blocked by x 4 . From the graph, we thus cannot conclude that x 3 ⊥ ⊥ x 2 | x 4 , and p(x 3 |x 2 , x 4 ) = p(x 3 |x 4 ) will generally not hold (the relation may hold for some carefully defined factors φ i ).</p><p>(c) Explain why x 2 ⊥ ⊥ x 5 | x 1 , x 3 , x 4 , x 6 holds for all distributions that factorise over the graph.</p><p>Solution. Distributions that factorise over the graph satisfy the pairwise Markov property. Since x 2 and x 5 are not neighbours, and x 1 , x 3 , x 4 , x 6 are the remaining nodes in the graph, the independence relation follows from the pairwise Markov property.</p><p>(d) Assume you would like to approximate E(x 1 x 2 x 5 | x 3 , x 4 ), i.e. the expected value of the product of x 1 , x 2 , and x 5 given x 3 and x 4 , with a sample average. Do you need to have joint observations for all five variables x 1 , . . . , x 5 ?</p><p>Solution. In the graph, all trails from {x 1 , x 2 } to x 5 are blocked by {x 3 , x 4 }, so that x 1 , x 2 ⊥ ⊥ x 5 | x 3 , x 4 . We thus have</p><formula xml:id="formula_158">E(x 1 x 2 x 5 | x 3 , x 4 ) = E(x 1 x 2 | x 3 , x 4 )E(x 5 | x 3 , x 4 ).</formula><p>Hence, we only need joint observations of (x 1 , x 2 , x 3 , x 4 ) and (x 3 , x 4 , x 5 ). Variables (x 1 , x 2 ) and x 5 do not need to be jointly measured.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Factorisation and independencies for undirected graphical models</head><p>Consider the undirected graphical model defined by the following graph, sometimes called a diamond configuration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution.</head><p>We can generate the independencies by conditioning on progressively larger sets. Since there is a trail between any two nodes, there are no unconditional independencies. If we condition on a single variable, there is still a trail that connects the remaining ones. Let us thus consider the case where we condition on two nodes. By graph separation, we have</p><formula xml:id="formula_159">w ⊥ ⊥ y | x, z x ⊥ ⊥ z | w, y (S.4.2)</formula><p>These are all the independencies that hold for the model, since conditioning on three nodes does not lead to any independencies in a model with four variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Factorisation from the Markov blankets I</head><p>Assume you know the following Markov blankets for all variables x 1 , . . . , x 4 , y 1 , . . . y 4 of a pdf or pmf p(x 1 , . . . , x 4 , y 1 , . . . , y 4 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MB(x</head><formula xml:id="formula_160">1 ) = {x 2 , y 1 } MB(x 2 ) = {x 1 , x 3 , y 2 } MB(x 3 ) = {x 2 , x 4 , y 3 } MB(x 4 ) = {x 3 , y 4 } (4.1) MB(y 1 ) = {x 1 } MB(y 2 ) = {x 2 } MB(y 3 ) = {x 3 } MB(y 4 ) = {x 4 } (4.2)</formula><p>Assuming that p is positive for all possible values of its variables, how does p factorise?</p><p>Solution. In undirected graphical models, the Markov blanket for a variable is the same as the set of its neighbours. Hence, when we are given all Markov blankets we know what local Markov property p must satisfy. For positive distributions we have an equivalence between p satisfying the local Markov property and p factorising over the graph. Hence, to specify the factorisation of p it suffices to construct the undirected graph H based on the Markov blankets and then read out the factorisation.</p><p>We need to build a graph where the neighbours of each variable equals the indicated Markov blanket. This can be easily done by starting with an empty graph and connecting each variable to the variables in its Markov blanket.</p><p>We see that each y i is only connected to x i . Including those Markov blankets we get the following graph:</p><formula xml:id="formula_161">y 1 y 2 y 3 y 4 x 1 x 2 x 3 x 4</formula><p>Connecting the x i to their neighbours according to the Markov blanket thus gives:</p><formula xml:id="formula_162">y 1 y 2 y 3 y 4 x 1 x 2 x 3 x 4</formula><p>The graph has maximal cliques of size two, namely the x i -y i for i = 1, . . . , 4, and the x i -x i+1 for i = 1, . . . , 3. Given the equivalence between the local Markov property and factorisation for positive distributions, we know that p must factorise as</p><formula xml:id="formula_163">p(x 1 , . . . , x 4 , y 1 , . . . , y 4 ) = 1 Z 3 i=1 m i (x i , x i+1 ) 4 i=1 g i (x i , y i ), (S.4.3) where m i (x i , x i+1 ) &gt; 0, g(x i , y i ) &gt; 0 are positive factors (potential functions).</formula><p>The graphical model corresponds to an undirected version of a hidden Markov model where the x i are the unobserved (latent, hidden) variables and the y i are the observed ones. Note that the x i form a Markov chain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Factorisation from the Markov blankets II</head><p>We consider the same setup as in Exercise 4.4 but we now assume that we do not know all Markov blankets but only</p><formula xml:id="formula_164">MB(x 1 ) = {x 2 , y 1 } MB(x 2 ) = {x 1 , x 3 , y 2 } MB(x 3 ) = {x 2 , x 4 , y 3 } MB(x 4 ) = {x 3 , y 4 } (4.3)</formula><p>Without inserting more independencies than those specified by the Markov blankets, draw the graph over which p factorises and state the factorisation. (Again assume that p is positive for all possible values of its variables).</p><p>Solution. We take the same approach as in Exercise 4.4. In particular, the Markov blankets of a variable are its neighbours in the graph. But since we are not given all Markov blankets and are not allowed to insert additional independencies, we must assume that each y i is connected to all the other y's. For example, if we didn't connect y 1 and y 4 we would assert the additional independency</p><formula xml:id="formula_165">y 1 ⊥ ⊥ y 4 | x 1 , x 2 , x 3 , x 4 , y 2 , y 3 .</formula><p>We thus have a graph as follows:</p><formula xml:id="formula_166">y 1 y 2 y 3 y 4 x 1 x 2 x 3 x 4</formula><p>The factorisation thus is p(x 1 , . . . , x 4 , y 1 , . . . , y 4 ) = 1 Z g(y 1 , . . . , y 4 )</p><formula xml:id="formula_167">3 i=1 m i (x i , x i+1 ) 4 i=1 g i (x i , y i ), (S.4.4)</formula><p>where the m i (x i , x i+1 ), g i (x i , y i ) and g(y 1 , . . . , y 4 ) are positive factors. Compared to the factorisation in Exercise 4.4, we still have the Markov structure for the x i , but only a single factor for (y 1 , y 2 , y 3 , y 4 ) to avoid inserting independencies beyond those specified by the given Markov blankets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Undirected graphical model with pairwise potentials</head><p>We here consider Gibbs distributions where the factors only depend on two variables at a time. The probability density or mass functions over d random variables x 1 , . . . , x d then take the form</p><formula xml:id="formula_168">p(x 1 , . . . , x d ) ∝ i≤j φ ij (x i , x j )</formula><p>Such models are sometimes called pairwise Markov networks.</p><p>(a) Let p(x 1 , . . . , x d ) ∝ exp -1 2 x Axb x where A is symmetric and x = (x 1 , . . . , x d ) . What are the corresponding factors φ ij for i ≤ j? Solution. Denote the (i, j)-th element of A by a ij . We have</p><formula xml:id="formula_169">x Ax = ij a ij x i x j (S.4.5) = i&lt;j 2a ij x i x j + i a ii x 2 i (S.4.6)</formula><p>where the second line follows from A = A. Hence,</p><formula xml:id="formula_170">- 1 2 x Ax -b x = - 1 2 i&lt;j 2a ij x i x j - 1 2 i a ii x 2 i - i b i x i (S.4.7) so that φ ij (x i , x j ) = exp (-a ij x i x j ) if i &lt; j exp -1 2 a ii x 2 i -b i x i if i = j (S.4.8)</formula><p>For x ∈ R d , the distribution is a Gaussian with A equal to the inverse covariance matrix. For binary x, the model is known as Ising model or Boltzmann machine. For x i ∈ {-1, 1}, x 2 i = 1 for all i, so that the a ii are constants that can be absorbed into the normalisation constant. This means that for x i ∈ {-1, 1}, we can work with matrices A that have zeros on the diagonal.</p><formula xml:id="formula_171">(b) For p(x 1 , . . . , x d ) ∝ exp -1 2 x Ax -b x , show that x i ⊥ ⊥ x j | {x 1 , . . . , x d } \ {x i , x j } if the (i, j)-th element of A is zero.</formula><p>Solution. The previous question showed that we can write p(x 1 , . . . , x d ) ∝ i≤j φ ij (x i , x j ) with potentials as in Equation (S.4.8). Consider two variables x i and x j for fixed (i, j). They only appear in the factorisation via the potential φ ij . If a ij = 0, the factor φ ij becomes a constant, and no other factor contains x i and x j , which means that there is no edge between x i and x j if a ij = 0. By the pairwise Markov property it then follows that The restricted Boltzmann machine is an undirected graphical model for binary variables v = (v 1 , . . . , v n ) and h = (h 1 , . . . , h m ) with a probability mass function equal to</p><formula xml:id="formula_172">x i ⊥ ⊥ x j | {x 1 , . . . , x d } \ {x i , x j }.</formula><formula xml:id="formula_173">p(v, h) ∝ exp v Wh + a v + b h , (4.4)</formula><p>where W is a n × m matrix. Both the v i and h i take values in {0, 1}. The v i are called the "visibles" variables since they are assumed to be observed while the h i are the hidden variables since it is assumed that we cannot measure them.</p><p>(a) Use graph separation to show that the joint conditional p(h|v) factorises as</p><formula xml:id="formula_174">p(h|v) = m i=1 p(h i |v).</formula><p>Solution. Figure <ref type="figure">4</ref>.2 on the left shows the undirected graph for p(v, h) with n = 3, m = 2. We note that the graph is bi-partite: there are only direct connections between the h i and the v i . Conditioning on v thus blocks all trails between the h i (graph on the right). This means that the h i are independent from each other given v so that (b) Show that</p><formula xml:id="formula_175">p(h|v) = m i=1 p(h i |v). h 1 h 2 v 1 v 2 v 3 h 1 h 2 v 1 v 2 v 3</formula><formula xml:id="formula_176">p(h i = 1|v) = 1 1 + exp -b i -j W ji v j (4.5)</formula><p>where W ji is the (ji)-th element of W, so that j W ji v j is the inner product (scalar product) between the i-th column of W and v.</p><p>Solution. For the conditional pmf p(h i |v) any quantity that does not depend on h i can be considered to be part of the normalisation constant. A general strategy is to first work out p(h i |v) up to the normalisation constant and then to normalise it afterwards.</p><p>We begin with p(h|v):</p><formula xml:id="formula_177">p(h|v) = p(h, v) p(v) (S.4.9) ∝ p(h, v) (S.4.10) ∝ exp v Wh + a v + b h (S.4.11) ∝ exp v Wh + b h (S.4.12) ∝ exp   i j v j W ji h i + i b i h i   (S.4.13)</formula><p>As we are interested in p(h i |v) for a fixed i, we can drop all the terms not depending on that h i , so that</p><formula xml:id="formula_178">p(h i |v) ∝ exp   j v j W ji h i + b i h i   (S.4.14)</formula><p>Since h i only takes two values, 0 and 1, normalisation is here straightforward. Call the unnormalised pmf p(h i |v),</p><formula xml:id="formula_179">p(h i |v) = exp   j v j W ji h i + b i h i   . (S.4.15)</formula><p>We then have</p><formula xml:id="formula_180">p(h i |v) = p(h i |v) p(h i = 0|v) + p(h i = 1|v) (S.4.16) = p(h i |v) 1 + exp j v j W ji + b i (S.4.17) = exp j v j W ji h i + b i h i 1 + exp j v j W ji + b i , (S.4.18) so that p(h i = 1|v) = exp j v j W ji + b i 1 + exp j v j W ji + b i (S.4.19) = 1 1 + exp -j v j W ji -b i . (S.4.20)</formula><p>The probability p(h = 0|v) equals 1 -p(h i = 1|v), which is</p><formula xml:id="formula_181">p(h i = 0|v) = 1 + exp j v j W ji + b i 1 + exp j v j W ji + b i - exp j v j W ji + b i 1 + exp j v j W ji + b i (S.4.21) = 1 1 + exp j W ji v j + b i (S.</formula><p>4.22) The function x → 1/(1 + exp(-x)) is called the logistic function. It is a sigmoid function and is thus sometimes denoted by σ(x). For other versions of the sigmoid function, see <ref type="url" target="https://en.wikipedia.org/wiki/Sigmoid_function">https://en.wikipedia.org/wiki/Sigmoid_function</ref>. -6 -4 -2 2 4 6 0.2 0.4 0.6 0.8 x σ(x)</p><p>With that notation, we have</p><formula xml:id="formula_182">p(h i = 1|v) = σ   j W ji v j + b i   .</formula><p>(c) Use a symmetry argument to show that</p><formula xml:id="formula_183">p(v|h) = i p(v i |h) and p(v i = 1|h) = 1 1 + exp -a i -j W ij h j Solution. Since v Wh is a scalar we have (v Wh) = h W v = v Wh, so that p(v, h) ∝ exp v Wh + a v + b h (S.4.23) ∝ exp h W v + b h + a v . (S.4.24)</formula><p>To derive the result, we note that v and a now take the place of h and b from before, and that we now have W rather than W. In Equation (4.5), we thus replace h i with v i , b i with a i , and W ji with W ij to obtain p(v i = 1|h). In terms of the sigmoid function, we have</p><formula xml:id="formula_184">p(v i = 1|h) = σ   j W ij h j + a i   .</formula><p>Note that while p(v|h) factorises, the marginal p(v) does generally not. The marginal p(v) can here be obtained in closed form up to its normalisation constant.</p><formula xml:id="formula_185">p(v) = h∈{0,1} m p(v, h) (S.4.25) = 1 Z h∈{0,1} m exp v Wh + a v + b h (S.4.26) = 1 Z h∈{0,1} m exp   ij v i h j W ij + i a i v i + j b j h j   (S.4.27) = 1 Z h∈{0,1} m exp   m j=1 h j i v i W ij + b j + i a i v i   (S.4.28) = 1 Z h∈{0,1} m m j=1 exp h j i v i W ij + b j exp i a i v i (S.4.29) = 1 Z exp i a i v i h∈{0,1} m m j=1 exp h j i v i W ij + b j (S.4.30) = 1 Z exp i a i v i h 1 ,...,hm m j=1 exp h j i v i W ij + b j (S.4.31)</formula><p>Importantly, each term in the product only depends on a single h j , so that by sequentially applying the distributive law, we have</p><formula xml:id="formula_186">h 1 ,...,hm m j=1 exp h j i v i W ij + b j =   h 1 ,...,h m-1 m-1 j=1 exp h j i v i W ij + b j   • hm exp h m i v i W im + b m (S.4.32) = . . . = m j=1   h j exp h j i v i W ij + b j   (S.4.33)</formula><p>Since h j ∈ {0, 1}, we obtain</p><formula xml:id="formula_187">h j exp h j i v i W ij + b j = 1 + exp i v i W ij + b j (S.4.34)</formula><p>and thus</p><formula xml:id="formula_188">p(v) = 1 Z exp i a i v i m j=1 1 + exp i v i W ij + b j . (S.4.35)</formula><p>Note that in the derivation of p(v) we have not used the assumption that the visibles v i are binary. The same expression would thus obtained if the visibles were defined in another space, e.g. the real numbers.</p><p>While p(v) is written as a product, p(v) does not factorise into terms that depend on subsets of the v i . On the contrary, all v i are present in all factors. Since p(v) does not factorise, computing the normalising Z is expensive. For binary visibles</p><formula xml:id="formula_189">v i ∈ {0, 1}, Z equals Z = v∈{0,1} n exp i a i v i m j=1 1 + exp i v i W ij + b j (S.4.36)</formula><p>where we have to sum over all 2 n configurations of the visibles v.</p><p>This is computationally expensive, or even prohibitive if n is large (2 20 = 1048576, 2 30 &gt; 10 9 ). Note that different values of a i , b i , W ij yield different values of Z. (This is a reason why Z is called the partition function when the a i , b i , W ij are free parameters.) It is instructive to write p(v) in the log-domain,</p><formula xml:id="formula_190">log p(v) = log Z + n i=1 a i v i + m j=1 log 1 + exp i v i W ij + b j , (S.4.37)</formula><p>and to introduce the nonlinearity f (u),</p><formula xml:id="formula_191">f (u) = log [1 + exp(u)] , (S.4.38)</formula><p>which is called the softplus function and plotted below. The softplus function is a smooth approximation of max(0, u), see e.g. <ref type="url" target="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">https://en.wikipedia.org/wiki/  Rectifier_(neural_networks)</ref> </p><formula xml:id="formula_192">-6 -4 -2 2 4 6 2 4 6 u f (u)</formula><p>With the softplus function f (u), we can write log p(v) as</p><formula xml:id="formula_193">log p(v) = log Z + n i=1 a i v i + m j=1 f i v i W ij + b j . (S.4.39)</formula><p>The parameter b j plays the role of a threshold as shown in the figure below. The terms f ( i v i W ij + b j ) can be interpreted in terms of feature detection. The sum i v i W ij is the inner product between v and the j-th column of W, and the inner product is largest if v equals the j-th column. We can thus consider the columns of W to be feature-templates, and the f ( i v i W ij + b j ) a way to measure how much of each feature is present in v.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Further,</head><p>i v i W ij + b j is also the input to the sigmoid function when computing p(h j = 1|v). Thus, the conditional probability for h j to be one, i.e. "active", can be considered to be an indicator of the presence of the j-th feature (j-th column of W) in the input v.</p><p>If v is such that i v i W ij + b j is large for many j, i.e. if many features are detected, then f ( i v i W ij + b j ) will be non-zero for many j, and log p(v) will be large.</p><formula xml:id="formula_194">-6 -4 -2 2 4 6 2 4 6 8 f (u) f (u + 2) f (u -2) u f (u)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Hidden Markov models and change of measure</head><p>Consider the following undirected graph for a hidden Markov model where the y i correspond to observed (visible) variables and the x i to unobserved (hidden/latent) variables.</p><formula xml:id="formula_195">x 1 x 2 x 3 . . . . . . x t y 1 y 2 y 3 y t</formula><p>The graph implies the following factorisation p(x 1 , . . . , x t , y 1 , . . . , y t ) ∝ φ y 1 (x 1 , y 1 )</p><formula xml:id="formula_196">t i=2 φ x i (x i-1 , x i )φ y i (x i , y i ), (4.6)</formula><p>where the φ x i and φ y i are non-negative factors. Let us consider the situation where t i=2 φ</p><formula xml:id="formula_197">x i (x i-1 , x i ) equals f (x) = t i=2 φ x i (x i-1 , x i ) = f 1 (x 1 ) t i=2 f i (x i |x i-</formula><p>1 ), (4.7) with x = (x 1 , . . . , x t ) and where the f i are (conditional) pdfs. We thus have p(x 1 , . . . , x t , y 1 , . . . , y t ) ∝ f 1 (x 1 ) t i=2 f i (x i |x i-1 ) t i=1 φ y i (x i , y i ). (4.8) (a) Provide a factorised expression for p(x 1 , . . . , x t |y 1 , . . . , y t ) Solution. For fixed (observed) values of the y i , p(x 1 , . . . , x t |y 1 , . . . , y t ) factorises as p(x 1 , . . . , x t |y 1 , . . . , y t ) ∝ f 1 (x 1 )g 1 (x 1 ) t i=1 f i (x i |x i-1 )g i (x i ). (S.4.40) where g i (x i ) is φ y i (x i , y i ) for a fixed value of y i . (b) Draw the undirected graph for p(x 1 , . . . , x t |y 1 , . . . , y t ) Solution. Conditioning corresponds to removing nodes from an undirected graph. We thus have the following Markov chain for p(x 1 , . . . , x t |y 1 , . . . , y t ). x 1 x 2 x 3 . . . x t (c) Show that if φ y i (x i , y i ) equals the conditional pdf of y i given x i , i.e. p(y i |x i ), the marginal p(x 1 , . . . , x t ), obtained by integrating out y 1 , . . . , y t from (4.8), equals f (x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution.</head><p>In this setting all factors in (4.8) are conditional pdfs and we are dealing with a directed graphical model that factorises as</p><formula xml:id="formula_198">p(x 1 , . . . , x t , y 1 , . . . , y t ) = f 1 (x 1 ) t i=2 f i (x i |x i-1 ) t i=1 p(y i |x i ).</formula><p>(S.4.41) By integrating over the y i , we have p(x 1 , . . . , x t ) = p(x 1 , . . . , x t , y 1 , . . . , y t )dy 1 . . . dy t (S.4.42)</p><formula xml:id="formula_199">= f 1 (x 1 ) t i=2 f i (x i |x i-1 ) t i=1 p(y i |x i )dy 1 . . . dy t (S.4.43) = f 1 (x 1 ) t i=2 f i (x i |x i-1 ) t i=1 p(y i |x i )dy i 1 (S.4.44) = f 1 (x 1 ) t i=2 f i (x i |x i-1 ) (S.4.45) = f (x) (S.</formula><p>4.46) (d) Compute the normalising constant for p(x 1 , . . . , x t |y 1 , . . . , y t ) and express it as an expectation over f (x). Solution. With p(x 1 , . . . , x t , y 1 , . . . , y t</p><formula xml:id="formula_200">) ∝ f 1 (x 1 ) t 2=1 f i (x i |x i-1 ) t i=1 φ y i (x i , y i ). (S.4.47)</formula><p>The normalising constant is given by</p><formula xml:id="formula_201">Z = f 1 (x 1 ) t 2=1 f i (x i |x i-1 ) t i=1 g i (x i )dx 1 . . . dx t (S.4.48) = E f t i=1 g i (x i ) (S.4.49)</formula><p>Since we can use ancestral sampling to sample from f , the above expectation can be easily computed via sampling.</p><p>(e) Express the expectation of a test function h(x) with respect to p(x 1 , . . . , x t |y 1 , . . . , y t ) as a reweighted expectation with respect to f (x).</p><p>Solution. By definition, the expectation over a test function h(x) is</p><formula xml:id="formula_202">E p(x 1 ,...,xt|y 1 ,...,yt) [h(x)] = 1 Z h(x)f 1 (x 1 ) t 2=1 f (x i |x i-1 ) t i=1 g i (x i )dx 1 . . . dx t (S.4.50) = E f [h(x) i g i (x i )] E f [ i g i (x i )] (S.4.51)</formula><p>Both the numerator and denominator can be approximated using samples from f . Since the g i (x i ) = φ y i (x i , y i ) involve the observed variables y i , this has a nice interpretation: We can think we have two models for x: f (x) that does not involve the observations and p(x 1 , . . . , x t |y 1 , . . . , y t ) that does. Note, however, that unless φ y i (x i , y i ) is the conditional pdf p(y i |x i ), f (x) is not the marginal p(x 1 , . . . , x t ) that you would obtain by integrating out the y's from the joint model . We can thus generally think it is a base distribution that got "enhanced" by a change of measure in our expression for p(x 1 , . . . , x t |y 1 , . . . , y t ). If φ y i (x i , y i ) is the conditional pdf p(y i |x i ), the change of measure corresponds to going from the prior to the posterior by multiplication with the likelihood (the terms g i ).</p><p>From the expression for the expectation, we can see that the "enhancing" leads to a corresponding introduction of weights in the expectation that depend via g i on the observations. This can be particularly well seen when we approximate the expectation as a sample average over n samples x (k) ∼ f (x):</p><formula xml:id="formula_203">E p(x 1 ,...,xt|y 1 ,...,yt) [h(x)] ≈ n k=1 W (k) h(x (k) )</formula><p>(S.4.52)</p><formula xml:id="formula_204">W (k) = w (k) n k=1 w (k)</formula><p>(S.4.53)</p><formula xml:id="formula_205">w (k) = i g i (x (k) i ) (S.4.54) where x (k) i</formula><p>is the i-th dimension of the vector x (k) .</p><p>Chapter 5</p><p>Expressive Power of Graphical Models  Solution. The skeleton of graph 3 is different from the skeleton of graphs 1 and 2, so that graph 3 cannot be I-equivalent to graph 1 or 2, and we do not need to further check the immoralities for graph 3. Graph 1 and 2 have the same skeleton, and they also have the same immorality. Hence, graph 1 and 2 are I-equivalent. Note that node w in graph 1 is in a collider configuration along trail v -w -x but it is not an immorality because its parents are connected (covering edge); equivalently for node v in graph 2. x 1 x 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">I-equivalence</head><p>x 3 x 4 x 5</p><p>x 6</p><p>x 7</p><p>Graph 0</p><p>For each of the three graphs below, explain whether the graph is a perfect map, an I-map, or not an I-map for U.</p><p>x 1 x 2</p><p>x 3 x 4 x 5</p><p>x 6 x 7</p><p>Graph 1</p><p>x 1 x 2</p><p>x 3 x 4 x 5</p><p>x 6 x 7</p><p>Graph 2</p><p>x 1 x 2</p><p>x 3 x 4 x 5</p><p>x 6 x 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph 3</head><p>Solution.</p><p>• Graph 1 has an immorality x 2 → x 5 ← x 7 which graph 0 does not have. The graph is thus not I-equivalent to graph 0 and can thus not be a perfect map. Moreover, graph 1 asserts that x 2 ⊥ ⊥ x 7 |x 4 which is not case for graph 0. Since graph 0 is a perfect map for U, graph 1 asserts an independency that does not hold for U and can thus not be an I-map for U. • Graph 2 has an immorality x 1 → x 3 ← x 7 which graph 0 does not have. Graph 2 thus asserts that x 1 ⊥ ⊥ x 7 , which is not the case for graph 0. Hence, for the same reason as for graph 1, graph 2 is not an I-map for U. • Graph 3 has the same skeleton and set of immoralities as graph 0. It is thus I-equivalent to graph 0, and hence also a perfect map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Minimal I-maps</head><p>(a) Assume that the graph G in Figure <ref type="figure" target="#fig_26">5</ref>.1 is a perfect I-map for p(a, z, q, e, h). Determine the minimal directed I-map using the ordering (e, h, q, z, a). Is the obtained graph I-equivalent to G? Solution. Since the graph G is a perfect I-map for p, we can use G to check whether p satisfies a certain independency. This gives the following recipe to construct the minimal directed I-map:</p><p>1. Assume an ordering of the variables. Denote the ordered random variables by x 1 , . . . , x d .</p><p>2. For each i, find a minimal subset of variables π i ⊆ pre i such that</p><formula xml:id="formula_206">x i ⊥ ⊥ {pre i \ π i } | π i is in I(G) (only works if G is a perfect I-map for I(p))</formula><p>3. Construct a graph with parents pa i = π i .</p><p>Note: For I-maps G that are not perfect, if the graph does not indicate that a certain independency holds, we have to check that the independency indeed does not hold for p. If we don't, we won't obtain a minimal I-map but just an I-map for I(p). This is because p may have independencies that are not encoded in the graph G.</p><p>Given the ordering (e, h, q, z, a), we build a graph where e is the root. From Figure <ref type="figure" target="#fig_26">5</ref>.1 (and the perfect map assumption), we see that h ⊥ ⊥ e does not hold. We thus set e as parent of h, see first graph in Figure <ref type="figure" target="#fig_26">5</ref>.2. Then:</p><p>• We consider q: pre q = {e, h}. There is no subset π q of pre q on which we could condition to make q independent of pre q \ π q , so that we set the parents of q in the graph to pa q = {e, h}. (Second graph in Figure <ref type="figure" target="#fig_26">5</ref>.2.)</p><p>• We consider z: pre z = {e, h, q}. From the graph in Figure <ref type="figure" target="#fig_26">5</ref>.1, we see that for π z = {q, h} we have z ⊥ ⊥ pre z \ π z |π z . Note that π z = {q} does not work because z ⊥ ⊥ e, h|q does not hold. We thus set pa z = {q, h}. (Third graph in Figure <ref type="figure" target="#fig_26">5</ref>.2.)</p><p>• We consider a: pre a = {e, h, q, z}. This is the last node in the ordering. To find the minimal set π a for which a ⊥ ⊥ pre a \ π a |π a , we can determine its Markov blanket MB(a). The Markov blanket is the set of parents (none), children (q), and co-parents of a (z) in Since the skeleton in the obtained minimal I-map is different from the skeleton of G, we do not have I-equivalence. Note that the ordering (e, h, q, z, a) yields a denser graph (Figure <ref type="figure" target="#fig_26">5</ref>.2) than the graph in Figure <ref type="figure" target="#fig_26">5</ref>.1. Whilst a minimal I-map, the graph does e.g. not show that a ⊥ ⊥ z. Furthermore, the causal interpretation of the two graphs is different.</p><p>(b) For the collection of random variables (a, z, h, q, e) you are given the following Markov blankets for each variable: For positive distributions, the set of distributions that satisfy the local Markov property relative to a graph (as given by the Markov blankets) is the same as the set of Gibbs distributions that factorise according to the graph. Given the I-map, we can now easily find the Gibbs distribution p(a, z, h, q, e) = 1 Z φ 1 (a, z, q)φ 2 (q, e)φ 3 (z, h),</p><formula xml:id="formula_207">• MB(a) = {q,z} • MB(z) = {a,q,h} • MB(h) = {z} • MB(q) = {a,</formula><p>where the φ i must take positive values on their domain. Note that we used the maximal clique (a, z, q). First, note that both graphs share the same skeleton and the only reason that they are not fully connected is the missing edge between x and z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">I-equivalence between directed and undirected graphs</head><p>For the DAG, there is also only one ordering that is topological to the graph: x, u, y, z.</p><p>The missing edge between x and y corresponds to the only independency encoded by the graph: z ⊥ ⊥ pre z \ pa z |pa z , i.e.</p><p>z ⊥ ⊥ x|u, y.</p><p>This is the same independency that we get from the directed local Markov property.</p><p>For the undirected graph, z ⊥ ⊥ x|u, y holds because u, y block all paths between z and x. All variables but z and x are connected to each other, so that no further independency can hold.</p><p>Hence both graphs only encode z ⊥ ⊥ x|u, y and they are thus I-equivalent.</p><p>(b) Are the following two graphs, which are directed and undirected hidden Markov models, I-equivalent?</p><formula xml:id="formula_208">y 1 y 2 y 3 y 4 x 1 x 2 x 3 x 4 y 1 y 2 y 3 y 4 x 1 x 2 x 3 x 4</formula><p>Solution. The skeleton of the two graphs is the same and there are no immoralities. Hence, the two graphs are I-equivalent.</p><p>(c) Are the following two graphs I-equivalent?</p><formula xml:id="formula_209">y 1 y 2 y 3 y 4 x 1 x 2 x 3 x 4 y 1 y 2 y 3 y 4 x 1 x 2 x 3 x 4</formula><p>Solution. The two graphs are not I-equivalent because x 1 -x 2 -x 3 forms an immorality. Hence, the undirected graph encodes x 1 ⊥ ⊥ x 3 |x 2 which is not represented in the directed graph. On the other hand, the directed graph asserts x 1 ⊥ ⊥ x 3 which is not represented in the undirected graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Moralisation: Converting DAGs to undirected minimal I-maps</head><p>The following recipe constructs undirected minimal I-maps for I(p):</p><p>• Determine the Markov blanket for each variable x i</p><p>• Construct a graph where the neighbours of x i are given by its Markov blanket.</p><p>We can adapt the recipe to construct an undirected minimal I-map for the independencies I(G) encoded by a DAG G. What we need to do is to use G to read out the Markov blankets for the variables x i rather than determining the Markov blankets from the distribution p.</p><p>Show that this procedure leads to the following recipe to convert DAGs to undirected minimal I-maps:</p><p>1. For all immoralities in the graph: add edges between all parents of the collider node.</p><p>2. Make all edges in the graph undirected.</p><p>The first step is sometimes called "moralisation" because we "marry" all the parents in the graph that are not already directly connected by an edge. The resulting undirected graph is called the moral graph of G, sometimes denoted by M(G).</p><p>Solution. The Markov blanket of a variable x is the set of its parents, children, and co-parents, as shown in the graph below in sub-figure (a). The parents and children are connected to x in the directed graph, but the co-parents are not directly connected to x. Hence, according to "Construct a graph where the neighbours of x i are its Markov blanket.", we need to introduce edges between x and all its co-parents. This gives the intermediate graph in sub-figure (b). Now, considering the top-left parent of x, we see that for that node, the Markov blanket includes the other parents of x. This means that we need to connect all parents of x, which gives the graph in sub-figure <ref type="bibr">(c)</ref>. This is sometimes called "marrying" the parents of x.</p><p>Continuing in this way, we see that we need to "marry" all parents in the graph that are not already married.</p><p>Finally, we need to make all edges in the graph undirected, which gives sub-figure (d).</p><p>A simpler approach is to note that the DAG specifies the factorisation p(x) = i p(x i |pa i ).</p><p>We can consider each conditional p(x i |pa i ) to be a factor φ i (x i , pa i ) so that we obtain the Gibbs distribution p(x) = i φ i (x i |pa i ). Visualising the distribution by connecting all variables in the same factor φ i (x i |pa i ) leads to the "marriage" of all parents of x i . This corresponds to the first step in the recipe because x i is in a collider configuration with respect to the parent nodes. Not all parents form an immorality but this does here not matter because those that do not form an immorality are already connected by a covering edge in the first place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Moralisation exercise</head><p>For the DAG G below find the minimal undirected I-map for I(G). x 3</p><p>x 4 x 5</p><p>x 6 x 7</p><p>Solution. To derive an undirected minimal I-map from a directed one, we have to construct the moralised graph where the "unmarried" parents are connected by a covering edge. This is because each conditional p(x i |pa i ) corresponds to a factor φ i (x i , pa i ) and we need to connect all variables that are arguments of the same factor with edges.</p><p>Statistically, the reason for marrying the parents is as follows: An independency x ⊥ ⊥ y|{child, other nodes} does not hold in the directed graph in case of collider connections but would hold in the undirected graph if we didn't marry the parents. Hence links between the parents must be added.</p><p>It is important to add edges between all parents of a node. Here, p(x 4 |x 1 , x 2 , x 3 ) corresponds to a factor φ(x 4 , x 1 , x 2 , x 3 ) so that all four variables need to be connected. Just adding edges x 1 -x 2 and x 2 -x 3 would not be enough.</p><p>The moral graph, which is the requested minimal undirected I-map, is shown below.</p><p>x 2 x 1</p><p>x 3</p><p>x 4 x 5</p><p>x 6 x 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Moralisation exercise</head><p>Consider the DAG G:</p><formula xml:id="formula_210">y z 1 z 2 x 1 x 2 x 3 x 4 x 5 x 6</formula><p>A friend claims that the undirected graph below is the moral graph M(G) of G. Is your friend correct? If not, state which edges needed to be removed or added, and explain, in terms of represented independencies, why the changes are necessary for the graph to become the moral graph of G.</p><formula xml:id="formula_211">y z 1 z 2 x 1 x 2 x 3 x 4 x 5 x 6</formula><p>Solution. The moral graph M(G) is an undirected minimal I-map of the independencies represented by G. Following the procedure of connecting "unmarried" parents of colliders, we obtain the following moral graph of G:</p><formula xml:id="formula_212">y z 1 z 2 x 1 x 2 x 3 x 4 x 5 x 6</formula><p>We can thus see that the friend's undirected graph is not the moral graph of G.</p><p>The edge between x 1 and x 6 can be removed. This is because for G, we have e.g. the independencies</p><formula xml:id="formula_213">x 1 ⊥ ⊥ x 6 |z 1 , x 1 ⊥ ⊥ x 6 |z 2 , x 1 ⊥ ⊥ x 6 |z 1 , z<label>2</label></formula><p>which is not represented by the drawn undirected graph.</p><p>We need to add edges between x 1 and x 3 , and between x 4 and x 6 . Otherwise, the undirected graph makes the wrong independency assertion that x 1 ⊥ ⊥ x 3 |x 2 , z 1 (and equivalent for x 4 and x 6 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Triangulation: Converting undirected graphs to directed minimal I-maps</head><p>In Exercise 5.4 we adapted a recipe for constructing undirected minimal I-maps for I(p) to the case of I(G), where G is a DAG. The key difference was that we used the graph G to determine independencies rather than the distribution p.</p><p>We can similarly adapt the recipe for constructing a directed minimal I-map for I(p) to build a directed minimal I-map for I(H), where H is an undirected graph:</p><p>1. Choose an ordering of the random variables.</p><p>2. For all variables x i , use H to determine a minimal subset π i of the predecessors pre i such that</p><formula xml:id="formula_214">x i ⊥ ⊥ (pre i \ π i ) | π i holds.</formula><p>3. Construct a DAG with the π i as parents pa i of x i .</p><p>Remarks: (1) Directed minimal I-maps obtained with different orderings are generally not I-equivalent. (2) The directed minimal I-maps obtained with the above method are always chordal graphs. Chordal graphs are graphs where the longest trail without shortcuts is a triangle (<ref type="url" target="https://en.wikipedia.org/wiki/Chordal_graph">https://en.wikipedia.org/wiki/Chordal_graph</ref>). They are thus also called triangulated graphs. We obtain chordal graphs because if we had trails without shortcuts that involved more than 3 nodes, we would necessarily have an immorality in the graph. But immoralities encode independencies that an undirected graph cannot represent, which would make the DAG not an I-map for I(H) any more.</p><p>(a) Let H be the undirected graph below. Determine the directed minimal I-map for I(H) with the variable ordering x 1 , x 2 , x 3 , x 4 , x 5 .</p><p>x 1 x 2</p><p>x 3 x 4</p><p>x 5</p><p>Solution. We use the ordering x 1 , x 2 , x 3 , x 4 , x 5 and follow the conversion procedure:</p><p>• x 2 is not independent from x 1 so that we set pa 2 = {x 1 }. See first graph in Figure <ref type="figure" target="#fig_26">5</ref>.4.</p><p>• Since x 3 is connected to both x 1 and x 2 , we don't have x 3 ⊥ ⊥ x 2 , x 1 . We cannot make x 3 independent from x 2 by conditioning on x 1 because there are two paths from x 3 to x 2 and x 1 only blocks the upper one. Moreover, x 1 is a neighbour of x 3 so that conditioning on x 2 does make them independent. Hence we must set pa 3 = {x 1 , x 2 }. See second graph in Figure <ref type="figure" target="#fig_26">5</ref>.4.</p><p>• For x 4 , we see from the undirected graph, that</p><formula xml:id="formula_215">x 4 ⊥ ⊥ x 1 | x 3 , x 2 .</formula><p>The graph further shows that removing either x 3 or x 2 from the conditioning set is not possible and conditioning on x 1 won't make x 4 independent from x 2 or x 3 . We thus have pa 4 = {x 2 , x 3 }. See fourth graph in Figure <ref type="figure" target="#fig_26">5</ref>.4.</p><p>• The same reasoning shows that pa 5 = {x 3 , x 4 }. See last graph in Figure <ref type="figure" target="#fig_26">5</ref>.4.</p><p>This results in the triangulated directed graph in Figure <ref type="figure" target="#fig_26">5</ref>.4 on the right.</p><p>x 1 x 2</p><p>x 3 x 4</p><p>x 5</p><p>x 1 x 2</p><p>x 3 x 4</p><p>x 5</p><p>x 1 x 2</p><p>x 3 x 4</p><p>x 5</p><p>x 1 x 2</p><p>x 3 x 4</p><p>x 5</p><p>Figure <ref type="figure" target="#fig_26">5</ref>.4: . Answer to Exercise 5.7, Question (a).</p><p>To see why triangulation is necessary consider the case where we didn't have the edge between x 2 and x 3 as in Figure <ref type="figure" target="#fig_26">5</ref>.5. The directed graph would then imply that x 3 ⊥ ⊥ x 2 | x 1 (check!). But this independency assertion does not hold in the undirected graph so that the graph in Figure <ref type="figure" target="#fig_26">5</ref>.5 is not an I-map.</p><p>(b) For the undirected graph from question (a) above, which variable ordering yields the directed minimal I-map below?</p><p>x 1 x 2</p><p>x 3 x 4</p><p>x 5</p><p>Figure <ref type="figure" target="#fig_26">5</ref>.5: Not a directed I-map for the undirected graphical model defined by the graph in Exercise 5.7, Question (a).</p><p>x 1 x 2</p><p>x 3 x 4</p><p>x 5</p><p>Solution.</p><p>x 1 is the root of the DAG, so it comes first. Next in the ordering are the children of x 1 : x 2 , x 3 , x 4 . Since x 3 is a child of x 4 , and x 4 a child of x 2 , we must have x 1 , x 2 , x 4 , x 3 . Furthermore, x 3 must come before x 5 in the ordering since x 5 is a child of x 3 , hence the ordering used must have been:</p><p>x 1 , x 2 , x 4 , x 3 , x 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">I-maps, minimal I-maps, and I-equivalency</head><p>Consider the following probability density function for random variables x 1 , . . . , x 6 .</p><formula xml:id="formula_216">p a (x 1 , . . . , x 6 ) = p(x 1 )p(x 2 )p(x 3 |x 1 , x 2 )p(x 4 |x 2 )p(x 5 |x 1 )p(x 6 |x 3 , x 4 , x 5 )</formula><p>For each of the two graphs below, explain whether it is a minimal I-map, not a minimal I-map but still an I-map, or not an I-map for the independencies that hold for p a .</p><p>x 1 x 2</p><formula xml:id="formula_217">x 3 x 4 x 5 x 6 graph 1 x 1 x 2 x 3 x 4 x 5 x 6 graph 2</formula><p>Solution. The pdf can be visualised as the following directed graph, which is a minimal I-map for it.</p><p>x 1 x 2</p><p>x 3 x 4 x 5</p><p>x 6</p><p>Graph 1 defines distributions that factorise as</p><formula xml:id="formula_218">p b (x) = p(x 1 )p(x 2 )p(x 3 |x 1 , x 2 )p(x 4 |x 2 , x 3 )p(x 5 |x 1 , x 3 )p(x 6 |x 3 , x 4 , x 5 ).</formula><p>(S.5.1)</p><p>Comparing with p a (x 1 , . . . , x 6 ), we see that only the conditionals p(x 4 |x 2 , x 3 ) and p(x 5 |x 1 , x 3 ) are different. Specifically, their conditioning set includes x 3 , which means that Graph 1 encodes fewer independencies than what p a (x 1 , . . . , x 6 ) satisfies. In particular x 4 ⊥ ⊥ x 3 |x 2 and x 5 ⊥ ⊥ x 3 |x 1 are not represented in the graph. This means that we could remove x 3 from the conditioning sets, or equivalently remove the edges x 3 → x 4 and x 3 → x 5 from the graph without introducing independence assertions that do not hold for p a . This means graph 1 is an I-map but not a minimal I-map.</p><p>Graph 2 is not an I-map. To be an undirected minimal I-map, we had to connect variables x 5 and x 4 that are parents of x 6 . Graph 2 wrongly claims that x 5 ⊥ ⊥ x 4 | x 1 , x 3 , x 6 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9">Limits of directed and undirected graphical models</head><p>We here consider the probabilistic model p(y 1 , y 2 , x 1 , x 2 ) = p(y 1 , y 2 |x 1 , x 2 )p(x 1 )p(x 2 ) where p(y 1 , y 2 |x 1 , x 2 ) factorises as</p><formula xml:id="formula_219">p(y 1 , y 2 |x 1 , x 2 ) = p(y 1 |x 1 )p(y 2 |x 2 )φ(y 1 , y 2 )n(x 1 , x 2 ) (5.1) with n(x 1 , x 2 ) equal to n(x 1 , x 2 ) = p(y 1 |x 1 )p(y 2 |x 2 )φ(y 1 , y 2 )dy 1 dy 2 -1</formula><p>.</p><p>(5.2)</p><p>In the model, x 1 and x 2 are two independent inputs that each control the interacting variables y 1 and y 2 (see graph below). However, the nature of the interaction between y 1 and y 2 is not modelled. In particular, we do not assume a directionality, i.e. y 1 → y 2 , or y 2 → y 1 . some interaction</p><p>x 1 x 2 y 1 y 2 (a) Use the basic characterisations of statistical independence</p><formula xml:id="formula_220">u ⊥ ⊥ v|z ⇐⇒ p(u, v|z) = p(u|z)p(v|z) (5.3) u ⊥ ⊥ v|z ⇐⇒ p(u, v|z) = a(u, z)b(v, z) (a(u, z) ≥ 0, b(v, z) ≥ 0) (5.4)</formula><p>to show that p(y 1 , y 2 , x 1 , x 2 ) satisfies the following independencies</p><formula xml:id="formula_221">x 1 ⊥ ⊥ x 2 x 1 ⊥ ⊥ y 2 | y 1 , x 2 x 2 ⊥ ⊥ y 1 | y 2 , x 1 Solution. The pdf/pmf is p(y 1 , y 2 , x 1 , x 2 ) = p(y 1 |x 1 )p(y 2 |x 2 )φ(y 1 , y 2 )n(x 1 , x 2 )p(x 1 )p(x 2 ) For x 1 ⊥ ⊥ x 2 We compute p(x 1 , x 2 ) as p(x 1 , x 2 ) = p(y 1 , y 2 , x 1 , x 2 )dy 1 dy 2 (S.5.2) = p(y 1 |x 1 )p(y 2 |x 2 )φ(y 1 , y 2 )n(x 1 , x 2 )p(x 1 )p(x 2 )dy 1 dy 2 (S.5.3) = n(x 1 , x 2 )p(x 1 )p(x 2 ) p(y 1 |x 1 )p(y 2 |x 2 )φ(y 1 , y 2 )dy 1 dy 2 (S.5.4) (5.2) = n(x 1 , x 2 )p(x 1 )p(x 2 ) 1 n(x 1 , x 2 ) (S.5.5) = p(x 1 )p(x 2 ).</formula><p>(S.5.6) Since p(x 1 ) and p(x 2 ) are the univariate marginals of x 1 and x 2 , respectively, it follows from (5.3) that x 1 ⊥ ⊥ x 2 .</p><p>For</p><formula xml:id="formula_222">x 1 ⊥ ⊥ y 2 | y 1 , x 2</formula><p>We rewrite p(y 1 , y 2 , x 1 , x 2 ) as</p><formula xml:id="formula_223">p(y 1 , y 2 , x 1 , x 2 ) = p(y 1 |x 1 )p(y 2 |x 2 )φ(y 1 , y 2 )n(x 1 , x 2 )p(x 1 )p(x 2 ) (S.5.7) = [p(y 1 |x 1 )p(x 1 )n(x 1 , x 2 )] [p(y 2 |x 2 )φ(y 1 , y 2 )p(x 2 )] (S.5.8) = φ A (x 1 , y 1 , x 2 )φ B (y 2 , y 1 , x 2 ) (S.5.9)</formula><p>With (5.4), we have that x 1 ⊥ ⊥ y 2 | y 1 , x 2 . Note that p(x 2 ) can be associated either with φ A or with φ B .</p><p>For</p><formula xml:id="formula_224">x 2 ⊥ ⊥ y 1 | y 2 , x 1</formula><p>We use here the same approach as for x 1 ⊥ ⊥ y 2 | y 1 , x 2 . (By symmetry considerations, we could immediately see that the relation holds but let us write it out for clarity). We rewrite p(y 1 , y 2 , x 1 , x 2 ) as</p><formula xml:id="formula_225">p(y 1 , y 2 , x 1 , x 2 ) = p(y 1 |x 1 )p(y 2 |x 2 )φ(y 1 , y 2 )n(x 1 , x 2 )p(x 1 )p(x 2 ) (S.5.10) = [p(y 2 |x 2 )n(x 1 , x 2 )p(x 2 )p(x 1 ))] [p(y 1 |x 1 )φ(y 1 , y 2 )]) (S.5.11)</formula><p>= φA (x 2 , x 1 , y 2 ) φB (y 1 , y 2 , x 1 ) (S.5.12) With (5.4), we have that</p><formula xml:id="formula_226">x 2 ⊥ ⊥ y 1 | y 2 , x 1 .</formula><p>(b) Is there an undirected perfect map for the independencies satisfied by p(y 1 , y 2 , x 1 , x 2 )?</p><p>Solution. We write</p><formula xml:id="formula_227">p(y 1 , y 2 , x 1 , x 2 ) = p(y 1 |x 1 )p(y 2 |x 2 )φ(y 1 , y 2 )n(x 1 , x 2 )p(x 1 )p(x 2 )</formula><p>as a Gibbs distribution p(y 1 , y 2 , x 1 , x 2 ) = φ 1 (y 1 , x 1 )φ 2 (y 2 , x 2 )φ 3 (y 1 , y 2 )φ 4 (x 1 , x 2 ) with (S.5.13) φ 1 (y 1 , x 1 ) = p(y 1 |x 1 )p(x 1 ) (S.5.14)</p><formula xml:id="formula_228">φ 2 (y 2 , x 2 ) = p(y 2 |x 2 )p(x 2 ) (S.5.15) φ 3 (y 1 , y 2 ) = φ(y 1 , y 2 ) (S.5.16) φ 4 (x 1 , x 2 ) = n(x 1 , x 2 ).</formula><p>(S.5.17)</p><p>Visualising it as an undirected graph gives an I-map:</p><formula xml:id="formula_229">x 1 x 2 y 1 y 2</formula><p>While the graph implies x 1 ⊥ ⊥ y 2 | y 1 , x 2 and x 2 ⊥ ⊥ y 1 | y 2 , x 1 , the independency x 1 ⊥ ⊥ x 2 is not represented. Hence the graph is not a perfect map. Note further that removing any edge would result in a graph that is not an I-map for I(p) anymore. Hence the graph is a minimal I-map for I(p) but that we cannot obtain a perfect I-map.</p><p>(c) Is there a directed perfect map for the independencies satisfied by p(y 1 , y 2 , x 1 , x 2 )?</p><p>Solution. We construct directed minimal I-maps for p(y 1 , y 2 , x 1 , x 2 ) = p(y 1 , y 2 |x 1 , x 2 )p(x 1 )p(x 2 ) for different orderings. We will see that they do not represent all independencies in I(p) and hence that they are not perfect I-maps.</p><p>To guarantee unconditional independence of x 1 and x 2 , the two variables must come first in the orderings (either x 1 and then x 2 or the other way around).</p><p>If we use the ordering x 1 , x 2 , y 1 , y 2 , and that</p><formula xml:id="formula_230">• x 1 ⊥ ⊥ x 2 • y 2 ⊥ ⊥ x 1 |y 1 , x 2 , which is y 2 ⊥ ⊥ pre(y 2 ) \ π|π for π = (y 1 , x 2 )</formula><p>are in I(p), we obtain the following directed minimal I-map:</p><formula xml:id="formula_231">x 1 x 2 y 1 y 2</formula><p>The graphs misses</p><formula xml:id="formula_232">x 2 ⊥ ⊥ y 1 | y 2 , x 1 .</formula><p>If we use the ordering x 1 , x 2 , y 2 , y 1 , and that</p><formula xml:id="formula_233">• x 1 ⊥ ⊥ x 2 • y 1 ⊥ ⊥ x 2 |x 1 , y 2 , which is y 1 ⊥ ⊥ pre(y 1 ) \ π|π for π = (x 1 , y 2 )</formula><p>are in I(p), we obtain the following directed minimal I-map:</p><formula xml:id="formula_234">x 1 x 2 y 1 y 2</formula><p>The graph misses</p><formula xml:id="formula_235">x 1 ⊥ ⊥ y 2 | y 1 , x 2 .</formula><p>Moreover, the graphs imply a directionality between y 1 and y 2 , or a direct influence of x 1 on y 2 , or of x 2 on y 1 , in contrast to the original modelling goals.</p><p>(d) (advanced) The following factor graph represents p(y 1 , y 2 , x 1 , x 2 ):</p><formula xml:id="formula_236">p(x 1 ) x 1 p(x 2 ) x 2 p(y 1 |x 1 ) p(y 2 |x 2 ) y 1 y 2 n(x 1 x 2 ) φ(y 1 y 2 )</formula><p>Use the separation rules for factor graphs to verify that we can find all independence relations. The separation rules are (see <ref type="bibr" target="#b23">Barber, 2012</ref>, Section 4.4.1), or the original paper by <ref type="bibr" target="#b26">Frey (2003)</ref>:</p><p>"If all paths are blocked, the variables are conditionally independent. A path is blocked if one or more of the following conditions is satisfied:</p><p>1. One of the variables in the path is in the conditioning set.</p><p>2. One of the variables or factors in the path has two incoming edges that are part of the path (variable or factor collider), and neither the variable or factor nor any of its descendants are in the conditioning set."</p><p>Remarks:</p><p>• "one or more of the following" should best be read as "one of the following".</p><p>• "incoming edges" means directed incoming edges</p><p>• the descendants of a variable or factor node are all the variables that you can reach by following a path (containing directed or directed edges, but for directed edges, all directions have to be consistent)</p><p>• In the graph we have dashed directed edges: they do count when you determine the descendants but they do not contribute to paths. For example, y 1 is a descendant of the n(x 1 , x 2 ) factor node but x 1 -n -y 2 is not a path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution. x 1 ⊥ ⊥ x 2</head><p>There are two paths from x 1 to x 2 marked with red and blue below:</p><formula xml:id="formula_237">p(x 1 ) x 1 p(x 2 )</formula><p>x 2 p(y 1 |x 1 ) p(y 2 |x 2 )</p><formula xml:id="formula_238">y 1 y 2 n(x 1 x 2 ) φ(y 1 y 2 )</formula><p>Both the blue and red path are blocked by condition 2.</p><formula xml:id="formula_239">x 1 ⊥ ⊥ y 2 | y 1 , x 2</formula><p>There are two paths from x 1 to y 2 marked with red and blue below:</p><formula xml:id="formula_240">p(x 1 ) x 1 p(x 2 ) x 2 p(y 1 |x 1 ) p(y 2 |x 2 ) y 1 y 2 n(x 1 x 2 ) φ(y 1 y 2 )</formula><p>The observed variables are marked in blue. For the red path, the observed x 2 blocks the path (condition 1). Note that the n(x 1 , x 2 ) node would be open by condition 2. The blue path is blocked by condition 1 too. In directed graphical models, the y 1 node would be open, but here while condition 2 does not apply, condition 1 still applies (note the one or more of ... in the separation rules), so that the path is blocked.</p><formula xml:id="formula_241">x 2 ⊥ ⊥ y 1 | y 2 , x 1</formula><p>There are two paths from x 2 to y 1 marked with red and blue below:</p><formula xml:id="formula_242">p(x 1 ) x 1 p(x 2 ) x 2 p(y 1 |x 1 ) p(y 2 |x 2 ) y 1 y 2 n(x 1 x 2 ) φ(x 1 x 2 )</formula><p>The same reasoning as before yields the result.</p><p>Finally note that x 1 and x 2 are not independent given y 1 or y 2 because the upper path through n(x 1 , x 2 ) is not blocked whenever y 1 or y 2 are observed (condition 2).</p><p>Credit: this example is discussed in the original paper by B. Frey (Figure <ref type="figure" target="#fig_11">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 6</head><p>Factor Graphs and Message Passing </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Conversion to factor graphs</head><p>(a) Draw an undirected graph and an undirected factor graph for p(x 1 , x 2 , x 3 ) = p(x 1 )p(x 2 )p(x 3 |x 1 , x 2 ) Solution.</p><p>x</p><formula xml:id="formula_243">1 x 2 x 3 x 1 x 2 p(x 3 |x 1 x 2 ) x 3 p(x 1 ) p(x 2 )</formula><p>(b) Draw an undirected factor graph for the directed graphical model defined by the graph below.</p><formula xml:id="formula_244">y 1 y 2 y 3 y 4 x 1 x 2 x 3 x 4</formula><p>Solution. The graph specifies probabilistic models that factorise as p(x 1 , . . . , x 4 , y 1 , . . . , y 4 ) = p(x 1 )p(y 1 |x 1 )</p><formula xml:id="formula_245">4 i=2 p(y i |x i )p(x i |x i-1 )</formula><p>It is the graph for a hidden Markov model. The corresponding factor graph is shown below.</p><formula xml:id="formula_246">y 1 p(y 1 |x 1 ) y 2 p(y 2 |x 2 ) y 3 p(y 3 |x 3 ) y 4 p(y 4 |x 4 ) p(x 1 ) x 1 p(x 2 |x 1 ) x 2 p(x 3 |x 2 ) x 3 p(x 4 |x 3 ) x 4</formula><p>(c) Draw the moralised graph and an undirected factor graph for directed graphical models defined by the graph below (this kind of graph is called a polytree: there are no loops but a node may have more than one parent).</p><p>x 1 x 2</p><p>x 3 x 4</p><p>x 5 x 6</p><p>Solution. The moral graph is obtained by connecting the parents of the collider node x 4 . See the graph on the left in the figure below.</p><p>For the factor graph, we note that the directed graph defines the following class of probabilistic models</p><formula xml:id="formula_247">p(x 1 , . . . x 6 ) = p(x 1 )p(x 2 )p(x 3 |x 1 )p(x 4 |x 1 , x 2 )p(x 5 |x 4 )p(x 6 |x 4 )</formula><p>This gives the factor graph on right in the figure below.</p><p>x 1 x 2</p><p>x 3 x 4</p><p>x 5 x 6 p(x 1 )</p><formula xml:id="formula_248">x 1 p(x 2 ) x 2 p(x 3 |x 1 ) x 3 p(x 4 |x 1 x 2 ) x 4 p(x 5 |x 4 ) x 5 p(x 6 |x 4 )</formula><p>x 6</p><p>Note:</p><p>• The moral graph contains a loop while the factor graph does not. The factor graph is still a polytree. This can be exploited for inference.</p><p>• One may choose to group some factors together in order to obtain a factor graph with a particular structure (see factor graph below)</p><formula xml:id="formula_249">x 1 x 2 p(x 3 |x 1 ) x 3 p(x 4 |x 1 x 2 )p(x 1 )p(x 2 )</formula><p>x 4 p(x 5 |x 4 )p(x 6 |x 4 )</p><p>x 5 x 6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Sum-product message passing</head><p>We here consider the following factor tree:</p><formula xml:id="formula_250">φ A x 1 φ C x 2 φ B x 3 φ D x 4 φ E x 5 φ F</formula><p>Let all variables be binary, x i ∈ {0, 1}, and the factors be defined as follows:</p><formula xml:id="formula_251">x 1 φ A 0 2 1 4 x 2 φ B 0 4 1 4 x 1 x 2 x 3 φ C 0 0 0 4 1 0 0 2 0 1 0 2 1 1 0 6 0 0 1 2 1 0 1 6 0 1 1 6 1 1 1 4 x 3 x 4 φ D 0 0 8 1 0 2 0 1 2 1 1 6 x 3 x 5 φ E 0 0 3 1 0 6 0 1 6 1 1 3 x 5 φ F 0 1 1 8</formula><p>(a) Mark the graph with arrows indicating all messages that need to be computed for the computation of p(x 1 ).</p><p>Solution.</p><formula xml:id="formula_252">φ A x 1 φ C x 2 φ B x 3 φ D x 4 φ E x 5 φ F → ← ↓ ↓ ← ← ← ← ← ← (b)</formula><p>Compute the messages that you have identified.</p><p>Assuming that the computation of the messages is scheduled according to a common clock, group the messages together so that all messages in the same group can be computed in parallel during a clock cycle.</p><p>Solution. Since the variables are binary, each message can be represented as a two-dimensional vector. We use the convention that the first element of the vector corresponds to the message for x i = 0 and the second element to the message for x i = 1. For example,</p><formula xml:id="formula_253">µ φ A →x 1 µ φ A →x 1 µ φ A →x 1 = 2 4 (S.6.1)</formula><p>means that the message µ φ A →x 1 (x 1 ) equals 2 for x 1 = 0, i.e. µ φ A →x 1 (0) = 2.</p><p>The following figure shows a grouping (scheduling) of the computation of the messages.</p><formula xml:id="formula_254">φ A x 1 φ C x 2 φ B x 3 φ D x 4 φ E x 5 φ F [1] → ← [5] [2]↓ [1]↓ ← [4] [ 2 ] ← [1] ← ← [ 3 ] ← [2] ← [1]</formula><p>Clock cycle 1:</p><formula xml:id="formula_255">µ φ A →x 1 µ φ A →x 1 µ φ A →x 1 = 2 4 µ φ B →x 2 µ φ B →x 2 µ φ B →x 2 = 4 4 µ x 4 →φ D µ x 4 →φ D µ x 4 →φ D = 1 1 µ φ F →x 5 µ φ F →x 5 µ φ F →x 5 = 1 8 (S.6.2)</formula><p>Clock cycle 2:</p><formula xml:id="formula_256">µ x 2 →φ C µ x 2 →φ C µ x 2 →φ C = µ φ B →x 2 µ φ B →x 2 µ φ B →x 2 = 4 4 µ x 5 →φ E µ x 5 →φ E µ x 5 →φ E = µ φ F →x 5 µ φ F →x 5 µ φ F →x 5 = 1 8 (S.6.3)</formula><p>Message µ φ D →x 3 is defined as</p><formula xml:id="formula_257">µ φ D →x 3 (x 3 ) = x 4</formula><p>φ D (x 3 , x 4 )µ x 4 →φ D (x 4 ) (S.6.4) so that</p><formula xml:id="formula_258">µ φ D →x 3 (0) = 1 x 4 =0 φ D (0, x 4 )µ x 4 →φ D (x 4 ) (S.6.5) = φ D (0, 0)µ x 4 →φ D (0) + φ D (0, 1)µ x 4 →φ D (1) (S.6.6) = 8 • 1 + 2 • 1 (S.6.7)</formula><p>= 10 (S.6.8)</p><formula xml:id="formula_259">µ φ D →x 3 (1) = 1 x 4 =0 φ D (1, x 4 )µ x 4 →φ D (x 4 ) (S.6.9) = φ D (1, 0)µ x 4 →φ D (0) + φ D (1, 1)µ x 4 →φ D (1) (S.6.10) = 2 • 1 + 6 • 1 (S.6.11) = 8</formula><p>(S.6.12) and thus</p><formula xml:id="formula_260">µ φ D →x 3 µ φ D →x 3 µ φ D →x 3 = 10 8 .</formula><p>(S.6.13)</p><p>The above computations can be written more compactly in matrix notation. Let φ D φ D φ D be the matrix that contains the outputs of φ D (x 3 , x 4 )</p><formula xml:id="formula_261">φ D φ D φ D = φ D (x 3 = 0, x 4 = 0) φ D (x 3 = 0, x 4 = 1) φ D (x 3 = 1, x 4 = 0) φ D (x 3 = 1, x 4 = 1) = 8 2 2 6 . (S.6.14)</formula><p>We can then write µ φ D →x 3 µ φ D →x 3 µ φ D →x 3 in terms of a matrix vector product,</p><formula xml:id="formula_262">µ φ D →x 3 µ φ D →x 3 µ φ D →x 3 = φ D φ D φ D µ x 4 →φ D µ x 4 →φ D µ x 4 →φ D .</formula><p>(S.6.15)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clock cycle 3:</head><p>Representing the factor φ E as matrix</p><formula xml:id="formula_263">φ E φ E φ E , φ E φ E φ E = φ E (x 3 = 0, x 5 = 0) φ E (x 3 = 0, x 5 = 1) φ E (x 3 = 1, x 5 = 0) φ E (x 3 = 1, x 5 = 1) = 3 6 6 3 , (S.6.16)</formula><p>we can write</p><formula xml:id="formula_264">µ φ E →x 3 (x 3 ) = x 5</formula><p>φ E (x 3 , x 5 )µ x 5 →φ E (x 5 ) (S.6.17) as a matrix vector product,</p><formula xml:id="formula_265">µ φ E →x 3 µ φ E →x 3 µ φ E →x 3 = φ E φ E φ E µ x 5 →φ E µ x 5 →φ E µ x 5 →φ E (S.</formula><p>6.18) = 3 6 6 3 1 8 (S.6.19) = 51 30 . (S.6.20) Clock cycle 4: Variable node x 3 has received all incoming messages, and can thus output µ x 3 →φ C ,</p><formula xml:id="formula_266">µ x 3 →φ C (x 3 ) = µ φ D →x 3 (x 3 )µ φ E →x 3 (x 3 ). (S.6.21)</formula><p>Using to denote element-wise multiplication of two vectors, we have</p><formula xml:id="formula_267">µ x 3 →φ C µ x 3 →φ C µ x 3 →φ C = µ φ D →x 3 µ φ D →x 3 µ φ D →x 3 µ φ E →x 3 µ φ E →x 3 µ φ E →x 3 (S.</formula><p>6.22) = 10 8 51 30 (S.6.23) = 510 240 . (S.6.24) Clock cycle 5: Factor node φ C has received all incoming messages, and can thus output µ φ C →x 1 , If we also computed the messages toward the leaf factor nodes, we needed six cycles, but they are not necessary for computation of the marginals so they are omitted.</p><formula xml:id="formula_268">µ φ C →x 1 (x 1 ) = x 2 ,x 3 φ C (x 1 , x 2 , x 3 )µ x 2 →φ C (x 2 )µ x 3 →φ C (x 3 ). (S.6.25) φ A x 1 φ C x 2 φ B x 3 φ D x 4 φ E x 5 φ F [1] → ← [5] [2] → [2]↓ ↑[5] [1]↓ ← [4] [3] → [ 2 ] ← → [ 4 ] [1] ← → [5] ← [ 3 ] [ 4 ] → ← [2] [5] → ← [1]</formula><p>which is in vector notation</p><formula xml:id="formula_269">p(x 1 = 0) p(x 1 = 1) ∝ µ φ A →x 1 µ φ A →x 1 µ φ A →x 1 µ φ C →x 1 µ φ C →x 1 µ φ C →x 1 (S.</formula><p>6.48) ∝ 2 4 19920 25920 (S.6.49) ∝ 39840 103680 . (S.6.50) Normalisation gives p(x 1 = 0) p(x 1 = 1) = 1 39840 + 103680 39840 103680 (S.6.51) = 0.2776 0.7224 (S.6.52)</p><p>so that p(x 1 = 1) = 0.7224.</p><p>Note the relatively large numbers in the messages that we computed. In other cases, one may obtain very small ones depending on the scale of the factors. This can cause numerical issues that can be addressed by working in the logarithmic domain.</p><p>(d) Draw the factor graph corresponding to p(x 1 , x 3 , x 4 , x 5 |x 2 = 1) and provide the numerical values for all factors.</p><p>Solution. The pmf represented by the original factor graph is</p><formula xml:id="formula_270">p(x 1 , . . . , x 5 ) ∝ φ A (x 1 )φ B (x 2 )φ C (x 1 , x 2 , x 3 )φ D (x 3 , x 4 )φ E (x 3 , x 5 )φ F (x 5 )</formula><p>The conditional p(x 1 , x 3 , x 4 , x 5 |x 2 = 1) is proportional to p(x 1 , . . . , x 5 ) with x 2 fixed to x 2 = 1, i.e.</p><p>p(x 1 , x 3 , x 4 , x 5 |x 2 = 1) ∝ p(x 1 , x 2 = 1, x 3 , x 4 , x 5 ) (S.6.53)</p><formula xml:id="formula_271">∝ φ A (x 1 )φ B (x 2 = 1)φ C (x 1 , x 2 = 1, x 3 )φ D (x 3 , x 4 )φ E (x 3 , x 5 )φ F (x 5 ) (S.6.54) ∝ φ A (x 1 )φ x 2 C (x 1 , x 3 )φ D (x 3 , x 4 )φ E (x 3 , x 5 )φ F (x 5 ) (S.6.55) where φ x 2 C (x 1 , x 3 ) = φ C (x 1 , x 2 = 1, x 3 ).</formula><p>The numerical values of φ x 2 C (x 1 , x 3 ) can be read from the table defining φ C (x 1 , x 2 , x 3 ), extracting those rows where x 2 = 1,</p><formula xml:id="formula_272">x 1 x 2 x 3 φ C 0 0 0 4 1 0 0 2 → 0 1 0 2 → 1 1 0 6 0 0 1 2 1 0 1 6 → 0 1 1 6 → 1 1 1 4 so that x 1 x 3 φ x 2 C 0 0 2 1 0 6 0 1 6 1 1 4</formula><p>The factor graph for p(x 1 , x 3 , x 4 , x 5 |x 2 = 1) is shown below. Factor φ B has disappeared since it only depended on x 2 and thus became a constant. Factor φ C is replaced by φ x 2 C defined above. The remaining factors are the same as in the original factor graph.</p><formula xml:id="formula_273">φ A x 1 φ x 2 C x 3 φ D x 4 φ E x 5 φ F</formula><p>(e) Compute p(x 1 = 1|x 2 = 1), re-using messages that you have already computed for the evaluation of p(x 1 = 1).</p><p>Solution. The message µ φ A →x 1 is the same as in the original factor graph and µ x 3 →φ x 2 C = µ x 3 →φ C . This is because the outgoing message from x 3 corresponds to the effective factor obtained by summing out all variables in the sub-trees attached to x 3 (without the φ x 2 C branch), and these sub-trees do not depend on x 2 . The message µ φ x 2 C →x 1 needs to be newly computed. We have</p><formula xml:id="formula_274">µ φ x 2 C →x 1 (x 1 ) = x 3 φ x 2 C (x 1 , x 3 )µ x 3 →φ x 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C</head><p>(S.6.56)</p><p>or in vector notation</p><formula xml:id="formula_275">µ φ x 2 C →x 1 µ φ x 2 C →x 1 µ φ x 2 C →x 1 = φ x 2 C φ x 2 C φ x 2 C µ x 3 →φ x 2 C µ x 3 →φ x 2 C µ x 3 →φ x 2 C (S.6.57) = φ x 2 C (x 1 = 0, x 3 = 0) φ x 2 C (x 1 = 0, x 3 = 1) φ x 2 C (x 1 = 1, x 3 = 0) φ x 2 C (x 1 = 1, x 3 = 1) µ x 3 →φ x 2 C µ x 3 →φ x 2 C µ x 3 →φ x 2 C (S.</formula><p>6.58) = 2 6 6 4 510 240 (S.6.59) = 2460 4020 (S.6.60)</p><p>We thus obtain for the marginal posterior of x 1 given x 2 = 1:</p><formula xml:id="formula_276">p(x 1 = 0|x 2 = 1) p(x 1 = 1|x 2 = 1) ∝ µ φ A →x 1 µ φ A →x 1 µ φ A →x 1 µ φ x 2 C →x 1 µ φ x 2 C →x 1 µ φ x 2 C →x 1 (S.</formula><p>6.61) ∝ 2 4 2460 4020 (S.6.62) ∝ 4920 16080 . (S.6.63) Normalisation gives p(x 1 = 0|x 2 = 1) p(x 1 = 1|x 2 = 1) = 0.2343 0.7657 (S.6.64)</p><p>and thus p(x 1 = 1|x 2 = 1) = 0.7657. The posterior probability is slightly larger than the prior probability, p(x 1 = 1) = 0.7224.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Sum-product message passing</head><p>The following factor graph represents a Gibbs distribution over four binary variables</p><formula xml:id="formula_277">x i ∈ {0, 1}. φ a x 1 φ b x 2 φ c x 3 x 4 φ d φ e</formula><p>The factors φ a , φ b , φ d are defined as follows:</p><formula xml:id="formula_278">x 1 φ a 0 2 1 1 x 1 x 2 φ b 0 0 5 1 0 2 0 1 2 1 1 6 x 3 φ d 0 1 1 2 and φ c (x 1 , x 3 , x 4 ) = 1 if x 1 = x 3 = x 4</formula><p>, and is zero otherwise.</p><p>For all questions below, justify your answer:</p><p>(a) Compute the values of µ x 2 →φ b (x 2 ) for x 2 = 0 and x 2 = 1.</p><p>Solution. Messages from leaf-variable nodes to factor nodes are equal to one, so that µ x 2 →φ b (x 2 ) = 1 for all x 2 .</p><p>(b) Assume the message µ x 4 →φc (x 4 ) equals</p><formula xml:id="formula_279">µ x 4 →φc (x 4 ) = 1 if x 4 = 0 3 if x 4 = 1</formula><p>Compute the values of φ e (x 4 ) for x 4 = 0 and x 4 = 1.</p><p>Solution. Messages from leaf-factors to their variable nodes are equal to the leaffactors, and variable nodes with single incoming messages copy the message. We thus have µ φe→x 4 (x 4 ) = φ e (x 4 ) (S.6.65) µ x 4 →φc (x 4 ) = µ φe→x 4 (x 4 ) (S.6.66) and hence</p><formula xml:id="formula_280">φ e (x 4 ) = 1 if x 4 = 0 3 if x 4 = 1 (S.6.67) (c)</formula><p>Compute the values of µ φc→x 1 (x 1 ) for x 1 = 0 and x 1 = 1.</p><p>Solution. We first compute µ x 3 →φc (x 3 ):</p><formula xml:id="formula_281">µ x 3 →φc (x 3 ) = µ φ d →x 3 (x 3 ) (S.6.68) = 1 if x 3 = 0 2 if x 3 = 1 (S.6.69)</formula><p>The desired message µ φc→x 1 (x 1 ) is by definition</p><formula xml:id="formula_282">µ φc→x 1 (x 1 ) = x 3 ,x 4 φ c (x 1 , x 3 , x 4 )µ x 3 →φc (x 3 )µ x 4 →φc (x 4 ) (S.6.70) Since φ c (x 1 , x 3 , x 4 ) is only non-zero if x 1 = x 3 = x 4</formula><p>, where it equals one, the computations simplify:</p><formula xml:id="formula_283">µ φc→x 1 (x 1 = 0) = φ c (0, 0, 0)µ x 3 →φc (0)µ x 4 →φc (0) (S.6.71) = 1 • 1 • 1 (S.6.72)</formula><p>= 1 (S.6.73)</p><formula xml:id="formula_284">µ φc→x 1 (x 1 = 1) = φ c (1, 1, 1)µ x 3 →φc (1)µ x 4 →φc (1) (S.6.74) = 1 • 2 • 3 (S.6.75) = 6 (S.6.76) (d) The message µ φ b →x 1 (x 1 ) equals µ φ b →x 1 (x 1 ) = 7 if x 1 = 0 8 if x 1 = 1</formula><p>What is the probability that x 1 = 1, i.e. p(x 1 = 1)?</p><p>Solution. The unnormalised marginal p(x 1 ) is given by the product of the three incoming messages</p><formula xml:id="formula_285">p(x 1 ) ∝ µ φa→x 1 (x 1 )µ φ b →x 1 (x 1 )µ φc→x 1 (x 1 ) (S.6.77) With µ φ b →x 1 (x 1 ) = x 2 φ b (x 1 , x 2 ) (S.6.78) it follows that µ φ b →x 1 (x 1 = 0) = x 2</formula><p>φ b (0, x 2 ) (S.6.79) = 5 + 2 (S.6.80) = 7 (S.6.81)</p><formula xml:id="formula_286">µ φ b →x 1 (x 1 = 1) = x 2 φ b (1, x 2 ) (S.</formula><p>6.82) = 2 + 6 (S.6.83) = 8 (S.6.84) Hence, we obtain p(x 1 = 0) ∝ 2 • 7 • 1 = 14 (S.6.85) p(x 1 = 1) ∝ 1 • 8 • 6 = 48 (S.6.86) and normalisation yields the desired result p(x 1 = 1) = 48 14 + 48 = 48 62 = 24 31 = 0.774 (S.6.87)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Max-sum message passing</head><p>We here compute most probable states for the factor graph and factors below.</p><formula xml:id="formula_287">φ A x 1 φ C x 2 φ B x 3 φ D x 4 φ E x 5 φ F</formula><p>Let all variables be binary, x i ∈ {0, 1}, and the factors be defined as follows:</p><formula xml:id="formula_288">x 1 φ A 0 2 1 4 x 2 φ B 0 4 1 4 x 1 x 2 x 3 φ C 0 0 0 4 1 0 0 2 0 1 0 2 1 1 0 6 0 0 1 2 1 0 1 6 0 1 1 6 1 1 1 4 x 3 x 4 φ D 0 0 8 1 0 2 0 1 2 1 1 6 x 3 x 5 φ E 0 0 3 1 0 6 0 1 6 1 1 3 x 5 φ F 0 1 1 8</formula><p>(a) Will we need to compute the normalising constant Z to determine argmax x p(x 1 , . . . , x 5 )?</p><p>Solution. This is not necessary since argmax x p(x 1 , . . . , x 5 ) = argmax x cp(x 1 , . . . , x 5 ) for any constant c. Algorithmically, the backtracking algorithm is also invariant to any scaling of the factors.</p><p>(b) Compute argmax x 1 ,x 2 ,x 3 p(x 1 , x 2 , x 3 |x 4 = 0, x 5 = 0) via max-sum message passing.</p><p>Solution. We first derive the factor graph and corresponding factors for p(x 1 , x 2 , x 3 |x 4 = 0, x 5 = 0).</p><p>For fixed values of x 4 , x 5 , the two variables are removed from the graph, and the factors φ D (x 3 , x 4 ) and φ E (x 3 , x 5 ) are reduced to univariate factors φ x 4 D (x 3 ) and φ x 5 D (x 3 ) by retaining those rows in the table where x 4 = 0 and x 5 = 0, respectively:</p><formula xml:id="formula_289">x 3 φ x 4 D 0 8 1 2 x 3 φ x 5 E 0 3 1 6</formula><p>Since both factors only depend on x 3 , they can be combined into a new factor φ(x 3 ) by element-wise multiplication.</p><p>x 3 φ 0 24 1 12</p><p>Moreover, since we work with an unnormalised model, we can rescale the factor so that the maximum value is one, so that</p><formula xml:id="formula_290">x 3 φ 0 2 1 1 Factor φ F (x 5</formula><p>) is a constant for fixed value of x 5 and can be ignored. The factor graph for p(x 1 , x 2 , x 3 |x 4 = 0, x 5 = 0) thus is</p><formula xml:id="formula_291">φ A x 1 φ C x 2 φ B x 3 φ</formula><p>Let us fix x 1 as root towards which we compute the messages. The messages that we need to compute are shown in the following graph</p><formula xml:id="formula_292">φ A x 1 φ C x 2 φ B x 3 φ → ← ↓ ↓ ← ←</formula><p>Next, we compute the leaf (log) messages. We only have factor nodes as leaf nodes so that</p><formula xml:id="formula_293">λ φ A →x 1 = log φ A (x 1 = 0) log φ A (x 1 = 1) = log 2 log 4 (S.6.88)</formula><p>and similarly</p><formula xml:id="formula_294">λ φ B →x 2 = log φ B (x 2 = 0) log φ B (x 2 = 1) = log 4 log 4 λ φ→x 3 = log φ(x 3 = 0) log φ(x 3 = 1) = log 2 log 1 (S.6.89)</formula><p>Since the variable nodes x 2 and x 3 only have one incoming edge each, we obtain</p><formula xml:id="formula_295">λ x 2 →φ C = λ φ B →x 2 = log 4 log 4 λ x 3 →φ C = λ φ→x 3 = log 2 log 1 (S.6.90)</formula><p>The message λ φ C →x 1 (x 1 ) equals</p><formula xml:id="formula_296">λ φ C →x 1 (x 1 ) = max x 2 ,x 3 log φ C (x 1 , x 2 , x 3 ) + λ x 2 →φ C (x 2 ) + λ x 3 →φ C (x 3 ) (S.6.91)</formula><p>where we wrote the messages in non-vector notation to highlight their dependency on the variables x 2 and x 3 . We now have to consider all combinations of x 2 and x 3</p><formula xml:id="formula_297">x 2 x 3 log φ C (x 1 = 0, x 2 , x 3 ) 0 0 log 4 1 0 log 2 0 1 log 2 1 1 log 6 x 2 x 3 log φ C (x 1 = 1, x 2 , x 3 ) 0 0 log 2 1 0 log 6 0 1 log 6 1 1 log 4 Furthermore x 2 x 3 λ x 2 →φ C (x 2 ) + λ x 3 →φ C (x 3 ) 0 0 log 4 + log 2 = log 8 1 0 log 4 + log 2 = log 8 0 1 log 4 1 1 log 4</formula><p>Hence for x 1 = 0, we have</p><formula xml:id="formula_298">x 2 x 3 log φ C (x 1 = 0, x 2 , x 3 ) + λ x 2 →φ C (x 2 ) + λ x 3 →φ C (x 3 )<label>0</label></formula><p>0 log 4 + log 8 = log 32 1 0 log 2 + log 8 = log 16 0 1 log 2 + log 4 = log 8 1 1 log 6 + log 4 = log 24</p><p>The maximal value is log 32 and for backtracking, we also need to keep track of the argmax which is here x2 = x3 = 0.</p><p>For x 1 = 1, we have</p><formula xml:id="formula_299">x 2 x 3 log φ C (x 1 = 1, x 2 , x 3 ) + λ x 2 →φ C (x 2 ) + λ x 3 →φ C (x 3 ) 0 0 log 2 + log 8 = log 16 1 0 log 6 + log 8 = log 48 0 1 log 6 + log 4 = log 24 1 1 log 4 + log 4 = log 16</formula><p>The maximal value is log 48 and the argmax is (x 2 = 1, x3 = 0).</p><p>So overall, we have</p><formula xml:id="formula_300">λ φ C →x 1 = λ φ C →x 1 (x 1 = 0) λ φ C →x 1 (x 1 = 1) = log 32 log 48 (S.6.92)</formula><p>and the argmax back-tracking function is</p><formula xml:id="formula_301">λ * φ C →x 1 (x 1 ) = (x 2 = 0, x3 = 0) if x 1 = 0 (x 2 = 1, x3 = 0) if x 1 = 1 (S.6.93)</formula><p>We now have all incoming messages to the assigned root node x 1 . Ignoring the normalising constant, we obtain</p><formula xml:id="formula_302">γ = γ * (x 1 = 0) γ * (x 1 = 1) = λ φ A →x 1 + λ φ C →x 1 (S.</formula><p>6.94) = log 2 log 4 + log 32 log 48 = log 64 log 192 (S.6.95)</p><p>The value x 1 for which γ * (x 1 ) is largest is thus x1 = 1. Plugging x1 = 1 into the backtracking function λ * φ C →x 1 (x 1 ) gives</p><formula xml:id="formula_303">(x 1 , x2 , x3 ) = argmax x 1 ,x 2 ,x 3 p(x 1 , x 2 , x 3 |x 4 = 0, x 5 = 0) = (1, 1, 0). (S.6.96)</formula><p>In this low-dimensional example, we can verify the solution by computing the unnormalised pmf for all combinations of x 1 , x 2 , x 3 . This is done in the following table where we start with the table for φ C and then multiply-in the further factors φ A , φ and φ B .</p><formula xml:id="formula_304">x 1 x 2 x 3 φ C φ C φ A φ C φ A φ φ C φ A φφ B 0 0 0 4</formula><p>8 16 16 • 4 1 0 0 2 8 16 16 • 4 0 1 0 2 8 16 16 • 4 1 1 0 6 24 48 48 • 4 0 0 1 2 8 8 8 • 4 1 0 1 6 24 24 24 • 4 0 1 1 6 12 12 12 • 4 1 1 1 4 16 16 16 • 4</p><p>For example, for the column φ c φ A , we multiply each value of φ C (x 1 , x 2 , x 3 ) by φ A (x 1 ), so that the rows with x 1 = 0 get multiplied by 2, and the rows with x 1 = 1 by 4.</p><p>The maximal value in the final column is achieved for x 1 = 1, x 2 = 1, x 3 = 0, in line with the result above (and 48 • 4 = 192). Since φ B (x 2 ) is a constant, being equal to 4 for all values of x 2 , we could have ignored it in the computation. The formal reason for this is that since the model is unnormalised, we are allowed to rescale each factor by an arbitrary (factor-dependent) constant. This operation does not change the model. So we could divide φ B by 4 which would give a value of 1, so that the factor can indeed be ignored.</p><p>(c) Compute argmax x 1 ,...,x 5 p(x 1 , . . . , x 5 ) via max-sum message passing with x 1 as root.</p><p>Solution. As discussed in the solution to the answer above, we can drop factor φ B (x 2 ) since it takes the same value for all x 2 . Moreover, we can rescale the individual factors by a constant so they are more amenable to calculations by hand. We normalise them such that the largest value is one, which gives the following factors. Note that this is entirely optional.</p><formula xml:id="formula_305">x 1 φ A 0 1 1 2 x 1 x 2 x 3 φ C 0 0 0 2 1 0 0 1 0 1 0 1 1 1 0 3 0 0 1 1 1 0 1 3 0 1 1 3 1 1 1 2 x 3 x 4 φ D 0 0 4 1 0 1 0 1 1 1 1 3 x 3 x 5 φ E 0 0 1 1 0 2 0 1 2 1 1 1 x 5 φ F 0 1 1 8</formula><p>The factor graph without φ B together with the messages that we need to compute is:</p><formula xml:id="formula_306">φ A x 1 φ C x 2 x 3 φ D x 4 φ E x 5 φ F → ← ↓ ← ← ← ← ← ←</formula><p>The leaf (log) messages are (using vector notation where the top element corresponds to x i = 0 and the bottom one to x i = 1):</p><formula xml:id="formula_307">λ φ A →x 1 = 0 log 2 λ x 2 →φ C = 0 0 λ x 4 →φ D = 0 0 λ φ F →x 5 = 0 log 8</formula><p>(S.6.97)</p><p>The variable node x 5 only has one incoming edge so that λ x 5 →φ E = λ φ F →x 5 . The message λ φ E →x 3 (x 3 ) equals</p><formula xml:id="formula_308">λ φ E →x 3 (x 3 ) = max x 5</formula><p>log φ E (x 3 , x 5 ) + λ x 5 →φ E (x 5 ) (S.6.98)</p><p>Writing out log φ E (x 3 , x 5 ) + λ x 5 →φ E (x 5 ) for all x 5 as a function of x 3 we have</p><formula xml:id="formula_309">x 5 log φ E (x 3 = 0, x 5 ) + λ x 5 →φ E (x 5 ) 0 log 1 + 0 = 0 1 log 2 + log 8 = log 16 x 5 log φ E (x 3 = 1, x 5 ) + λ x 5 →φ E (x 5 ) 0 log 2 + 0 = log 2 1 log 1 + log 8 = log 8</formula><p>Taking the maximum over x 5 as a function of x 3 , we obtain λ φ E →x 3 = log 16 log 8 (S.6.99)</p><p>and the backtracking function that indicates the maximiser x5 = argmax x 5 log φ E (x 3 , x 5 )+ λ x 5 →φ E (x 5 ) as a function of x 3 equals</p><formula xml:id="formula_310">λ * φ E →x 3 (x 3 ) = x5 = 1 if x 3 = 0 x5 = 1 if x 3 = 1 (S.6.100)</formula><p>We perform the same kind of operation for λ φ D →x 3 (x 3 )</p><formula xml:id="formula_311">λ φ D →x 3 (x 3 ) = max x 4 log φ D (x 3 , x 4 ) + λ x 4 →φ D (x 4 ) (S.6.101)</formula><p>Since λ x 4 →φ D (x 4 ) = 0 for all x 4 , the table with all values of log φ D (x 3 , x 4 ) + λ x 4 →φ D (x 4 ) is</p><formula xml:id="formula_312">x 3 x 4 log φ D (x 3 , x 4 ) + λ x 4 →φ D (x 4 ) 0 0 log 4 + 0 = log 4 1 0 log 1 + 0 = 0 0 1 log 1 + 0 = 0 1 1 log 3 + 0 = log 3</formula><p>Taking the maximum over x 4 as a function of x 3 we thus obtain</p><formula xml:id="formula_313">λ φ D →x 3 = log 4 log 3 (S.6.102)</formula><p>and the backtracking function that indicates the maximiser x4 = argmax x 4 log φ D (x 3 , x 4 )+ λ x 4 →φ D (x 4 ) as a function of x 3 equals</p><formula xml:id="formula_314">λ * φ D →x 3 (x 3 ) = x4 = 0 if x 3 = 0 x4 = 1 if x 3 = 1 (S.6.103)</formula><p>For the message λ x 3 →φ C (x 3 ) we add together the messages λ φ E →x 3 (x 3 ) and λ φ D →x 3 (x 3 ) which gives λ x 3 →φ C = log 16 + log 4 log 8 + log 3 = log 64 log 24 (S.6.104)</p><p>Next we compute the message λ φ C →x 1 (x 1 ) by maximising over x 2 and x 3 ,</p><formula xml:id="formula_315">λ φ C →x 1 (x 1 ) = max x 2 ,x 3 log φ C (x 1 , x 2 , x 3 ) + λ x 2 →φ C (x 2 ) + λ x 3 →φ C (x 3 ) (S.6.105) Since λ x 2 →φ C (x 2 ) = 0, the problem becomes λ φ C →x 1 (x 1 ) = max x 2 ,x 3 log φ C (x 1 , x 2 , x 3 ) + λ x 3 →φ C (x 3 ) (S.</formula><p>6.106) Building on the table for φ C , we form a table with all values of log φ</p><formula xml:id="formula_316">C (x 1 , x 2 , x 3 ) + λ x 3 →φ C (x 3 ) x 1 x 2 x 3 log φ C (x 1 , x 2 , x 3 ) + λ x 3 →φ C (x 3 ) 0 0 0 log 2 +</formula><p>log 64 = log 128 1 0 0 0 + log 64 = log 64 0 1 0 0 + log 64 = log 64 1 1 0 log 3 + log 64 = log 192 0 0 1 log 24 1 0 1 log 3 + log 24 = log 72 0 1 1 log 3 + log 24 = log 72 1 1 1 log 2 + log 24 = log 48 The maximal value as a function of x 1 are highlighted in the table, which gives the message λ φ C →x 1 = log 128 log 192 (S.6.107) and the backtracking function</p><formula xml:id="formula_317">λ * φ C →x 1 (x 1 ) = (x 2 = 0, x3 = 0) if x 1 = 0 (x 2 = 1, x3 = 0) if x 1 = 1 (S.6.108)</formula><p>We now have all incoming messages to the assigned root node x 1 . Ignoring the normalising constant, we obtain</p><formula xml:id="formula_318">γ = γ * (x 1 = 0) γ * (x 1 = 1) = 0 + log 128 log 2 + log 192</formula><p>(S.6.109)</p><p>We can now start the backtracking to compute the desired argmax x 1 ,...,x 5 p(x 1 , . . . , x 5 ).</p><p>Starting at the root we have x1 = argmax x 1 γ * (x 1 ) = 1. Plugging this value into the look-up table λ * φ C →x 1 (x 1 ), we obtain (x 2 = 1, x3 = 0). With the look-up table λ * φ E →x 3 (x 3 ) we find x5 = 1 and λ * φ D →x 3 (x 3 ) gives x4 = 0 so that overall argmax x 1 ,...,x 5 p(x 1 , . . . , x 5 ) = (1, 1, 0, 0, 1). (S.6.110) (d) Compute argmax x 1 ,...,x 5 p(x 1 , . . . , x 5 ) via max-sum message passing with x 3 as root.</p><p>Solution. With x 3 as root, we need the following messages:</p><formula xml:id="formula_319">φ A x 1 φ C x 2 x 3 φ D x 4 φ E x 5 φ F → → ↓ → ← ← ← ← ←</formula><p>The following messages are the same as when x 1 was the root:</p><formula xml:id="formula_320">λ φ D →x 3 = log 4 log 3 λ φ E →x 3 = log 16 log 8 λ φ A →x 1 = 0 log 2 λ x 2 →φ C = 0 0 (S.6.111)</formula><p>Since x 1 has only one incoming message, we further have</p><formula xml:id="formula_321">λ x 1 →φ C = λ φ A →x 1 = 0 log 2 . (S.6.112)</formula><p>We next compute λ φ C →x 3 (x 3 ),</p><formula xml:id="formula_322">λ φ C →x 3 (x 3 ) = max x 1 ,x 2 log φ C (x 1 , x 2 , x 3 ) + λ x 1 →φ C (x 1 ) + λ x 2 →φ C (x 2 ). (S.6.113) We first form a table for log φ C (x 1 , x 2 , x 3 ) + λ x 1 →φ C (x 1 ) + λ x 2 →φ C (x 2 ) noting that λ x 2 →φ C (x 2 ) = 0 x 1 x 2 x 3 log φ C (x 1 , x 2 , x 3 ) + λ x 1 →φ C (x 1 ) + λ x 2 →φ C (x 2 ) 0 0 0 log 2 + 0 = log 2 1 0 0 0 + log 2 = log 2 0 1 0 0 + 0 = 0 1 1 0 log 3 + log 2 = log 6 0 0 1 0 + 0 = 0 1 0 1 log 3 + log 2 = log 6 0 1 1 log 3 + 0 = log 3 1 1 1 log 2 + log 2 = log 4</formula><p>The maximal value as a function of x 3 are highlighted in the table, which gives the message</p><formula xml:id="formula_323">λ φ C →x 3 = log 6 log 6 (S.6.114)</formula><p>and the backtracking function</p><formula xml:id="formula_324">λ * φ C →x 3 (x 3 ) = (x 1 = 1, x2 = 1) if x 3 = 0 (x 1 = 1, x2 = 0) if x 3 = 1 (S.6.115)</formula><p>We have now all incoming messages for x 3 and can compute γ * (x 3 ) up the normalising constant -log Z (which is not needed if we are interested in the argmax only:</p><formula xml:id="formula_325">γ = γ * (x 3 = 0) γ * (x 3 = 1) = λ φ C →x 3 + λ φ D →x 3 + λ φ E →x 3 (S.</formula><p>6.116) = log 6 + log 4 + log 16 = log 384 log 6 + log 3 + log 8 = log 144 (S.6.117)</p><p>We can now start the backtracking which gives: x3 = 0, so that λ * φ C →x 3 (0) = (x 1 = 1, x2 = 1). The backtracking functions λ * φ E →x 3 (x 3 ) and λ * φ D →x 3 (x 3 ) are the same for question <ref type="bibr">(c)</ref>, which gives λ * φ E →x 3 (0) = x5 = 1 and λ * φ D →x 3 (0) = x4 = 0. Hence, overall, we find argmax</p><p>x 1 ,...,x 5 p(x 1 , . . . , x 5 ) = (1, 1, 0, 0, 1). (S.6.118)</p><p>Note that this matches the result from question (c) where x 1 was the root. This is because the output of the max-sum algorithm is invariant to the choice of the root.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Choice of elimination order in factor graphs</head><p>Consider the following factor graph, which contains a loop:</p><formula xml:id="formula_326">x 1 φ A x 2 x 3 φ B x 4 φ C x 5 x 6 φ D</formula><p>Let all variables be binary, x i ∈ {0, 1}, and the factors be defined as follows:</p><formula xml:id="formula_327">x 1 x x 3 φ A 0 0 4 1 0 2 0 0 2 1 0 6 0 1 2 1 1 6 0 1 6 1 1 4 x 2 x 3 x 4 φ B 0 0 0 2 1 0 0 2 0 1 0 4 1 1 0 2 0 0 1 6 1 0 1 8 0 1 1 4 1 1 1 2 x 4 x 5 φ C 0 0 8 1 0 2 0 1 2 1 1 6 x 4 x 6 φ D 0 0 3 1 0 6 0 1 6 1 1 3 (a)</formula><p>Draw the factor graph corresponding to p(x 2 , x 3 , x 4 , x 5 | x 1 = 0, x 6 = 1) and give the tables defining the new factors φ x 1 =0 A (x 2 , x 3 ) and φ x 6 =1 D (x 4 ) that you obtain.</p><p>Solution. First condition on x 1 = 0:</p><p>Factor node φ A (x 1 , x 2 , x 3 ) depends on x 1 , thus we create a new factor φ x 1 =0 A (x 2 , x 3 ) from the table for φ A using the rows where x 1 = 0.</p><formula xml:id="formula_328">φ x 1 =0 A x 2 x 3 φ B x 4 φ C x 5 x 6 φ D x 1 x 2 x 3 φ A → 0 0 0 4 1 0 0 2 → 0 1 0 2 1 1 0 6 → 0 0 1 2 1 0 1 6 → 0 1 1 6 1 1 1 4 so that x 2 x 3 φ x 1 =0 A 0 0 4 1 0 2 0 1 2 1 1 6</formula><p>Next condition on x 6 = 1:</p><p>Factor node φ D (x 4 , x 6 ) depends on x 6 , thus we create a new factor φ x 6 =1 D (x 4 ) from the table for φ D using the rows where x 6 = 1.</p><formula xml:id="formula_329">φ x 1 =0 A x 2 x 3 φ B x 4 φ C x 5 φ x 6 =1 D x 4 x 6 φ D 0 0 3 1 0 6 → 0 1 6 → 1 1 3 so that x 4 φ x 6 =1 D 0 6 1 3 (b) Find p(x 2 |</formula><p>x 1 = 0, x 6 = 1) using the elimination ordering (x 4 , x 5 , x 3 ):</p><p>(i) Draw the graph for p(x 2 , x 3 , x 5 | x 1 = 0, x 6 = 1) by marginalising x 4 Compute the table for the new factor φ4 (x 2 , x 3 , x 5 )</p><p>(ii) Draw the graph for p(x 2 , x 3 | x 1 = 0, x 6 = 1) by marginalising x 5 Compute the table for the new factor φ45 (x 2 , x 3 ) (iii) Draw the graph for p(x 2 | x 1 = 0, x 6 = 1) by marginalising x 3 Compute the table for the new factor φ453 (x 2 )</p><p>Solution. Starting with the factor graph for p(x 2 , x 3 , x 4 , x 5 | x 1 = 0, x 6 = 1)</p><formula xml:id="formula_330">φ x 1 =0 A x 2 x 3 φ B x 4 φ C x 5 φ x 6 =1 D Marginalising x 4 combines the three factors φ B , φ C and φ x 6 =1 D φ x 1 =0 A x 2 x 3 φ4 x 5</formula><p>Marginalising x 5 modifies the factor φ4</p><formula xml:id="formula_331">φ x 1 =0 A x 2 x 3 φ45 Marginalising x 3 combines the factors φ x 1 =0</formula><p>A and φ45</p><p>x 2 φ453</p><p>We now compute the tables for the new factors φ4 , φ45 , φ453 .</p><p>First find φ4 (x 2 , x 3 , x 5 )</p><formula xml:id="formula_332">x 2 x 3 x 4 φ B 0 0 2 0 0 2 1 0 4 1 0 2 0 1 6 0 1 8 1 1 4 1 1 2 x 4 x 5 φ C 0 0 8 1 0 2 0 1 2 1 1 6 x 4 φ x 6 =1 D 0 6 1 3 so that φ * (x 2 , x , x 4 , x 5 ) = φ B (x 2 , x 3 , x 4 )φ C (x 4 , x 5 )φ x 6 =1 D (x 4 ) equals x 2 x 3 x 4 x 5 φ * (x 2 , x 3 , x 4 , x 5 ) 0 0 0 0 2 * 8 * 6 1 0 0 0 2 * 8 * 6 0 1 0 0 4 * 8 * 6 1 1 0 0 2 * 8 * 6 0 0 1 0 6 * 2 * 3 1 0 1 0 8 * 2 * 3 0 1 1 0 4 * 2 * 3 1 1 1 0 2 * 2 * 3 0 0 0 1 2 * 2 * 6 1 0 0 1 2 * 2 * 6 0 1 0 1 4 * 2 * 6 1 1 0 1 2 * 2 * 6 0 0 1 1 6 * 6 * 3 1 0 1 1 8 * 6 * 3 0 1 1 1 4 * 6 * 3 1 1 1 1 2 * 6 * 3 and x 2 x x 5 x 4 φ B (x 2 , x 3 , x 4 )φ C (x 4 , x 5 )φ x 6 =1 D (x 4 ) φ4<label>0</label></formula><p>0 (2 * 8 * 6) + (6 * 2 * 3) = 132 1 0 (2 * 8 * 6) + (8 * 2 * 3) = 144 0 0 (4 * 8 * 6) + (4 * 2 * 3) = 216 1 0 (2 * 8 * 6) + (2 * 2 * 3) = 108 0 1 (2 * 2 * 6) + (6 * 6 * 3) = 132 1 1 (2 * 2 * 6) + (8 * 6 * 3) = 168 0 1 (4 * 2 * 6) + (4 * 6 * 3) = 120 1 1 (2 * 2 * 6) + (2 * 6 * 3) = 60 Next find φ45 (x 2 , x 3 ) x 2 x 3 x 5 φ4 0 0 0 132 1 0 0 144 0 1 0 216 1 1 0 108 0 0 1 132 1 0 1 168 0 1 1 120 1 1 1 60 so that x 2 x 3 x 5 φ4 (x 2 , x 3 , x 5 ) φ45 0 0 132 + 132 = 264 1 0 144 + 168 = 312 0 1 216 + 120 = 336 1 1 108 + 60 = 168</p><p>Finally find φ453 (x 2 )</p><formula xml:id="formula_333">x 2 x 3 φ x 1 =0 A 0 0 4 1 0 2 0 1 2 1 1 6 x 2 x 3 φ45 0 0 264 1 0 312 0 1 336 1 1 168 so that x 2 x 3 φ45 (x 2 , x 3 )φ x 1 =0 A (x 2 , x 3 ) φ453 0 (4 * 264) + (2 * 336) = 1728 1 (2 * 312) + (6 * 168) = 1632</formula><p>The normalising constant is Z = 1728 + 1632. Our conditional marginal is thus:</p><formula xml:id="formula_334">p(x 2 | x 1 = 0, x 6 = 1) = 1728/Z 1632/Z = 0.514 0.486 (S.6.119) (c) Now determine p(x 2 | x 1 = 0, x 6 = 1</formula><p>) with the elimination ordering (x 5 , x 4 , x 3 ):</p><p>(i) Draw the graph for p(x 2 , x 3 , x 4 , | x 1 = 0, x 6 = 1) by marginalising x 5 Compute the table for the new factor φ5 (x 4 )</p><p>(ii) Draw the graph for p(x 2 , x 3 | x 1 = 0, x 6 = 1) by marginalising x 4 Compute the table for the new factor φ54 (x 2 , x 3 ) (iii) Draw the graph for p(x 2 | x 1 = 0, x 6 = 1) by marginalising x 3 Compute the table for the new factor φ543 (x 2 )</p><p>Solution. Starting with the factor graph for p(x 2 , x 3 , x 4 , x 5 | x 1 = 0, x 6 = 1)</p><formula xml:id="formula_335">φ x 1 =0 A x 2 x 3 φ B x 4 φ C x 5 φ x 6 =1 D Marginalising x 5 modifies the factor φ C φ x 1 =0 A x 2 x 3 φ B x 4 φ5 φ x 6 =1 D Marginalising x 4 combines the three factors φ B , φ5 and φ x 6 =1 D φ x 1 =0 A x 2 x 3 φ54 Marginalising x 3 combines the factors φ x 1 =0</formula><p>A and φ54</p><p>x 2 φ543</p><p>We now compute the tables for the new factors φ5 , φ54 , and φ543 .</p><p>First find φ5 (x 4 )</p><formula xml:id="formula_336">x 4 x 5 φ C 0 0 8 1 0 2 0 1 2 1 1 6 so that x 4 x 5 φ C (x 4 , x 5 ) φ5 0 8 + 2 = 10 1 2 + 6 = 8</formula><p>Next find φ54 (x 2 , x 3 )</p><formula xml:id="formula_337">x 2 x 3 x 4 φ B 0 0 0 2 1 0 0 2 0 1 0 4 1 1 0 2 0 0 1 6 1 0 1 8 0 1 1 4 1 1 1 2</formula><p>x 4 φ5 0 10 1 8</p><formula xml:id="formula_338">x 4 φ x 6 =1 D 0 6 1 3 so that φ * (x 2 , x 3 , x 4 ) = φ B (x 2 , x 3 , x 4 ) φ5 (x 4 )φ x 6 =1 D (x 4 ) equals x 2 x 3 x 4 φ * (x 2 , x 3 , x 4 ) 0 0 0 2 *</formula><p>10 * 6 1 0 0 2 * 10 * 6 0 1 0 4 * 10 * 6 1 1 0 2 * 10 * 6 0 0 1 6 * 8 * 3 1 0 1 8 * 8 * 3 0 1 1 4 * 8 * 3 1 1 1 2 * 8 * 3 and x 2 x 3 x 4 φ B (x 2 , x 3 , x 4 ) φ5 (x 4 )φ x 6 =1 D (x 4 ) φ54 0 0 (2 * 10 * 6) + (6 * 8 * 3) = 264 1 0 (2 * 10 * 6) + (8 * 8 * 3) = 312 0 1 (4 * 10 * 6) + (4 * 8 * 3) = 336 1 1 (2 * 10 * 6) + (2 * 8 * 3) = 168</p><p>Finally find φ543 (x 2 )</p><formula xml:id="formula_339">x 2 x 3 φ x 1 =0 A 0 0 4 1 0 2 0 1 2 1 1 6 x 2 x 3 φ54 0 0 264 1 0 312 0 1 336 1 1 168 so that x 2 x 3 φ54 (x 2 , x 3 )φ x 1 =0 A (x 2 , x 3 ) φ543 0 (4 * 264) + (2 * 336) = 1728 1 (2 * 312) + (6 * 168) = 1632</formula><p>As with the ordering in the previous part, we should come to the same result for our conditional marginal distribution.The normalising constant is Z = 1728 + 1632, so that the conditional marginal is p(x 2 | x 1 = 0, x 6 = 1) = 1728/Z 1632/Z = 0.514 0.486 (S.6.120) (d) Which variable ordering, (x 4 , x 5 , x 3 ) or (x 5 , x 4 , x 3 ) do you prefer?</p><p>Solution. The ordering (x 5 , x 4 , x 3 ) is cheaper and should be preferred over the ordering (x 4 , x 5 , x 3 ) .</p><p>The reason for the difference in the cost is that x 4 has three neighbours in the factor graph for p(x 2 , x 3 , x 4 , x 5 | x 1 = 0, x 6 = 1). However, after elimination of x 5 , which has only one neighbour, x 4 has only two neighbours left. Eliminating variables with more neighbours leads to larger (temporary) factors and hence a larger cost. We can see this from the tables that were generated during the computation (or numbers that we needed to add together): for the ordering (x 4 , x 5 , x 3 ), the largest table had 2 4 entries while for (x 5 , x 4 , x 3 ), it had 2 3 entries.</p><p>Choosing a reasonable variable ordering has a direct effect on the computational complexity of variable elimination. This effect becomes even more pronounced when the domain of our discrete variables has a size greater than 2 (binary variables), or if the variables are continuous.</p><formula xml:id="formula_340">φ x 1 =0 A x 2 x 3 φ B x 4 φ C x 5 φ x 6 =1 D</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Choice of elimination order in factor graphs</head><p>We would like to compute the marginal p(x 1 ) by variable elimination for a joint pmf represented by the following factor graph. All variables x i can take K different values.</p><formula xml:id="formula_341">x 1 φ a x 2 φ b x 3 φ c x 4 x 5 φ d x 6 φ e x 7</formula><p>φ f (a) A friend proposes the elimination order x 4 , x 5 , x 6 , x 7 , x 3 , x 2 , i.e. to do x 4 first and x 2 last. Explain why this is computationally inefficient.</p><p>Solution. According to the factor graph, p(x 1 , . . . , x 7 ) factorises as p(x 1 , . . . , x 7 ) ∝ φ a (x 1 , x 4 )φ b (x 2 , x 4 )φ c (x 3 , x 4 )φ d (x 5 , x 4 )φ e (x 6 , x 4 )φ f (x 7 , x 4 ) (S.6.121)</p><p>If we choose to eliminate x 4 first, i.e. compute p(x 1 , x 2 , x 3 , x 5 , x 6 , x 7 ) =</p><p>x 4 p(x 1 , . . . , x 7 ) (S.6.122)</p><formula xml:id="formula_342">∝ x 4 φ a (x 1 , x 4 )φ b (x 2 , x 4 )φ c (x 3 , x 4 )φ d (x 5 , x 4 )φ e (x 6 , x 4 )φ f (x 7 , x 4 ) (S.6.123)</formula><p>we cannot pull any of the factors out of the sum since each of them depends on x 4 . This means the cost to sum out x 4 for all combinations of the six variables (x 1 , x 2 , x 3 , x 5 , x 6 , x 7 ) is K 7 . Moreover, the new factor</p><formula xml:id="formula_343">φ(x 1 , x 2 , x 3 , x 5 , x 6 , x 7 ) = x 4 φ a (x 1 , x 4 )φ b (x 2 , x 4 )φ c (x 3 , x 4 )φ d (x 5 , x 4 )φ e (x 6 , x 4 )φ f (x 7 , x 4 )</formula><p>(S.6.124) does not factorise anymore so that subsequent variable eliminations will be expensive too.</p><p>(b) Propose an elimination ordering that achieves O(K 2 ) computational cost per variable elimination and explain why it does so.</p><p>Solution. Any ordering where x 4 is eliminated last will do. At any stage, elimination of one of the variables x 2 , x 3 , x 5 , x 6 , x 7 is then a O(K 2 ) operation. This is because e.g. p(x 1 , . . . , x 6 ) =</p><p>x 7 p(x 1 , . . . , x 7 ) (S.6.125)</p><formula xml:id="formula_344">∝ φ a (x 1 , x 4 )φ b (x 2 , x 4 )φ c (x 3 , x 4 )φ d (x 5 , x 4 )φ e (x 6 , x 4 ) x 7 φ f (x 7 , x 4 ) φ7 (x 4 ) (S.6.126) ∝ φ a (x 1 , x 4 )φ b (x 2 , x 4 )φ c (x 3 , x 4 )φ d (x 5 , x 4 )φ e (x 6 , x 4 ) φ7 (x 4 ) (S.6.127)</formula><p>where computing φ7 (x 4 ) for all values of x 4 is O(K 2 ). Further, p(x 1 , . . . , x 5 ) =</p><p>x 6 p(x 1 , . . . , x 6 ) (S.6.128)</p><formula xml:id="formula_345">∝ φ a (x 1 , x 4 )φ b (x 2 , x 4 )φ c (x 3 , x 4 )φ d (x 5 , x 4 ) φ7 (x 4 )</formula><p>x 6 φ e (x 6 , x 4 ) (S.6.129)</p><formula xml:id="formula_346">∝ φ a (x 1 , x 4 )φ b (x 2 , x 4 )φ c (x 3 , x 4 )φ d (x 5 , x 4 ) φ7 (x 4 ) φ6 (x 4 ), (S.6.130)</formula><p>where computation of φ6 (x 4 ) for all values of x 4 is again O(K ). Continuing in this manner, one obtains p(x 1 , x 4 ) ∝ φ a (x 1 , x 4 ) φ2 (x 4 ) φ3 (x 4 ) φ5 (x 4 ) φ6 (x 4 ) φ7 (x ). (S.6.131)</p><p>where each derived factor φ has O(K 2 ) cost. Summing out x and normalising the pmf is again a O(K 2 ) operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 7</head><p>Inference for Hidden Markov Models </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Predictive distributions for hidden Markov models</head><p>For the hidden Markov model</p><formula xml:id="formula_347">p(h 1:d , v 1:d ) = p(v 1 |h 1 )p(h 1 ) d i=2 p(v i |h i )p(h i |h i-1 )</formula><p>assume you have observations for v i , i = 1, . . . , u &lt; d.</p><p>(a) Use message passing to compute p(h t |v 1:u ) for u &lt; t ≤ d. For the sake of concreteness, you may consider the case d = 6, u = 2, t = 4.</p><p>Solution. The factor graph for d = 6, u = 2, with messages that are required for the computation of p(h t |v 1:u ) for t = 4, is as follows.</p><formula xml:id="formula_348">φ 1 h 1 φ 2 h 2 p(h3|h2) h 3 p(h4|h3) h 4 p(h 5 |h 4 ) h 5 p(h 6 |h 5 ) h 6 v 3 p<label>(v3|h3) v 4 p(v4|h4) v 5 p(v5|h5) v 6 p(v6|h6)</label></formula><formula xml:id="formula_349">→ → → → → → → ← ← ← ← ↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑</formula><p>The messages from the unobserved visibles v i to their corresponding h i , e.g. v 3 to h 3 , are all one. Moreover, the message from the p(h 5 |h 4 ) node to h 4 equals one as well. This is because all involved factors, p(v i |h i ) and p(h i |h i-1 ), sum to one. Hence the factor graph reduces to a chain:</p><formula xml:id="formula_350">φ 1 h 1 φ 2 h 2 p(h 3 |h 2 ) h 3 p(h 4 |h 3 ) h 4 → → → →</formula><p>Since the variable nodes copy the messages in case of a chain, we only show the factor-to-variable messages.</p><p>The graph shows that we are essentially in the same situation as in filtering, with the difference that we use the factors p(h s |h s-1 ) for s ≥ u + 1. Hence, we can use filtering to compute the messages until time s = u and then compute the further messages with the p(h s |h s-1 ) as factors. This gives the following algorithm:</p><p>1. Compute α(h u ) by filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">For s</head><formula xml:id="formula_351">= u + 1, . . . , t, compute α(h s ) = h s-1 p(h s |h s-1 )α(h s-1 ) (S.7.1)</formula><p>3. The required predictive distribution is</p><formula xml:id="formula_352">p(h t |v 1:u ) = 1 Z α(h t ) Z = ht α(h t ) (S.7.2) For s ≥ u + 1, we have that hs α(h s ) = hs h s-1 p(h s |h s-1 )α(h s-1 ) (S.7.3) = h s-1 α(h s-1 ) (S.7.4) since p(h s |h s-1 ) is normalised. This means that the normalising constant Z above equals Z = hu α(h u ) = p(v 1:u ) (S.7.5)</formula><p>which is the likelihood.</p><p>For filtering, we have seen that α(h s ) ∝ p(h s |v 1:s ), s ≤ u. The α(h s ) for all s &gt; u are proportional to p(h s |v 1:u ). This may be seen by noting that the above arguments hold for any t &gt; u.</p><p>(b) Use message passing to compute p(v t |v 1:u ) for u &lt; t ≤ d. For the sake of concreteness, you may consider the case d = 6, u = 2, t = 4.</p><p>Solution. The factor graph for d = 6, u = 2, with messages that are required for the computation of p(v t |v 1:u ) for t = 4, is as follows.</p><formula xml:id="formula_353">φ 1 h 1 φ 2 h 2 p(h3|h2) h 3 p(h4|h3) h 4 p(h 5 |h 4 ) h 5 p(h 6 |h 5 ) h 6 v 3 p(v3|h3) v 4 p(v4|h4) v 5 p(v5|h5) v 6 p(v6|h6) → → → → → → → ← ← ← ← ↑ ↑ ↓ ↓ ↑ ↑ ↑ ↑</formula><p>Due to the normalised factors, as above, the messages to the right of h t are all one. Moreover the messages that go up from the v i to the h i , i = t, are also all one. Hence the graph simplifies to a chain.</p><formula xml:id="formula_354">φ 1 h 1 φ 2 h 2 p(h 3 |h 2 ) h 3 p(h 4 |h 3 ) h 4 p(v 4 |h 4 ) v 4 → → → → →</formula><p>The message in blue is proportional to p(h t |v 1:u ) computed in question (a). Thus assume that we have computed p(h t |v 1:u ). The predictive distribution on the level of the visibles thus is</p><formula xml:id="formula_355">p(v t |v 1:u ) = ht p(v t |h t )p(h t |v 1:u ). (S.7.6)</formula><p>This follows from message passing since the last node (h 4 in the graph) just copies the (normalised) message and the next factor equals p(v t |h t ).</p><p>An alternative derivation follows from basic definitions and operations, together with the independencies in HMMs:</p><formula xml:id="formula_356">(sum rule) p(v t |v 1:u ) = ht p(v t , h t |v 1:u ) (S.7.7) (product rule) = ht p(v t |h t , v 1:u )p(h t |v 1:u ) (S.7.8) (vt ⊥ ⊥ v 1:u | ht) = ht p(v t |h t )p(h t |v 1:u ) (S.7.9)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Viterbi algorithm</head><p>For the hidden Markov model</p><formula xml:id="formula_357">p(h 1:t , v 1:t ) = p(v 1 |h 1 )p(h 1 ) t i=2 p(v i |h i )p(h i |h i-1 )</formula><p>assume you have observations for v i , i = 1, . . . , t. Use the max-sum algorithm to derive an iterative algorithm to compute ĥ = argmax</p><formula xml:id="formula_358">h 1 ,...,ht p(h 1:t |v 1:t )<label>(7.1)</label></formula><p>Assume that the latent variables h i can take K different values, e.g.</p><formula xml:id="formula_359">h i ∈ {0, . . . , K -1}.</formula><p>The resulting algorithm is known as Viterbi algorithm.</p><p>Solution. We first form the factors</p><formula xml:id="formula_360">φ 1 (h 1 ) = p(v 1 |h 1 )p(h 1 ) φ 2 (h 1 , h 2 ) = p(v 2 |h 2 )p(h 2 |h 1 ) (S.7.10) . . . φ t (h t-1 , h t ) = p(v t |h t )p(h t |h t-1 ) (S.7.11)</formula><p>where the v i are known and fixed. The posterior p(h 1 , . . . , h t |v 1 , . . . , v t ) is then represented by the following factor graph (assuming t = 4).</p><formula xml:id="formula_361">φ 1 h 1 φ 2 h 2 φ 3 h 3 φ 4 h 4</formula><p>For the max-sum algorithm, we here choose h t to be the root. We thus initialise the algorithm with γ φ 1 →h 1 (h 1 ) = log φ 1 (h 1 ) = log p(v 1 |h 1 ) + log p(h 1 ) and then compute the messages from left to right, moving from the leaf φ 1 to the root h t .</p><p>Since we are dealing with a chain, the variable nodes, much like in the sum-product algorithm, just copy the incoming messages. It thus suffices to compute the factor to variable messages shown in the graph, and then backtrack to h 1 .</p><formula xml:id="formula_362">φ 1 h 1 φ 2 h 2 φ 3 h 3 φ 4 h 4 → → → → With γ h i-1 →φ i (h i-1 ) = γ φ i-1 →h i-1 (h i-1</formula><p>), the factor-to-variable update equation is</p><formula xml:id="formula_363">γ φ i →h i (h i ) = max h i-1 log φ i (h i-1 , h i ) + γ h i-1 →φ i (h i-1 ) (S.7.12) = max h i-1 log φ i (h i-1 , h i ) + γ φ i-1 →h i-1 (h i-1 ) (S.7.13)</formula><p>To simplify notation, denote γ φ i →h i (h i ) by V i (h i ). We thus have</p><formula xml:id="formula_364">V 1 (h 1 ) = log p(v 1 |h 1 ) + log p(h 1 ) (S.7.14) V i (h i ) = max h i-1 log φ i (h i-1 , h i ) + V i-1 (h i-1 ) i = 2, . . . , t (S.7.15)</formula><p>In general, V 1 (h 1 ) and V i (h i ) are functions that depend on h 1 and h i , respectively. Assuming that the h i can take on the values 0, . . . , K -1, the above equations can be written as</p><formula xml:id="formula_365">v 1,k = log p(v 1 |k) + log p(k) k = 0, . . . , K -1 (S.7.16) v i,k = max m∈0,...,K-1 log φ i (m, k) + v i-1,m k = 0, . . . , K -1, i = 2, . . . , t, (S.7.17)</formula><p>At the end of the algorithm, we thus have a t × K matrix V with elements v i,k .</p><p>The maximisation can be performed by computing the temporary matrix A (via broadcasting) where the (m, k)-th element is log φ i (m, k) + v i-1,m . Maximisation then corresponds to determining the maximal value in each column.</p><p>To support the backtracking, when we compute V i (h i ) by maximising over h i-1 , we compute at the same time the look-up table</p><formula xml:id="formula_366">γ * i (h i ) = argmax h i-1 log φ i (h i-1 , h i ) + V i-1 (h i-1 ) (S.7.18)</formula><p>When h i takes on the values 0, . . . , K -1, this can be written as</p><formula xml:id="formula_367">γ * i,k = argmax m∈0,...,K-1 log φ i (m, k) + v i-1,m (S.7.19)</formula><p>This is the (row) index of the maximal element in each column of the temporary matrix A.</p><p>After computing v t,k and γ * t,k , we then perform backtracking via</p><formula xml:id="formula_368">ĥt = argmax k v t,k (S.7.20) ĥi = γ * i+1, ĥi+1 i = t -1, . . . , 1 (S.7.21)</formula><p>This gives recursively ĥ = ( ĥ1 , . . . , ĥt ) = argmax h 1 ,...,ht p(h 1:t |v 1:t ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Forward filtering backward sampling for hidden Markov models</head><p>Consider the hidden Markov model specified by the following DAG.</p><formula xml:id="formula_369">h 1 . . . . . . h t-1 h t . . . . . . h n v 1 v t-1 v t v n</formula><p>We assume that have already run the alpha-recursion (filtering) and can compute p(h t |v 1:t ) for all t. The goal is now to generate samples p(h 1 , . . . , h n |v 1:n ), i.e. entire trajectories (h 1 , . . . , h n ) from the posterior. Note that this is not the same as sampling from the n filtering distributions p(h t |v 1:t ). Moreover, compared to the Viterbi algorithm, the sampling approach generates samples from the full posterior rather than just returning the most probable state and its corresponding probability.</p><p>(a) Show that p(h 1 , . . . , h n |v 1:n ) forms a first-order Markov chain.</p><p>Solution. There are several ways to show this. The simplest is to notice that the undirected graph for the hidden Markov model is the same as the DAG but with the arrows removed as there are no colliders in the DAG. Moreover, conditioning corresponds to removing nodes from an undirected graph. This leaves us with a chain that connects the h i .</p><formula xml:id="formula_370">h 1 h 2 h 3 . . . h n</formula><p>By graph separation, we see that p(h 1 , . . . , h n |v 1:n ) forms a first-order Markov chain so that e.g. h 1:t-1 ⊥ ⊥ h t+1:n |h t (past independent from the future given the present).</p><p>(b) Since p(h 1 , . . . , h n |v 1:n ) is a first-order Markov chain, it suffices to determine p(h t-1 |h t , v 1:n ), the probability mass function for h t-1 given h t and all the data v 1:n . Use message passing to show that</p><formula xml:id="formula_371">p(h t-1 , h t |v 1:n ) ∝ α(h t-1 )β(h t )p(h t |h t-1 )p(v t |h t )<label>(7.2)</label></formula><p>Solution. Since all visibles are in the conditioning set, i.e. assumed observed, we can represent the conditional model p(h 1 , . . . , h n |v 1:n ) as a chain factor tree, e.g. as follows in case of n = 4</p><formula xml:id="formula_372">φ 1 h 1 φ 2 h 2 φ 3 h 3 φ 4 h 4</formula><p>Combining the emission distributions p(v s |h s ) (and marginal p(h 1 )) with the transition distributions p(h s |h s-1 ) we obtain the factors</p><formula xml:id="formula_373">φ 1 (h 1 ) = p(h 1 )p(v 1 |h 1 ) (S.7.22) φ s (h s-1 , h s ) = p(h s |h s-1 )p(v s |h s ) for t = 2, . . . , n (S.7.23)</formula><p>We see from the factor tree that h t-1 and h t are neighbours, being attached to the same factor node φ t (h t-1 , h t ), e.g. φ 3 in case of p(h 2 , h 3 |v 1:4 ).</p><p>By the rules of message passing, the joint p(h t-1 , h t |v 1:n ) is thus proportional to φ t times the messages into φ t . The following graph shows the messages for the case of p(h 2 , h 3 |v 1:4 ).</p><formula xml:id="formula_374">φ 1 h 1 φ 2 h 2 φ 3 h 3 φ 4 h 4 → ←</formula><p>Since the variable nodes only receive single messages from any direction, they copy the messages so that the messages into φ t are given by α(h t-1 ) and β(h t ) shown below in red and blue, respectively.</p><formula xml:id="formula_375">φ 1 h 1 φ 2 h 2 φ 3 h 3 φ 4 h 4 → ← Hence, p(h t-1 , h t |v 1:n ) ∝ α(h t-1 )β(h t )φ t (h t-1 , h t ) (S.7.24) ∝ α(h t-1 )β(h t )p(h t |h t-1 )p(v t |h t ) (S.7.25)</formula><p>which is the result that we want to show.</p><formula xml:id="formula_376">(c) Show that p(h t-1 |h t , v 1:n ) = α(h t-1 ) α(ht) p(h t |h t-1 )p(v t |h t ).</formula><p>Solution. The conditional p(h t-1 |h t , v 1:n ) can be written as the ratio</p><formula xml:id="formula_377">p(h t-1 |h t , v 1:n ) = p(h t-1 , h t |v 1:n ) p(h t |v 1:n ) . (S.7.26)</formula><p>Above, we have shown that the numerator satisfies</p><formula xml:id="formula_378">p(h t-1 , h t |v 1:n ) ∝ α(h t-1 )β(h t )p(h t |h t-1 )p(v t |h t ).</formula><p>(S.7.27)</p><p>The denominator p(h t |v 1:n ) is proportional to α(h t )β(h t ) since it is the smoothing distribution than can be determined via the alpha-beta recursion.</p><p>Normally, we needed to sum the messages over all values of (h t-1 , h t ) to find the normalising constant of the numerator. For the denominator, we had to sum over all values of h t . Next, I will argue qualitatively that this summation is not needed; the normalising constants are both equal to p(v 1:t ). A more mathematical argument is given below.</p><p>We started with a factor graph and factors that represent the joint p(h</p><formula xml:id="formula_379">1:n , v 1:n ). The conditional p(h 1:n , v 1:n ) equals p(h 1:n |v 1:n ) = p(h 1:n , v 1:n ) p(v 1:n ) (S.7.28)</formula><p>Message passing is variable elimination. Hence, when computing p(h t |v 1:n ) as α(h t )β(h t ) from a factor graph for p(h 1:n , v 1:n ), we only need to divide by p(v 1:n ) for normalisation; explicitly summing out h t is not needed. In other words,</p><formula xml:id="formula_380">p(h t |v 1:n ) = α(h t )β(h t ) p(v 1:n ) . (S.7.29)</formula><p>Similarly, p(h t-1 , h t |v 1:n ) is also obtained from (S.7.28) by marginalisation/variable elimination. Again, when computing</p><formula xml:id="formula_381">p(h t-1 , h t |v 1:n ) as α(h t-1 )β(h t )p(h t |h t-1 )p(v t |h t ) v 1 p(v 1 |h 1 ) v 2 p(v 2 |h 2 ) v 3 p(v 3 |h 3 ) p(h 1 ) h 1 p(h 2 |h 1 ) h 2 p(h 3 |h 2 ) h 3</formula><p>This question is about computing the predictive probability p(v 3 = 1|v 1 = 1).</p><p>(a) The factor graph below represents p(h</p><formula xml:id="formula_382">1 , h 2 , h 3 , v 2 , v 3 | v 1 = 1)</formula><p>. Provide an equation that defines φ A in terms of the factors in the factor graph above.</p><formula xml:id="formula_383">v 2 p(v 2 |h 2 ) v 3 p(v 3 |h 3 ) h 1 φ A h 2 p(h 3 |h 2 ) h 3 Solution. φ A (h 1 , h 2 ) ∝ p(v 1 |h 1 )p(h 1 )p(h 2 |h 1 ) with v 1 = 1.</formula><p>(b) Assume further that all variables are binary, h i ∈ {0, 1}, v i ∈ {0, 1}; that p(h 1 = 1) = 0.5, and that the transition and emission distributions are, for all i, given by:</p><formula xml:id="formula_384">p(h i+1 |h i ) h i+1 h i 0 0 0 1 1 0 1 0 1 0 1 1 p(v i |h i ) v i h i 0.6 0 0 0.4 1 0 0.4 0 1 0.6 1 1</formula><p>Compute the numerical values of the factor φ A .</p><p>(c) Given the definition of the transition and emission probabilities, we have</p><formula xml:id="formula_385">φ A (h 1 , h 2 ) = 0 if h 1 = h 2 . For h 1 = 0, h 2 = 1, we obtain φ A (h 1 = 0, h 2 = 1) = p(v 1 = 1|h 1 = 0)p(h 1 = 0)p(h 2 = 1|h 1 = 0) (S.7.52) = 0.4 • 0.5 • 1 (S.7.53) = 4 10 • 1 2 (S.7.54) = 2 10 = 0.2 (S.7.55) For h 1 = 1, h 2 = 0, we obtain φ A (h 1 = 1, h 2 = 0) = p(v 1 = 1|h 1 = 1)p(h 1 = 1)p(h 2 = 0|h 1 = 1) (S.7.56) = 0.6 • 0.5 • 1 (S.7.57) = 6 10 • 1 2 (S.7.58) = 3 10 = 0.3 (S.7.59) Hence φ A (h 1 , h 2 ) h 1 h 2 0 0 0 0.3 1 0 0.2 0 1 0 1 1 (d)</formula><p>Denote the message from variable node h 2 to factor node p(h 3 |h 2 ) by α(h 2 ). Use message passing to compute α(h 2 ) for h 2 = 0 and h 2 = 1. Report the values of any intermediate messages that need to be computed for the computation of α(h 2 ).</p><p>Solution. The message from h 1 to φ A is one. The message from φ A to h 2 is</p><formula xml:id="formula_386">µ φ A →h 2 (h 2 = 0) = h 1 φ A (h 1 , h 2 = 0) (S.7.60) = 0.3 (S.7.61) µ φ A →h 2 (h 2 = 1) = h 1 φ A (h 1 , h 2 =</formula><p>1) (S.7.62) = 0.2 (S.7.63) Since v 2 is not observed and p(v 2 |h 2 ) normalised, the message from p(v 2 |h 2 ) to h 2 equals one.</p><p>This means that the message from h 2 to p(h</p><formula xml:id="formula_387">3 |h 2 ), which is α(h 2 ) equals µ φ A →h 2 (h 2 ), i.e. α(h 2 = 0) = 0.3 (S.7.64) α(h 2 = 1) = 0.2 (S.7.65) (e)</formula><p>With α(h 2 ) defined as above, use message passing to show that the predictive probability p(v 3 = 1|v 1 = 1) can be expressed in terms of α(h 2 ) as</p><formula xml:id="formula_388">p(v 3 = 1|v 1 = 1) = xα(h 2 = 1) + yα(h 2 = 0) α(h 2 = 1) + α(h 2 = 0) (7.4)</formula><p>and report the values of x and y.</p><p>Solution. Given the definition of p(h 3 |h 2 ), the message µ p(h</p><formula xml:id="formula_389">3 |h 2 )→h 3 (h 3 ) is µ p(h 3 |h 2 )→h 3 (h 3 = 0) = α(h 2 = 1) (S.7.66) µ p(h 3 |h 2 )→h 3 (h 3 = 1) = α(h 2 = 0) (S.7.67)</formula><p>The variable node h 3 copies the message so that we have</p><formula xml:id="formula_390">µ p(v 3 |h 3 )→v 3 (v 3 = 0) = h 3 p(v 3 = 0|h 3 )µ p(h 3 |h 2 )→h 3 (h 3 ) (S.7.68) = p(v 3 = 0|h 3 = 0)α(h 2 = 1) + p(v 3 = 0|h 3 = 1)α(h 2 = 0) (S.7.69) = 0.6α(h 2 = 1) + 0.4α(h 2 = 0) (S.7.70) µ p(v 3 |h h 3)→v 3 (v 3 = 1) = h 3 p(v 3 = 1|h 3 ))µ p(h 3 |h 2 )→h 3 (h 3 ) (S.7.71) = p(v 3 = 1|h 3 = 0)α(h 2 = 1) + p(v 3 = 1|h 3 = 1)α(h 2 = 0) (S.7.72) = 0.4α(h 2 = 1) + 0.6α(h 2 = 0) (S.7.73)</formula><p>We thus have p(v 3 = 1|v 1 = 1) = 0.4α(h 2 = 1) + 0.6α(h 2 = 0) 0.4α(h 2 = 1) + 0.6α(h 2 = 0) + 0.6α(h 2 = 1) + 0.4α(h 2 = 0) (S.7.74) = 0.4α(h 2 = 1) + 0.6α(h 2 = 0) α(h 2 = 1) + α(h 2 = 0) (S.7.75)</p><p>The requested x and y are thus: x = 0.4, y = 0.6.</p><p>(f) Compute the numerical value of p(v 3 = 1|v 1 = 1).</p><p>Solution. Inserting the numbers gives α(h 2 = 0) + α(h 2 = 1) = 5/10 = 1/2 so that</p><formula xml:id="formula_391">p(v 3 = 1|v 1 = 1) = 0.4 • 0.2 + 0.6 • 0.3<label>1</label></formula><p>2 (S.7.76) = 2 • 4 10 • 2 10 + 6 10 3 10 (S.7.77) = 4 10 • 4 10 + 6 10 6 10 (S.7.78) = 1 100 (16 + 36) (S.7.79) = 1 100 52 (S.7.80) = 52 100 = 0.52 (S.7.81) Integrating out x 2 , . . . , x n gives p 1 (x 1 ) = p 1 (x 1 , . . . , x n )dx 2 . . . dx n (S.7.91) ∝ p(x 1 ) n i=2 p(x i |x i-1 )g 1 (x 1 )dx 2 . . . dx n (S.7.92) ∝ p(x 1 )g 1 (x 1 ) n i=2 p(x i |x i-1 )dx 2 . . . dx n (S.7.93) ∝ p(x 1 )g 1 (x 1 ) n i=2 p(x i |x i-1 )dx i =1 (S.7.94) ∝ p(x 1 )g 1 (x 1 ) (S.7.95) The normalising constant is Z 1 = p(x 1 )g 1 (x 1 )dx 1 (S.7.96) This establishes the result for t = 1. From (7.8), we further have p t-1 (x 1 , . . . , x n ) = p(x 1 , . . . , x n |y 1 , . . . , y t-1 ) (S.7.97) ∝ p(x 1 ) n i=2 p(x i |x i-1 ) t-1 i=1 g i (x i ) (S.7.98) Integrating out x t+1 , . . . , x n thus gives p t-1 (x 1 , . . . , x t ) = p t-1 (x 1 , . . . , x n )dx t+1 . . . dx n (S.7.99) ∝ p(x 1 ) n i=2 p(x i |x i-1 ) t-1 i=1 g i (x i )dx t+1 . . . dx n (S.7.100) ∝ p(x 1 ) t i=2 p(x i |x i-1 ) t-1 i=1 g i (x i ) n i=t+1 p(x i |x i-1 )dx t+1 . . . dx n (S.7.101) ∝ p(x 1 ) t i=2 p(x i |x i-1 ) t-1 i=1 g i (x i ) n i=t+1 p(x i |x i-1 )dx i (S.7.102) ∝ p(x 1 ) t i=2 p(x i |x i-1 ) t-1 i=1 g i (x i ) (S.7.103) Noting that the product over the g i does not involve x t and that p(x t |x t-1 ) is a pdf, we have further p t-1 (x 1 , . . . , x t-1 ) = p t-1 (x 1 , . . . , x t )dx t (S.7.104) ∝ p(x 1 ) t-1 i=2 p(x i |x i-1 ) t-1 i=1 g i (x i ) (S.7.105) Solution. Let t &gt; 1. With (7.9), we have p t-1 (x t-1 , x t ) = p t-1 (x 1 , . . . , x t )dx 1 . . . dx t-2 (S.7.112) = p t-1 (x 1 , . . . , x t-1 )p(x t |x t-1 )dx 1 . . . dx t-2 (S.7.113) = p(x t |x t-1 ) p t-1 (x 1 , . . . , x t-1 )dx 1 . . . dx t-2 (S.7.114) = p(x t |x t-1 )p t-1 (x t-1 ) (S.7.115) which proves the "extension". With (7.10), we have p t (x t ) = p t (x 1 , . . . , x t )dx 1 , . . . dx t-1 (S.7.116) = 1 Z t p t-1 (x 1 , . . . , x t )g t (x t )dx 1 , . . . dx t-1 (S.7.117) = 1 Z t g t (x t ) p t-1 (x 1 , . . . , x t )dx 1 , . . . dx t-1 (S.7.118) = 1 Z t g t (x t )p t-1 (x t ) (S.7.119)</p><p>which proves the "change of measure". Moreover, the normalising constant Z t is the same as before. Hence completing the iteration until t = n yields the likelihood p(y 1 , . . . , y n ) = Z n as a by-product of the recursion. The initialisation of the recursion with p 0 (x 1 ) = p(x 1 ) is also the same as above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Kalman filtering</head><p>We here consider filtering for hidden Markov models with Gaussian transition and emission distributions. For simplicity, we assume one-dimensional hidden variables and observables. We denote the probability density function of a Gaussian random variable x with mean µ and variance σ 2 by N (x|µ, σ 2 ),</p><formula xml:id="formula_392">N (x|µ, σ 2 ) = 1 √ 2πσ 2 exp - (x -µ) 2 2σ 2 . (7.16)</formula><p>The transition and emission distributions are assumed to be</p><formula xml:id="formula_393">p(h s |h s-1 ) = N (h s |A s h s-1 , B 2 s ) (7.17) p(v s |h s ) = N (v s |C s h s , D<label>2</label></formula><p>s ). (7.18) The distribution p(h 1 ) is assumed Gaussian with known parameters. The A s , B s , C s , D s are also assumed known. (a) Show that h s and v s as defined in the following update and observation equations h s = A s h s-1 + B s ξ s (7.19) v s = C s h s + D s η s (7.20) follow the conditional distributions in (7.17) and (7.18). The random variables ξ s and η s are independent from the other variables in the model and follow a standard normal Gaussian distribution, e.g. ξ s ∼ N (ξ s |0, 1). Hint: For two constants c 1 and c 2 , y = c 1 + c 2 x is Gaussian if x is Gaussian. In other words, an affine transformation of a Gaussian is Gaussian. The equations mean that h s is obtained by scaling h s-1 and by adding noise with variance B 2 s . The observed value v s is obtained by scaling the hidden h s and by corrupting it with Gaussian observation noise of variance D 2 s . Solution. By assumption, ξ s is Gaussian. Since we condition on h s-1 , A s h s-1 in (7.19) is a constant, and since B s is a constant too, h s is Gaussian. What we have to show next is that (7.19) defines the same conditional mean and variance as the conditional Gaussian in (7.17): The conditional expectation of h s given h s-1 is E(h s |h s-1 ) = A s h s-1 + E(B s ξ s ) (since we condition on h s-1 ) (S.7.120) = A s h s-1 + B s E(ξ s ) (by linearity of expectation) (S.7.121) = A s h s-1 (since ξ s has zero mean) (S.7.122) The conditional variance of h s given h s-1 is V(h s |h s-1 ) = V(B s ξ s ) (since we condition on h s-1 ) (S.7.123) = B 2 s V(ξ s ) (by properties of the variance) (S.7.124) = B 2 s (since ξ s has variance one) (S.7.125)</p><p>We see that the conditional mean and variance of h s given h s-1 match those in (7.17). And since h s given h s-1 is Gaussian as argued above, the result follows.</p><p>Exactly the same reasoning also applies to the case of (7.20). Conditional on h s , v s is Gaussian because it is an affine transformation of a Gaussian. The conditional mean of v s given h s is:</p><formula xml:id="formula_394">E(v s |h s ) = C s h s + E(D s η s ) (since</formula><p>we condition on h s ) (S.7.126) = C s h s + D s E(η s ) (by linearity of expectation) (S.7.127) = C s h s (since η s has zero mean) (S.7.128) The conditional variance of v s given h s is V(v s |h s ) = V(D s η s ) (since we condition on h s ) (S.7.129) = D 2 s V(η s ) (by properties of the variance) (S.7.130) = D 2 s (since η s has variance one) (S.7.131) Hence, conditional on h s , v s is Gaussian with mean and variance as in (7.18). (b) Show that N (x|µ, σ 2 )N (y|Ax, B 2 )dx ∝ N (y|Aµ, A 2 σ 2 + B 2 ) (7.21)</p><p>Hint: While this result can be obtained by integration, an approach that avoids this is as follows: First note that N (x|µ, σ 2 )N (y|Ax, B 2 ) is proportional to the joint pdf of x and y. We can thus consider the integral to correspond to the computation of the marginal of y from the joint. Using the equivalence of Equations (7.17)-(7.18) and (7.19)-(7.20), and the fact that the weighted sum of two Gaussian random variables is a Gaussian random variable then allows one to obtain the result.</p><p>Solution. We follow the procedure outlined above. The two Gaussian densities correspond to the equations</p><formula xml:id="formula_395">x = µ + σξ (S.</formula><p>7.132) y = Ax + Bη (S.7.133) where ξ and η are independent standard normal random variables. The mean of y is E(y) = AE(x) + BE(η) (S.7.134) = Aµ (S.7.135)</p><p>where we have use the linearity of expectation and E(η) = 0. The variance of y is</p><formula xml:id="formula_396">V(y) = V(Ax) + V(Bη)</formula><p>(since x and η are independent) (S.7.136)</p><formula xml:id="formula_397">= A 2 V(x) + B 2 V(η)</formula><p>(by properties of the variance) (S.7.137)</p><formula xml:id="formula_398">= A 2 σ 2 + B 2 (S.7.138)</formula><p>Since y is the (weighted) sum of two Gaussians, it is Gaussian itself, and hence its distribution is completely defined by its mean and variance, so that y ∼ N (y|Aµ, A 2 σ 2 + B 2 ). (S.7.139)</p><p>Now, the product N (x|µ, σ 2 )N (y|Ax, B 2 ) is proportional to the joint pdf of x and y, so that the integral can be considered to correspond to the marginalisation of x, and hence its result is proportional to the density of y, which is N (y|Aµ, A 2 σ 2 + B 2 ).</p><p>(c) Show that</p><formula xml:id="formula_399">N (x|m 1 , σ 2 1 )N (x|m 2 , σ 2 2 ) ∝ N (x|m 3 , σ 2 3 ) (7.22)</formula><p>where</p><formula xml:id="formula_400">σ 2 3 = 1 σ 2 1 + 1 σ 2 2 -1 = σ 2 1 σ 2 2 σ 2 1 + σ 2 2 (7.23) m 3 = σ 2 3 m 1 σ 2 1 + m 2 σ 2 2 = m 1 + σ 2 1 σ 2 1 + σ 2 2 (m 2 -m 1 ) (7.24)</formula><p>Hint: Work in the negative log domain.</p><p>Solution. We show the result using a classical technique called "completing the square", see e.g. <ref type="url" target="https://en.wikipedia.org/wiki/Completing_the_square">https://en.wikipedia.org/wiki/Completing_the_square</ref>.</p><p>We work in the (negative) log-domain and use that</p><formula xml:id="formula_401">-log N (x|m, σ 2 ) = (x -m) 2 2σ 2 + const (S.7.140) = x 2 2σ 2 -x m σ 2 + m 2 2σ 2 + const (S.7.141) = x 2 2σ 2 -x m σ 2 + const (S.7.142)</formula><p>where const indicates terms not depending on x. We thus obtain</p><formula xml:id="formula_402">-log N (x|m 1 , σ 2 1 )N (x|m 2 , σ 2 2 ) = -log N (x|m 1 , σ 2 1 ) -log N (x|m 2 , σ<label>2</label></formula><p>2 ) (S.7.143)</p><formula xml:id="formula_403">= (x -m 1 ) 2 2σ 2 1 + (x -m 2 ) 2 2σ 2 2 + const (S.7.144) = x 2 2σ 2 1 -x m 1 σ 2 1 + x 2 2σ 2 2 -x m 2 σ 2 2 + const (S.7.145) = x 2 2 1 σ 2 1 + 1 σ 2 2 -x m 1 σ 2 1 + m 2 σ 2 2 + const (S.7.146) = x 2 2σ 2 3 - x σ 2 3 σ 2 3 m 1 σ 2 1 + m 2 σ 2 2</formula><p>+ const, (S.7.147)</p><p>where</p><formula xml:id="formula_404">1 σ 2 3 = 1 σ 2 1 + 1 σ 2 2 .</formula><p>(S.7.148)</p><p>Comparison with (S.7.142) shows that we can further write</p><formula xml:id="formula_405">x 2 2σ 2 3 - x σ 2 3 σ 2 3 m 1 σ 2 1 + m 2 σ 2 2 = (x -m 3 ) 2 2σ 2 3 + const (S.7.149)</formula><p>where</p><formula xml:id="formula_406">m 3 = σ 2 3 m 1 σ 2 1 + m 2 σ 2 2 (S.7.150) so that -log N (x|m 1 , σ 2 1 )N (x|m 2 , σ 2 2 ) = (x -m 3 ) 2 2σ 2 3</formula><p>+ const (S.7.151) and hence</p><formula xml:id="formula_407">N (x|m 1 , σ 2 1 )N (x|m 2 , σ 2 2 ) ∝ N (x|m 3 , σ<label>2</label></formula><p>3 ). (S.7.152)</p><p>Note that the identity</p><formula xml:id="formula_408">m 3 = σ 2 3 m 1 σ 2 1 + m 2 σ 2 2 = m 1 + σ 2 1 σ 2 1 + σ 2 2 (m 2 -m 1 ) (S.7.153)</formula><p>is obtained as follows</p><formula xml:id="formula_409">σ 2 3 m 1 σ 2 1 + m 2 σ 2 2 = σ 2 1 σ 2 2 σ 2 1 + σ 2 2 m 1 σ 2 1 + m 2 σ 2 2 (S.7.154) = m 1 σ 2 2 σ 2 1 + σ 2 2 + m 2 σ 2 1 σ 2 1 + σ 2 2 (S.7.155) = m 1 1 - σ 2 1 σ 2 1 + σ 2 2 + m 2 σ 2 1 σ 2 1 + σ 2 2 (S.7.156) = m 1 + σ 2 1 σ 2 1 + σ 2 2 (m 2 -m 1 ) (S.7.157) (d)</formula><p>We can use the "alpha-recursion" to recursively compute p(h t |v 1:t ) ∝ α(h t ) as follows.</p><formula xml:id="formula_410">α(h 1 ) = p(h 1 ) • p(v 1 |h 1 ) α(h s ) = p(v s |h s ) h s-1 p(h s |h s-1 )α(h s-1 ). (7.25)</formula><p>For continuous random variables, the sum above becomes an integral so that</p><formula xml:id="formula_411">α(h s ) = p(v s |h s ) p(h s |h s-1 )α(h s-1 )dh s-1 . (7.26)</formula><p>For reference, let us denote the integral by I(h s ),</p><formula xml:id="formula_412">I(h s ) = p(h s |h s-1 )α(h s-1 )dh s-1 .<label>(7.27)</label></formula><p>Note that I(h s ) is proportional to the predictive distribution p(h s |v 1:s-1 ).</p><p>For a Gaussian prior distribution for h 1 and Gaussian emission probability p(v 1 |h 1 ), α(h 1 ) = p(h 1 ) • p(v 1 |h 1 ) ∝ p(h 1 |v 1 ) is proportional to a Gaussian. We denote its mean by µ 1 and its variance by σ 2 1 so that α(h 1 ) ∝ N (h 1 |µ 1 , σ 2 1 ).</p><p>(7.28)</p><p>Assuming α(h s-1 ) ∝ N (h s-1 |µ s-1 , σ 2 s-1 ) (which holds for s = 2), use Equation (7.21) to show that</p><formula xml:id="formula_413">I(h s ) ∝ N (h s |A s µ s-1 , P s ) (7.29)</formula><p>where</p><formula xml:id="formula_414">P s = A 2 s σ 2 s-1 + B 2 s .</formula><p>(7.30) Solution. We can set α(h s-1 ) ∝ N (h s-1 |µ s-1 , σ 2 s-1 ). Since p(h s |h s-1 ) is Gaussian, see Equation (7.17), Equation (7.27) becomes</p><formula xml:id="formula_415">I(h s ) ∝ N (h s |A s h s-1 , B 2 s )N (h s-1 |µ s-1 , σ</formula><p>2 s-1 )dh s-1 . (S.7.158) Equation (7.21) with x ≡ h s-1 and y ≡ h s yields the desired result, I(h s ) ∝ N (h s |A s µ s-1 , A 2 s σ 2 s-1 + B 2 s ). (S.7.159) We can understand the equation as follows: To compute the predictive mean of h s given v 1:s-1 , we forward propagate the mean of h s-1 |v 1:s-1 using the update equation (7.19). This gives the mean term A s µ s-1 . Since h s-1 |v 1:s-1 has variance σ 2 s-1 , the variance of h s |v 1:s-1 is given by A 2 s σ 2 s-1 plus an additional term, B 2 s , due to the noise in the forward propagation. This gives the variance term A 2 s σ 2 s-1 + B 2 s . (e) Use Equation (7.22) to show that α(h s ) ∝ N h s |µ s , σ 2 s (7.31) where µ s = A s µ s-1 + P s C s C 2 s P s + D 2 s (v s -C s A s µ s-1 ) (7.32) σ 2 s = P s D 2 s P s C 2 s + D 2 s (7.33) Solution. Having computed I(h s ), the final step in the alpha-recursion is α(h s ) = p(v s |h s )I(h s ) (S.7.160) With Equation (7.18) we obtain α(h s ) ∝ N (v s |C s h s , D 2 s )N (h s |A s µ s-1 , P s ). (S.7.161) We further note that N (v s |C s h s , D 2 s ) ∝ N h s |C -1 s v s , D 2 s C 2 s (S.7.162) so that we can apply Equation (7.22) (with m 1 = Aµ s-1 , σ 2 1 = P s ) α(h s ) ∝ N h s |C -1 s v s , D 2 s C 2 s N (h s |A s µ s-1 , P s ) (S.7.163) ∝ N h s , µ s , σ 2 s (S.7.164) with µ s = A s µ s-1 + P s</p><formula xml:id="formula_416">P s + D 2 s C 2 s C -1 s v s -A s µ s-1 (S.7.165) = A s µ s-1 + P s C 2 s C 2 s P s + D 2 s C -1 s v s -A s µ s-1 (S.7.166) = A s µ s-1 + P s C s C 2 s P s + D 2 s (v s -C s A s µ s-</formula><p>1 ) (S.7.167) σ 2 s = P s D 2 s C 2 s P s + D 2 s C 2 s (S.7.168) = P s D 2 s P s C 2 s + D 2 s (S.7.169) (S.7.170) (f) Show that α(h s ) can be re-written as α(h s ) ∝ N h s |µ s , σ 2 s (7.34) where µ s = A s µ s-1 + K s (v s -C s A s µ s-1 ) (7.35) σ 2 s = (1 -K s C s )P s (7.36) K s = P s C s C 2 s P s + D 2 s (7.37) These are the Kalman filter equations and K s is called the Kalman filter gain. Solution. We start from µ s = A s µ s-1 + P s C s C 2 s P s + D 2 s (v s -C s A s µ s-1 ) , (S.7.171) and see that P s C s C 2 s P s + D 2 s = K s (S.7.172) so that µ s = A s µ s-1 + K s (v s -C s A s µ s-1 ) . (S.7.173) For the variance σ 2 s , we have σ 2 s = P s D 2 s P s C 2 s + D 2 s (S.7.174) = D 2 s P s C 2 s + D 2 s P s (S.7.175) = 1 -P s C 2 s P s C 2 s + D 2 s P s (S.7.176) = (1 -K s C s )P s , (S.7.177) which is the desired result.</p><p>The filtering result generalises to vector valued latents and visibles where the transition and emission distributions in (7.17) and (7.18) become</p><formula xml:id="formula_417">p(h s |h s-1 ) = N (h s |Ah s-1 , Σ Σ Σ h ), (S.7.178) p(v s |h s ) = N (v s |C s h s , Σ Σ Σ v ), (S.7.179)</formula><p>where N () denotes multivariate Gaussian pdfs, e.g.</p><formula xml:id="formula_418">N (v s |C s h s , Σ Σ Σ v ) = 1 | det(2πΣ Σ Σ v )| 1/2 exp - 1 2 (v s -C s h s ) (Σ Σ Σ v ) -1 (v s -C s h s ) .</formula><p>(S.7.180)</p><p>We then have</p><formula xml:id="formula_419">p(h t |v 1:t ) = N (h t |µ µ µ t , Σ Σ Σ t ) (S.7.181)</formula><p>where the posterior mean and variance are recursively computed as</p><formula xml:id="formula_420">µ µ µ s = A s µ µ µ s-1 + K s (v s -C s A s µ µ µ s-1 ) (S.7.182) Σ Σ Σ s = (I -K s C s )P s (S.7.183) P s = A s Σ Σ Σ s-1 A s + Σ Σ Σ h (S.7.184) K s = P s C s C s P s C s + Σ Σ Σ v -1 (S.7.185)</formula><p>and initialised with µ µ µ 1 and Σ Σ Σ 1 equal to the mean and variance of p(h 1 |v 1 ). The matrix K s is then called the Kalman gain matrix.</p><p>The Kalman filter is widely applicable, see e.g. <ref type="url" target="https://en.wikipedia.org/wiki/Kalman_filter">https://en.wikipedia.org/wiki/  Kalman_filter</ref>, and has played a role in historic events such as the moon landing, see e.g. (Grewal and Andrews, 2010).</p><p>An example of the application of the Kalman filter to tracking is shown in Figure <ref type="figure" target="#fig_21">7</ref>.1. (g) Explain Equation (7.35) in non-technical terms. What happens if the variance D 2 s of the observation noise goes to zero?</p><p>Solution. We have already seen that A s µ s-1 is the predictive mean of h s given v 1:s-1 . The term C s A s µ s-1 is thus the predictive mean of v s given the observations so far, v 1:s-1 . The difference v s -C s A s µ s-1 is thus the prediction error of the observable. Since α(h s ) is proportional to p(h s |v 1:s ) and µ s its mean, we thus see that the posterior mean of h s |v 1:s equals the posterior mean of h s |v 1:s-1 , A s µ s-1 , updated by the prediction error of the observable weighted by the Kalman gain.</p><p>For D 2 s → 0, K s → C -1 s and</p><formula xml:id="formula_421">µ s = A s µ s-1 + K s (v s -C s A s µ s-1 ) (S.7.186) = A s µ s-1 + C -1 s (v s -C s A s µ s-1 ) (S.7.187) = A s µ s-1 + C -1 s v s -A s µ s-1 (S.7.188) = C -1 s v s ,<label>(</label></formula><p>S.7.189) so that the posterior mean of p(h s |v 1:s ) is obtained by inverting the observation equation. Moreover, the variance σ 2 s of h s |v 1:s goes to zero so that the value of h s is known precisely and equals C -1 s v s . The posterior is p(µ|D) ∝ L(θ)p(µ; µ 0 , σ 2 0 ) (S.8.25) ∝ N (µ; x, σ 2 /n)N (µ; µ 0 , σ 2 0 ) (S.8.26) so that with (8.4), we have p(µ|D) ∝ N (µ; µ n , σ 2 n ) (S.8.27) σ 2 n = 1 σ 2 /n + 1 σ 2 0 -1 (S.8.28) = σ 2 0 σ 2 /n σ 2 0 + σ 2 /n (S.8.29)</p><formula xml:id="formula_422">µ n = σ 2 n x σ 2 /n + µ 0 σ 2 0 (S.8.30) = 1 σ 2 0 + σ 2 /n σ 2 0 x + (σ 2 /n)µ 0 (S.8.31) = σ 2 0 σ 2 0 + σ 2 /n x + σ 2 /n σ 2 0 + σ 2 /n µ 0 . (S.8.32)</formula><p>As n increases, σ 2 /n goes to zero so that σ 2 n → 0 and µ n → x. This means that with an increasing amount of data, the posterior of the mean tends to be concentrated around the maximum likelihood estimate x.</p><p>From (8.7), we also have that</p><formula xml:id="formula_423">µ n = µ 0 + σ 2 0 σ 2 /n + σ 2 0 (x -µ 0 ),<label>(S.8.33)</label></formula><p>which shows more clearly that the value of µ n lies on a line with end-points µ 0 (for n = 0) and x (for n → ∞). As the amount of data increases, µ n moves form the mean under the prior, µ 0 , to the average of the observed sample, that is the MLE x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Maximum likelihood estimation of probability tables in fully observed directed graphical models of binary variables</head><p>We assume that we are given a parametrised directed graphical model for variables x 1 , . . . , x d ,</p><formula xml:id="formula_424">p(x; θ) = d i=1 p(x i |pa i ; θ i ) x i ∈ {0, 1}<label>(8.8)</label></formula><p>where the conditionals are represented by parametrised probability tables, For example, if pa 3 = {x 1 , x 2 }, p(x 3 |pa 3 ; θ 3 ) is represented as</p><formula xml:id="formula_425">p(x 3 = 1|x 1 , x 2 ; θ 1 3 , . . . , θ 4 3 )) x 1 x 2 θ 1 3 0 0 θ 2 3 1 0 θ 3 3 0 1 θ 4 3 1 1 with θ 3 = (θ 1 3 , θ 2 3 , θ 3 3 , θ<label>4</label></formula><p>3 ), and where the superscripts j of θ j 3 enumerate the different states that the parents can be in.</p><p>(a) Assuming that x i has m i parents, verify that the table parametrisation of p(x i |pa i ; θ i ) is equivalent to writing p(x i |pa i ; θ i ) as</p><formula xml:id="formula_426">p(x i |pa i ; θ i ) = S i s=1 (θ s i ) 1(x i =1,pa i =s) (1 -θ s i ) 1(x i =0,pa i =s) (8.9)</formula><p>where S i = 2 m i is the total number of states/configurations that the parents can be in, and 1(x i = 1, pa i = s) is one if x i = 1 and pa i = s, and zero otherwise.</p><p>Solution. The number of configurations that m binary parents can be in is given by S i . The questions thus boils down to showing that p(</p><formula xml:id="formula_427">x i = 1|pa i = k; θ i ) = θ k i for any state k ∈ {1, . . . , S i } of the parents of x i . Since 1(x i = 1, pa i = s) = 0 unless s = k, we have indeed that p(x i = 1|pa i = k; θ i ) =   s =k (θ s i ) 0 (1 -θ s i ) 0   (θ k i ) 1(x i =1,pa i =k) (1 -θ k i ) 1(x i =0,pa i =k) (S.8.34) = 1 • (θ k i ) 1(x i =1,pa i =k) (1 -θ k i ) 0 (S.8.35) = θ k i .</formula><p>(S.8.36) (b) For iid data D = {x (1) , . . . , x (n) } show that the likelihood can be represented as</p><formula xml:id="formula_428">p(D; θ) = d i=1 S i s=1 (θ s i ) n s x i =1 (1 -θ s i ) n s x i =0 (8.10)</formula><p>where n s x i =1 is the number of times the pattern (x i = 1, pa i = s) occurs in the data D, and equivalently for n s x i =0 .</p><p>Solution. Since the data are iid, we have</p><formula xml:id="formula_429">p(D; θ) = n j=1 p(x (j) ; θ) (S.</formula><p>8.37) (S.8.38) where each term p(x (j) ; θ) factorises as in (8.8), p(x (j) ; θ) = d i=1 p(x (j) i |pa (j) i ; θ i ) (S.8.39) with x (j)</p><p>i denoting the i-th element of x (j) and pa (j)</p><p>i the corresponding parents. The conditionals p(x (j) i |pa (j) i ; θ i ) factorise further according to (8.9), p(x</p><formula xml:id="formula_430">(j) i |pa (j) i ; θ i ) = S i s=1 (θ s i ) 1(x (j) i =1,pa<label>(j)</label></formula><formula xml:id="formula_431">i =s) (1 -θ s i ) 1(x (j) i =0,pa<label>(j)</label></formula><p>i =s) , (S.8.40) so that</p><formula xml:id="formula_432">p(D; θ) = n j=1 d i=1 p(x (j) i |pa (j) i ; θ i ) (S.8.41) = n j=1 d i=1 S i s=1 (θ s i ) 1(x (j) i =1,pa<label>(j)</label></formula><formula xml:id="formula_433">i =s) (1 -θ s i ) 1(x (j) i =0,pa<label>(j)</label></formula><p>i =s)</p><p>(S.8.42)</p><p>Swapping the order of the products so that the product over the data points comes first, we obtain</p><formula xml:id="formula_434">p(D; θ) = d i=1 S i s=1 n j=1 (θ s i ) 1(x (j) i =1,pa<label>(j)</label></formula><formula xml:id="formula_435">i =s) (1 -θ s i ) 1(x (j) i =0,pa<label>(j)</label></formula><p>i =s)</p><p>(S.8.43)</p><p>We next split the product over j into two products, one for all j where x (j) i = 1, and one for all j where x (j)</p><formula xml:id="formula_436">i = 0 p(D; θ) = d i=1 S i s=1 j: x (j) i =1 j: x (j) i =0 (θ s i ) 1(x (j) i =1,pa<label>(j)</label></formula><formula xml:id="formula_437">i =s) (1 -θ s i ) 1(x (j) i =0,pa<label>(j)</label></formula><p>i =s)</p><p>(S.8.44)</p><formula xml:id="formula_438">= d i=1 S i s=1 j: x (j) i =1 (θ s i ) 1(x (j) i =1,pa<label>(j)</label></formula><p>i =s)</p><formula xml:id="formula_439">j: x (j) i =0 (1 -θ s i ) 1(x (j) i =0,pa<label>(j)</label></formula><p>i =s)</p><p>(S.8.45)</p><formula xml:id="formula_440">= d i=1 S i s=1 (θ s i ) n j=1 1(x (j) i =1,pa<label>(j)</label></formula><formula xml:id="formula_441">i =s) (1 -θ s i ) n j=1 1(x (j) i =0,pa<label>(j)</label></formula><p>i =s) (S.8.46)</p><formula xml:id="formula_442">= d i=1 S i s=1 (θ s i ) n s x i =1 (1 -θ s i ) n s x i =0 (S.8.47)</formula><p>where</p><formula xml:id="formula_443">n s x i =1 = n j=1 1(x (j) i = 1, pa<label>(j)</label></formula><formula xml:id="formula_444">i = s) n s x i =0 = n j=1 1(x (j) i = 0, pa<label>(j)</label></formula><formula xml:id="formula_445">i = s) (S.8.48)</formula><p>is the number of times x i = 1 and x i = 0, respectively, with its parents being in state s.</p><p>(c) Show that the log-likelihood decomposes into sums of terms that can be independently optimised, and that each term corresponds to the log-likelihood for a Bernoulli model.</p><p>Solution. The log-likelihood ℓ(θ) equals</p><formula xml:id="formula_446">ℓ(θ) = log p(D; θ) (S.8.49) = log d i=1 S i s=1 (θ s i ) n s x i =1 (1 -θ s i ) n s x i =0 (S.8.50) = d i=1 S i s=1 log (θ s i ) n s x i =1 (1 -θ s i ) n s x i =0 (S.8.51) = d i=1 S i s=1 n s x i =1 log(θ s i ) + n s x i =0 log(1 -θ s i ) (S.8.52)</formula><p>Since the parameters θ s i are not coupled in any way, maximising ℓ(θ) can be achieved by maximising each term ℓ is (θ s i ) individually,</p><formula xml:id="formula_447">ℓ is (θ s i ) = n s x i =1 log(θ s i ) + n s x i =0 log(1 -θ s i ). (S.8.53)</formula><p>Moreover, ℓ is (θ s i ) corresponds to the log-likelihood for a Bernoulli model with success probability θ s i and data with n s x i =1 number of ones and n s x i =0 number of zeros.</p><p>(d) Determine the maximum likelihood estimate θ for the Bernoulli model</p><formula xml:id="formula_448">p(x; θ) = θ x (1 -θ) 1-x , θ ∈ [0, 1], x ∈ {0, 1}<label>(8.11)</label></formula><p>and iid data x 1 , . . . , x n .</p><p>Solution. The log-likelihood function is</p><formula xml:id="formula_449">ℓ(θ) = n i=1 log p(x i ; θ) (S.8.54) = n i=1 x i log(θ) + 1 -x i log(1 -θ). (S.8.55)</formula><p>Since log(θ) and log(1 -θ) do not depend on i, we can pull them outside the sum and the log-likelihood function can be written as There are multiple ways to solve the problem. One option is to determine the unconstrained optimiser and then check whether it satisfies the constraint. The first derivative equals</p><formula xml:id="formula_450">ℓ(θ) = n x=1 log(θ) + n x=0 log(1 -θ) (S.</formula><formula xml:id="formula_451">ℓ (θ) = n x=1 θ - n x=0 1 -θ (S.8.58)</formula><p>and the second derivative is</p><formula xml:id="formula_452">ℓ (θ) = - n x=1 θ 2 - n x=0 (1 -θ) 2 (S.8.59)</formula><p>The reason for this is as follows: Let J(η) = ℓ(g -1 (η)) be the log-likelihood seen as a function of η. Since g and g -1 are invertible, we have that</p><formula xml:id="formula_453">max θ∈[0,1] ℓ(θ) = max η J(η) (S.8.70) argmax θ∈[0,1] ℓ(θ) = g -1 argmax η J(η) .</formula><p>(S.8.71) (e) Returning to the fully observed directed graphical model, conclude that the maximum likelihood estimates are given by</p><formula xml:id="formula_454">θs i = n s x i =1 n s x i =1 + n s x i =0 = n j=1 1(x (j) i = 1, pa<label>(j)</label></formula><formula xml:id="formula_455">i = s) n j=1 1(pa (j) i = s) (8.12)</formula><p>Solution. Given the result from question (c), we can optimise each term ℓ is (θ s i ) separately. Each term formally corresponds to a log-likelihood for a Bernoulli model, so that we can use the results from question (d) to obtain</p><formula xml:id="formula_456">θs i = n s x i =1 n s x i =1 + n s x i =0 . (S.8.72) Since n s x i =1 = n j=1 1(x (j) i = 1, pa<label>(j)</label></formula><p>i = s) and</p><formula xml:id="formula_457">n s x i =1 + n s x i =0 = n j=1 1(x (j) i = 1, pa<label>(j)</label></formula><formula xml:id="formula_458">i = s) + n j=1 1(x (j) i = 0, pa<label>(j)</label></formula><p>i = s) (S.8.73) = n j=1 1(pa (j) i = s), (S.8.74)</p><p>we further have</p><formula xml:id="formula_459">θs i = n j=1 1(x (j) i = 1, pa<label>(j)</label></formula><formula xml:id="formula_460">i = s) n j=1 1(pa (j) i = s) . (S.8.75)</formula><p>Hence, to determine θs i , we first count the number of times the parents of x i are in state s, which gives the denominator, and then among them, count the number of times x i = 1, which gives the numerator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Cancer-asbestos-smoking example: MLE</head><p>Consider the model specified by the DAG a s c</p><p>The distribution of a and s are Bernoulli distributions with parameter (success probability) θ a and θ s , respectively, i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>p(a; θ</head><formula xml:id="formula_461">a ) = θ a a (1 -θ a ) 1-a p(s; θ s ) = θ s s (1 -θ s ) 1-s ,<label>(8.13)</label></formula><p>and the distribution of c given the parents is parametrised as specified in the following table</p><formula xml:id="formula_462">p(c = 1|a, s; θ 1 c , . . . , θ 4 c )) a s θ 1 c 0 0 θ 2 c 1 0 θ 3 c 0 1 θ 4 c 1 1</formula><p>The free parameters of the model are (θ a , θ s , θ 1 c , . . . , θ 4 c ).</p><p>Assume we observe the following iid data (each row is a data point).</p><p>a s c 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 (a) Determine the maximum-likelihood estimates of θ a and θ s Solution. The maximum likelihood estimate (MLE) θa is given by the fraction of times that a is 1 in the data set. Hence θa = 1/5. Similarly, the MLE θs is 2/5.</p><p>(b) Determine the maximum-likelihood estimates of θ 1 c , . . . , θ 4 c .</p><p>Solution. With (S.8.75), we have</p><formula xml:id="formula_463">p(c = 1|a, s) a s θ1 c = 0 0 0 θ2 c = 1/1 1 0 θ3 c = 1/2 0 1 θ4 c not defined 1 1</formula><p>This because, for example, we have two observations where (a, s) = (0, 0), and among them, c = 1 never occurs, so that the MLE for p(c = 1|a, s) is zero.</p><p>This example illustrates some issues with maximum likelihood estimates: We may get extreme probabilities, zero or one, or if the parent configuration does not occur in the observed data, the estimate is undefined.</p><p>where B(α, β) denotes the Beta function and where the Gamma function Γ(t) is defined as</p><formula xml:id="formula_464">Γ(t) = ∞ o f t-1 exp(-f )df (8.17)</formula><p>and satisfies Γ(t + 1) = tΓ(t).</p><p>Hint: It will be useful to represent the partition function in terms of the Beta function.</p><p>Solution. We first write the partition function of p(f ; α, β) in terms of the Beta function</p><formula xml:id="formula_465">Z(α, β) = 1 0 f α-1 (1 -f ) β-1 (S.8.84) = B(α, β). (S.8.85)</formula><p>We then have that the mean E[f ] is given by</p><formula xml:id="formula_466">E[f ] = 1 0 f p(f ; α, β)df (S.8.86) = 1 B(α, β) 1 0 f f α-1 (1 -f ) β-1 df (S.8.87) = 1 B(α, β) 1 0 f α+1-1 (1 -f ) β-1 df (S.8.88) = B(α + 1, β) B(α, β) (S.8.89) = Γ(α + 1)Γ(β) Γ(α + 1 + β) Γ(α + β) Γ(α)Γ(β) (S.8.90) = αΓ(α)Γ(β) (α + β)Γ(α + β) Γ(α + β) Γ(α)Γ(β) (S.8.91) = α α + β (S.8.92)</formula><p>where we have used the definition of the Beta function in terms of the Gamma function and the property Γ(t + 1) = tΓ(t).</p><p>(c) Show that the predictive posterior probability p(x = 1|D) for a new independently observed data point x equals the posterior mean of p(θ|D), which in turn is given by</p><formula xml:id="formula_467">E(θ|D) = α 0 + n x=1 α 0 + β 0 + n . (<label>8</label></formula><p>.18) Solution. We obtain p(x = 1|D) = 1 0 p(x = 1, θ|D)dθ (sum rule) (S.8.93) = 1 0 p(x = 1|θ, D)p(θ|D)dθ (product rule) (S.8.94) = 1 0 p(x = 1|θ)p(θ|D)dθ (x ⊥ ⊥ D|θ) (S.8.95) = 1 0 θp(θ|D)dθ (S.</p><p>8.96) = E[θ|D] (S.8.97) From the previous question we know the mean of a Beta random variable. Since θ ∼ B(θ; α n , β n ), we obtain p(x = 1|D) = E[θ|D] (S.8.98) = α n α n + β n (S.8.99) = α 0 + n x=1 α 0 + n x=1 + β 0 + n x=0 (S.8.100) = α 0 + n x=1 α 0 + β 0 + n (S.8.101) where the last equation follows from the fact that n = n x=0 + n x=1 . Note that for n → ∞, the posterior mean tends to the MLE n x=1 /n. 8.6 Bayesian inference of probability tables in fully observed directed graphical models of binary variables This is the Bayesian analogue of Exercise 8.3 and the notation follows that exercise. We consider the Bayesian model p</p><formula xml:id="formula_468">(x|θ) = d i=1 p(x i |pa i , θ i ) x i ∈ {0, 1}<label>(8.19)</label></formula><formula xml:id="formula_469">p(θ; α 0 , β 0 ) = d i=1 S i s=1 B(θ s i ; α s i,0 , β s i,0 ) (8.20)</formula><p>where p(x i |pa i , θ i ) is defined via (8.9), α 0 is a vector of hyperparameters containing all α s i,0 , β 0 the vector containing all β s i,0 , and as before B denotes the Beta distribution. Under the prior, all parameters are independent.</p><p>(a) For iid data D = {x (1) , . . . , x (n) } show that</p><formula xml:id="formula_470">p(θ|D) = d i=1 S i s=1 B(θ s i , α s i,n , β s i,n ) (8.21)</formula><p>where <ref type="bibr">8.22)</ref> and that the parameters are also independent under the posterior.</p><formula xml:id="formula_471">α s i,n = α s i,0 + n s x i =1 β s i,n = β s i,0 + n s x i =0<label>(</label></formula><p>Solution. We start with p(θ|D) ∝ p(D|θ)p(θ; α 0 , β 0 ). (S.8.102)</p><p>Inserting the expression for p(D|θ) given in (8.10) and the assumed form of the prior gives</p><formula xml:id="formula_472">p(θ|D) ∝ d i=1 S i s=1 (θ s i ) n s x i =1 (1 -θ s i ) n s x i =0 d i=1 S i s=1 B(θ s i ; α s i,0 , β s i,0 ) (S.8.103) ∝ d i=1 S i s=1 (θ s i ) n s x i =1 (1 -θ s i ) n s x i =0 B(θ s i ; α s i,0 , β s i,0 ) (S.8.104) ∝ d i=1 S i s=1 (θ s i ) n s x i =1 (1 -θ s i ) n s x i =0 (θ s i ) α s i,0 -1 (1 -θ s i ) β s i,0 -1 (S.8.105) ∝ d i=1 S i s=1 (θ s i ) α s i,0 +n s x i =1 -1 (1 -θ s i ) β s i,0 +n s x i =0 -1 (S.8.106) ∝ d i=1 S i s=1 B(θ s i ; α s i,0 + n s x i =1 , β s i,0 + n s x i =0 ) (S.8.107)</formula><p>It can be immediately verified that B(θ s i ;</p><formula xml:id="formula_473">α s i,0 + n s x i =1 , β s i,0 + n s x i =0</formula><p>) is proportional to the marginal p(θ s i |D) so that the parameters are independent under the posterior too.</p><p>(b) For a variable x i with parents pa i , compute the posterior predictive probability p(x i = 1|pa i , D)</p><p>Solution. The solution is analogue to the solution for question (c), using the sum rule, independencies, and properties of beta random variables:</p><formula xml:id="formula_474">p(x i = 1|pa i = s, D) = p(x i = 1, θ s i |pa i = s, D)dθ s i (S.8.108) = p(x i = 1|θ s i , pa i = s, D)p(θ s i |pa i = s, D) (S.8.109) = p(x i = 1|θ s i , pa i = s)p(θ s i |D) (S.8.110) = θ s i p(θ s i |D) (S.8.111) = E[θ s i |D)] (S.8.112) (S.8.92) = α s i,n α s i,n + β s i,n (S.8.113) = α s i,0 + n s x i =1 α s i,0 + β s i,0 + n s (S.8.114)</formula><p>where n s = n s x i =0 + n s x i =1 denotes the number of times the parent configuration s occurs in the observed data D. The distribution of a and s are Bernoulli distributions with parameter (success probability) θ a and θ s , respectively, i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.7">Cancer-asbestos-smoking example: Bayesian inference</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>p(a|θ</head><formula xml:id="formula_475">a ) = θ a a (1 -θ a ) 1-a p(s|θ s ) = θ s s (1 -θ s ) 1-s ,<label>(8.23)</label></formula><p>and the distribution of c given the parents is parametrised as specified in the following table</p><formula xml:id="formula_476">p(c = 1|a, s, θ 1 c , . . . , θ 4 c )) a s θ 1 c 0 0 θ 2 c 1 0 θ 3 c 0 1 θ 4 c 1 1</formula><p>We assume that the prior over the parameters of the model, (θ a , θ s , θ 1 c , . . . , θ 4 c ), factorises and is given by beta distributions with hyperparameters α 0 = 1 and β 0 = 1 (same for all parameters). Assume we observe the following iid data (each row is a data point). (1 + 0)/(1 + 1 + 2) = 1/4 0 0</p><formula xml:id="formula_477">(1 + 1)/(1 + 1 + 1) = 2/3 1 0 (1 + 1)/(1 + 1 + 2) = 1/2 0 1 (1 + 0)/(1 + 1) = 1/2 1 1</formula><p>Compared to the MLE solution in Exercise (b) question (b), we see that the estimates are less extreme. This is because they are a combination of the prior knowledge and the observed data. Moreover, when we do not have any data, the posterior equals the prior, unlike for the mle where the estimate is not defined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.8">Learning parameters of a directed graphical model</head><p>We consider the directed graphical model shown below on the left for the four binary variables t, b, s, x, each being either zero or one. Assume that we have observed the data shown in the table on the right. x s t b 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 We assume the (conditional) pmf of s|t, b is specified by the following parametrised probability table:</p><formula xml:id="formula_478">p(s = 1|t, b; θ 1 s , . . . , θ 4 s )) t b θ 1 s 0 0 θ 2 s 1 0 θ 3 s 0 1 θ 4 s 1 1</formula><p>(a) What are the maximum likelihood estimates for p(s = 1|b = 0, t = 0) and p(s = 1|b = 0, t = 1), i.e. the parameters θ 1 s and θ 3 s ?</p><p>the score matching objective function becomes a quadratic form, which can be optimised efficiently (see e.g. Barber, 2012, Appendix A.5.3).</p><p>The set of models above are called the (continuous) exponential family, or also log-linear models because the models are linear in the parameters θ k . Since the exponential family generally includes probability mass functions as well, the qualifier "continuous" may be used to highlight that we are here considering continuous random variables only. The functions F k (x) are assumed to be known (they are called the sufficient statistics).</p><p>(a) Denote by K(x) the matrix with elements K kj (x),</p><formula xml:id="formula_479">K kj (x) = ∂F k (x) ∂x j , k = 1 . . . K, j = 1 . . . m,<label>(8.34)</label></formula><p>and by H(x) the matrix with elements H kj (x),</p><formula xml:id="formula_480">H kj (x) = ∂ 2 F k (x) ∂x 2 j , k = 1 . . . K, j = 1 . . . m. (8.35)</formula><p>Furthermore, let h j (x) = (H 1j (x), . . . , H Kj (x)) be the j-th column vector of H(x).</p><p>Show that for the continuous exponential family, the score matching objective in Equation (8.32) becomes</p><formula xml:id="formula_481">J(θ) = θ r + 1 2 θ Mθ,<label>(8.36)</label></formula><p>where the first derivative with respect to x j , the j-th element of x, is</p><formula xml:id="formula_482">r = 1 n n i=1 m j=1 h j (x i ), M = 1 n n i=1 K(x i )K(x i ) . (<label>8</label></formula><formula xml:id="formula_483">ψ j (x; θ) = ∂ log p(x; θ) ∂x j (S.8.155) = K k=1 θ k ∂F k (x) ∂x j (S.8.156) = K k=1 θ k K kj (x). (S.8.157)</formula><p>The second derivative is</p><formula xml:id="formula_484">∂ j ψ j (x; θ) = ∂ 2 log p(x; θ) ∂x 2 j (S.8.158) = K k=1 θ k ∂ 2 F k (x) ∂x 2 j (S.8.159) = K k=1 θ k H kj (x), (S.8.160)</formula><p>Inserting the expressions into Equation (8.32) gives</p><formula xml:id="formula_485">J(θ) = 1 n n i=1 m j=1 ∂ j ψ j (x i ; θ) + 1 2 ψ j (x i ; θ) 2 (S.8.170) = 1 n n i=1 m j=1 ∂ j ψ j (x i ; θ) + 1 2 1 n n i=1 m j=1 ψ j (x i ; θ) 2 (S.8.171) = 1 n n i=1 m j=1 θ h j (x i ) + 1 2 1 n n i=1 θ K(x i )K(x i ) θ (S.8.172) = θ   1 n n i=1 m j=1 h j (x i )   + 1 2 θ 1 n n i=1 K(x i )K(x i ) θ (S.8.173) = θ r + 1 2 θ Mθ, (S.8.174)</formula><p>which is the desired result.</p><p>(b) The pdf of a zero mean Gaussian parametrised by the variance σ 2 is</p><formula xml:id="formula_486">p(x; σ 2 ) = 1 √ 2πσ 2 exp - x 2 2σ 2 , x ∈ R.<label>(8.38)</label></formula><p>The (multivariate) Gaussian is a member of the exponential family. By comparison with Equation (8.33), we can re-parametrise the statistical model {p(x; σ 2 )} σ 2 and work with</p><formula xml:id="formula_487">p(x; θ) = 1 Z(θ) exp θx 2 , θ &lt; 0, x ∈ R,<label>(8.39)</label></formula><p>instead. The two parametrisations are related by θ = -1/(2σ 2 ). Using the previous result on the (continuous) exponential family, determine the score matching estimate θ, and show that the corresponding σ2 is the same as the maximum likelihood estimate. This result is noteworthy because unlike in maximum likelihood estimation, score matching does not need the partition function Z(θ) for the estimation.</p><p>Solution. By comparison with Equation (8.33), the sufficient statistics F (x) is x 2 .</p><p>We first determine the score matching objective function. For that, we need to determine the quantities r and M in Equation (8.37). Here, both r and M are scalars, and so are the matrices K and H that define r and M. By their definitions, we obtain</p><formula xml:id="formula_488">K(x) = ∂F (x) ∂x = 2x (S.8.175) H(x) = ∂ 2 F (x) ∂x 2 = 2 (S.</formula><p>8.176) r = 2 (S.8.177) M = 1 n n i=1 K(x i ) 2 (S.8.178) = 4m 2 (S.8.179) 9.1 Importance sampling to estimate tail probabilities (based on Robert and Casella, 2010, Exercise 3.5)</p><p>We would like to use importance sampling to compute the probability that a standard Gaussian random variable x takes on a value larger than 5, i.e</p><formula xml:id="formula_489">P(x &gt; 5) = ∞ 5 1 √ 2π exp - x 2 2 dx (9.1)</formula><p>We know that the probability equals</p><formula xml:id="formula_490">P(x &gt; 5) = 1 - 5 -∞ 1 √ 2π exp - x 2 2 dx (9.2) = 1 -Φ(5) (9.3) ≈ 2.87 • 10 -7 (9.4)</formula><p>where Φ(.) is the cumulative distribution function of a standard normal random variable.</p><p>(a) With the indicator function 1 x&gt;5 (x), which equals one if x is larger than 5 and zero otherwise, we can write P(x &gt; 5) in form of the expectation</p><formula xml:id="formula_491">P(x &gt; 5) = E[1 x&gt;5 (x)],<label>(9.5)</label></formula><p>where the expectation is taken with respect to the density N (x; 0, 1) of a standard normal random variable, N (x; 0, 1) = 1 √ 2π exp -x 2 2 . (9.6)</p><p>This suggests that we can approximate P(x &gt; 5) by a Monte Carlo average</p><formula xml:id="formula_492">P(x &gt; 5) ≈ 1 n n i=1 1 x&gt;5 (x i ),</formula><p>x i ∼ N (x; 0, 1). (9.7)</p><p>Explain why this approach does not work well.</p><p>Solution. In this approach, we essentially count how many times the x i are larger than 5. However, we know that the chance that x i &gt; 5 is only 2.87 • 10 -7 . That is, we only get about one value above 5 every 20 million simulations! The approach is thus very sample inefficient.</p><p>(b) Another approach is to use importance sampling with an importance distribution q(x) that is zero for x &lt; 5. We can then write P(x &gt; 5) as</p><formula xml:id="formula_493">P(x &gt; 5) = ∞ 5 1 √ 2π exp - x 2 2 dx (9.8) = ∞ 5 1 √ 2π exp - x 2<label>2</label></formula><p>q(x) q(x) dx (9.9)</p><formula xml:id="formula_494">= E q(x) 1 √ 2π exp - x 2<label>2</label></formula><p>1 q(x) (9.10) and estimate P(x &gt; 5) as a sample average.</p><p>We here use an exponential distribution shifted by 5 to the right. It has pdf q(x) = exp(-(x -5)) if x ≥ 5 0 otherwise (9.11)</p><p>For background on the exponential distribution, see e.g. <ref type="url" target="https://en.wikipedia.org/wiki/Exponential_distribution">https://en.wikipedia.  org/wiki/Exponential_distribution</ref>. Provide a formula that approximates P(x &gt; 5) as a sample average over n samples x i ∼ q(x).</p><p>Solution. The provided equation</p><formula xml:id="formula_495">P(x &gt; 5) = E q(x) 1 √ 2π exp - x 2<label>2</label></formula><p>1 q(x) (S.9.1) can be approximated as a sample average as follows:</p><formula xml:id="formula_496">P(x &gt; 5) ≈ 1 n n i=1 1 √ 2π exp - x 2 i 2 1 q(x i ) (S.9.2) = 1 n n i=1 1 √ 2π exp - x 2 i 2 +</formula><p>x -5 (S.9.3) with x i ∼ q(x). Plot the estimate against the sample size and compare with the ground truth value.</p><p>Solution. The following figure shows the importance sampling estimate as a function of the sample size (numbers do depend on the random seed used). We can see that we can obtain a good estimate with a few hundred samples already.</p><p>Python code is as follows.</p><p>Ihat[k] = mean(w.(x[1:k])); end # plot plt=plot(Ihat, label="approximation"); hline!([p], color=:red, label="ground truth") xlabel!("number of samples")</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Monte Carlo integration and importance sampling</head><p>A standard Cauchy distribution has the density function (pdf)</p><formula xml:id="formula_497">p(x) = 1 π 1 1 + x 2</formula><p>(9.12) with x ∈ R. A friend would like to verify that p(x)dx = 1 but doesn't quite know how to solve the integral analytically. They thus use importance sampling and approximate the integral as</p><formula xml:id="formula_498">p(x)dx ≈ 1 n n i=1 p(x i ) q(x i ) x i ∼ q (9.13)</formula><p>where q is the density of the auxiliary/importance distribution. Your friend chooses a standard normal density for q and produces the following figure:</p><p>The figure shows two independent runs. In each run, your friend computes the approximation with different sample sizes by subsequently including more and more x i in the approximation, so that, for example, the approximation with n = 2000 shares the first 1000 samples with the approximation that uses n = 1000.</p><p>Your friend is puzzled that the two runs give rather different results (which are not equal to one), and also that within each run, the estimate very much depends on the sample size. Explain these findings. The Cauchy pdf has much heavier tails than a Gaussian so that the Gaussian pdf is already "small" when the Cauchy pdf is still "large".</p><p>where p x denotes the pdf of the random variable x (u is here a dummy variable). Note that F x maps the domain of x to the interval [0, 1]. For simplicity, we here assume that F x is invertible.</p><p>For a continuous random variable x with cdf F x show that the random variable y = F x (x) is uniformly distributed on [0, 1].</p><p>Importantly, this implies that for a random variable y which is uniformly distributed on [0, 1], the transformed random variable F -1 x (y) has cdf F x . This gives rise to a method called "inverse transform sampling" to generate n iid samples of a random variable x with cdf F x . Given a target cdf F x , the method consists of:</p><p>• calculating the inverse F -1 x • sampling n iid random variables uniformly distributed on [0, 1]: y (i) ∼ U(0, 1), i = 1, . . . , n.</p><p>• transforming each sample by F -1 x : x (i) = F -1 x (y (i) ), i = 1, . . . , n.</p><p>By construction of the method, the x (i) are n iid samples of x.</p><p>Solution. We start with the cumulative distribution function (cdf) F y for y, F y (β) = P(y ≤ β). (S.9.11) Since F x (x) maps x to [0, 1], F y (β) is zero for β &lt; 0 and one for β &gt; 1. We next consider β ∈ [0, 1].</p><p>Let α be the value of x that F x maps to β, i.e. F x (α) = β, which means α = F -1 x (β). Since F x is a non-decreasing function, we have F y (β) = P(y ≤ β) = P(F x (x) ≤ β) = P(x ≤ F -1</p><p>x (β)) = P(x ≤ α) = F x (α). (S.9.12)</p><p>0 0.2 0.4 0.6 0.8 1 y 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 g(y)</p><p>To generate n iid samples from x, we first generate n iid samples y (i) that are uniformly distributed on [0, 1], and then compute for each F -1 x (y (i) ). The properties of inverse transform sampling guarantee that the x (i) ,</p><formula xml:id="formula_499">x (i) = F -1</formula><p>x (y (i) ), (S.9.44) are independent and Laplace distributed. We can sample from it by sampling a Laplace variable with variance 1 as in Exercise 9.5 and then scaling the sample by √ 2b.</p><p>Rejection sampling then repeats the following steps:</p><p>• Generate x ∼ q(x; b)</p><p>• Accept x with probability f (x) = 1 M p(x) q(x) , i.e. generate u ∼ U (0, 1) and accept x if u ≤ f (x).   for some function g(θ). If d is small, e.g. d ≤ 3, deterministic numerical methods can be used to approximate the integral to high accuracy, see e.g. <ref type="url" target="https://en.wikipedia.org/wiki/Numerical_integration">https://en.wikipedia.org/  wiki/Numerical_integration</ref>. But for higher dimensions, these methods are generally not applicable any more. The expectation, however, can be approximated as a sample average if we have samples θ (i) from p(θ | D):</p><formula xml:id="formula_500">E p(θ|D) [g(θ)] ≈ 1 S S i=1</formula><p>g(θ (i) ) (9.25)</p><p>Note that in MCMC methods, the samples θ (<ref type="foot" target="#foot_0">foot_0</ref>) , . . . , θ (S) used in the above approximation are typically not statistically independent.</p><p>Metropolis-Hastings is an MCMC algorithm that generates samples from a distribution p(θ), where p(θ) can be any distribution on the parameters (and not only posteriors). The algorithm is iterative and at iteration t, it uses:</p><p>• a proposal distribution q(θ; θ (t) ), parametrised by the current state of the Markov chain, i.e. θ (t) ;</p><p>• a function p * (θ), which is proportional to p(θ). In other words, p * (θ) is unnormalised 1 and the normalised density p(θ) is p(θ) = p * (θ) p * (θ)dθ . (9.26) For all tasks in this exercise, we work with a Gaussian proposal distribution q(θ; θ (t) ), whose mean is the previous sample in the Markov chain, and whose variance is 2 . That is, at iteration t of our Metropolis-Hastings algorithm, q(θ; θ (t-1) ) = • p_star: a function on θ that is proportional to the density of interest p(θ);</p><p>• param_init: the initial sample -a value for θ from where the Markov chain starts;</p><p>• num_samples: the number S of samples to generate;</p><p>• vari: the variance 2 for the Gaussian proposal distribution q;</p><p>and return [θ (1) , . . . , θ (S) ] -a list of S samples from p(θ) ∝ p * (θ).  Ideally, the time series covers the whole domain of the target distribution and it is hard to "see" any structure in it so that predicting values of future samples from the current one is difficult. If so, the samples are likely independent from each other and the chain is said to be well "mixed".</p><p>(a) Consider the trace plots in Figure <ref type="figure" target="#fig_53">9</ref>.6: Is the variance vari used in Figure <ref type="figure" target="#fig_53">9</ref>.6b larger or smaller than the value of vari used in Figure <ref type="figure" target="#fig_53">9</ref>.6a? Is vari used in Figure <ref type="figure" target="#fig_53">9</ref>.6c larger or smaller than the value used in Figure <ref type="figure" target="#fig_53">9</ref>.6a?</p><p>In both cases, explain the behaviour of the trace plots in terms of the workings of the Metropolis Hastings algorithm and the effect of the variance vari.</p><p>Solution. MCMC methods are sensitive to different hyperparameters, and we usually need to carefully diagnose the inference results to ensure that our algorithm adequately approximates the target posterior distribution.</p><p>(i) Figure <ref type="figure" target="#fig_53">9</ref>.6b uses a small variance (vari was set to 0.001) . The trace plots show that the samples for β are very highly correlated and evolve very slowly through time. This is because the introduced randomness is quite small compared to the scale of the posterior, thus the proposed sample at each MCMC iteration will be very close to the current sample and hence likely accepted. More mathematical explanation: for a symmetric proposal distribution, the acceptance ratio a becomes a = p * (θ * ) p * (θ) , (S.9.77)</p><p>where θ is the current sample and θ * is the proposed sample. For variances that are small compared to the (squared) scale of the posterior, a is close to one and the proposed sample θ * gets likely accepted. This then gives rise to the slowly changing time series shown in Figure <ref type="figure" target="#fig_53">9</ref>.6b.</p><p>(ii) In Figure <ref type="figure" target="#fig_53">9</ref>.6c, the variance is larger than the reference (vari was set to 50) . The trace plots suggest that many iterations of the algorithm result in the proposed sample being rejected, and thus we end up copying the same sample over and over again. This is because if the random perturbations are large compared to the scale of the posterior, p * (θ * ) may be very different from p * (θ) and a may be very small.</p><p>(b) In Metropolis-Hastings, and MCMC in general, any sample depends on the previously generated sample, and hence the algorithm generates samples that are generally statistically dependent. The effective sample size of a sequence of dependent samples is the number of independent samples that are, in some sense, equivalent to our number of dependent samples. A definition of the effective sample size (ESS) is</p><formula xml:id="formula_501">ESS = S 1 + 2 ∞ k=1 ρ(k) (9.34)</formula><p>where S is the number of dependent samples drawn and ρ(k) the correlation coefficient between two samples in the Markov chain that are k time points apart. We can 10.1 Mean field variational inference I Let L x (q) be the evidence lower bound for the marginal p(x) of a joint pdf/pmf p(x, y), L x (q) = E q(y|x) log p(x, y) q(y|x) .</p><p>(10.1)</p><p>Mean field variational inference assumes that the variational distribution q(y|x) fully factorises, i.e.</p><formula xml:id="formula_502">q(y|x) = d i=1 q i (y i |x),<label>(10.2)</label></formula><p>when y is d-dimensional. An approach to learning the q i for each dimension is to update one at a time while keeping the others fixed. We here derive the corresponding update equations.</p><p>(a) Show that the evidence lower bound L x (q) can be written as L x (q) = E q 1 (y 1 |x) E q(y \1 |x) [log p(x, y)] -d i=1 E q i (y i |x) [log q i (y i |x)] (10.3) where q(y \1 |x) = d i=2 q i (y i |x) is the variational distribution without q 1 (y 1 |x).</p><p>Solution. This follows directly from the definition of the ELBO and the assumed factorisation of q(y|x). We have L x (q) = E q(y|x) log p(x, y) -E q(y|x) log q(y|x) (S.10.1) = E d i=1 q i (y i |x) log p(x, y) -E d i=1 q i (y i |x) d i=1 log q i (y i |x) (S.10.2) = E d i=1 q i (y i |x) log p(x, y) -d i=1 E q i (y i |x) log q i (y i |x) (S.10.3) = E q 1 (y 1 |x) E d i=2 q i (y i |x) log p(x, y) -d i=1 E q i (y i |x) log q i (y i |x) (S.10.4) = E q 1 (y 1 |x) E q(y \1 |x) [log p(x, y)] -d i=1 E q i (y i |x) [log q i (y i |x)] (S.10.5)</p><p>We have here used the linearity of expectation. In case of continuous random variables, for instance, we have q i (y i |x) log q i (y i |x)dy i j =i q j (y j |x)dy j =1 (S.10.8)</p><formula xml:id="formula_503">= d i=1</formula><p>E q i (y i |x) log q i (y i |x) (S.10.9)</p><p>For discrete random variables, the integral is replaced with a sum and leads to the same result.</p><p>(b) Assume that we would like to update q 1 (y 1 |x) and that the variational marginals of the other dimensions are kept fixed. Show that argmax q 1 (y 1 |x) L x (q) = argmin where Z is the normalising constant. Note that variables y 2 , . . . , y d are marginalised out due to the expectation with respect to q(y \1 |x).</p><p>Solution. Starting from L x (q) = E q 1 (y 1 |x) E q(y \1 |x) [log p(x, y)] -d i=1 E q i (y i |x) [log q i (y i |x)] (S.10.10) we drop terms that do not depend on q 1 . We then obtain J(q 1 ) = E q 1 (y 1 |x) E q(y \1 |x) [log p(x, y)] -E q 1 (y 1 |x) [log q 1 (y 1 |x)] (S.10.11) = E q 1 (y 1 |x) log p(y 1 |x) -E q 1 (y 1 |x) [log q 1 (y 1 |x)] + const (S.10.12)</p><p>= E q 1 (y 1 |x) log p(y 1 |x) q 1 (y 1 |x) (S.10.13) = -KL(q 1 (y 1 |x)||p(y 1 |x)) (S.10.14)</p><p>The covariance between y 2 and x is computed in the same way and equals 1 too.</p><p>We thus obtain the covariance matrix Σ Σ Σ, Since x is the sum of three random variables that have the same distribution, it makes intuitive sense that the mean assigns 1/3 of the observed value of x to y 1 and y 2 . Moreover, y 1 and y 2 are negatively corrected since an increase in y 1 must be compensated with a decrease in y 2 .</p><p>Let us now approximate the posterior p(y 1 , y 2 |x) with mean field variational inference. Determine the optimal variational distribution using the method and results from Exercise 10.1. You may use that p(y 1 , y 2 , x) = N ((y 1 , y 2 , x); 0,</p><formula xml:id="formula_504">Σ Σ Σ) Σ Σ Σ =   1 0 1 0 1 1 0 1 3   Σ Σ Σ -1 =   2 1 -1 1 2 -1 -1 -1 1   (10.11)</formula><p>Solution. The mean field assumption means that the variational distribution is assumed to factorise as q(y 1 , y 2 |x) = q 1 (y 1 |x)q 2 (y 2 |x) (S.10.23) From Exercise 10.1, the optimal q 1 (y 1 |x) and q 2 (y 2 |x) satisfy q 1 (y 1 |x) = p(y 1 |x), p(y 1 |x) = 1 Z exp E q 2 (y 2 |x) [log p(y 1 , y 2 , x)] (S.10.24) q 2 (y 2 |x) = p(y 2 |x), p(y 2 |x) = 1 Z exp E q 1 (y 1 |x) [log p(y 1 , y 2 , x)] (S.10.25)</p><p>Note that these are coupled equations: q 2 features in the equation for q 1 via p(y 1 |x), and q 1 features in the equation for q 2 via p(y 2 |x). But we have two equations for two unknowns, which for the Gaussian joint model p(x, y 1 , y 2 ) can be solved in closed form.</p><p>Given the provided equation for p(y 1 , y 2 , x), we have that log p(y 1 , y 2 , x) = -1 2</p><formula xml:id="formula_505">  y 1 y 2 x     2 1 -1 1 2 -1 -1 -1 1    </formula><p>y 1 y 2 x   + const (S.10.26) = -1 2 2y 2 1 + 2y 2 2 + x 2 + 2y 1 y 2 -2y 1 x -2y 2 x + const (S.10.27) We further have E q log N (x i ; λ 2 ) = E q log 1 √ 2πλ 2 exp -x 2 i 2λ 2 (S.10.53) = log 1 √ 2πλ 2 -E q x 2 i 2λ 2 (S.10.54) = -log λ -λ 2 2λ 2 + const (S.10.55) = -log λ -1 2 + const (S.10.56) = -log λ + const (S.10.57)</p><p>where we have used that for zero mean x i , E q [x 2 i ] = V(x i ) = λ 2 . We similarly obtain </p><formula xml:id="formula_506">E q log N (x i ; σ 2 i ) = E q log   1 2πσ 2 i exp - x 2</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2 Optimisation 2 . 1</head><label>221</label><figDesc>-Schmidt orthogonalisation . . . . . . . . . . . . . . . . . . . . . . . . 1.2 Linear transforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3 Eigenvalue decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.4 Trace, determinants and eigenvalues . . . . . . . . . . . . . . . . . . . . . . 1.5 Eigenvalue decomposition for symmetric matrices . . . . . . . . . . . . . . . 1.6 Power method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Gradient of vector-valued functions . . . . . . . . . . . . . . . . . . . . . . . 2.2 Newton's method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.3 Gradient of matrix-valued functions . . . . . . . . . . . . . . . . . . . . . . . 2.4 Gradient of the log-determinant . . . . . . . . . . . . . . . . . . . . . . . . . 2.5 Descent directions for matrix-valued functions . . . . . . . . . . . . . . . . . 3 Directed Graphical Models 3.1 Directed graph concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2 Canonical connections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3 Ordered and local Markov properties, d-separation . . . . . . . . . . . . . . 3.4 More on ordered and local Markov properties, d-separation . . . . . . . . . 3.5 Chest clinic (based on Barber, 2012, Exercise 3.3) . . . . . . . . . . . . . . . . 3.6 More on the chest clinic (based on Barber, 2012, Exercise 3.3) . . . . . . . . . 3.7 Hidden Markov models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . -Schmidt orthogonalisation . . . . . . . . . . . . . . . . . . 1.2 Linear transforms . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3 Eigenvalue decomposition . . . . . . . . . . . . . . . . . . . . . . 1.4 Trace, determinants and eigenvalues . . . . . . . . . . . . . . . . 1.5 Eigenvalue decomposition for symmetric matrices . . . . . . . . 1.6 Power method . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>=</head><figDesc>|∆ 1 ∆ 2 a 11 a 22 -∆ 1 ∆ 2 a 12 a 21 | (S.1.45) = |∆ 1 ∆ 2 (a 11 a 22 -a 12 a 21 )| (S.1.46) = ∆ 1 ∆ 2 | det A| (S.1.47) Therefore the area of U y is the area of U x times | det A|. (d) Give an intuitive explanation why we have equality in the change of variables formula Uy f (y)dy = Ux f (Ax)| det A|dx.(1.6)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc>(a) Use Exercise 1.3 to show that tr(A) = i A ii = i λ i . (You can use tr(AB) = tr(BA).) Solution. Since tr(AB) = tr(BA and A = UΛU -1 tr(A) = tr(UΛU -1 ) (S.1.67) = tr(ΛU -1 U) Use Exercise 1.3 to show that det A = i λ i . (Use det A -1 = 1/(det A) and det(AB) = det(A) det(B) for any A and B.) Solution. We use the eigenvalue decomposition of A to obtain det(A) = det(UΛU -1 ) (S.1.71) = det(U) det(Λ) det(U -1 ) (S.1.72)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>.10) where ||v k+1 || 2 denotes the Euclidean norm. (a) Let U the matrix with the (orthonormal) eigenvectors u i of Σ Σ Σ as columns. What is the eigenvalue decomposition of the covariance matrix Σ Σ Σ? Solution. Since the columns of U are orthonormal (eigen)vectors, U is orthogonal, i.e. U -1 = U . With Exercise 1.3 and Exercise 1.5, we obtain Σ Σ Σ = UΛU , (S.1.87)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><figDesc>2.84) (c) Write J(W) in terms of the eigenvalues λ n and calculate ∇J(W). Solution. In Exercise 1.4, we have shown that det(W) = i λ i and hence |det(W )| = i |λ i |.(i) If W is positive definite, its eigenvalues are positive and we can drop the absolute values so that | det(W )| = i λ i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>( c )</head><label>c</label><figDesc>What are the descendants of z? Solution. desc(z) = {q, e, h} (d) What are the non-descendants of q?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 . 1 :</head><label>31</label><figDesc>Figure 3.1: The three canonical connections in DAGs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>( c )</head><label>c</label><figDesc>For the diverging connection, use the ordered Markov property to show that x ⊥ ⊥ y | z. Solution. A topological ordering is z, x, y. The predecessors of y are pre y = {x, z} and its parents pa y = {z}. The ordered Markov property y ⊥ ⊥ (pre y \ pa y ) | pa y (S.3.10) thus becomes again y ⊥ ⊥ x | z, (S.3.11) which is, since the independence relationship is symmetric, the same as x ⊥ ⊥ z | z.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 3 . 2 :</head><label>32</label><figDesc>Figure 3.2: Graphical model for Exercise 3.5 (Barber Figure 3.15).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><figDesc>2. l ⊥ ⊥ b | s Solution. • There are two trails from l to b: (l, s, b) and (l, e, d, b) • The trail (l, s, b) is blocked by s (s is in a tail-tail configuration and part of the conditioning set) • The trail (l, e, d, b) is blocked by the collider configuration for node d. • All trails are blocked so that the independence relation holds. (b) Can we simplify p(l|b, s) to p(l|s)? Solution. Since l ⊥ ⊥ b | s, we have p(l|b, s) = p(l|s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>3. 6</head><label>6</label><figDesc>More on the chest clinic (based on Barber, 2012, Exercise 3.3)Consider the directed graphical model in Figure3.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><figDesc>(x, e, l, s, b) and (x, e, d, b) • Trail (x, e, l, s, b) is blocked by l • Trail (x, e, d, b) is blocked by the collider configuration of node d. • For t, we have the trails (t, e, l, s, b) and (t, e, d, b) • Trail (t, e, l, s, b) is blocked by l. • Trail (t, e, d, b) is blocked by the collider configuration of node d. As all trails are blocked we have x, t ⊥ ⊥ b | l and E[g(x, t) | l, b] = E[g(x, t) | l].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><figDesc>have seen that x ⊥ ⊥ y|z is characterised by p(x, y|z) = p(x|z)p(y|z) or, equivalently, by p(x|y, z) = p(x|z). Show that further equivalent characterisations are p(x, y, z) = p(x|z)p(y|z)p(z) and (3.1) p(x, y, z) = a(x, z)b(y, z) for some non-neg. functions a(x, z) and b(x, z). (3.2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Equation ( 3</head><label>3</label><figDesc>.1) implies (3.2) with a(x, z) = p(x|z) and b(y, z) = p(y|z)p(z). We now show the inverse. Let us assume that p(x, y, z) = a(x, z)b(y, z). By the product rule, we havep(x, y|z)p(z) = a(x,z)b(y, z). (S.3.50) (S.3.51) Summing over y gives y p(x, y|z)p(z) = p(z) y p(x, y|z) (S.3.52) = p(z)p(x|z) of p(x|z) over x equals one we have x a(x, z) = p(z) y b(y, z) . (S.3.57) Now, summing p(x, y|z)p(z) over x yields x p(x, y|z)p(z) = p(z) z)b(y, z) (S.3.60) = b(y, z) x a(x, z) (S.3.61) (S.3.57) = b(y, z) p(z) y b(y, z) (S.3.62) so that p(y|z)p(z) = p(z) b(y, z) y b(y, z) (S.3.63) We thus have p(x, y, z) = a(x, z)b(y, z)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>( a )</head><label>a</label><figDesc>Without using d-separation, show that x ⊥ ⊥ {y, w} | z implies that x ⊥ ⊥ y | z and x ⊥ ⊥ w | z. Hint: use the definition of statistical independence in terms of the factorisation of pmfs/pdfs. Solution. We consider the joint distribution p(x, y, w|z). By assumption p(x, y, w|z) = p(x|z)p(y, w|z) (S.3.68)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><figDesc>w p(y, w|z) is the marginal p(y|z), we have p(x, y|z) = p(x|z)p(y|z), (S.3.72)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><figDesc>x)p(y) (S.3.77) Since p(x, y) = p(x)p(y) we have x ⊥ ⊥ y. For x ⊥ ⊥ y|w, compute p(x, y, w) and use the result x ⊥ ⊥ y|w ⇔ p(x, y, w) = a(x, w)b(y, w). p(x, y, w) = z p(x, y, z, w) (S.3.78) = z p(x)p(y)p(z|x, y)p(w|z) (S.3.79) = p(x) p(y) z p(z|x, y)p(w|z) k(x,y,w) (S.3.80) Since p(x, y, w) cannot be factorised as a(x, w)b(y, w), the relation x ⊥ ⊥ y|w cannot generally hold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Exercises 4. 1</head><label>1</label><figDesc>Visualising and analysing Gibbs distributions via undirected graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2 Factorisation and independencies for undirected graphical models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.3 Factorisation and independencies for undirected graphical models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.4 Factorisation from the Markov blankets I . . . . . . . . . . . . . 4.5 Factorisation from the Markov blankets II . . . . . . . . . . . . 4.6 Undirected graphical model with pairwise potentials . . . . . . 4.7 Restricted Boltzmann machine (based on Barber, 2012, Exercise 4.4) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.8 Hidden Markov models and change of measure . . . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 4 . 1 :</head><label>41</label><figDesc>Figure 4.1: Graph for Exercise 4.2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><figDesc>How do the pdfs/pmfs of the undirected graphical model factorise?Solution. The maximal cliques are (x, w), (w, z), (z, y) and (x, y). The undirected graphical model thus consists of pdfs/pmfs that factorise as follows p(x, w, z, y) ∝ φ 1 (x, w)φ 2 (w, z)φ 3 (z, y)φ 4 (x, y) (S.4.1) (b) List all independencies that hold for the undirected graphical model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>4. 7</head><label>7</label><figDesc>Restricted Boltzmann machine (based on Barber, 2012, Exercise 4.4)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 4 . 2 :</head><label>42</label><figDesc>Figure 4.2: Left: Graph for p(v, h). Right: Graph for p(h|v)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><figDesc>Exercises 5.1 I-equivalence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.2 Minimal I-maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.3 I-equivalence between directed and undirected graphs . . . . . 5.4 Moralisation: Converting DAGs to undirected minimal I-maps 5.5 Moralisation exercise . . . . . . . . . . . . . . . . . . . . . . . . . 5.6 Moralisation exercise . . . . . . . . . . . . . . . . . . . . . . . . . 5.7 Triangulation: Converting undirected graphs to directed minimal I-maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.8 I-maps, minimal I-maps, and I-equivalency . . . . . . . . . . . . 5.9 Limits of directed and undirected graphical models . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><figDesc>(a) Which of three graphs represent the same set of independencies? Explain.To check whether the graphs are I-equivalent, we have to check the skeletons and the immoralities. All have the same skeleton, but graph 1 and graph 2 also have the same immorality. The answer is thus: graph 1 and 2 encode the same independencies.Which of three graphs represent the same set of independencies? Explain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><figDesc>Assume the graph below is a perfect map for a set of independencies U.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 5</head><label>5</label><figDesc>Figure 5.1: Perfect I-map G for Exercise 5.2, question (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 5 . 2 :</head><label>52</label><figDesc>Figure 5.2: Exercise 5.2, Question (a):Construction of a minimal directed I-map for the ordering (e, h, q, z, a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><figDesc>z,e} • MB(e) = {q} (i) Draw the undirected minimal I-map representing the independencies. (ii) Indicate a Gibbs distribution that satisfies the independence relations specified by the Markov blankets.Solution. Connecting each variable to all variables in its Markov blanket yields the desired undirected minimal I-map. Note that the Markov blankets are not mutually disjoint.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>( a )</head><label>a</label><figDesc>Verify that the following two graphs are I-equivalent by listing and comparing the independencies that each graph implies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 5</head><label>5</label><figDesc>Figure 5.3: Answer to Exercise 5.4: Illustrating the moralisation process</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Exercises 6. 1</head><label>1</label><figDesc>Conversion to factor graphs . . . . . . . . . . . . . . . . . . . . . 6.2 Sum-product message passing . . . . . . . . . . . . . . . . . . . . 6.3 Sum-product message passing . . . . . . . . . . . . . . . . . . . . 6.4 Max-sum message passing . . . . . . . . . . . . . . . . . . . . . . 6.5 Choice of elimination order in factor graphs . . . . . . . . . . . 6.6 Choice of elimination order in factor graphs . . . . . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 6 . 1 :</head><label>61</label><figDesc>Figure 6.1: Answer to Exercise 6.2 Question (b): Computing all messages in five clock cycles.If we also computed the messages toward the leaf factor nodes, we needed six cycles, but they are not necessary for computation of the marginals so they are omitted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Exercises 7. 1</head><label>1</label><figDesc>Predictive distributions for hidden Markov models . . . . . . . 7.2 Viterbi algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 7.3 Forward filtering backward sampling for hidden Markov models115 7.4 Prediction exercise . . . . . . . . . . . . . . . . . . . . . . . . . . 7.5 Hidden Markov models and change of measure . . . . . . . . . 7.6 Kalman filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>Figure 7 . 1 : 2 s</head><label>712</label><figDesc>Figure 7.1: Kalman filtering for tracking of a moving object. The blue points indicate the true positions of the object in a two-dimensional space at successive time steps, the green points denote noisy measurements of the positions, and the red crosses indicate the means of the inferred posterior distributions of the positions obtained by running the Kalman filtering equations. The covariances of the inferred positions are indicated by the red ellipses, which correspond to contours having one standard deviation. (Bishop, 2006, Figure 13.22)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_36"><figDesc>x i = 1) and n x=0 = n -n x=1 are the number of ones and zeros in the data. Since θ ∈ [0, 1], we have to solve the constrained optimisation problem</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_40"><figDesc>Consider the model specified by the DAG a s c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_41"><figDesc>Determine the posterior predictive probabilities p(a = 1|D) and p(s = 1|D). Solution. With Exercise 8.5 question (c), we have p(a = 1|D) = E(θ a |D) Determine the posterior predictive probabilities p(c = 1|pa, D) for all possible parent configurations. Solution. The parents of c are (a, s). With Exercise 8.6 question (b), we have p(c = 1|a, s, D) a s</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_42"><figDesc>has tuberculosis b = 1 has bronchitis s = 1 has shortness of breath x = 1 has positive x-ray Observed data:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_43"><figDesc>.37)Solution. For log p(x; θ) = K k=1 θ k F k (x) -log Z(θ)(S.8.154)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_44"><head>( c )</head><label>c</label><figDesc>Numerically compute the importance estimate for various sample sizes n ∈ [0, 1000].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_45"><head>Figure 9 . 1 :</head><label>91</label><figDesc>Figure 9.1: Exercise 9.2. Comparison of the log pdf of a standard normal (blue) and the Cauchy random variable (red) for positive inputs. The Cauchy pdf has much heavier tails than a Gaussian so that the Gaussian pdf is already "small" when the Cauchy pdf is still "large".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_47"><head>9. 6 8 )</head><label>68</label><figDesc>Rejection sampling (based on Robert and Casella, 2010, Exercise 2.Most compute environments provide functions to sample from a standard normal distribution. Popular algorithms include the Box-Muller transform, see e.g. https://en. wikipedia.org/wiki/Box-Muller_transform. We here use rejection sampling to sample from a standard normal distribution with density p(x) using a Laplace distribution as our proposal/auxiliary distribution.The density q(x) of a zero-mean Laplace distribution with variance 2b 2 is q(x; b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_48"><figDesc>(a) Compute the ratio M (b) = max x p(x) q(x;b) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_49"><figDesc>Density represented by 10, 000 samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_50"><head>Figure 9 . 3 :</head><label>93</label><figDesc>Figure 9.3: Density and samples from p(x, y) = N (x; 0, 1)N (y; 0, 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_51"><figDesc>used with this proposal distribution, the algorithm is called Random Walk Metropolis-Hastings algorithm. (a) Read Section 27.4 of Barber (2012) to familiarise yourself with the Metropolis-Hastings algorithm. (b) Write a function mh implementing the Metropolis Hasting algorithm, as given in Algorithm 27.3 in Barber (2012), using the Gaussian proposal distribution in (9.27) above. The function should take as arguments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_52"><figDesc>For example: def mh(p_star, param_init, num_samples=5000, vari=1.0): # your code here return samples Solution. Below is a Python implementation. def mh(p_star, param_init, num_samples=5000, vari=1.0): x = [] x_current = param_init for n in range(num_samples): # proposal x_proposed = multivariate_normal.rvs(mean=x_current, cov=vari) # MH step a = multivariate_normal.pdf(x_current, mean=x_proposed, cov=vari) * p_star(x_proposed) a = a / (multivariate_normal.pdf(x_proposed, mean=x_current, cov= vari) * p_star(x_current)) # accept or not if a &gt;= 1: x_next = np.copy(x_proposed) elif uniform.rvs(0, 1) &lt; a: x_next = np.copy(x_proposed) else: x_next = np.copy(x_current) # keep record x.append(x_next) x_current = x_next through time, i.e. they are a time-series of the samples generated by the Markov chain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_53"><head>Figure 9 .</head><label>9</label><figDesc>6 shows examples of trace plots obtained by running the Metropolis Hastings algorithm for different values of the hyperparameters vari and param_init.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_54"><head>((</head><figDesc>i (y i |x)d i=1 log q i (y i |x) = q 1 (y 1 |x) • . . . • q d (y d |x) d i=1 log q i (y i |x)dy 1 . . . dy d y 1 |x) • . . . • q d (y d |x) log q i (y i |x)dy 1 . . . dy d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_55"><head>q 1</head><label>1</label><figDesc>(y 1 |x) KL(q 1 (y 1 |x)||p(y 1 |x))(10.4) with log p(y 1 |x) = E q(y \1 |x) [log p(x, y)] + const, (10.5)where const refers to terms not depending on y 1 . That is,p(y 1 |x) = 1 Z exp E q(y \1 |x) [log p(x, y)] ,(10.6)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_56"><head>Σ</head><figDesc>The conditional p(y 1 , y 2 |x) is Gaussian with mean m and covariance C,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_57"><head>σ 2 2 (</head><label>2</label><figDesc>x; λ 2 ||p(x)) = -2 log λ + λ 2 Determine the value of λ that minimises J(λ) = KL(q(x; λ 2 )||p(x)). Interpret the result and relate it to properties of the Kullback-Leibler divergence.Solution. Taking derivatives of J(λ) with respect to λ gives S.10.65)</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We here follow the notation of<ref type="bibr" target="#b23">Barber (2012)</ref>; p or φ are often to denote unnormalised models too.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Writing out the sum for x 1 = 0 and x 1 = 1 gives µ φ C →x 1 (0) = x 2 ,x 3 φ C (0, x 2 , x 3 )µ x 2 →φ C (x 2 )µ x 3 →φ C (x 3 ) (S.6.26) =φ C (0, x 2 , x 3 )µ x 2 →φ C (x 2 )µ x 3 →φ C (x 3 ) | (x 2 ,x 3 )=(0,0) + (S.6.27) φ C (0, x 2 , x 3 )µ x 2 →φ C (x 2 )µ x 3 →φ C (x 3 ) | (x 2 ,x 3 )=(1,0) + (S.6.28) φ C (0, x 2 , x 3 )µ x 2 →φ C (x 2 )µ x 3 →φ C (x 3 ) | (x 2 ,x 3 )=(0,1) + (S.6.29) φ C (0, x 2 , x 3 )µ x 2 →φ C (x 2 )µ x 3 →φ C (x 3 ) | (x 2 ,x 3 )=(1,1) (S.6.30) </p><p>x 3 )=(0,0) + (S.6.37)</p><p>x 3 )=(1,0) + (S.6.38)</p><p>x 3 )=(0,1) + (S.6.39) After step 5, variable node x 1 has received all incoming messages and the marginal can be computed.</p><p>In addition to the messages needed for computation of p(x 1 ) one can compute all messages in the graph in five clock cycles, see Figure <ref type="figure">6</ref>.1. This means that all marginals, as well as the joints of those variables sharing a factor node, are available after five clock cycles.</p><p>(c) What is p(x 1 = 1)?</p><p>Solution. We compute the marginal p(x 1 ) as p(x 1 ) ∝ µ φ A →x 1 (x 1 )µ φ C →x 1 (x 1 ) (S.6.47) from a factor graph for p(h 1:n , v 1:n ), we do not need to explicitly sum over all values of h t and h t-1 for normalisation. The definition of the factors in the factor graph together with (S.7.28) shows that we can simply divide by p(v 1:n ). This gives which is the result that we wanted to show.</p><p>We thus obtain the following algorithm to generate samples from p(h 1 , . . . , h n |v 1:n ):</p><p>1. Run the alpha-recursion (filtering) to determine all α(h t ) forward in time for t = 1, . . . , n.</p><p>2. Sample h n from p(h n |v 1:n ) ∝ α(h n )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Go backwards in time using</head><p>to generate samples h t-1 |h t , v 1:n for t = n, . . . , 2.</p><p>This algorithm is known as forward filtering backward sampling (FFBS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Prediction exercise</head><p>Consider a hidden Markov model with three visibles v 1 , v 2 , v 3 and three hidden variables h 1 , h 2 , h 3 which can be represented with the following factor graph:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Hidden Markov models and change of measure</head><p>We take here a change of measure perspective on the alpha-recursion.</p><p>Consider the following directed graph for a hidden Markov model where the y i correspond to observed (visible) variables and the x i to unobserved (hidden/latent) variables.</p><p>The joint model for x = (x 1 , . . . , x n ) and y = (y 1 , . . . , y n ) thus is</p><p>for t = 0, . . . , n. We take the case t = 0 to correspond to p(x 1 , . . . , x n ), This recursion, and some slight generalisations, forms the basis for what is known as the "forward recursion" in particle filtering and sequential Monte Carlo. An excellent introduction to these topics is book (Chopin and Papaspiliopoulos, 2020).</p><p>(d) Use the recursion above to derive the following form of the alpha recursion:</p><p>(7.12)</p><p>(7.13)</p><p>with p 0 (x 1 ) = p(x 1 ).</p><p>The term p t (x t ) corresponds to α(x t ) from the alpha-recursion after normalisation. Moreover, p t-1 (x t ) is the predictive distribution for x t given observations until time t-1. Multiplying p t-1 (x t ) with g t (x t ) gives the new α(x t ). The term g t (x t ) = p(y t |x t ) is sometimes called the "correction" term. We see here that the correction has the effect of a change of measure, changing the predictive distribution p t-1 (x t ) into the filtering distribution p t (x t ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Maximum likelihood estimation for a Gaussian</head><p>The Gaussian pdf parametrised by mean µ and standard deviation σ is given by</p><p>(a) Given iid data D = {x 1 , . . . , x n }, what is the likelihood function L(θ) for the Gaussian model?</p><p>Solution. For iid data, the likelihood function is</p><p>(S.8.3) (b) What is the log-likelihood function ℓ(θ)?</p><p>Solution. Taking the log of the likelihood function gives</p><p>(x i -µ) 2 (S.8.4) (c) Show that the maximum likelihood estimates for the mean µ and standard deviation σ are the sample mean</p><p>and the square root of the sample variance</p><p>Solution. Since the logarithm is strictly monotonically increasing, the maximiser of the log-likelihood equals the maximiser of the likelihood. It is easier to take derivatives for the log-likelihood function than for the likelihood function so that the maximum likelihood estimate is typically determined using the log-likelihood.</p><p>Given the algebraic expression of ℓ(θ), it is simpler to work with the variance v = σ 2 rather than the standard deviation. Since σ &gt; 0 the function v = g(σ) = σ 2 is invertible, and the invariance of the MLE to re-parametrisation guarantees that σ = √ v.</p><p>We now thus maximise the function J(µ, v),</p><p>with respect to µ and v.</p><p>Taking partial derivatives gives</p><p>A necessary condition for optimality is that the partial derivatives are zero. We thus obtain the conditions</p><p>From the first condition it follows that</p><p>x i (S.8.11)</p><p>The second condition thus becomes</p><p>(x i -μ) 2 = 0 (multiply with v 2 and rearrange) (S.8.12)</p><p>We now check that this solution corresponds to a maximum by computing the Hessian matrix</p><p>If the Hessian negative definite at (μ, v), the point is a (local) maximum. Since we only have one critical point, (μ, v), the local maximum is also a global maximum. Taking second derivatives gives</p><p>(S.8.16) Substituting the values for (μ, v) gives</p><p>, (S.8.17) which is negative definite. Note that the the (negative) curvature increases with n, which means that J(µ, v), and hence the log-likelihood becomes more and more peaked as the number of data points n increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Posterior of the mean of a Gaussian with known variance</head><p>Given iid data D = {x 1 , . . . , x n }, compute p(µ|D, σ 2 ) for the Bayesian model</p><p>where σ 2 is a fixed known quantity. Hint: You may use that</p><p>where</p><p>Solution. We re-use the expression for the likelihood L(µ) from Exercise 8.1.</p><p>(S.8.18) which we can write as The second derivative is always negative for θ ∈ (0, 1), which means that ℓ(θ) is strictly concave on (0, 1) and that an optimiser that is not on the boundary corresponds to a maximum. Setting the first derivative to zero gives the condition For n x=1 &lt; n, we have θ ∈ (0, 1) so that the constraint is actually not active.</p><p>In the derivation, we had to exclude boundary cases where θ is 0 or 1. We note that e.g. θ = 1 is obtained when n x=1 = n, i.e. when we only observe 1's in the data set. In that case, n x=0 = 0 and the log-likelihood function equals n log(θ), which is strictly increasing and hence attains the maximum at θ = 1. A similar argument shows that if n x=1 = 0, the maximum is at θ = 0. Hence, the maximum likelihood estimate θ = n x=1 n (S.8.66)</p><p>is valid for all n x=1 ∈ {0, . . . , n}.</p><p>An alternative approach to deal with the constraint is to reparametrise the objective function and work with the log-odds η,</p><p>The log-odds take values in R so that η is unconstrained. The transformation from θ to η is invertible and</p><p>The optimisation problem then becomes</p><p>Computing the second derivative shows that the objective is concave for all η and the maximiser η can be determined by setting the first derivative to zero. The maximum likelihood estimate of θ is then given by θ = exp(η) 1 + exp(η) (S.8.69)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5">Bayesian inference for the Bernoulli model</head><p>Consider the Bayesian model</p><p>where n x=1 denotes the number of ones and n x=0 the number of zeros in the data.</p><p>Solution. This follows from</p><p>and from the expression for the likelihood function of the Bernoulli model, which is</p><p>where n x=1 = n i=1 x i denotes the number of 1's in the data, and</p><p>Inserting the expressions for the likelihood and prior into (S.8.76) gives</p><p>which is the desired result. Since α 0 and β 0 are updated by the counts of ones and zeros in the data, these hyperparameters are also referred to as "pseudo-counts". Alternatively, one can think that they are the counts that are observed in another iid data set which has been previously analysed and used to determine the prior.</p><p>(b) Compute the mean of a Beta random variable f ,</p><p>using that</p><p>Solution. The maximum likelihood estimates (MLEs) are equal to the fraction of occurrences of the relevant events.</p><p>Assume each parameter in the table for p(s|t, b) has a uniform prior on (0, 1). Compute the posterior mean of the parameters of p(s = 1|b = 0, t = 0) and p(s = 1|b = 0, t = 1) and explain the difference to the maximum likelihood estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution.</head><p>A uniform prior corresponds to a Beta distribution with hyperparameters α 0 = β 0 = 1. With Exercise 8.6 question (b), we have</p><p>Compared to the MLE, the posterior mean is less extreme. It can be considered a "smoothed out" or regularised estimate, where α 0 &gt; 0 and β 0 &gt; 0 provides regularisation (see <ref type="url" target="https://en.wikipedia.org/wiki/Additive_smoothing">https://en.wikipedia.org/wiki/Additive_smoothing</ref>). We can see a pull of the parameters towards the prior predictive mean, which equals 1/2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.9">Factor analysis</head><p>A friend proposes to improve the factor analysis model by working with correlated latent variables. The proposed model is</p><p>where C is some H × H covariance matrix, F is the D × H matrix with the factor loadings, Ψ Ψ Ψ = diag(Ψ 1 , . . . , Ψ D ), c ∈ R D and the dimension of the latents H is less than the dimension of the visibles D. N (x; µ µ µ, Σ Σ Σ) denotes the pdf of a Gaussian with mean µ µ µ and covariance matrix Σ Σ Σ. The standard factor analysis model is obtained when C is the identity matrix.</p><p>(a) What is marginal distribution of the visibles p(v; θ) where θ stands for the parameters C, F, c, Ψ Ψ Ψ?</p><p>Solution. The model specifications are equivalent to the following data generating process:</p><p>Recall the basic result on the distribution of linear transformations of Gaussians: if</p><p>It thus follows that v is Gaussian with mean µ µ µ and covariance Σ Σ Σ, where Λ = diag(λ 1 , . . . , λ D ) is a diagonal matrix containing the eigenvalues, and E is a orthonormal matrix containing the corresponding eigenvectors. The matrix square root of C is the matrix M such that</p><p>and we denote it by C 1/2 . Show that the matrix square root of C equals </p><p>, so that the extra parameters given by the covariance matrix C are actually redundant and nothing is gained with the richer parametrisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution.</head><p>We verify that the model has the same distribution for the visibles. As before E[v] = c, and the covariance matrix is</p><p>where we have used that C 1/2 is a symmetric matrix. This means that the correlation between the h can be absorbed into the factor matrix F and the set of pdfs defined by the proposed model equals the set of pdfs of the original factor analysis model.</p><p>Another way to see the result is to consider the data generating process and noting that we can sample h from N (h; 0, C) by first sampling h from N (h ; 0, I) and then transforming the sample by</p><p>This follows again from the basic properties of linear transformations of Gaussians, i.e.</p><p>To generate samples from the proposed factor analysis model, we would thus proceed as follows:</p><p>and since h follows N (h ; 0, I), we are back at the original factor analysis model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.10">Independent component analysis</head><p>(a) Whitening corresponds to linearly transforming a random variable x (or the corresponding data) so that the resulting random variable z has an identity covariance matrix, i.e.</p><p>The matrix V is called the whitening matrix. We do not make a distributional assumption on x, in particular x may or may not be Gaussian.</p><p>Given the eigenvalue decomposition C = EΛE , show that</p><p>is a whitening matrix.</p><p>where we have used that E E = I. Since</p><p>we further have</p><p>so that V is indeed a valid whitening matrix. Note that whitening matrices are not unique. For example,</p><p>is also a valid whitening matrix. More generally, if V is a whitening matrix, then RV is also a whitening matrix when R is an orthonormal matrix. This is because</p><p>where we have used that V is a whitening matrix so that Vx has identity covariance matrix.</p><p>(b) Consider the ICA model</p><p>where the matrix A is invertible and the h i are independent random variables of mean zero and variance one. Let V be a whitening matrix for v. Show that z = Vv follows the ICA model</p><p>where Ã is an orthonormal matrix. with Ã = VA. By the whitening operation, the covariance matrix of z is identity, so that</p><p>By the ICA model, V(h) = I, so that Ã must satisfy</p><p>which means that Ã is orthonormal.</p><p>In the original ICA model, the number of parameters is given by the number of elements of the matrix A, which is D 2 if v is D-dimensional. An orthogonal matrix contains D(D -1)/2 degrees of freedom (see e.g. <ref type="url" target="https://en.wikipedia.org/wiki/Orthogonal_matrix">https://en.wikipedia.org/  wiki/Orthogonal_matrix</ref>), so that we can think that whitening "solves half of the ICA problem". Since whitening is a relatively simple standard operation, many algorithms (e.g. "fastICA", Hyvärinen, 1999) first reduce the complexity of the estimation problem by whitening the data. Moreover, due to the properties of the orthogonal matrix, the log-likelihood for the ICA model also simplifies for whitened data: The log-likelihood for ICA model without whitening is </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.11">Score matching for the exponential family</head><p>The objective function J(θ) that is minimised in score matching is</p><p>where ψ j is the partial derivative of the log model-pdf log p(x; θ) with respect to the j-th coordinate (slope) and ∂ j ψ j its second partial derivative (curvature). The observed data are denoted by x 1 , . . . , x n and x ∈ R m .</p><p>The goal of this exercise is to show that for statistical models of the form</p><p>which we can write more compactly as</p><p>The score matching objective in Equation (8.32) features the sum j ψ j (x; θ) 2 . The term ψ j (x; θ) 2 equals</p><p>which can be more compactly expressed using matrix notation. Noting that</p><p>we can write</p><p>where we have used that for some matrix A The only parameter value that satisfies the condition is</p><p>The second derivative of J(θ) is</p><p>which is positive (as long as all data points are non-zero). Hence θ is a minimiser.</p><p>From the relation θ = -1/(2σ 2 ), we obtain that the score matching estimate of the variance</p><p>(S.8.187)</p><p>We can obtain the score matching estimate σ2 from θ in this manner for the same reason that we were able to work with transformed parameters in maximum likelihood estimation.</p><p>For zero mean Gaussians, the second moment m 2 is the maximum likelihood estimate of the variance, which shows that the score matching and maximum likelihood estimate are here the same. While the two methods generally yield different estimates, the result also holds for multivariate Gaussians where the score matching estimates also equal the maximum likelihood estimates, see the original article on score matching by Hyvärinen (2005).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.12">Maximum likelihood estimation and unnormalised models</head><p>Consider the Ising model for two binary random variables (x 1 , x 2 ), Solution. The definition of the partition function is</p><p>where have have to sum over (x 1 , x 2 ) ∈ {-1, 1} 2 = {(-1, 1), (1, 1), (1, -1) (-1 -1)}. This gives Assume you observe three data points (x 1 , x 2 ) equal to (-1, -1), (-1, 1), and (1, -1).</p><p>Using the figure, what is the maximum likelihood estimate of θ? Justify your answer.</p><p>Solution. Denoting the i-th observed data point by (x i 1 , x i 2 ), the log-likelihood is</p><p>Inserting the definition of the p(x 1 , x 2 ; θ) yields</p><p>Its derivative with respect to the θ is</p><p>Setting it to zero yields</p><p>An alternative approach is to start with the more general relationship that relates the gradient of the partition function to the gradient of the log unnormalised model. For example, if</p><p>we have</p><p>Setting the derivative to zero gives,</p><p>From the graph, we see that f (θ) takes on the value -1/3 for θ = -1, which is the desired MLE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.13">Parameter estimation for unnormalised models</head><p>Let p(x; A) ∝ exp(-x Ax) be a parametric statistical model for x = (x 1 , . . . , x 100 ), where the parameters are the elements of the matrix A. Assume that A is symmetric and positive semi-definite, i.e. A satisfies x Ax ≥ 0 for all values of x.</p><p>(a) For n iid data points x 1 , . . . , x n , a friend proposes to estimate A by maximising J(A),</p><p>Explain why this procedure cannot give reasonable parameter estimates.</p><p>Solution. We have that x k Ax k ≥ 0 so that exp -x k Ax k ≤ 1. Hence exp -x k Ax k is maximal if the elements of A are zero. This means that J(A) is maximal if A = 0 whatever the observed data, which does not correspond to a meaningful estimation procedure (estimator).</p><p>(b) Explain why maximum likelihood estimation is easy when the x i are real numbers, i.e. x i ∈ R, while typically very difficult when the x i are binary, i.e. x i ∈ {0, 1}.  p(x i ) q(x i ) (S.9.4) is unbiased by construction, we have to check whether its second moment is finite. Otherwise, we have an invalid estimator that behaves erratically in practice. The ratio w(x) between p(x) and q(x) equals w(x) = p(x) q(x) (S.9.5)</p><p>which can be simplified to</p><p>(S.9.7)</p><p>The second moment of w(x) under q(x) thus is</p><p>The exponential function grows more quickly than any polynomial so that the integral becomes arbitrarily large. Hence, the second moment (and the variance) of În is unbounded, which explains the erratic behaviour of the curves in the plot.</p><p>A less formal but quicker way to see that, for this problem, a standard normal is a poor choice of an importance distribution is to note that its density decays more quickly than the Cauchy pdf in (9.12), which means that the standard normal pdf is "small" when the Cauchy pdf is still "large" (see Figure <ref type="figure">9</ref>.1). This leads to large variance of the estimate. The overall conclusion is that the integral p(x)dx should not be approximated with importance sampling with a Gaussian importance distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Inverse transform sampling</head><p>The cumulative distribution function (cdf) F x (α) of a (continuous or discrete) random variable x indicates the probability that x takes on values smaller or equal to α, F x (α) = P(x ≤ α). (9.14)</p><p>For continuous random variables, the cdf is defined via the integral</p><p>Since α = F -1 x (β) we obtain</p><p>The cdf F y is thus given by </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4">Sampling from the exponential distribution</head><p>The exponential distribution has the density</p><p>where λ is a parameter of the distribution. Use inverse transform sampling to generate n iid samples from p(x; λ).</p><p>Solution. We first compute the cumulative distribution function. (S.9.17)</p><p>= 1 -exp(-λα) (S.9.18)</p><p>It's inverse is obtained by solving y = 1 -exp(-λx) (S.9.19) for x, which gives:</p><p>exp(-λx) = 1 -y (S.9.20)</p><p>To generate samples x (i) ∼ p(x; λ), we thus first sample y (i) ∼ U (0, 1), and then set</p><p>(S.9.23)</p><p>Inverse transform sampling can be used to generate samples from many standard distributions. For example, it allows one to generate Gaussian random variables from uniformly distributed random variables. The method is called the Box-Muller transform, see e.g. <ref type="url" target="https://en.wikipedia.org/wiki/Box-Muller_transform">https://en.wikipedia.org/wiki/Box-Muller_transform</ref>. How to generate the required samples from the uniform distribution is a research field on its own, see e.g. <ref type="url" target="https://en.wikipedia.org/wiki/Random_number_generation">https://en.wikipedia.org/wiki/Random_number_generation</ref> and (Owen, 2013, Chapter 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.5">Sampling from a Laplace distribution</head><p>A Laplace random variable x of mean zero and variance one has the density p(x)</p><p>Use inverse transform sampling to generate n iid samples from x.</p><p>Solution. The main task is to compute the cumulative distribution function (cdf) F x of x and its inverse. The cdf is by definition</p><p>(S.9.24)</p><p>We first consider the case where α ≤ 0. Since -|u| = u for u ≤ 0, we have</p><p>(S.9.27)</p><p>For α &gt; 0, we have</p><p>where we have used the fact that the pdf has to integrate to one. For values of u &gt; 0, -|u| = -u, so that</p><p>(S.9.32)</p><p>In total, for α ∈ R, we thus have  As the figure suggests, there is a unique inverse to y = F x (α). For y ≤ 1/2, we have</p><p>2y) (S.9.36)</p><p>For y &gt; 1/2, we have</p><p>(S.9.37)</p><p>The function y → g(y) that occurs in the logarithm in both cases is</p><p>(S.9.42)</p><p>It is shown below and can be written more compactly as g(y) = 1 -2|y -1/2|.</p><p>We thus can write the inverse F -1 x (y) of the cdf y = F x (α) as</p><p>(S.9.43) Solution. By the definitions of the pdf p(x) of a standard normal and the pdf q(x; b) of the Laplace distribution, we have</p><p>The ratio is symmetric in x. Moreover, since the exponential function is strictly increasing, we can find the maximiser of -x 2 /2 + x/b for x ≥ 0 to determine the maximiser of M (b). With g(x) = -x 2 /2 + x/b, we have g (x) = -x + 1/b (S.9.47)</p><p>The critical point (for which the first derivative is zero) is x = 1/b and since the second derivative is negative for all x, the point is a maximum. The maximal ratio M (b) thus is Solution. The probability of acceptance is 1/M . Hence to maximise it, we have to choose b such that M (b) is minimal. We compute the derivatives</p><p>)) (S.9.55) (S.9.56)</p><p>Setting the first derivative to zero gives</p><p>))b -2 (S.9.57)</p><p>Hence the optimal b = 1. The second derivative at b = 1 is</p><p>which is positive so that the b = 1 is a minimum. The smallest value of M thus is This means for each sample x generated from q(x; 1), there is chance of 0.76 that it gets accepted. In other words, for each accepted sample, we need to generate 1/0.76 = 1.32 samples from q(x; 1).</p><p>The variance of the Laplace distribution for b = 1 equals 2. Hence the variance of the auxiliary distribution is larger (twice as large) as the variance of the distribution we would like to sample from.</p><p>(c) Assume you sample from p(x 1 , . . . , x d ) = d i=1 p(x i ) using q(x 1 , . . . , x d ) = d i=1 q(x i ; b) as auxiliary distribution without exploiting any independencies. How does the acceptance probability scale as a function of d? You may denote the acceptance probability in case of d = 1 by A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution. We have to determine the maximal ratio</head><p>x 1 ,...,x d p(x 1 , . . . , x d ) q(x 1 , . . . , x d ) (S.9.65)</p><p>Plugging-in the factorisation gives</p><p>(S.9.67)</p><p>Hence, the acceptance probability is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>70)</head><p>Note that A ≤ 1 since it is a probability. This means that, unless A = 1, we have an acceptance probability that decays exponentially in the number of dimensions if the target and auxiliary distributions factorise and we do not exploit the independencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.7">Sampling from a restricted Boltzmann machine</head><p>The restricted Boltzmann machine (RBM) is a model for binary variables v = (v 1 , . . . , v n ) and h = (h 1 , . . . , h m ) which asserts that the joint distribution of (v, h) can be described by the probability mass function</p><p>where W is a n × m matrix, and a and b vectors of size n and m, respectively. Both the v i and h i take values in {0, 1}. The v i are called the "visibles" variables since they are assumed to be observed while the h i are the hidden variables since it is assumed that we cannot measure them.</p><p>Explain how to use Gibbs sampling to generate samples from the marginal p(v),</p><p>for any given values of W, a, and b.</p><p>Hint: You may use that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.22)</head><p>Solution. In order to generate samples v (k) from p(v) we generate samples (v (k) , h (k) ) from p(v, h) and then ignore the h (k) .</p><p>Gibbs sampling is a MCMC method to produce a sequence of samples x (1) , x (2) , x (3) , . . . that follow a pdf/pmf p(x) (if the chain is run long enough). Assuming that x is ddimensional, we generate the next sample x (k+1) in the sequence from the previous sample x (k) by:</p><p>1. picking (randomly) an index i ∈ {1, . . . , d}</p><p>For the RBM, the tuple (h, v) corresponds to x so that a x i in the above steps can either be a hidden variable or a visible. Hence</p><p>(h \i denotes the vector h with element h i removed, and equivalently for v \i )</p><p>To compute the conditionals on the right hand side, we use the hint:</p><p>(S.9.73)</p><p>Given the independencies between the hiddens given the visibles and vice versa, we have</p><p>so that the expressions for p(h i = 1|v) and p(v i = 1|h) allow us to implement the Gibbs sampler.</p><p>Given the independencies, it makes further sense to sample the h and v variables in blocks: first we sample all the h i given v, and then all the v i given the h (or vice versa). This is also known as block Gibbs sampling.</p><p>In summary, given a sample (h (k) , v (k) ), we thus generate the next sample (h (k+1) , v (k+1) ) in the sequence as follows:</p><p>• For all h i , i = 1, . . . , m:</p><p>As final step, after sampling S pairs (h (k) , v (k) ), k = 1, . . . , S, the set of visibles v (k) form samples from the marginal p(v).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.8">Basic Markov chain Monte Carlo inference</head><p>This exercise is on sampling and approximate inference by Markov chain Monte Carlo (MCMC). MCMC can be used to obtain samples from a probability distribution, e.g. a posterior distribution. The samples approximately represent the distribution, as illustrated in Figure <ref type="figure">9</ref>.3, and can be used to approximate expectations.</p><p>We denote the density of a zero mean Gaussian with variance σ 2 by N (x; µ, σ 2 ), i.e.</p><p>Consider a vector of d random variables θ = (θ 1 , . . . , θ d ) and some observed data D. In many cases, we are interested in computing expectations under the posterior distribution p(θ | D), e.g.</p><p>As we are using a symmetrical proposal distribution, q(θ | θ * ) = q(θ * | θ), and one could simplify the algorithm by having a = p * (θ * ) p * (θ) , where θ is the current sample and θ * is the proposed sample.</p><p>In practice, it is desirable to implement the function in the log domain, to avoid numerical problems. That is, instead of p * , mh will accept as an argument log p * , and a will be calculated as:</p><p>Test your algorithm by sampling 5, 000 samples from p(x, y) = N (x; 0, 1)N (y; 0, 1).</p><p>Initialise at (x = 0, y = 0) and use 2 = 1. Generate a scatter plot of the obtained samples. The plot should be similar to Figure <ref type="figure">9</ref>.3b. Highlight the first 20 samples only. Do these 20 samples alone adequately approximate the true density?</p><p>Sample another 5, 000 points from p(x, y) = N (x; 0, 1)N (y; 0, 1) using mh with 2 = 1, but this time initialise at (x = 7, y = 7). Generate a scatter plot of the drawn samples and highlight the first 20 samples. If everything went as expected, your plot probably shows a "trail" of samples, starting at (x = 7, y = 7) and slowly approaching the region of space where most of the probability mass is. Solution. Figure <ref type="figure">9</ref>.4 shows the two scatter plots of draws from N (x; 0, 1)N (y; 0, 1):</p><p>• Figure <ref type="figure">9</ref>.4a highlights the first 20 samples obtained by the chain when starting at (x = 0, y = 0). They appear to be representative samples from the distribution, however, they are not enough to approximate the distribution on their own. This would mean that a sample average computed with 20 samples only would have high variance, i.e. its value would depend strongly on the values of the 20 samples used to compute the average.</p><p>• Figure <ref type="figure">9</ref>.4b highlights the first 20 samples obtained by the chain when starting at (x = 7, y = 7). One can clearly see the "burn-in" tail which slowly approaches the region where most of the probability mass is.</p><p>(d) In practice, we don't know where the distribution we wish to sample from has high density, so we typically initialise the Markov Chain somewhat arbitrarily, or at the maximum a-posterior (MAP) sample if available. The samples obtained in the beginning of the chain are typically discarded, as they are not considered to be representative of the target distribution. This initial period between initialisation and starting to collect samples is called "warm-up", or also "burn-in".</p><p>Extended your function mh to include an additional warm-up argument W , which specifies the number of MCMC steps taken before starting to collect samples. Your function should still return a list of S samples as in (b).</p><p>Solution. We can extend the mh function with a warm-up argument by, for example, iterating for num_samples + warmup steps, and start recording samples only after the warm-up period: • param_init = (α init , β init ) = (0, 0),</p><p>• vari = 1, and</p><p>• number of warm-up steps W = 1000.</p><p>Plot the drawn samples with x-axis α and y-axis β and report the posterior mean of α and β, as well as their correlation coefficient under the posterior. A scatter plot showing 5, 000 samples from the posterior is shown on Figure <ref type="figure">9</ref>.5. The posterior mean of α is 0.84, the posterior mean of β is -0.2, and posterior correlation coefficient is -0.63. Note that the numerical values are sample-specific.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.10">Mixing and convergence of Metropolis-Hasting MCMC</head><p>Under weak conditions, an MCMC algorithm is an asymptotically exact inference algorithm, meaning that if it is run forever, it will generate samples that correspond to the desired probability distribution. In this case, the chain is said to converge.</p><p>In practice, we want to run the algorithm long enough to be able to approximate the posterior adequately. How long is long enough for the chain to converge varies drastically depending on the algorithm, the hyperparameters (e.g. the variance vari), and the target posterior distribution. It is impossible to determine exactly whether the chain has run long enough, but there exist various diagnostics that can help us determine if we can "trust" the sample-based approximation to the posterior.</p><p>A very quick and common way of assessing convergence of the Markov chain is to visually inspect the trace plots for each parameter. A trace plot shows how the drawn samples evolve  see that if the samples are strongly correlated, ∞ k=1 ρ(k) is large and the effective sample size is small. On the other hand, if ρ(k) = 0 for all k, the effective sample size is S.</p><p>ESS, as defined above, is the number of independent samples which are needed to obtain a sample average that has the same variance as the sample average computed from correlated samples.</p><p>To illustrate how correlation between samples is related to a reduction of sample size, consider two pairs of samples (θ 1 , θ 2 ) and (ω 1 , ω 2 ). All variables have variance σ 2 and the same mean µ, but ω 1 and ω 1 are uncorrelated while the covariance matrix for θ 1 , θ 2 is C,</p><p>with ρ &gt; 0. The variance of the average ω = 0.5(ω 1 + ω 2 ) is</p><p>where the 2 in the denominator is the sample size.</p><p>Derive an equation for the variance of θ = 0.5(θ 1 + θ 2 ) and compute the reduction α of the sample size when working with the correlated (θ 1 , θ 2 ). In other words, derive an equation of α in</p><p>What is the effective sample size 2/α as ρ → 1?</p><p>Solution. Note that E( θ) = µ. From the definition of variance, we then have </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hence argmax</head><p>q 1 (y 1 |x) L x (q) = argmin q 1 (y 1 |x) KL(q 1 (y 1 |x)||p(y 1 |x)) (S.10.15) (c) Conclude that given q i (y i |x), i = 2, . . . , d, the optimal q 1 (y 1 |x) equals p(y 1 |x).</p><p>This then leads to an iterative updating scheme where we cycle through the different dimensions, each time updating the corresponding marginal variational distribution according to:</p><p>where q(y \i |x) = j =i q(y j |x) is the product of all marginals without marginal q i (y i |x).</p><p>Solution. This follows immediately from the fact that the KL divergence is minimised when q 1 (y 1 |x) = p(y 1 |x). Side-note: The iterative update rule can be considered to be coordinate ascent optimisation in function space, where each "coordinate" corresponds to a q i (y i |x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.2">Mean field variational inference II</head><p>Assume random variables y 1 , y 2 , x are generated according to the following process y 1 ∼ N (y 1 ; 0, 1) y 2 ∼ N (y 2 ; 0, 1) (10.8)</p><p>n ∼ N (n; 0, 1) x = y 1 + y 2 + n (10.9)</p><p>where y 1 , y 2 , n are statistically independent.</p><p>(a) y 1 , y 2 , x are jointly Gaussian. Determine their mean and their covariance matrix.</p><p>Solution. The expected value of y 1 and y 2 is zero. By linearity of expectation, the expected value of x is</p><p>The variance of y 1 and y 2 is 1. Since y 1 , y 2 , n are statistically independent,</p><p>(S.10.17)</p><p>The covariance between y 1 and x is cov(y Note that an arbitrary Gaussian density N (y; m, σ 2 ) with mean m and variance σ 2 can be written in the log-domain as</p><p>Comparison with (S.10.32) shows that p(y 1 |x), and hence q 1 (y 1 |x), is Gaussian with variance and mean equal to</p><p>Note that we have not made a Gaussianity assumption on q 1 (y 1 |x). The optimal q 1 (y 1 |x) turns out to be Gaussian because the model p(y 1 , y 2 , x) is Gaussian.</p><p>The equation for p(y 2 |x) gives similarly</p><p>where we have absorbed all terms not involving y 2 into the constant. Moreover, we set E q 1 (y 1 |x) [y 1 ] = m 1 . With (S.10.34), this is defines a Gaussian distribution with variance and mean equal to</p><p>Hence the optimal marginal variational distributions q 1 (y 1 |x) and q 2 (y 2 |x) are both Gaussian with variance equal to 1/2. Their means satisfy</p><p>x -m 1 ) (S.10.42)</p><p>These are two equations for two unknowns. We can solve them as follows In summary, we find q 1 (y 1 |x) = N y 1 ; x 3 , 1 2 q 2 (y 2 |x) = N y 2 ; x 3 , 1 2 (S.10.49) and the optimal variational distribution q(y 1 , y 2 |x) = q 1 (y 1 |x)q 2 (y 2 |x) is Gaussian.</p><p>We have made the mean field (independence) assumption but not the Gaussianity assumption. Gaussianity of the variational distribution is a consequence of the Gaussianity of the model p(y 1 , y 2 , x).</p><p>Comparison with the true posterior shows that the mean field variational distribution q(y 1 , y 2 |x) has the same mean but ignores the correlation and underestimates the marginal variances. The true posterior and the mean field approximation are shown in Figure <ref type="figure">10</ref>.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.3">Variational posterior approximation I</head><p>We have seen that maximising the evidence lower bound (ELBO) with respect to the variational distribution q minimises the Kullback-Leibler divergence to the true posterior p. We here assume that q and p are probability density functions so that the Kullback-Leibler divergence between them is defined as KL(q||p) = q(x) log q(x) p(x) dx = E q log q(x) p(x) .</p><p>(10.12) (a) You can here assume that x is one-dimensional so that p and q are univariate densities. Consider the case where p is a bimodal density but the variational densities q are unimodal. Sketch a figure that shows p and a variational distribution q that has been learned by minimising KL(q||p). Explain qualitatively why the sketched q minimises KL(q||p). Explanation: We can divide the domain of p and q into the areas where p is small (zero) and those where p has significant mass. Since the objective features q in the numerator while p is in the denominator, an optimal q needs to be zero where p is zero. Otherwise, it would incur a large penalty (division by zero). Since we take the expectation with respect to q, however, regions where p &gt; 0 do not need to be covered by q; cutting them out does not incur a penalty. Hence, optimal unimodal q only cover one peak of the bimodal p. Assume further that the variational density q(x 1 , x 2 ; λ 2 ) is parametrised as q(x 1 , x 2 ; λ 2 ) = 1 2πλ 2 exp -</p><p>where λ 2 is the variational parameter that is learned by minimising KL(q||p). If σ 2 2 is much larger than σ 2 1 , do you expect λ 2 to be closer to σ 2 2 or to σ 2 1 ? Provide an explanation.</p><p>Solution. The learned variational parameter will be closer to σ 2 1 (the smaller of the two σ 2 i ). Explanation: First note that the σ 2 i are the variances along the two different axes, and that λ 2 is the single variance for both x 1 and x 2 . The objective penalises q if it is non-zero where p is zero (see above). The variational parameter λ 2 thus will get adjusted during learning so that the variance of q is close to the smallest of the two σ 2 i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.4">Variational posterior approximation II</head><p>We have seen that maximising the evidence lower bound (ELBO) with respect to the variational distribution minimises the Kullback-Leibler divergence to the true posterior.</p><p>We here investigate the nature of the approximation if the family of variational distributions does not include the true posterior.</p><p>(a) Assume that the true posterior for x = (x 1 , x 2 ) is given by p(x) = N (x 1 ; σ 2 1 )N (x 2 ; σ 2 2 ) (10.15) and that our variational distribution q(x; λ 2 ) is q(x; λ 2 ) = N (x 1 ; λ 2 )N (x 2 ; λ 2 ), (10.16)</p><p>where λ &gt; 0 is the variational parameter. Provide an equation for J(λ) = KL(q(x; λ 2 )||p(x)), (10.17)</p><p>where you can omit additive terms that do not depend on λ.</p><p>Solution. We write KL(q(x; λ 2 )||p(x)) = E q log q(x; λ 2 ) p(x) (S.10.50)</p><p>= E q log q(x; λ 2 ) -E q log p(x) (S.10.51) = E q log N (x 1 ; λ 2 ) + E q log N (x 2 ; λ 2 ) -E q log N (x 1 ; σ 2 1 ) -E q log N (x 2 ; σ is positive for all λ &gt; 0.</p><p>The result has an intuitive explanation: the optimal variance λ 2 is the harmonic mean of the variances σ 2 i of the true posterior. In other words, the optimal precision 1/λ 2 is given by the average of the precisions 1/σ 2 i of the two dimensions. If the variances are not equal, e.g. if σ 2 2 &gt; σ 2 1 , we see that the optimal variance of the variational distribution strikes a compromise between two types of penalties in the KL-divergence: the penalty of having a bad fit because the variational distribution along dimension two is too narrow; and along dimension one, the penalty for the variational distribution to be nonzero when p is small.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="middle">. . .</forename><surname>Gaussian</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Posterior of the mean of a Gaussian with known variance</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Maximum likelihood estimation of probability tables in fully observed directed graphical models of binary variables</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">4 Cancer-asbestos-smoking example: MLE . . . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">5 Bayesian inference for the Bernoulli model . . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Bayesian inference of probability tables in fully observed directed graphical models of binary variables</title>
		<author>
			<orgName type="collaboration">. . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Cancer-asbestos-smoking example: Bayesian inference</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Learning parameters of a directed graphical model</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">9 Factor analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">10 Independent component analysis . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">11 Score matching for the exponential family . . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">12 Maximum likelihood estimation and unnormalised models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Solution. For maximum likelihood estimation, we needed to normalise the model by computing the partition function Z(θ), which is defined as the sum/integral of exp(-x Ax) over the domain of x. When the x i are numbers, we can here obtain an analytical expression for Z(θ). However, if the x i are binary</title>
		<author>
			<orgName type="collaboration">13 Parameter estimation for unnormalised models . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
	<note>such analytical expression is available and computing Z(θ) is then very costly</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Can we use score matching instead of maximum likelihood estimation to learn A if the x i are binary? Solution. No, score matching cannot be used for binary data</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Sampling and Monte Carlo Integration Exercises 9.1 Importance sampling to estimate tail probabilities (based on Robert and Casella Exercise 3.5) . . . . . . . . . . . . .</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">Monte Carlo integration and importance sampling . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">3 Inverse transform sampling . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">4 Sampling from the exponential distribution . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">5 Sampling from a Laplace distribution . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Rejection sampling (based on Robert and Casella</title>
		<author>
			<orgName type="collaboration">Exercise 2.8) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Sampling from a restricted Boltzmann machine</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">8 Basic Markov chain Monte Carlo inference . . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">9 Bayesian Poisson regression . . . . . . . . . . . . . . . . . . . .</orgName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">10 Mixing and convergence of Metropolis-Hasting MCMC</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">David</forename><surname>Barber</surname></persName>
		</author>
		<ptr target="http://www.cs.ucl.ac.uk/staff/d.barber/brml/" />
		<title level="m">Bayesian Reasoning and Machine Learning</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<ptr target="https://link.springer.com/book/9780387310732" />
		<title level="m">Pattern Recognition and Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">An introduction to Sequential Monte Carlo</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Chopin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omiros</forename><surname>Papaspiliopoulos</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-47845-2</idno>
		<ptr target="https://link.springer.com/book/10.1007/978-3-030-47845-2" />
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Extending factor graphs so as to unify directed and undirected graphical models</title>
		<author>
			<persName><forename type="first">Brendan</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1212.2486" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>the Nineteenth Conference on Uncertainty in Artificial Intelligence (UAI)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Applications of kalman filtering in aerospace 1960 to the present [historical perspectives]</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mohinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angus</forename><forename type="middle">P</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><surname>Andrews</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/5466132" />
	</analytic>
	<monogr>
		<title level="j">IEEE Control Systems Magazine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="69" to="78" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fast and robust fixed-point algorithms for independent component analysis</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/761722" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="626" to="634" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Estimation of non-normalized statistical models using score matching</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Independent Component Analysis</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erkki</forename><surname>Oja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juha</forename><surname>Karhunen</surname></persName>
		</author>
		<ptr target="https://www.cs.helsinki.fi/u/ahyvarin/papers/bookfinal_ICA.pdf" />
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Numerical Optimization</title>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Monte Carlo theory, methods and examples</title>
		<author>
			<persName><forename type="first">Art</forename><forename type="middle">B</forename><surname>Owen</surname></persName>
		</author>
		<ptr target="https://artowen.su.domains/mc/" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Introducing Monte Carlo Methods with R</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Casella</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4419-1576-4</idno>
		<ptr target="https://link.springer.com/book/10.1007/978-1-4419-1576-4" />
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Walter</forename><surname>Rudin</surname></persName>
		</author>
		<title level="m">Principles of Mathematical Analysis</title>
		<imprint>
			<publisher>McGraw Hill</publisher>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
	<note>3rd edition edition</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
