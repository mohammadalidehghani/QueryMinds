<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data Pricing in Machine Learning Pipelines</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2021-08-18">18 Aug 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zicun</forename><surname>Cong</surname></persName>
							<email>zicuncong@cs.sfu.ca</email>
						</author>
						<author>
							<persName><forename type="first">Xuan</forename><surname>Luo</surname></persName>
							<email>xuanluo@cs.sfu.ca</email>
						</author>
						<author>
							<persName><forename type="first">Pei</forename><surname>Jian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Feida</forename><surname>Zhu</surname></persName>
							<email>fdzhu@smu.edu.sg</email>
						</author>
						<author>
							<persName><forename type="first">Yong</forename><surname>Zhang</surname></persName>
							<email>yong.zhang3@huawei.com</email>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
							<email>jpei@cs.sfu.ca</email>
						</author>
						<author>
							<persName><surname>User</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Simon Fraser University</orgName>
								<address>
									<settlement>Burnaby</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Simon Fraser University</orgName>
								<address>
									<settlement>Burnaby</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Simon Fraser University</orgName>
								<address>
									<settlement>Burnaby</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Singapore Management University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Huawei Technologies Canada</orgName>
								<address>
									<settlement>Burnaby</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data Pricing in Machine Learning Pipelines</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-08-18">18 Aug 2021</date>
						</imprint>
					</monogr>
					<idno type="MD5">AAE217FDD718CAF7A01B2478BD30A843</idno>
					<idno type="arXiv">arXiv:2108.07915v1[cs.LG]</idno>
					<note type="submission">Received: date / Accepted: date</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine learning is disruptive. At the same time, machine learning can only succeed by collaboration among many parties in multiple steps naturally as pipelines in an eco-system, such as collecting data for possible machine learning applications, collaboratively training models by multiple parties and delivering machine learning services to end users. Data is critical and penetrating in the whole machine learning pipelines. As machine learning pipelines involve many parties and, in order to be successful, have to form a constructive and dynamic eco-system, marketplaces and data pricing are fundamental in connecting and facilitating those many parties. In this article, we survey the principles and the latest research development of data pricing in machine learning pipelines. We start with a brief review of data marketplaces and pricing desiderata. Then, we focus on pricing in three important steps in machine learning pipelines. To understand pricing in the step of training data collection, we review pricing raw data sets and data labels. We also investigate pricing in the step of collaborative training of machine learning models, and overview</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The disruptive success of machine learning in many applications has led to an explosion in demand <ref type="bibr" target="#b99">[100,</ref><ref type="bibr" target="#b0">1]</ref>. Recent research predicts that the global machine learning market is expected to reach 20.83 billion dollars in 2024 <ref type="bibr" target="#b64">[64]</ref>.</p><p>To succeed in building a machine learning application, one party is far from enough. Many parties have to collaborate in one way or another. For example, one party may have to acquire raw data and data labeling services from some other parties to construct training data, multiple parties may need to collaborate in building a machine learning model, and one party may want to use some other parties' models to solve its business problems. Machine learning applications are indeed pipelines connecting many parties.</p><p>Data is critical for machine learning. Machine learning models, especially deep models, rely on large amounts of data for training and testing. Deploying machine learning services also needs data -machine learning models consume users' data as input, and return insights and recommend possible actions. Maintaining and updating machine learning models still need data. The importance of data for machine learning cannot be over emphasized. Data penetrates the whole machine learning pipelines.</p><p>Obtaining data for machine learning is far from easy <ref type="bibr" target="#b61">[61]</ref>. For a party that wants to build a machine learning model, the challenges come from multiple aspects. First, within the party, in order to develop a training data set, more often than not it is costly to collect data, create proper labels and ensure data quality. Second, the party may realize that it does not have the necessary data to train the target model. Thus, the party may have to explore external sources for the data needed. This involves acquiring external data. Last, to build or strengthen business edges, the party may want to provide machine learning services to other parties. Then, the party has to exchange data with other parties, such as accessing data from end users and providing end users model output.</p><p>Connecting many parties in an eco-system in scale requires a general and principled mechanism. As data and models are essential in machine learning pipelines and data and model exchanges are the most fundamental interactions among different parties, data and model marketplaces become a natural choice for machine learning pipelines and eco-systems, and pricing becomes the core mechanism in machine learning pipelines.</p><p>In response to the massive and diversified demands for various data, data products become valuable assets for purchase and sale. Here, data products refer to data sets as products and information services derived from data sets <ref type="bibr" target="#b80">[80]</ref>. Data commoditization motivates data owners to share their data Fig. <ref type="figure">1:</ref> Steps and pricing tasks in machine learning pipelines products in exchange of rewards and thus helps data buyers to access data products of high quality and large quantities.</p><p>To enable tradings between data owners and data buyers, data must be priced. Pricing data, however, is far from trivial. Agarwal et al. <ref type="bibr" target="#b0">[1]</ref> summarize five properties making data a unique asset. First, data can be replicated at zero marginal cost. Second, the value of data is inherently combinatorial. Third, the value of data varies widely among different buyers. Last, the usefulness of data lies in the value of information derived from it, which is difficult to verify a priori. Due to those properties, pricing models for physical goods cannot be directly applied or straightforwardly extended to data products, and thus new principles, theories, and methods need to be developed.</p><p>Based on an extensive survey on existing research, we identify and focus on three steps in data and model supply tasks in the manufacturing pipeline of machine learning models <ref type="bibr" target="#b32">[32]</ref>. The steps and their corresponding tasks are illustrated in Figure <ref type="figure">1</ref>. In the step of training data collection, raw data is collected and the associated labels are annotated. We review the research on pricing for raw data sets and data labels. In the step of collaborative training of machine learning models, we investigate how to price different participants' contributions through their data. In the model deployment step, we overview pricing machine learning models for end users. We focus on the four pricing tasks in machine learning pipelines as follows.</p><p>-Pricing raw data sets. To build a machine learning model, the first step is collecting training data. Monetizing and trading raw data sets provide people with a convenient and efficient way to acquire a large amount of training data. A key challenge in pricing raw data sets is how to set the price reflecting the usefulness of a data set. Moreover, pricing models may be optimized towards different objectives, such as revenue maximization, arbitrage-freeness, and truthfulness. Achieving those optimization goals in-troduces additional challenges in the design and implementation of pricing models. -Pricing data labels. In the training data collection step, in addition to collecting raw data, obtaining data labels is critical. Crowdsourcing is a popular way for this purpose <ref type="bibr" target="#b101">[102]</ref>. Unfortunately, spammers may commit no efforts in their assigned tasks and produce random answers, which leads to data sets of poor quality. Thus, a key challenge in pricing data labels is how to estimate label accuracy and compensate crowdworkers correspondingly, such that they are motivated and driven to invest high efforts and report accurate data labels <ref type="bibr" target="#b101">[102]</ref>. This task only appears in machine learning pipelines where supervised machine learning models are produced. -Revenue allocation in collaborative machine learning. Collaborative machine learning is an emerging paradigm, where multiple data owners collaboratively train machine learning models on their aggregate data, and share the revenues of using/selling these models. Data sets from different owners may have different contributions to the learned models. Evenly distributing the revenues is not fair to data owners, particularly for those who contribute more valuable data, and thus may discourage future collaborations. To this end, a key challenge is how to fairly reward data owners' contributions. -Pricing machine learning models. Machine learning as a service (MLaaS) <ref type="bibr" target="#b99">[100,</ref><ref type="bibr" target="#b16">17]</ref> is a rapidly growing industry. Customers may purchase well-trained machine learning models or build models on top of those welltrained rather than building models from scratch by themselves. For example, one may use Google prediction API to classify an image for only $0.0015 <ref type="bibr" target="#b16">[17]</ref>. While machine learning models and raw data sets share a series of common ideas in pricing, the pricing models of raw data sets cannot be trivially adapted to price machine learning models. How to version machine learning models and avoid arbitrage among multiple versions is a key challenge in this task.</p><p>The four tasks are related to each other. They share some core ideas, that is, linking prices of data products to their utilities to customers. But as the tasks have different application scenarios and pricing goals, they are solved by orthogonal techniques.</p><p>The existing models in the first two tasks aim at pricing training data sets with absolute utility functions, that is, the utility of a data product only depends on the properties of the product. One important difference between the first two tasks is about the utility functions. The utility (e.g., accuracy) of data labels is very hard to compute due to the lack of ground-truth verifications. The third task evaluates the utility of a data set by its marginal contribution to a machine learning model. Thus, the utility of a data set also depends on the utility of other data sets used to jointly build the model. The existing methods in the last task also employ absolute utility functions. But as machine learning models and data sets have different properties, new pricing models are developed.</p><p>The four tasks are connected when machine learning models and data sets are priced in an end-to-end manner. On the one hand, the price of a machine learning model limits the budget of training data procurement and the revenue that can be split among data owners <ref type="bibr" target="#b0">[1]</ref>. On the other hand, the costs of data procurement and model training also influence the selling price of machine learning models, as they are part of the manufacturing cost <ref type="bibr" target="#b61">[61]</ref>. Figure <ref type="figure">1</ref> shows the connections of the four tasks.</p><p>There are some previous surveys related to data pricing <ref type="bibr" target="#b58">[58,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b109">110]</ref>. This article covers a substantially deeper and more focused scope than those. In this article, we try to present a comprehensive survey on data pricing in machine learning pipelines. Very recently, Pei <ref type="bibr" target="#b80">[80]</ref> presents a survey connecting economics, digital product pricing, and data product pricing. He identifies a series of desirable properties in data pricing and reviews the techniques achieving those properties. But Pei <ref type="bibr" target="#b80">[80]</ref> does not focus on machine learning pipeline and does not cover the studies of pricing data labels.</p><p>The rest of this survey is organized as follows. Section 2 reviews basic concepts and essential principles in data product pricing. Section 3 reviews pricing raw data sets. Pricing data labels is discussed in Section 4. In Section 5, we review the recent progress in revenue allocation in collaborative machine learning. Section 6 is about how to price machine learning models. We conclude this survey and discuss some future directions in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Marketplaces and Pricing</head><p>In this section, we briefly review data marketplaces and pricing in general. We first discuss the basic structures of data marketplaces. Then, we discuss some major pricing strategies in general. Third, we discuss different types of data markets in terms of competition and dominance. Last, we discuss the desiderata of data pricing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Marketplaces</head><p>A data marketplace is a platform that allows people to buy and sell data products <ref type="bibr" target="#b87">[87]</ref>. Some examples of data marketplaces include Dawex <ref type="bibr" target="#b22">[22]</ref>, Snowflake data marketplace [96], and BDEX <ref type="bibr" target="#b5">[6]</ref>. Muschalle et al. <ref type="bibr" target="#b70">[70]</ref> identify seven categories of participants in data marketplaces, namely analysts, application vendors, data processing algorithm developers, data providers, consultants, licensing and certification entities, and data market owners.</p><p>Figure <ref type="figure" target="#fig_1">2a</ref> shows the conceptual architecture of data marketplaces. A data marketplace mainly consists of three major entities, namely data sellers, an arbiter (also known as data vendor <ref type="bibr" target="#b87">[87]</ref> and data broker <ref type="bibr" target="#b78">[78]</ref>), and data buyers. Data sellers own data products and are willing to share those products with the arbiter in exchange for rewards. Data buyers want to obtain data products to solve their problems. The function of an arbiter is to facilitate transactions  between data sellers and data buyers. The arbiter collects data products from data sellers and sells them to data buyers. After collecting the payments from buyers, the arbiter distributes the payments to data sellers. In general, arbiters are modeled as non-profit participants in data marketplaces. Some studies simplify the architecture of data marketplaces to sell-side marketplaces and buy-side marketplaces. A sell-side marketplace <ref type="bibr" target="#b109">[110]</ref>, as shown in Figure <ref type="figure" target="#fig_1">2b</ref>, has a single data provider and multiple data buyers. In a sell-side marketplace, the arbiter is operated by a monopoly data seller to sell the single seller's data products. In literature, sell-side marketplaces are considered by pricing models of both general data sets <ref type="bibr" target="#b39">[39]</ref> and specific types of data products, such as XML documents <ref type="bibr" target="#b98">[99]</ref> and data queries on a relational database <ref type="bibr" target="#b25">[25]</ref>.</p><p>A buy-side marketplace <ref type="bibr" target="#b109">[110]</ref>, as shown in Figure <ref type="figure" target="#fig_1">2c</ref>, has multiple data providers and a single consumer/data buyer. In a buy-side marketplace, the arbiter is operated by the single data buyer for purchasing data products from providers. Buy-side marketplaces are considered in many existing studies <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b45">45]</ref>. For instance, de Alfaro et al. <ref type="bibr" target="#b1">[2]</ref> study a buy-side marketplace, where a single consumer pays crowdsource workers for labeling the single buyer's data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pricing Strategies</head><p>Many pricing strategies have been developed in pricing theory. Cost-based pricing, customer value-based pricing, and competition-based pricing are three important categories <ref type="bibr" target="#b23">[23]</ref>.</p><p>Cost-based pricing considers that the price of a product is determined by adding a specific amount of markup to the cost. This strategy is adopted in personal data pricing, where the cost is the total privacy compensation to data owners <ref type="bibr" target="#b78">[78]</ref>. A disadvantage of the cost-based pricing strategy is that it only considers internal factors in determining the selling price. External factors, such as competition and demands, are not included <ref type="bibr" target="#b65">[65]</ref>.</p><p>Customer value-based pricing determines the price of a product primarily based on how much the target customers believe a product is worth <ref type="bibr" target="#b23">[23]</ref>. To apply customer value-based pricing, a seller needs to estimate customers' demands for a product through their willingness and affordability <ref type="bibr" target="#b65">[65]</ref>. Customer value-based pricing is the most popularly used strategy for data pricing.</p><p>Competition-based pricing determines the price of a product strategically based on competitors' price levels and behavior expectations <ref type="bibr" target="#b23">[23]</ref>. Game theory provides a powerful tool to implement the strategy. In a non-cooperative game, every seller is selfish and sets the price that maximizes the seller's profit independently <ref type="bibr" target="#b65">[65]</ref>. The competition result, that is the asking price of each seller, is the Nash equilibrium <ref type="bibr" target="#b74">[74]</ref>.</p><p>There are some other major pricing strategies in literature <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b72">72,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b76">76,</ref><ref type="bibr" target="#b44">44]</ref>, such as operation-oriented pricing, revenue-oriented pricing, and relationshiporiented pricing. The remarkably rich body of studies in economics and marketing research on pricing tactics is far beyond the scope and capacity of this survey.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Four Types of Data Markets</head><p>Similar to physical goods, the prices of data products are also influenced by the dominance and diversity of supplies and demands in the market.</p><p>Fricker and Maksimov <ref type="bibr" target="#b31">[31]</ref> identify four types of data markets. First, in a monopoly, a supplier holds enough market power to set prices to maximize profits. Second, in an oligopoly, a small number of suppliers dominate the market. Third, in strong competition markets, individual suppliers do not have enough market powers to set profit-maximizing prices, and prices tend to align with marginal costs. Last, in a monopsony, a single buyer controls the market as the only consumer of products provided by sellers.</p><p>Most studies assume explicitly or implicitly a monopoly (monopsony) market structure where the data seller (data buyer) does not care about competing with others. Data pricing in oligopoly market is considered by Balasubramanian et al. <ref type="bibr" target="#b4">[5]</ref>. Jiang et al. <ref type="bibr" target="#b47">[47]</ref> study a perfect competition market where participants can directly trade with each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Desiderata of Data Pricing</head><p>There are some desiderata perferred by most pricing models. In this section, we briefly review the six desiderata suggested by Pei <ref type="bibr" target="#b80">[80]</ref>. In addition, we complement the existing study by an important desideratum, effort elicitation.</p><p>Truthfulness Truthfulness is an important economic property of robust markets <ref type="bibr" target="#b112">[113]</ref>. In a truthful market, all participants are selfish and only offer prices that maximize their utility values. Participants may have their own valuations on the same product, but a truthful market guarantees that for each participant, offering the real valuation is an individual's best strategy. In other words, no participants will lie about their valuations. Truthfulness simplifies all participants' strategies and ensures basic market fairness <ref type="bibr" target="#b30">[30]</ref>.</p><p>Reverse auction is a common tool to implement truthful data markets. In a reverse auction, N sellers D = {s 1 , . . . , s N } compete for a buyer's deal by submitting their asking prices {b 1 , . . . , b N }. An auction mechanism takes as input the submitted bids, selects a subset of sellers as winners, and determines the payment p i to each winner s i , where p i ≥ b i . In a truthful reverse auction, the best strategy (dominant strategy) for a seller s i to maximize the expected utility is submitting the individual's real valuation, no matter what others submit.</p><p>In his seminal paper on optimal mechanism design, Myerson <ref type="bibr" target="#b71">[71]</ref> shows that a sealed-bid reverse auction mechanism is truthful if and only if <ref type="bibr" target="#b0">(1)</ref> The selection rule is monotone, that is, if a seller s i wins the auction by bidding b i , it also wins by bidding b i ≤ b i ; and (2) Each winner is paid the critical value, that is, seller s i would not win the auction if s i bids higher than this value.</p><p>Revenue Maximization Revenue maximization is a strategy to increase a seller's customer base by having low prices. This strategy is widely adopted by sellers in an emerging market to build market share and reputations. For traditional physical goods, the curves of marginal cost are U-shaped with respect to manufacturing level. The revenue of a seller is maximized when the manufacturing level is set such that the marginal revenue is zero <ref type="bibr" target="#b10">[11]</ref>. Since data products can be re-produced at almost zero costs <ref type="bibr" target="#b0">[1]</ref>, the revenue maximization techniques for data products and physical products are quite different <ref type="bibr" target="#b80">[80]</ref>.</p><p>Fairness In some scenarios, sellers need to cooperatively participate in a transaction. A data market is fair to the contributors in a coalition if the revenue generated by the coalition is fairly divided among the sellers.</p><p>Suppose a set of sellers D = {s 1 , . . . , s N } cooperatively participate in a transaction that leads to a payment v. Shapley <ref type="bibr" target="#b91">[91]</ref> lays out four axioms for a fair allocation.</p><p>-Balance: The payment v should be fully distributed to the sellers in D.</p><p>-Symmetry: Sellers making the same contribution to the payment should be paid the same. For a set of sellers S and two additional sellers s and s , if S ∪ {s} and S ∪ {s } lead to the same payment, sellers s and s should get the same payment. -Zero element: If a seller's data does not contribute to the payment of any coalitions, the seller should receive no payment. -Additivity: If the data of a group of sellers can be used for two tasks t 1 and t 2 with payments v 1 and v 2 , respectively, then the payment to solve both tasks</p><formula xml:id="formula_0">t 1 + t 2 should be v 1 + v 2 .</formula><p>It is proved that Shapley value ψ(s) is the unique allocation method that satisfies the four axioms, which is defined as the average marginal contribution of s i to all possible subsets of sellers S ⊆ D \ {s i }</p><formula xml:id="formula_1">ψ(s) = 1 N S⊆D\{s} U(S ∪ {s}) -U(S) N -1 |S| ,<label>(1)</label></formula><p>where U(•) is the utility function <ref type="bibr" target="#b91">[91]</ref>. For example, in the context of collaborative machine learning, U(S) is the performance score of the machine learning model trained on the data sets of S, such as precision. Equation 1 can be rewritten to</p><formula xml:id="formula_2">ψ(s) = 1 N ! π∈ (D) (U(P π s ∪ {s} -U(P π s ))),<label>(2)</label></formula><p>where π ∈ (D) is a permutation of sellers and P π s is the set of sellers that precede seller s in π.</p><p>The fact that Shapley value uniquely possesses Shapley fairness, combined with its flexibility to support different utility functions, makes it a popular tool to implement fair data marketplaces.</p><p>Arbitrage-free Pricing Arbitrage is the activities that take advantage of price differences between multiple markets. In a data marketplace, a data seller may offer multiple versions of products. As a consequence, a critical concern is that a data buyer may circumvent the advertised price of a product through buying a bundle of cheaper ones, which negatively affects the seller's revenue. For example, consider a data seller selling noisy queries to the seller's database <ref type="bibr" target="#b78">[78,</ref><ref type="bibr" target="#b80">80]</ref>, and the seller perturbs each query answer independently with random noise. An answer with a variance of 5 is sold at $5 and with a variance of 1 is sold at $50. A data buyer wants to obtain an answer of variance 1. The buyer can purchase the cheaper answer 5 times and compute their average. Since the noises are added independently, the aggregated average has variance 1. Thus the customer saves $25 by arbitrage. A desirable pricing function should guarantee that no arbitrage is possible, in which case we call it arbitrage-free.</p><p>Privacy-preservation Privacy protection during the transactions of data raises more and more concerns. In data marketplaces, the privacy of buyers, sellers, and involved third parties are highly vulnerable, and might be disclosed in many different ways <ref type="bibr" target="#b80">[80]</ref>. Many different solutions have been proposed for privacy protection in data markets <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b57">57,</ref><ref type="bibr" target="#b43">43]</ref>. In this survey, we focus on the studies along the line of privacy compensation <ref type="bibr" target="#b57">[57,</ref><ref type="bibr" target="#b78">78,</ref><ref type="bibr" target="#b77">77]</ref>, which investigate how to provide compensations for the privacy disclosure of data owners. For the purpose of privacy protection, sensitive data sets are usually traded with injected random noise <ref type="bibr" target="#b77">[77]</ref>. A data set with less random noise is more accurate, but may leak more privacy and thus more compensations should be made to the data owner.</p><p>Computational Efficiency The numbers of transactions, sellers and buyers may be huge in a data marketplace. Therefore, it is a fundamental requirement for a pricing model to compute prices efficiently with respect to a large number of goods and participants. Prices should be computed in polynomial time with respect to the number of participants <ref type="bibr" target="#b0">[1]</ref> or the number of data products <ref type="bibr" target="#b15">[16]</ref>. In some application scenarios, however, it takes exponential time to compute the pricing functions with desirable properties, such as Shapley fairness <ref type="bibr" target="#b33">[33]</ref>, arbitrage-freeness <ref type="bibr" target="#b53">[53]</ref>, and revenue maximization <ref type="bibr" target="#b15">[16]</ref>. For example, Koutris et al. <ref type="bibr" target="#b53">[53]</ref> show that computing arbitrage-free prices of join queries on a relational database is in general NP-hard. How to efficiently determine prices with desirable properties presents technical challenges.</p><p>Effort Elicitation In addition to the above six desiderata, here we propose a new one, effort elicitation.</p><p>In a data marketplace, a data buyer may purchase training data labels via crowdsourcing. Crowdworkers are presented with unlabeled data instances (for instance, images) and are asked to provide labels (for instance, a binary label indicating whether or not the image contains pedestrains). A major challenge in label collection is to ensure that workers invest their efforts and provide accurate answers. A poorly designed pricing model may result in labels with very low quality <ref type="bibr" target="#b88">[88]</ref>. For example, if each task has a fixed price, an obvious strategy that maximizes a worker's profit is to just provide arbitrary answers without even solving the tasks <ref type="bibr" target="#b101">[102]</ref>. Many techniques have been developed to post-process noisy answers in order to improve their quality. However, when the inputs to these algorithms are highly erroneous, it is difficult to guarantee that the processed answers will be reliable enough for downstream machine learning tasks <ref type="bibr" target="#b88">[88]</ref>. In order to avoid the troubles of "garbage in, garbage out", a desirable approach is to design proper rewards for crowdsourcing tasks that incent workers to invest efforts and provide higher quality answers <ref type="bibr" target="#b101">[102]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Pricing Raw Data Sets</head><p>In this section, we review the existing studies focusing on pricing raw data sets. The existing studies consider four types of scenarios. The most tradi-tional methods price data sets as indivisible units and do not consider supplier competitions. The intrinsic properties of data sets, such as volumes, are factors determining prices. In the second scenario, how to price indivisible data sets in a competitive market is studied. In the third scenario, data consumers can purchase just a fraction of an entire data set, which is more flexible to consumers but may have the issue of arbitrage. The last scenario addresses pricing personal data by privacy compensation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pricing General Data</head><p>Machine learning and statistical models are vulnerable to poor quality training data, thus high quality data is valuable to data buyers <ref type="bibr" target="#b101">[102]</ref>. Pricing data sets based on quality becomes a natural choice.</p><p>Heckman et al. <ref type="bibr" target="#b39">[39]</ref> identify a list of factors to assess the quality of a data set, such as age of data, accuracy of data, and volume of data. A linear model is proposed to set the price of a data set as</p><formula xml:id="formula_3">price = Fixed cost + i w i • factor i .</formula><p>Estimating the model parameters w i is a difficult task, as many data sets may not have public prices associated with them. A more comprehensive list of quality criteria is proposed in <ref type="bibr" target="#b96">[97]</ref>.</p><p>Yu and Zhang <ref type="bibr" target="#b106">[107]</ref> study the problem of trading multiple versions of a data set, constructed by different data quality factors. They assume customers' demands and maximum acceptable prices of different versions are public. A bi-level programming model is established to address the problem. At the first level, the data seller determines versions and their prices to maximize the total revenue. At the second level, a group of buyers select data products to maximize their utilities. Solving the bi-level programming model is NPhard. Yu and Zhang <ref type="bibr" target="#b106">[107]</ref> propose a heuristic genetic algorithm to approach it numerically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pricing Crowdsensing Data</head><p>Crowdsensing is a powerful tool to quickly and cheaply obtain vast amounts of training data for machine learning models <ref type="bibr" target="#b101">[102,</ref><ref type="bibr" target="#b111">112]</ref>. In a crowdsensing marketplace, a task requester initiates a data collection task and compensates participating workers according to their reported costs. As workers may exaggerate their costs, pricing models should incentivize workers to truthfully reveal their costs.</p><p>Yang et al. <ref type="bibr" target="#b104">[105]</ref> design a reverse auction mechanism for mobile sensing data, that is truthful, individually rational, and profitable. A pricing model is truthful if all sellers truthfully report their data collection costs. A model is individually rational if all sellers have non-negative net profits, and profitable if the data buyer has non-negative net profits. The authors assume that a buyer has a set Γ = {τ 1 , . . . , τ n } of sensing tasks, where each task τ i has a value v i to the buyer. Each seller s i chooses a subset of tasks Γ i ⊆ Γ and has a private cost c i for performing the tasks. Seller s i decides a price b i for the sensed data and submits the task-bid pair (Γ i , b i ) to the buyer. After collecting all bids, the buyer selects a subset of sellers S as winners and determines the payment p i to each winner s i .</p><p>The proposed auction mechanism, MSensing, selects winners S in a greedy manner. Starting with S = ∅, it iteratively chooses the seller that brings the largest non-negative net marginal profit. Each winner s i ∈ S is paid the critical value p i of s i , that is, seller s i would not win the auction if s i bids higher than p i . Specifically, MSensing runs the winner selection algorithm over users S = U \ {s i }. The payment p i is the largest price s i can bid, such that s i can replace a user in S . Please note that p i ≥ b i , this is because due to incomplete cost information, the buyer provides extra compensations to sellers on top of their bids to motivate them to reveal actual costs. MSensing satisfies Myerson's characterization of truthful auction mechanisms <ref type="bibr" target="#b71">[71]</ref>.</p><p>The follow-up work by Jin et al. <ref type="bibr" target="#b48">[48]</ref> considers the situation where a data buyer has a data quality requirement Q j for each sensing task t j . The authors propose a Vickrey-Clarke-Groves mechanism <ref type="bibr" target="#b3">[4]</ref> like truthful reverse combinatorial auction. They assume that the data quality q i of each seller s i is public and q i is the same for all sensing tasks. The authors first consider the scenario where each seller only bids for one bundle of sensing tasks Γ i . The auction winners S must satisfy the quality requirement for each task t j , that is, si∈S, if tj ∈Γi q i ≥ Q j . The objective of the auction is to maximize the total utility of the buyer and the sellers. The authors prove that winner determination under the setting is NP-hard and propose a greedy winner selection algorithm with a guaranteed approximation ratio to the optimal total utility. Each winner is paid by the winner's critical payment. The authors further study the total utility maximization problem in a more general scenario, where each seller can bid for multiple bundles of tasks. They propose an iterative descending algorithm that achieves close-to-optimal total utility. However, the auction is not truthful. Koutsopoulos <ref type="bibr" target="#b55">[55]</ref> considers a similar setting as Jin et al. <ref type="bibr" target="#b48">[48]</ref> do, but assumes that a data buyer has only one sensing task. The author proposes a truthful reverse auction that minimizes the expected cost of the buyer while guaranteeing the data quality requirement. The author assumes that the data buyer has prior knowledge about the distribution of each seller s i 's unit participation cost c i . The units of participation x i of s i is a positive real value indicating how much data is purchased from s i . Given the sellers' bids, the data buyer determines the auction winners and their participation units by solving a linear programming model, which minimizes the total expected payment under the data quality constraint. Critical payments are made to the selected winners. All sellers bidding truthfully forms a Bayesian Nash equilibrium <ref type="bibr" target="#b56">[56]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Pricing Data Queries</head><p>Query-based pricing models tailor the purchase of data to users' needs. Customers can purchase their interested parts of a data set through data queries, and are charged according to their issued queries. While such a marketplace mechanism provides greater flexibility to buyers, a less carefully designed pricing model may open the loophole for arbitrage, which allows buyers to obtain a query result in a cost less than the advertised prices.</p><p>Given a database D and a multi-set of query bundles S = {Q 1 , . . . , Q m }, a query bundle Q is determined by S, if the answer to Q can be computed only from the answers to the query bundles in S. A pricing function is arbitragefree if the advertised price π(Q) ≤ m i=1 π(Q i ), that is, the answer to a query bundle Q cannot be obtained more cheaply from an alternative set of query bundles.</p><p>The first formal framework for arbitrage-free query-based data pricing was introduced by Koutris et al. <ref type="bibr" target="#b53">[53]</ref>. The major idea is that a data seller can first specify the prices of a few views V over a database, and then the price of a query bundle Q is decided algorithmically. Theoretically, the authors show that if there are no arbitrage situations among the views in V, there exists a unique arbitrage-free and discount-free pricing function π(Q). Specifically, π(Q) is the total price of the cheapest subset of V that determines Q, which is found by query determinacy <ref type="bibr" target="#b73">[73]</ref>. They also show the complexity of evaluating the price functions. Unfortunately, the pricing model is NP-hard for a large class of practical queries. They develop polynomial time algorithms for specific classes of conjunctive queries, chain queries, and cyclic queries.</p><p>Subsequently, Koutris et al. <ref type="bibr" target="#b54">[54]</ref> develop a prototype pricing system, Query-Market, based on the idea <ref type="bibr" target="#b53">[53]</ref>. They formulate the pricing model as an integer linear program (ILP) with the objective to minimize the total cost of purchased views V p . The purchased views V p must satisfy the following requirements. For a tuple t in the query answer Q(D), there must exist a subset of views in V p that can produce t and for each relation R in Q, at lease one view on R should be purchased. For a tuple t not in Q(D), there must exist a subset of views in V p that can indicate t / ∈ Q(D). Although the pricing problem in the setting is in general NP-hard, QueryMarket shows that a large class of queries can be priced in practice, albeit for small data sets. To handle the case that a query Q may require databases from multiple sellers, they introduce a revenue sharing policy among sellers. Specifically, each seller gets a share of the query price π(Q), which is proportional to the maximum revenue that the seller can get among all minimum-cost solutions to the ILP.</p><p>The problem of designing arbitrage-free pricing models for linear aggregation queries is studied by Li et al. <ref type="bibr" target="#b57">[57]</ref>. Given a data set of n real values x = x 1 , . . . , x n , a linear query over x is a real-valued vector q = w 1 , . . . , w n , and the answer is q(x) = i=1 w i x i . The authors propose a marketplace, where a data buyer can purchase a single linear query q with a variance constraint v defined by the buyer. The query Q = (q, v) is answered by an unbiased estimator of q(x) with a variance smaller than or equal to v. The authors first develop a proposition that the pricing function π cannot decrease faster than 1  v , that is, π(q, v) = Ω( 1 v ). Then, they propose a family of arbitragefree pricing functions, π(q, v) = f 2 (q) v , where the function f (•) is semi-norm. Last, they provide a general framework to synthesize new arbitrage-free pricing functions from the existing ones. For any arbitrage-free pricing functions π 1 , . . . , π k , the pricing function</p><formula xml:id="formula_4">π(Q) = f (π 1 (Q), . . . , π k (Q)) is also arbitrage- free if f (•)</formula><p>is a subadditive and nondecreasing function. A comprehensive list of celebrated arbitrage-free pricing functions are listed by Niu et al. <ref type="bibr" target="#b78">[78]</ref>. In addition to synthesized pricing functions, Li et al. <ref type="bibr" target="#b57">[57]</ref> also study a similar view-based pricing framework as Koutris et al. <ref type="bibr" target="#b53">[53]</ref> do. By adapting the theoretical results in <ref type="bibr" target="#b53">[53]</ref>, the authors show that the view-based pricing model for linear aggregation queries is NP-hard.</p><p>Lin and Kifer <ref type="bibr" target="#b59">[59]</ref> study arbitrage-free pricing for general data queries. They propose three pricing schemes, namely instance-independent pricing, upfront dependent pricing, and delayed pricing. The authors further summarize five forms of arbitrages, namely price-based arbitrage, separate account arbitrage, post-processing arbitrage, serendipitous arbitrage, and almost-certain arbitrage. The authors point out that the model by Koutris et al. <ref type="bibr" target="#b53">[53]</ref> has pricing-based arbitrage, that is, the computed prices may leak information about D. Theoretically, they propose an instance-independent pricing function and a delayed pricing function that are arbitrage-free across all forms. The major idea is to tackle the pricing problem from a probabilistic view. Queries that are more likely to reveal the true database instance are priced higher.</p><p>In the same vein, Deep and Koutris <ref type="bibr" target="#b24">[24]</ref> characterize the structure of pricing functions with respect to information arbitrage and bundle arbitrage, where information arbitrage covers both post-processing arbitrage and serendipitous arbitrage defined by Lin and Kifer <ref type="bibr" target="#b59">[59]</ref>. For both instance-independent pricing and answer-dependent pricing of a query, an arbitrage-free pricing function should be monotone and subadditive with respect to the amount of information revealed by asking the query. Several examples of arbitrage-free pricing functions are presented, including the weighted coverage function and the Shannon entropy function.</p><p>Deep and Koutris <ref type="bibr" target="#b25">[25]</ref> later implement the theoretical framework <ref type="bibr" target="#b24">[24]</ref> into a real time pricing system, QIRANA, which computes the price of a query bundle Q from the view of uncertainty reduction. They assume that a buyer is facing a set of all possible database instances S with the same schema as the true database instance D. After receiving the query answer E = Q(D), the buyer can rule out some database instances D i ∈ S that cannot be D by checking whether Q(D i ) = E. A query bundle that eliminates more database instances is priced higher, as it reveals more information about D. The authors propose an arbitrage-free answer-dependent pricing function, which assigns a weight w i to each database D i ∈ S, and computes the price of a query bundle by</p><formula xml:id="formula_5">π(Q) = i∈{i|Di∈S},Q(D) =Q(Di) w i .<label>(3)</label></formula><p>By default, the same weight w i = P |S| is assigned to each possible database instance D i , where P is a parameter set by the data owner. The data owner can also provide QIRANA with some example query bundles and their corresponding prices. Then, QIRANA will automatically learn instance weights w i from the given examples by solving an entropy maximization problem. Choosing S to be the complete set of possible database instances leads to a #P -hard problem. To make the pricing function tractable, QIRANA uses a random sample of database instances as S.</p><p>Chawla et al. <ref type="bibr" target="#b14">[15]</ref> extend the pricing function in Equation 3 to maximize seller revenue. They consider the setting that the supply is unlimited and the buyers are single-minded, that is, a buyer only wants to buy a single query bundle Q. A buyer will purchase Q if the advertised price π(Q) is smaller than or equal to the buyer's valuation v Q . The authors take a training data set consisting of some query bundles and their customer valuations. Three pricing schemes are investigated. The major idea of the pricing schemes is that, according to Equation 3, a query can be priced as a bundle of items (database instances). Uniform bundle pricing sets the same price for all query bundles. Item pricing sets the price of a query bundle using Equation <ref type="formula" target="#formula_5">3</ref>, where the weights w i are learned from the training data. XOS pricing learns k weights w 1 i , . . . , w k i for each item D i and sets the price of Q as</p><formula xml:id="formula_6">π(Q) = max k j=1 i∈{i|Di∈S},Q(D) =Q(Di) w j i .</formula><p>Theoretically, the approximation rate of each pricing scheme to the optimal revenue is studied. Although XOS pricing scheme enjoys the best approximation rate, the authors show that item pricing usually achieves larger revenue in practice.</p><p>Miao et al. <ref type="bibr" target="#b69">[69]</ref> study the problem of pricing selection-projection-natural join queries over incomplete databases. An arbitrage-free pricing function is proposed based on the idea of data provenance, which describes the origins of a piece of data and its processing history <ref type="bibr">[10,</ref><ref type="bibr" target="#b97">98]</ref>. Let t be a tuple in a query answer Q(D). The lineage L(t, D) of t is defined as the set of tuples in the database D that contribute to t. The authors assume that each tuple t has a base price p(t). The price of Q is set to the weighted aggregation of the costs of all tuples in</p><formula xml:id="formula_7">M (Q, D) = ∪ t∈Q(D) L(t, D). Specifically, π U CA (Q) = i∈{i|ti∈M (Q,D)} µ i p(t i )</formula><p>, where µ i is the percentage of attributes of t i that are not missing. The authors also propose an answer quality aware pricing function,</p><formula xml:id="formula_8">π QU CA (Q) = ∆ n π U CA (Q)κ(Q, D)</formula><p>, where κ(Q, D) is the answer quality and ∆ is a constant. However, π QU CA is not arbitrage-free.</p><p>Purchasing data is usually not a one-shot deal. A customer may purchase multiple queries from the same data seller. A history-aware pricing function will not charge the customer twice for already purchased information. Query-Market <ref type="bibr" target="#b54">[54]</ref> tracks the purchased views of a customer and avoids charging those views when pricing future queries of the customer. Both <ref type="bibr" target="#b25">[25]</ref> and <ref type="bibr" target="#b69">[69]</ref> support history-aware pricing in the same vein as <ref type="bibr" target="#b54">[54]</ref>. One drawback of these history-based approaches is that the seller must provide reliable storage to keep users' query history <ref type="bibr" target="#b100">[101]</ref>.</p><p>Upadhyaya et al. <ref type="bibr" target="#b100">[101]</ref> propose an optimal history-aware pricing function, that is, a buyer is only charged once for purchased data. The key idea is to allow buyers to ask for refunds of already purchased data. In their setting, a query is priced according to its output size. The seller computes an identifier (coupon) for each tuple in the query answer Q(D). Both Q(D) and the corresponding coupons are sent to the buyer. If the buyer receives the same tuple t from two queries, the buyer can ask for a refund of t by presenting the two coupons associated with t in the two corresponding queries. To prevent buyers from borrowing coupons from others and receiving unconscionable refunds, each coupon is uniquely associated with a buyer. By tracking coupon status, the data seller guarantees that each coupon will be used only once. However, the pricing function has no arbitrage-free guarantee <ref type="bibr" target="#b25">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Privacy Compensation</head><p>Machine learning models in many areas, like recommendation systems <ref type="bibr" target="#b19">[19]</ref> and personalized medical treatments <ref type="bibr" target="#b66">[66]</ref>, require a large amount of personal data. However, trading and sharing personal data may leak the privacy of data providers. Therefore, how to measure and properly compensate data providers for their privacy loss is an important concern in designing marketplaces of personal data.</p><p>Differential privacy <ref type="bibr" target="#b28">[28]</ref> is a mathematical framework rigorously providing privacy protection and plays an essential role in personal data pricing. Following the principle of differential privacy, random noises are injected into a data set, such that data buyers can learn useful information about the whole data set but cannot learn specifics accurately about an individual. The magnitude of random noise impacts data providers' privacy loss and the data price. A data set with less injected random noise may leak more privacy and is priced higher. Pricing models of personal data routinely adopt cost-plus pricing strategy, where sellers first compensate data providers for their privacy loss, and then scale up the total privacy compensation to determine the price for data buyers <ref type="bibr" target="#b78">[78]</ref>.</p><p>Ghosh and Roth <ref type="bibr" target="#b34">[34]</ref> initiate the study of pricing privacy by auction. They propose a truthful marketplace to sell single counting queries on binary data. In their settings, a data seller has a data set consisting of personal data d i ∈ {0, 1} of individual i. The data seller sells an estimator s of the sum s = i d i and compensates data providers for their privacy loss. Under the framework of differential privacy, the authors treat privacy as a commodity to be traded. In particular, if a provider's data is used in an -differentially private manner, privacy units should be purchased from the provider. Thus, the privacy compensation problem can be transformed into variants of multi-unit reverse auction. The authors assume that each data provider i has a privacy cost function</p><formula xml:id="formula_9">c i ( ) = v i * ,<label>(4)</label></formula><p>representing the cost for using the data in an -differentially private manner, where v i is the unit privacy cost of i. In an auction, data providers are asked to submit their asking prices b i for the use of their data. Ghosh and Roth <ref type="bibr" target="#b34">[34]</ref> consider two situations. In the first situation, a buyer has an accuracy requirement on s, that is, Pr[| s -s| ≥ k] ≤ 1 3 . The authors establish an observation that they only need to purchase data from m individuals and use them in an -dfferential privacy manner, where m and only depend on the accuracy goal. It's shown that the classic Vickrey-Clarke-Groves auction minimizes the buyer's payment and guarantees the accuracy goal. The major idea is to select m individuals with the cheapest bids and provide each winner with a uniform compensation •b, where b is the (m+1)-th smallest bid. In the second situation, a buyer has a budget constraint and wants to maximize the accuracy of ŝ. The authors propose a greedy-based approximation algorithm to solve the problem.</p><p>The value of personal data and privacy valuation may be correlated. For example, a patient may assign a higher price to the patient's medical report than the healthy people ask for. Ghosh and Roth <ref type="bibr" target="#b34">[34]</ref> show a negative result that in the situations having such correlations, no individually rational direct mechanism can protect privacy.</p><p>In a follow-up study, Dandekar et al. <ref type="bibr" target="#b19">[19]</ref> consider the scenario of selling linear aggregate queries q = w 1 , . . . , w n over real-valued personal data D = d 1 , . . . , d n . They assume data providers have the same privacy cost function as Equation <ref type="formula" target="#formula_9">4</ref>, and propose a truthful reverse auction mechanism to maximize the accuracy of estimators for budget-constraint buyers. The error of an estimator s of the true answer s = i w i d i is its squared error ( s -s) 2 . It is shown that an s computed from more providers with large corresponding weights in q is more accurate. Therefore, the problem is transformed into a knapsack reverse auction <ref type="bibr" target="#b95">[95]</ref> that maximizes the total weights of the selected providers under budget constraints. Specifically, the authors treat the budget as the capacity of the knapsack, the privacy cost of a data entry d i as its weight in the knapsack, and w i as the value of d i . A greedy-based algorithm with an approximation ratio of 5 is proposed to solve the problem.</p><p>The aforementioned studies <ref type="bibr" target="#b34">[34,</ref><ref type="bibr" target="#b19">19]</ref> assume that data buyers can purchase an arbitrary amount of privacy from each data provider. However, a conservative individual may not want to sell the individual's data if the privacy loss is too large. Nget et al. <ref type="bibr" target="#b77">[77]</ref> study the same problem as Dandekar et al. <ref type="bibr" target="#b19">[19]</ref> do in a more realistic situation, that is, an individual i can refuse to participate in an estimator if the privacy loss of i is larger than a threshold i . They assume that the privacy cost function of each data provider is public and propose a heuristic method to determine query price. The model first randomly samples a subset of data providers. Then, it uses the data from each sampled individual i in an i -differentially private manner, and computes the compensations correspondingly. If the total compensation is larger than the budget, the model decreases the differential privacy levels of the high cost providers, such that the budget goal is met. Last, they generate the perturbed query answers by personalized differential privacy <ref type="bibr" target="#b50">[50]</ref>, which guarantees the differential privacy for each selected individual i. They repeat the above steps several times and return the perturbed answer with the smallest squared error.</p><p>Later, Zhang et al. <ref type="bibr" target="#b110">[111]</ref> propose a truthful personal data marketplace, where each data provider i can specify the personal maximum tolerable privacy loss i . They first show that the accuracy of query answers is proportional to the total amount of purchased privacy. Under the assumption that the distributions of privacy costs of all individuals are public, they design a variant of Bayesian optimal knapsack procurement <ref type="bibr" target="#b29">[29]</ref>, which maximizes the expected total purchased privacy under the constraint of a data buyer's expected budget. The authors solve the problem by adopting the algorithm in <ref type="bibr" target="#b29">[29]</ref>. The noisy query answer is generated using personalized differential privacy <ref type="bibr" target="#b50">[50]</ref>, which guarantees i -differential privacy for each selected individual i.</p><p>The models proposed by Dandekar et al. <ref type="bibr" target="#b19">[19]</ref>, Ghosh and Roth <ref type="bibr" target="#b34">[34]</ref> may be attacked by arbitrage. Li et al. <ref type="bibr" target="#b57">[57]</ref> consider the situation where a data buyer has a variance constraint v on the purchased noisy query answers. They assume that the privacy costs of individuals are public, and propose a theoretical framework for assigning arbitrage-free prices to linear aggregate queries q. A perturbed answer is generated from the true answer by adding Laplace noise with the expectation 0 and variance v 2 . Measured by differential privacy, the privacy loss of an individual i is upper-bounded by = w √ v 2</p><p>if the individual is involved in the query, and 0 otherwise, where w is the largest absolute weight in q. Several privacy compensation functions are proposed, such as p i ( ) = c i , where c i is the unit privacy cost of individual i. The price of a query is the sum of the privacy compensations, which is proved to be arbitrage-free. Li et al. <ref type="bibr" target="#b57">[57]</ref> only compensate individuals involved in queries. However, as two individuals' data may be correlated, the privacy of a not-involved individual may be leaked due to the revelation of the other individual's data. To fairly compensate individuals for their privacy, Niu et al. <ref type="bibr" target="#b78">[78]</ref> extend the model by Li et al. <ref type="bibr" target="#b57">[57]</ref>, and propose a pricing model that is arbitrage-free and dependency fair. Dependent fairness requires that a data provider should receive a privacy compensation as long as some data of other providers that is correlated to the data of this provider is involved in a query. Employing dependent differential privacy <ref type="bibr" target="#b60">[60]</ref>, the privacy loss of a data provider i caused by a query is upper-bounded by</p><formula xml:id="formula_10">i = dsi √ v 2</formula><p>, where ds i is the dependent sensitivity of the query at provider i's data. The authors propose a bottom-up mechanism and a top-down mechanism to determine privacy compensations and query prices. The bottom-up mechanism computes compensations in the same way as Li et al. <ref type="bibr" target="#b57">[57]</ref> do and determines query prices as a multiple of the total compensations. The top-down mechanism first determines the query price using a user-defined arbitrage-free pricing function and spares some fraction of a buyer's payment for privacy compensation. Each data provider receives a division of the compensation proportional to the provider's privacy loss.</p><p>All of the privacy compensation methods discussed above assume a trustworthy platform/agent to trade data providers' privacy with data buyers. Data providers, however, cannot control the usage of their own data.</p><p>In this concern, Jin et al. <ref type="bibr" target="#b49">[49]</ref> develop a truthful crowdsensing marketplace, where data owners can determine how much privacy to disclose. In their marketplace, obfuscated geo-locations of data owners are traded by auctions. Data owners first inject random noise to their data based on their own privacy preferences. Then, each data owner bids with the cost as well as the mean and variance of the injected random noise. The buyer determines auction winners to maximize data accuracy with respect to the buyer's budget constraint. The authors show that the optimization problem is NP-hard and develop a greedy heuristic solution. The major idea is to iteratively select data owners that bring the largest marginal utility contributions until the budget is used up.</p><p>In this section, we review representative pricing models of raw data sets in four types of scenarios, where different desiderata are considered. A limitation of the discussed pricing models is that data sets are priced without considering their down-stream applications. Fernandez et al. <ref type="bibr" target="#b30">[30]</ref> argue that the value of a data set to customers is usually task dependent and cannot be evaluated by the intrinsic properties of the data set alone. As the pricing models of raw data sets are agnostic to the down-stream applications of raw data sets, these pricing models can be used in machine learning pipelines of building both supervised and unsupervised machine learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Pricing Data Labels</head><p>Crowdsourcing is a popular method for collecting large-scale labeled training data for machine learning tasks <ref type="bibr" target="#b88">[88]</ref>. Unfortunately, crowdsourced data often suffers from quality issues. This is mainly due to the existence of lazy and spamming workers, who submit low quality labels. Those workers can be discouraged from participating in the tasks by rewarding them with a performance-based payment <ref type="bibr" target="#b82">[82]</ref>. However, due to a lack of ground-truth verification of the collected labels, how to evaluate label quality and price the labels correspondingly is a challenging task. In this section, we review two types of label pricing models, which are designed to motivate workers to exert efforts and submit accurate data labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Gold Task-based Pricing Models</head><p>A gold task is one for which the answer is known to the data buyer a priori. Gold tasks can be uniformly mixed at random within the tasks for workers to evaluate workers' performance, which determines the payments to workers. Since workers cannot distinguish gold tasks from others, this strategy can motivate workers to provide accurate labels. Shah and Zhou <ref type="bibr" target="#b88">[88]</ref> consider a crowdsourcing setup where workers perform binary labeling tasks. The authors propose a multiplicative pricing model using gold tasks. The model allows a worker to skip an assigned task if the worker is not confident about the answer. The total payment to a worker u is computed based on u's performance on the answered tasks. The workers are selfish and want to maximize their individual expected payments. The authors assume that each worker has a private belief Pr(y t = l) about how likely the true label y t of a task t is l. The pricing model is designed to incentivize workers to only report high-confidence labels with beliefs greater than a threshold p. The total reward starts at β. For each correct answer in the gold tasks, the reward will be multiplied by 1  p . However, if any of these gold tasks are answered incorrectly, the reward will drop to zero, that is,</p><formula xml:id="formula_11">π(u) = β • 1 p c • 1(r = 0),<label>(5)</label></formula><p>where 1(•) is an indicator function, and c and r are the number of correct and wrong answers, respectively. This pricing model motivates workers to only answer tasks that they are sufficiently confident about. The pricing model is incentive compatible, that is, a worker receives the maximum expected payment if and only if the worker exerts efforts to report accurate labels. The pricing model also satisfies the "no-free-lunch" axiom, that is, workers who only provide wrong answers will receive no payments. In their setting, the proposed method is the unique incentive compatible model that satisfies the "no-free-lunch" axiom. Shah et al. <ref type="bibr" target="#b90">[90]</ref> further generalize the model <ref type="bibr" target="#b88">[88]</ref> to multi-label tasks. For each task, a worker can submit multiple answers Y that the worker believes is most likely to be correct. This multi-selection system provides workers more flexibility to express their beliefs, which can use the expertise of workers with partial knowledge more effectively than single-selection systems. The authors assume that the workers' beliefs for any label being the true label for a task lie in the set {0} ∪ (p, 1], where p is fixed and known. The authors want to encourage workers to only report the set of labels with positive beliefs. The reward of a worker for a gold task is (1-p) (| Y |-1) if one of the worker's answers is correct and 0 if otherwise. The total payment to a worker is determined by the product of the worker's rewards on all gold tasks.</p><p>In a later study, Shah and Zhou <ref type="bibr" target="#b89">[89]</ref> propose a two-stage multiplicative pricing model to motivate workers to self-correct their answers. In the first stage, a worker answers the assigned tasks. In the second stage, if the worker's answer to a task t does not agree with the answer from the peer workers, the worker has an opportunity to change the answer. The worker u receives a high reward for a gold task t if the initial answer to the task is correct, a low reward if the updated answer is correct, and 0 reward if the final answer is wrong. The total payment is determined by the product of the worker's rewards from gold tasks. Theoretically, the authors prove that the proposed method is the unique incentive compatible model that satisfies the no-freelunch axiom. Empirically, they show in a simulation that the self-correction setting can significantly improve the data quality compared to the standard single-stage settings.</p><p>To reduce the variance in payoffs, the aforementioned methods <ref type="bibr" target="#b89">[89,</ref><ref type="bibr" target="#b90">90,</ref><ref type="bibr" target="#b88">88</ref>] require each worker to solve a sufficient number of gold tasks. This leads to a waste of procurement budget, as the answers to the gold tasks are already known.</p><p>de Alfaro et al. <ref type="bibr" target="#b1">[2]</ref> address the limitation by combining the ideas from peer prediction and gold tasks. They arrange the workers in a hierarchy, where every worker shares one common task with each of its children. A few gold tasks are used to incentivize high efforts from the workers at the top level of the hierarchy. Assuming these workers exert sufficient efforts to provide high quality answers, their answers can be used as pseudo gold tasks for workers in the second layer, who can in turn provide pseudo gold tasks for the next level, and so forth. A worker will be punished if the worker does not agree with the parent on the task shared between them. As the workers at the top level are evaluated by the true gold tasks, they are evaluated more accurately than the other workers, which is not fair to workers at lower layers.</p><p>The follow-up work by Goel and Faltings <ref type="bibr" target="#b36">[36]</ref> considers fair payment among workers, that is, the expected reward of a worker is directly proportional to the accuracy of the worker's answers and independent of the strategy and proficiency of the worker's random peers. The key idea is to estimate the proficiency of workers, which is the probability that a worker can solve the tasks correctly. Goel and Faltings <ref type="bibr" target="#b36">[36]</ref> start by estimating the proficiency of a small group of workers with gold tasks. Then, the answers by the small group of workers to non-gold tasks are used as contributed gold tasks, where the workers' proficiencies are used as the trustworthy degree of those tasks. The contributed gold tasks are used to estimate the proficiency of more workers. Finally, the payoff of each worker is proportional to the worker's estimated proficiency, such that workers with good proficiency receive high payments. The model guarantees that exerting high efforts to provide accurate labels is a dominant strategy for each worker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Peer Prediction-based Pricing Models</head><p>Peer prediction-based pricing model can incentivize efforts and accurate data labels without access to gold tasks. Those models take advantage of the stochastic correlation of answers to the same tasks, and set up a game among workers, called a mechanism in game theory. The game is designed such that workers who exert effort in solving the tasks can achieve high expected rewards, whereas spammers providing random answers on average receive no payments. A pricing model is incentive compatible if it admits exerting high efforts and truthful reporting as an equilibrium.</p><p>Dasgupta and Ghosh <ref type="bibr" target="#b20">[20]</ref> initiate the study of effort elicitation and propose the DG model to price binary labels. A data buyer assigns a set of data labeling tasks to a group of workers, such that each task is labeled by multiple workers and each worker labels multiple tasks. They assume that a worker u i either invests no effort and thus provides a random label, or invests full effort with a cost c i and provides a true label with probability p i . Here, p i is called the proficiency of u i . The workers are self-interested, who want to maximize their payoffs.</p><p>The DG model pays a worker u i on an assigned task t based on how surprisingly u i 's report is consistent with that of the peer worker u p . Denote by y and y p the answers from u i and u p to a task, respectively. The model pays u i with a constant reward subtracting the probability Pr(u i , u p ) that u i and u p have the same answer to a random task, that is,</p><formula xml:id="formula_12">π(u i , t) = β • (1( y = y p ) -Pr(u i , u p )), (<label>6</label></formula><formula xml:id="formula_13">)</formula><p>where β is a non-negative payment scaling parameter that is chosen to cover workers' effort costs, and Pr(u i , u p ) is approximated from the submitted labels.</p><p>The total payment to a worker u i is the sum of u i 's payment for each task.</p><p>The pricing model incentivizes efforts, as the expected payment for spammers who do not solve their tasks and report random/constant labels is exactly zero. Under the assumption that the proficiency of all workers are better than random guess, it is shown that the DG model is incentive compatible. Even though the pricing model also has non-informive equilibria, such as all workers reporting the same label, those equilibria are less profitable to the workers, and thus are not attractive to the workers.</p><p>In a multi-label situation, two labels l 1 and l 2 may be positively correlated. Shnayder et al. <ref type="bibr" target="#b92">[92]</ref> show that under the DG model <ref type="bibr" target="#b20">[20]</ref>, workers can achieve more profits by misreporting l 1 by l 2 . The correlated agreement (CA) mechanism <ref type="bibr" target="#b92">[92]</ref> extends the DG model to multi-label tasks. In the CA mechanism, knowledge about label correlation is required. A label correlation matrix ∆ is learned from workers' submissions, where an element ∆ i,j = Pr(l i , l j ) -Pr(l i )Pr(l j ) is the correlation degree between labels l i and l j . Denote by S(•) the sign function of ∆, that is, S(l i , l j ) = 1 if ∆ i,j &gt; 0, and 0 otherwise. A worker u will be rewarded for a task t if u's report is positively correlated with that of peer u p . To penalize the case where all workers blindly report the same label, a worker u will be penalized if u is likely to be consistent with worker u p on random tasks. In particular, the payment to worker u for reporting ŷ is π(u, t) = β • (S( y, y p ) -S( y a , y b )),</p><p>where ŷp is the answer to task t by worker u p , y a is the answer to a random task by worker u, and y b is the answer to another random task by worker u p . When the number of tasks is large, such that label correlations ∆ can be accurately learned, the CA mechanism is incentive compatible with the highest payment. However, the mechanism fails if two labels l 1 and l 2 are not distinguishable with respect to S(•), that is,</p><formula xml:id="formula_14">∀l i ∈ Y , S(l 1 , l i ) = S(l 2 , l i ).</formula><p>In this situation, workers may misreport l 1 by l 2 and still receive the same payoffs. Radanovic et al. <ref type="bibr" target="#b82">[82]</ref> provide complementary theoretical results on pricing multi-label tasks. They assume that the labels only have limited correlations, that is, Pr(o p = l 2 |o = l 1 ) &lt; Pr(o p = l 2 |o = l 2 ), where o and o p are the observed labels of worker u and worker u p , respectively. The mechanism pays the report y by worker u on a task t by</p><formula xml:id="formula_15">π(u, t) = 1( y = y p ) R( y) -1,</formula><p>where R( y) is the empirical frequency of y, which is computed from all submissions. It is shown that exerting high efforts and truthful reporting is strictly more profitable than any other equilibria. However, their assumptions on label correlations may not hold in some applications <ref type="bibr" target="#b92">[92]</ref>.</p><p>The aforementioned methods <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b92">92,</ref><ref type="bibr" target="#b82">82]</ref> require that each task must be completed by at least two workers, which leads to duplicate answers, and thus does not use the crowd efficiently. For a setting with binary labels, Liu and Chen <ref type="bibr" target="#b62">[62]</ref> propose to learn a classifier M from workers' reports, and use the classifier's predictions M(t) as peer reports. Since workers' submitted labels are noisy, the classifier is trained by the techniques of learning with noisy labels <ref type="bibr" target="#b75">[75]</ref>. Specifically, they first estimate the error rates of submitted labels. Then, the classifier is optimized by an error rate calibrated loss function ϕ(•) proposed by Natarajan et al. <ref type="bibr" target="#b75">[75]</ref>. A report y to a task t is priced based on -ϕ(M(t), y), such that labels with large loss are priced lower. Under the assumption that M is better than random guess, exerting efforts to find the truth labels is the highest-paying equilibrium.</p><p>Liu and Chen <ref type="bibr" target="#b63">[63]</ref> study the problem of sequential label collection, where labeling tasks are published in multiple rounds. In their settings, an accurately labeled task has a fixed reward to a data buyer, whereas a mistakenly labeled task has no value to a data buyer. They propose an incentive compatible pricing model that maximizes the expected utility for a data buyer, which is the difference between the total rewards and the total payment.</p><p>They develop a multi-armed bandit algorithm to extend the DG model <ref type="bibr" target="#b20">[20]</ref>, which dynamically adjusts the parameter β in Equation <ref type="formula" target="#formula_12">6</ref>. A larger β encourages more accurate labels but costs more money. As the bandit algorithm requires a static environment, this method may fail to learn the optimal β if adversarial workers adjust their strategies according to their interactions with the mechanism <ref type="bibr" target="#b42">[42,</ref><ref type="bibr" target="#b37">37]</ref>. Hu et al. <ref type="bibr" target="#b42">[42]</ref> solve the problem by reinforcement learning, which is more robust to strategic behaviors of workers.</p><p>In practice, peer prediction-based models need to adjust payments to avoid negative payments. The adjustment may lead to an issue that spammers may receive positive and high rewards. Radanovic and Faltings <ref type="bibr" target="#b81">[81]</ref> address the issue by proposing a reputation system PropeRBoost to adjust the payments. PropeRBoost publishes tasks to workers in multiple rounds, and computes a reputation score for each worker based on the worker's past submissions. In each round r, it first applies the DG model <ref type="bibr" target="#b20">[20]</ref> to compute workers' payments, and then re-scales the payments by the reputations of the corresponding workers. It is shown that the average payment of a spammer converges to 0 as r approaches infinity.</p><p>In this section, we review gold task-based and peer prediction-based pricing models for data labels. The developed pricing models guarantee that exerting efforts to report accurate data labels is the most profitable strategy of all workers. A major concern of gold task-based methods is that these methods require a sufficient number of gold tasks to obtain good performance. In some scenarios, however, gold tasks are very expensive to obtain. For peer prediction-based methods, the existence of multiple equilibria is a major limitation, as workers may converge to an uninformative equilibrium, where workers do not exert full efforts <ref type="bibr" target="#b93">[93]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Pricing in Collaborative Training of Machine Learning Models</head><p>Collaborative machine learning is an appealing paradigm where multiple data owners collaboratively build high-quality machine learning models by contributing their data. As the data sets from different data owners may have different contributions to the trained machine learning models, data owners who contribute more valuable data should receive more rewards <ref type="bibr" target="#b94">[94]</ref>. In this section, we review contribution evaluation and revenue allocation techniques in collaborative machine learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Revenue Allocation by Shapley Value</head><p>Shapley fairness is widely adopted as the foundation of fair revenue allocation in collaborative machine learning. It guarantees that each participant receives a payment proportional to the participant's marginal contribution to the performance of the trained machine learning model. The challenge in adopting Shapley value lies in its exponential computational cost.</p><p>Maleki et al. <ref type="bibr" target="#b67">[67]</ref> tackle the efficiency issue of Shapley value by proposing a permutation sampling algorithm for bounded utility functions. By Equation 2, the Shapley value of a seller is the marginal utility contribution averaged over all possible subsets of sellers, which can be estimated by sample mean. Denote by ψ(s) an ( , δ)-approximator of a seller's Shapley value, that is, Pr(| ψ(s) -ψ(s)| ≤ ) ≥ 1 -δ. To compute the estimators for all sellers, by Hoeffding's inequality <ref type="bibr" target="#b40">[40]</ref>, we need O( 2r 2 N 2 log 2N δ ) samples and evaluate the utility function O(N 2 log N ) times, where N is the number of sellers and r is the range of the utility function. Evaluating the utility function itself, such as computing testing accuracy, is computationally expensive, as it requires training a machine learning model. Therefore, the method is not scalable to a large number of sellers.</p><p>Ghorbani and Zou <ref type="bibr" target="#b33">[33]</ref> extend the Monte-Carlo method by Maleki et al. <ref type="bibr" target="#b67">[67]</ref> to price individual data point in supervised learning, and propose truncatedbased and gradient-based approximation methods. Their truncated-based method reduces the number of utility evaluations by ignoring coalitions of large size. The authors argue that it is sufficient to estimate Shapley values up to the intrinsic noise in the prediction performance U on the test data set, which can be measured as the bootstrap variance of U. In addition, the performance change by adding one more training data point s to a large training data set S is ignorably small. Therefore, if the utility of S is close to the utility of the whole data set D, the marginal contribution of s to S can be regarded as 0 in practice, and thus its computation can be truncated. Their gradient-based method speeds up the evaluation of utility functions by reducing training time, where a model is trained with only one pass through the training data. They update the model by performing gradient descent on one data point s at a time and the marginal contribution of s is the change in the model performance. The two approximation methods introduce estimation bias into the approximated Shapley values, and have no guarantees on the approximation error.</p><p>Jia et al. <ref type="bibr" target="#b46">[46]</ref> propose two approximation algorithms with provable error bounds for Shapley value that significantly reduce the number of utility evaluations. The first algorithm adopts the idea of group testing in feature selection <ref type="bibr" target="#b113">[114]</ref>. Denote by β i a Boolean random variable indicating whether a seller s i is in a random sample of sellers. A sampling distribution of β 1 , . . . , β N is designed such that the difference in Shapley values between a seller s i and a seller s j is</p><formula xml:id="formula_16">ψ(s i ) -ψ(s j ) = 1 N -1 S⊆D\{si,sj } U(S ∪ {s i }) -U(S ∪ {s j }) N -2 |S| = E[(β i -β j )U(β 1 , . . . , β N )],</formula><p>where U(β 1 , . . . , β N ) is the utility evaluated on the appearing sellers and D are all sellers. The Shapley value of sellers can be derived from the estimated Shapley differences between all datum pairs by solving a feasibility problem. They demonstrate that the algorithm returns an ( , δ)-approximation with O(N (logN ) 2 ) utility evaluations. The second algorithm is based on their observation that Shapley values are approximately sparse, that is, most values are around the mean. Exploiting this property, they apply the idea of sparse signal recovering in compressive sensing <ref type="bibr" target="#b83">[83]</ref>, and develop an algorithm that produces an ( , δ)-approximation with only O(N log(log(N ))) utility evaluations. Jia et al. <ref type="bibr" target="#b45">[45]</ref> further discover that Shapley values for data points used in unweighted kNN classifiers can be computed exactly only in O(N log N ) time. Given a testing point x test with label y test , they define the utility of a kNN classifier as the likelihood of y test , that is,</p><formula xml:id="formula_17">U(S) = 1 k min(k,|S|) i=1 1(y αi(S) = y test ),</formula><p>where α i (S) is the index of the training data that is the i-th closest to x test in the set of data points S. The special utility function enables efficient computation of Shapley differences between two data points x αi(S) and x αi+1(S) , that is,</p><formula xml:id="formula_18">ψ(x αi(S) ) -ψ(x αi+1(S) ) = 1(y αi(S) = y test ) -1(y αi+1(S) = y test ) k min(i, k) i .</formula><p>(7) They start by computing ψ(x α N (S) ) =</p><formula xml:id="formula_19">1(y α N (S) =ytest) N</formula><p>and then exploiting Equation <ref type="formula">7</ref>to recursively compute the Shapley values in the order of x α N (S) , . . . , x α1(S) . They further develop an ( , δ)-approximation algorithm based on Locality Sensitive Hashing <ref type="bibr" target="#b21">[21]</ref> with only sublinear complexity. The major idea is to only compute Shapley values for the retrieved k * = max(k, 1 ) nearest neighbors of x test and ignore the rest data points, as their Shapley values are too small. Moreover, they present a Monte-Carlo approximation algorithm with O( N 2 log(k) log( k δ )) time complexity for weighted kNN classifiers. The aforementioned studies <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b33">33]</ref> evaluate the utility of a model by its performance on a validation data set. Sim et al. <ref type="bibr" target="#b94">[94]</ref> consider the situation where no validation data sets are available, and propose to use information gain on model parameters as the utility function. Denote by θ the model parameters. After training on data D, the information gain IG(θ) = H(θ) -H(θ|D) is the reduction in the uncertainty of θ, where H(•) is the entropy function. In addition to Shapley fairness, three additional incentive conditions for revenue allocation are proposed, namely individual rationality, stability of the grand coalition, and group welfare. They also present p-Shapley fairness, which assigns a reward π(s i ) = kψ(s i ) p to a seller s i . By tuning parameter p ∈ [0, 1], they can trade off between achieving different incentive conditions. Rather than monetary incentives, each participant receives a machine learning model as a reward. To realize different levels of rewards, the models are trained by injecting different levels of noise into training labels.</p><p>Federated Learning <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b68">68]</ref> enables multiple decentralized participants to collaboratively train a machine learning model while keeping their training data locally. The data sets contributed by the participants are used in a sequential order determined by a central server. Evaluating participants' contributions using Shapley value incurs high communication costs among the decentralized participants. Moreover, Shapley value neglects the order of data sources. To accommodate the challenges, Wang et al. <ref type="bibr" target="#b102">[103]</ref> propose federated Shapley value. Denote by U(s i + s j ) the utility of the model, which is trained on s i 's data first, then on s j 's data. Let I t be the set of selected participants in round t of the federated learning process. The federated Shapley value of participant s i at round t is defined as follows.</p><formula xml:id="formula_20">ψ t (s i ) =    1 |It| S⊆It\{si} U (I1:t-1+(S∪{si}))-U (I1:t-1+S) ( |I t |-1 |S| ) if s i ∈ I t 0 if s i / ∈ I t<label>(8)</label></formula><p>The federated Shapley value of s i is ψ(s i ) = T t=1 ψ(s i ), where T is the total rounds in federated learning. The authors show that federated Shapley values satisfy the balance and additivity axioms of Shapley fairness. The other two axioms, symmetry and zero element, are satisfied in each round. They extend the permutation sampling and group testing approximation methods <ref type="bibr" target="#b46">[46]</ref> to compute federated Shapley values.</p><p>Participants in federated learning spend some costs for contributing their data sets, such as privacy cost <ref type="bibr" target="#b41">[41]</ref> and energy costs <ref type="bibr" target="#b51">[51]</ref>. Yu et al. <ref type="bibr" target="#b107">[108]</ref> propose a fair revenue allocation mechanism for federated learning that jointly considers the costs and contributions of participants. At round t, each participant s i has a public cost c i (t) and receives a reward π i (t). The regret r i (t) of s i is a function of the difference between the total cost and total reward of s i . A large value of r i (t) indicates that s i is not well compensated for the costs incurred to s i . The authors argue that payments of participants at each round should achieve contribution fairness and regret fairness. Contribution fairness requires that the payment π i (t) and the Shapley value ψ t (s i ) of each participant s i should be positively correlated, that is, i π i (t)ψ t (s i ) should be maximized. Regret fairness requires that the participants should have similar regrets, that is, the difference of the regrets among participants should be minimized. The payments of participants are determined by solving an optimization problem with respect to a budget constraint. Theoretically, they show that the time-averaged regret of participants is upper-bounded by a constant value as t → ∞.</p><p>Shapley value is vulnerable to data-replication attacks. A data provider may replicate his/her data with zero cost and acts as an additional provider to get extra unconscionable rewards. Agarwal et al. <ref type="bibr" target="#b0">[1]</ref> address the issue by penalizing similar data sets to disincentivize replication, that is, the replicationrobust Shapley value is defined as</p><formula xml:id="formula_21">ψ r (s i ) = ψ(s i )e -λ s j ∈D\{s i } SM(si,sj ) ,</formula><p>where SM is a similarity metric and λ is a constant. However, the proposed replication-robust Shapley value no longer satisfies the balance axiom in Shapley fairness.</p><p>Han et al. <ref type="bibr" target="#b38">[38]</ref> study the replication attack in data markets with submodular utility functions. They show that the total reward received by an attacker increases monotonically with respect to the number of the attacker's replications. They discover that the extra reward to the attacker mainly comes from the marginal contributions to small seller groups by the attacker's replication. To fix the issue, the authors propose to down-weigh those contributions when computing Shapley values. Their method guarantees that attackers receive smaller rewards with more replications.</p><p>Ohrimenko et al. <ref type="bibr" target="#b79">[79]</ref> design a replication robust collaborative data market, where each participant is asked to pay a participation fee. This method discourages replication, as the extra reward received by an attacker cannot cover the attacker's participation cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Other Revenue Allocation Methods</head><p>There are some other revenue allocation methods in collaborative machine learning other than Shapley value.</p><p>Leave-one-out <ref type="bibr" target="#b17">[18]</ref> is a commonly used method to evaluate data importance. It compares the performance of a model trained on the full data set with the performance trained on the full set minus one point. The performance drop is defined as the value of the data point, that is, π(s i ) = U(D) -U(D \ {s i }). Leave-one-out is often approximated by influence function <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b52">52]</ref>, which measures how the model changes as the weight of a training point is changed without retraining the model. Richardson et al. <ref type="bibr" target="#b85">[85]</ref> apply an influence function to reward participants in federated learning for their contributed data points. It is shown that the pricing model is incentive compatible. Applying influence functions to price data points are also investigated in <ref type="bibr" target="#b84">[84,</ref><ref type="bibr" target="#b46">46]</ref>. Comparing with Shapley value, leave-one-out methods, in general, are more efficient as they do not require model retraining. However, leave-one-out methods may not accurately assess the values of data points. The methods may assign a low value to one of the two exactly equivalent data points, regardless of how important the datum is, as high performance may still be achieved by including the other datum <ref type="bibr" target="#b105">[106]</ref>.</p><p>Yan and Procaccia <ref type="bibr" target="#b103">[104]</ref> design a data pricing model based on core <ref type="bibr" target="#b35">[35]</ref>, which is a celebrated revenue allocation solution in cooperative game theory. The solution seeks to achieve maximum stability of how participants team up with each other. Core requires that the total reward of each coalition S should be at least equal to the utility U(S), that is, ∀S ⊆ D, si∈S π(s i ) ≥ U(S), where π(s i ) is the reward of participant s i and D is the set of all participants. When such a reward cannot be achieved, least core relaxes the constraints by allowing a minimum difference between the utility of S and the total reward of S. In particular, least core computes the payment to each participant by solving the following linear program. </p><p>The number of constraints in Equation 9 grows exponentially with respect to the number of participants. Yan and Procaccia <ref type="bibr" target="#b103">[104]</ref> tackle the efficiency issue by proposing a Monte Carlo approximation algorithm with guaranteed approximation errors. Their approximation method samples a relatively small number of coalitions and solves Equation 9 on the sampled coalitions. If Equation 9 has multiple solutions, the solution with the smallest l 2 -norm is chosen. Their revenue allocation satisfies the balance, symmetry, and zero element axioms of Shapley fairness.</p><p>Yoon et al. <ref type="bibr" target="#b105">[106]</ref> propose a reinforcement learning algorithm to value data points. They learn a data value estimator that estimates data values and selects the most valuable samples to train a target classifier. They jointly learn the data value estimator and the corresponding classifier, which enables the classifier and the data value estimator to improve the performance of each other. However, this method cannot guarantee fair revenue distribution among participants.</p><p>Most of the existing revenue allocation methods are developed in the settings that supervised machine learning models are jointly trained. The participants are rewarded based on the contributions of their data sets to the utility of the jointly trained machine learning model. To adapt existing pricing models to scenarios where unsupervised machine learning models are jointly trained, the major challenge is to develop a utility function that participants can all agree on. For some traditional unsupervised machine learning models, there are some widely accepted performance metrics that can serve as the utility functions. For example, Silhouette Coefficient <ref type="bibr" target="#b86">[86]</ref> and Calinski-Harabasz index <ref type="bibr" target="#b11">[12]</ref> are widely used to evaluate the performance of clustering algorithms when groundtruth clusters are unknown. However, developing a utility function for some unsupervised models, such as pre-trained deep language models <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b8">9]</ref>, may be challenging, as they are evaluated differently in many down-stream machine learning tasks.</p><p>In this section, we review pricing models in collaborative training of machine learning models. The major idea is to price each participant's data set based on its contribution to the performance of the jointly trained machine learning model. Shapley value-based methods guarantee fair revenue distribution among participants, but suffer from poor computational efficiency and scalability. Some alternative methods <ref type="bibr" target="#b105">[106,</ref><ref type="bibr" target="#b103">104]</ref> enjoy better efficiency or coalition stability, but lose fairness guarantee.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Pricing Machine Learning Models</head><p>Machine learning models are needed in many different applications and scenarios. Rather than building machine learning models from scratch, many users and companies turn to purchase well-trained machine learning models, due to their lack of expertise and computation resources <ref type="bibr" target="#b108">[109,</ref><ref type="bibr" target="#b15">16]</ref>. In this section, we review pricing models for machine learning models and discuss the differences between pricing machine learning models and raw data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Pricing Models</head><p>Pricing machine learning models is an emerging research area. To the best of our knowledge, the existing studies mainly focus on arbitrage-free and revenue maximization pricing.</p><p>Chen et al. <ref type="bibr" target="#b15">[16]</ref> propose an arbitrage-free and revenue maximization machine learning model marketplace. In their setting, a model owner sells multiple versions of a machine learning model to different buyers. The seller first trains an optimal model on the whole raw data set. Then, the seller produces different versions of the optimal model by adding Gaussian noises with different variances to the parameters of the optimal model. The expected error rates of the generated model instances are monotonically increasing with respect to the variance of the injected noise. An arbitrage-free pricing function guarantees that a buyer cannot derive a high performance model by paying less. Under their mechanism, a pricing function is arbitrage-free if and only if the function is monotone and subadditive with respect to the inverse of the noise variance. Unfortunately, their pricing model only works for machine learning models trained with strictly convex objective functions.</p><p>Chen et al. <ref type="bibr" target="#b15">[16]</ref> further study revenue maximization in pricing machine learning models with respect to the demands and valuations of a set of buyers. They show that determining the optimal prices is coNP-hard. To overcome the computational hardness, they relax the subadditive constraints π(x + y) ≤ π(x) + π(y) by π(x) x ≤ π(y) y , where x ≤ y and π is an approximation of the optimal pricing function π. They show that π is arbitrage-free and ∀x &gt; 0, π(x)/2 ≤ π(x) ≤ π(x). They propose a dynamic programming algorithm to compute π in O(n 2 ) time, where n is the number of model versions.</p><p>Liu et al. <ref type="bibr" target="#b61">[61]</ref> present an end-to-end model marketplace, which jointly considers data owners' privacy costs and model buyers' demands. A broker collects data from data owners, and produces multiple versions of a machine learning model for sale with different subsets of training data and different differential privacy levels . The revenues are fully distributed to data owners. Objective perturbation <ref type="bibr" target="#b13">[14]</ref> is used to train models with required differential privacy levels, which injects quantified random noise into the objective function of a model. Each data owner s i requests a minimum compensation for using the owner's data to train a model with -differential privacy, that is</p><formula xml:id="formula_23">π(s i , ) = b i • c i ( ),</formula><p>where b i is proportional to the Shapley value of s i with regard to all sellers' data sets and c i ( ) is the privacy cost of s i . A desirable pricing model should guarantee revenue maximization, arbitrage-freeness with respect to differential privacy levels, and covers the compensations to data owners. Computing the optimal pricing function is coNP-hard, and thus they propose a dynamic programming algorithm to solve the problem approximately. A limitation of the pricing model is that it cannot adjust prices with respect to dynamic customer demands, which may limit the broker's revenue.</p><p>Agarwal et al. <ref type="bibr" target="#b0">[1]</ref> consider an online auction for machine learning model market, which is truthful and revenue maximizing. They assume buyers come one at a time, and each wants to purchase a machine learning model for the buyer's prediction task. Denote by G( Y i , Y i ) the quality of a model's prediction Y i on buyer i's validation data set Y i . The reward that buyer i receives from the model is µ i • G( Y i , Y i ), where µ i is buyer i's private valuation on unit performance. Denote by p i and b i , respectively, the asking price of the broker and the bid of buyer i for unit performance. The broker produces a noisy machine learning model for buyer i based on the price difference p i -b i . Specifically, the model is trained on a data set with quantified injected random noise, such that the model's performance is degraded proportionally to p i -b i . Buyer i is charged by a function RF (p i , b i , Y i ), which is designed following Myerson's payment function rule <ref type="bibr" target="#b71">[71]</ref>. The utility that buyer i receives by bidding b i is</p><formula xml:id="formula_24">U(b i ) = µ i • G( Y i , Y i ) -RF (p i , b i , Y i ),</formula><p>where Y i is the prediction of the returned noisy model. It is shown that truthfully bidding the buyer's valuation µ i can maximize buyer i's utility. The authors apply a Multiplicative Weights method <ref type="bibr" target="#b2">[3]</ref> to compute the price p i from historical revenues. They show that the pricing mechanism achieves maximum revenue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Pricing Raw Data Products Versus Machine Learning Models</head><p>At a high level, pricing machine learning models and raw data sets share a series of common desiderata and techniques. But their pricing models are essentially different from each other on at least four aspects.</p><p>First, the pricing units of machine learning models are often well defined and fixed. A machine learning model is usually priced and sold as a whole. Customers can purchase either a machine learning model or the usage of a machine learning model via API calls, where each call has a fixed price. In contrast, a raw data set can be consumed in multiple granularities. For example, a customer may be interested in the sales information of American customers in the last year. Another customer, however, may want to purchase the sales information during the Christmas season. Such flexibility makes it easier to version raw data products, and enables more flexible pricing mechanisms. For example, according to how much information is revealed, different prices can be assigned to different queries on the same database <ref type="bibr" target="#b25">[25]</ref>.</p><p>Second, versioning in model markets is harder than that in data markets. As data sets have strong and flexible aggregateability, different versions of a data set can be easily produced by aggregating along different dimensions. Producing different versions of a machine learning model requires more sophisticated techniques <ref type="bibr" target="#b15">[16]</ref>, since it is challenging to accurately control the differences between multiple versions.</p><p>Third, the value of raw data sets to customers is generally harder to measure than that of machine learning models. Often, raw data sets are used to train machine learning models. The ultimate value of a data set dependents not only on its intrinsic properties but also on the specific task that the data set is used for and the analyzing methods <ref type="bibr" target="#b30">[30]</ref>. Therefore, it is usually hard for customers to understand the value of a data set. Many machine learning models are designed for specific tasks and are directly used by people to support decision making <ref type="bibr" target="#b0">[1]</ref>. It is easier for people to verify and understand the value of such machine learning models. For example, customers can value a classification model based on its prediction accuracy.</p><p>Last, preventing arbitrage is usually harder in model market than in raw data market. As shown by Tramèr et al. <ref type="bibr" target="#b99">[100]</ref>, Yu et al. <ref type="bibr" target="#b108">[109]</ref>, machine learning models may be stolen by adversaries via a reasonable number of API calls. A customer with a large number of query instances may first purchase some predictions from a target machine learning model. Then, the customer can train a local model with near-equivalent outputs as the target model and use the local model to predict the remaining query instances with almost no cost.</p><p>In this section, we review pricing machine learning models. We first revisit arbitrage-free and revenue maximization pricing models. Then, we discuss several major differences between machine learning model products and raw data set products, including pricing units, versioning, arbitrage prevention, and customer valuation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Directions</head><p>In this paper, we survey data pricing in end-to-end machine learning pipelines. We consider three important steps in machine learning pipelines where pricing may be substantially involved, namely raw data collection and labeling, collaborative training machine learning models, and machine learning model marketplaces. We systematically review representative studies in those steps, discuss the pricing principles and review the existing methods. End-to-end machine learning pipelines are playing a more and more important role in the current big data and AI economics era. To the best of our knowledge, this is the first survey on data pricing in machine learning pipelines.</p><p>Data pricing is still in its early stage. There are many research challenges for future works. We list some of them here.</p><p>First, the existing studies focus on designing proper rewarding models in each separate stage of machine learning pipelines. There is a lack of systematic study of an end-to-end revenue allocation solution. As presented in our survey, the manufacturing process of machine learning models involves multiple parties, including data owners, data processors, machine learning model designers, and other possible participants. Each party provides value-added contributions at one stage of the pipeline and receives a reward. A natural question is how to allocate manufacturing budgets among different parties.</p><p>To answer the question, we need a mechanism to measure and compare the contributions of different parties in different stages. We also need a system that can dynamically adjust the budget allocations in response to the changes in supply and demand.</p><p>Second, almost all pricing models of collaborative model training formulate revenue allocation as a cooperative game, and use Shapley value to carry out the allocation. They justify the usage of Shapley value through the four axioms, namely balance, symmetry, zero element, and additivity. However, Yan and Procaccia <ref type="bibr" target="#b103">[104]</ref> argue that the necessity of additivity for data valuation is debatable. Except for the additivity axiom, many other celebrated allocation solutions in cooperative game theory can also satisfy the other three axioms. Comparing with Shapley value, the other solutions have their advantages and limitations. For example, normalized Banzhaf value <ref type="bibr" target="#b12">[13]</ref> computes the payment to each player as the player's average marginal contribution towards all coalitions of other players. Even though normalized Banzhaf value does not satisfy the additivity axiom, it is more robust to data replication attacks than Shapley value <ref type="bibr" target="#b38">[38]</ref>. In a marketplace where robustness is more important than additivity, normalized Banzhaf value is more preferable than Shapley value. Different types of data marketplaces may have different goals <ref type="bibr" target="#b30">[30]</ref>, and thus require different axioms. Therefore, we need a better understanding about the necessary axioms in different marketplaces and explore revenue allocation solutions in specific marketplaces.</p><p>Third, fine-grained data procurement for machine learning tasks is not fully explored. In practice, data sets from two sellers may have similar or overlapping parts. A data buyer with a limited budget may not want to purchase many similar data points, as the diversity of training data sets is critical to the performance of machine learning models <ref type="bibr" target="#b30">[30]</ref>. Query-based pricing models <ref type="bibr" target="#b53">[53]</ref> allow data buyers to only purchase their interested parts of a data set. However, the existing query-based pricing models are only designed for relational data sets in monopoly markets. Supporting query-based pricing in marketplaces of general data sets with competing sellers brings new challenges and opportunities. For example, it is interesting for data buyers to explore how to distribute their budgets among data sellers to maximize the utility of purchased data sets. For data sellers, it is important to assign prices to different parts of their data sets based on supply and demand, such that the data sellers and their data sets can remain competitive in the market.</p><p>Last, rigorous evaluation methods for data pricing models need to be developed. Many existing pricing models are only evaluated in oversimplified experimental environments, where many assumptions are made on the behaviors of market participants. A theoretically sound model, however, may not work in practice, as some model assumptions may break. For example, in a real-world market, participants can have adversarial, ignorant, or coalition-building behaviors. However, the effects of those behaviors on the performance of pricing models are largely dismissed in detailed analysis. Therefore, as suggested by Fernandez et al. <ref type="bibr" target="#b30">[30]</ref>, a simulation platform that can simulate different behaviors of market participants should be developed. The platform can help us study the advantages and limitations of pricing models in target environments, and choose the best one to deploy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>Buy-side marketplace.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Architectures of data marketplace.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>i ) = U(D), si∈S π(s i ) + ≥ U(S) ∀S ⊆ D.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A marketplace for data: An algorithmic solution</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Dahleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sarkar</surname></persName>
		</author>
		<idno type="DOI">10.1145/3328526.3329589</idno>
		<ptr target="https://doi.org/10.1145/3328526.3329589" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACM Conference on Economics and Computation</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Karlin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Immorlica</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Johari</surname></persName>
		</editor>
		<meeting>the 2019 ACM Conference on Economics and Computation<address><addrLine>Phoenix, AZ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-06-24">2019. 2019. June 24-28, 2019</date>
			<biblScope unit="page" from="701" to="726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Incentives for truthful evaluations</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Alfaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Faella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Polychronopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shavlovsky</surname></persName>
		</author>
		<idno>1608.07886</idno>
		<ptr target="http://arxiv.org/abs/1608.07886" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The multiplicative weights update method: a meta-algorithm and applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kale</surname></persName>
		</author>
		<idno type="DOI">10.4086/toc.2012.v008a006</idno>
		<ptr target="https://doi.org/10.4086/toc.2012" />
	</analytic>
	<monogr>
		<title level="j">Theory Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The lovely but lonely vickrey auction</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Ausubel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milgrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorial auctions</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="22" to="26" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Pricing information goods: A strategic analysis of the selling and pay-per-use mechanisms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="218" to="234" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><surname>Bdex</surname></persName>
		</author>
		<ptr target="https://www.bdex.com" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2021" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Federated learning: Collaborative machine learning without centralized training data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Daniel</surname></persName>
		</author>
		<ptr target="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" />
	</analytic>
	<monogr>
		<title level="m">Google AI Blog URL</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2021" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Business-to-business marketing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Canning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcdowell</surname></persName>
		</author>
		<idno type="DOI">10.4135/9781446276518</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Sage Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><forename type="middle">A</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/hash/1457" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</editor>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06">2020. 2020. 2020. December 6-12, 2020</date>
		</imprint>
	</monogr>
	<note>c0d6bfcb4967418bfb8ac142f64a-Abstract.html</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Provenance in databases</title>
		<author>
			<persName><forename type="first">P</forename><surname>Buneman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.1145/1247480.1247646</idno>
		<ptr target="https://doi.org/10.1145/1247480.1247646" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD International Conference on Management of Data</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Chan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Ooi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</editor>
		<meeting>the ACM SIGMOD International Conference on Management of Data<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007-06-12">2007. June 12-14, 2007</date>
			<biblScope unit="page" from="1171" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Microeconomics: Optimization, Experiments, and Behavior</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Burkett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A dendrite method for cluster analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Caliński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harabasz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics-theory and Methods</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Computational Aspects of Cooperative Game Theory</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chalkiadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Elkind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wooldridge</surname></persName>
		</author>
		<idno type="DOI">10.2200/S00355ED1V01Y201107AIM016</idno>
		<ptr target="https://doi.org/10.2200/S00355ED1V01Y201107AIM016" />
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Artificial Intelligence and Machine Learning</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Differentially private empirical risk minimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Monteleoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2021036" />
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1069" to="1109" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Revenue maximization for query pricing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koutris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Teng</surname></persName>
		</author>
		<idno type="DOI">10.14778/3357377.3357378</idno>
		<ptr target="http://www.vldb.org/pvldb/vol13/p1-chawla.pdf" />
	</analytic>
	<monogr>
		<title level="j">Proc VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards model-based pricing for machine learning in a data marketplace</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koutris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.1145/3299869.3300078</idno>
		<ptr target="https://doi.org/10.1145/3299869.3300078" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data, SIGMOD Conference</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Boncz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Manegold</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</editor>
		<meeting>the 2019 International Conference on Management of Data, SIGMOD Conference<address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-06-30">2019. 2019. June 30 -July 5, 2019</date>
			<biblScope unit="page" from="1535" to="1552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Frugalml: How to use ml prediction apis more accurately and cheaply</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Characterizations of an empirical influence function for detecting influential cases in regression</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weisberg</surname></persName>
		</author>
		<idno type="DOI">10.1080/00401706.1980.10486199</idno>
		<ptr target="https://www.tandfonline.com/doi/pdf/" />
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="495" to="508" />
		</imprint>
	</monogr>
	<note type="report_type">Technometrics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/00401706.1980.10486199</idno>
		<idno>1080/00401706.1980.10486199</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Internet and Network Economics -8th International Workshop</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dandekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fawaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioannidis</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-35311-6_23</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-35311-623" />
	</analytic>
	<monogr>
		<title level="m">Proceedings</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Goldberg</surname></persName>
		</editor>
		<meeting>null<address><addrLine>Liverpool, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012-12-10">2012. 2012. December 10-12, 2012</date>
			<biblScope unit="volume">7695</biblScope>
			<biblScope unit="page" from="309" to="322" />
		</imprint>
	</monogr>
	<note>Privacy auctions for recommender systems</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Crowdsourced judgement elicitation with endogenous proficiency</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<idno type="DOI">10.1145/2488388.2488417</idno>
		<ptr target="https://doi.org/10.1145/2488388.2488417" />
	</analytic>
	<monogr>
		<title level="m">International World Wide Web Conferences Steering Committee / ACM</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Schwabe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vaf</forename><surname>Almeida</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Glaser</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Moon</surname></persName>
		</editor>
		<meeting><address><addrLine>Rio de Janeiro, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-05-13">2013. May 13-17, 2013</date>
			<biblScope unit="page" from="319" to="330" />
		</imprint>
	</monogr>
	<note>nd International World Wide Web Conference, WWW &apos;13</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Locality-sensitive hashing scheme based on p-stable distributions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Immorlica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Mirrokni</surname></persName>
		</author>
		<idno type="DOI">10.1145/997817.997857</idno>
		<ptr target="https://doi.org/10.1145/997817.997857" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM Symposium on Computational Geometry</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Snoeyink</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Boissonnat</surname></persName>
		</editor>
		<meeting>the 20th ACM Symposium on Computational Geometry<address><addrLine>Brooklyn, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004-06-08">2004. June 8-11, 2004</date>
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName><surname>Dawex</surname></persName>
		</author>
		<ptr target="https://www.dawex.com/en/" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2021" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pricing strategies and levels and their impact on corporate profitability</title>
		<author>
			<persName><forename type="first">De</forename><surname>Toni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Saciloto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Larentis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Revista de Administração (São Paulo)</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="120" to="133" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The design of arbitrage-free data pricing schemes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Deep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koutris</surname></persName>
		</author>
		<idno type="DOI">10.4230/LIPIcs.ICDT.2017.12</idno>
		<ptr target="https://doi.org/10.4230/LIPIcs.ICDT.2017.12" />
	</analytic>
	<monogr>
		<title level="m">Schloss Dagstuhl -Leibniz-Zentrum für Informatik, LIPIcs</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Benedikt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Orsi</surname></persName>
		</editor>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-03-21">2017. 2017. March 21-24, 2017</date>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
	<note>20th International Conference on Database Theory</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">QIRANA: A framework for scalable query pricing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Deep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koutris</surname></persName>
		</author>
		<idno type="DOI">10.1145/3035918.3064017</idno>
		<ptr target="https://doi.org/10.1145/3035918.3064017" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data, SIGMOD Conference</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Salihoglu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Chirkova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</editor>
		<meeting>the 2017 ACM International Conference on Management of Data, SIGMOD Conference<address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-05-14">2017. 2017. May 14-19, 2017</date>
			<biblScope unit="page" from="699" to="713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06-02">2019. June 2-7, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Marketing: Concepts and Strategies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dibb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Simkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Pride</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ferrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Houghton Mifflin, Abingdon, UK</pubPlace>
		</imprint>
	</monogr>
	<note>5th Edition</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Differential privacy: A survey of results</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-79228-4_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-540-79228-41" />
	</analytic>
	<monogr>
		<title level="m">Theory and Applications of Models of Computation, 5th International Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Du</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Duan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Xi&apos;an, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008-04-25">2008. 2008. April 25-29, 2008</date>
			<biblScope unit="volume">4978</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bayesian optimal knapsack procurement</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ensthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Giebe</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ejor.2013.09.031</idno>
		<ptr target="https://doi.org/10.1016/j.ejor.2013.09.031" />
	</analytic>
	<monogr>
		<title level="j">Eur J Oper Res</title>
		<imprint>
			<biblScope unit="volume">234</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="774" to="779" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Data market platforms: Trading data assets to solve data problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Subramaniam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<idno type="DOI">10.14778/3407790.3407800</idno>
	</analytic>
	<monogr>
		<title level="j">Proc VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1933" to="1947" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Pricing of data products in data marketplaces</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Fricker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">V</forename><surname>Maksimov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Software Business</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Ojala</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Holmström Olsson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Werder</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="49" to="66" />
			<date type="published" when="2017">2017</date>
			<publisher>Springer International Publishing</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Brokered agreements in multi-party machine learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Beschastnikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM SIGOPS Asia-Pacific Workshop on Systems</title>
		<meeting>the 10th ACM SIGOPS Asia-Pacific Workshop on Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="69" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Data shapley: Equitable valuation of data for machine learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v97/ghorbani19c.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</editor>
		<meeting>the 36th International Conference on Machine Learning, ICML<address><addrLine>Long Beach, California, USA, PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06">2019. 2019, 9-15 June 2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="2242" to="2251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Selling privacy at auction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.1145/1993574.1993605</idno>
		<ptr target="https://doi.org/10.1145/1993574" />
	</analytic>
	<monogr>
		<title level="m">Proceedings 12th ACM Conference on Electronic Commerce (EC-2011)</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Roughgarden</surname></persName>
		</editor>
		<meeting>12th ACM Conference on Electronic Commerce (EC-2011)<address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011-06-05">2011. June 5-9, 2011. 1993605</date>
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Solutions to general non-zero-sum games</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Gillies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contributions to the Theory of Games</title>
		<imprint>
			<date type="published" when="1959">1959</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="47" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep bayesian trust: A dominant and fair incentive mechanism for crowd</title>
		<author>
			<persName><forename type="first">N</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33011996</idno>
		<ptr target="https://doi.org/10.1609/aaai.v33i01.33011996" />
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019-01-27">2019. 2019. January 27 -February 1, 2019</date>
			<biblScope unit="page" from="1996" to="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Stochastic multi-armed-bandit problem with non-stationary rewards</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Zeevi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Besbes</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2014/hash/903" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-08">2014. 2014. December 8-13 2014</date>
			<biblScope unit="page" from="199" to="207" />
		</imprint>
	</monogr>
	<note>ce9225fca3e988c2af215d4e544d3-Abstract.html</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Replication-robust payoff-allocation with applications in machine learning marketplaces</title>
		<author>
			<persName><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tople</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wooldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ohrimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tschiatschek</surname></persName>
		</author>
		<idno>CoRR abs/2006.14583</idno>
		<ptr target="https://arxiv.org/abs/2006.14583" />
		<imprint>
			<date type="published" when="2006">2020. 2006</date>
			<biblScope unit="page">14583</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">A pricing model for data markets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Heckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Boehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davaloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Kurup</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Probability inequalities for sums of bounded random variables</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hoeffding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Collected Works of Wassily Hoeffding</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="409" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Trading data for learning: Incentive mechanism for on-device federated learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<idno type="DOI">10.1109/GLOBECOM42002.2020.9322475</idno>
		<ptr target="https://doi.org/10.1109/GLOBECOM42002.2020.9322475" />
	</analytic>
	<monogr>
		<title level="m">IEEE Global Communications Conference</title>
		<meeting><address><addrLine>Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020-12-07">2020. December 7-11, 2020</date>
		</imprint>
	</monogr>
	<note>GLOBECOM 2020, Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Inference aided reinforcement learning for incentive mechanism design in crowdsourcing</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y ;</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2018/hash/f" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Sys-tems 31: Annual Conference on Neural Information Processing Systems 2018</title>
		<meeting><address><addrLine>NeurIPS; Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12-03">2018. 2018. December 3-8, 2018</date>
			<biblScope unit="page" from="5512" to="5522" />
		</imprint>
	</monogr>
	<note>2e43fa3400d826df4195a9ac70dca62-Abstract.html</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A demonstration of sterling: A privacy-preserving data marketplace</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.14778/3229863.3236266</idno>
		<ptr target="http://www.vldb.org/pvldb/vol11/p2086-hynes.pdf" />
	</analytic>
	<monogr>
		<title level="j">Proc VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2086" to="2089" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Modern Cost-Benefit Methods</title>
		<author>
			<persName><forename type="first">G</forename><surname>Irvin</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-349-15912-3</idno>
		<imprint>
			<date type="published" when="1978">1978</date>
			<publisher>Macmillan Publishers Limited</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Efficient task-specific data valuation for nearest neighbor algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Hubis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Gürel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Spanos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.14778/3342263.3342637</idno>
		<ptr target="http://www.vldb.org/pvldb/vol12/p1610-jia.pdf" />
	</analytic>
	<monogr>
		<title level="j">Proc VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1610" to="1623" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Towards efficient data valuation based on the shapley value</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Hubis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Gürel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Spanos</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v89/jia19a.html" />
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<meeting><address><addrLine>Naha, Okinawa, Japan, PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-04-18">2019. 2019, 16-18 April 2019</date>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="1167" to="1176" />
		</imprint>
	</monogr>
	<note>AIS-TATS</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Economics of peer-to-peer mobile crowdsensing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Global Communications Conference (GLOBECOM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Quality of information aware incentive mechanisms for mobile crowd sensing systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nahrstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1145/2746285.2746310</idno>
		<ptr target="https://doi.org/10.1145/2746285.2746310" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM International Symposium on Mobile Ad Hoc Networking and Computing</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Shen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Zussman</surname></persName>
		</editor>
		<meeting>the 16th ACM International Symposium on Mobile Ad Hoc Networking and Computing<address><addrLine>Hangzhou, China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-06-22">2015. 2015. June 22-25, 2015</date>
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">If you do not care about it, sell it: Trading location privacy in mobile crowd sensing</title>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">W</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
		<idno type="DOI">10.1109/INFOCOM.2019.8737457</idno>
		<ptr target="https://doi.org/10.1109/INFOCOM.2019.8737457" />
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Conference on Computer Communications, INFOCOM 2019</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-04-29">2019. April 29 -May 2, 2019</date>
			<biblScope unit="page" from="1045" to="1053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Conservative or liberal? personalized differential privacy</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jorgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDE.2015.7113353</idno>
		<ptr target="https://doi.org/10.1109/ICDE.2015.7113353" />
	</analytic>
	<monogr>
		<title level="m">st IEEE International Conference on Data Engineering, ICDE 2015</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Lehner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Shim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Cha</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Lohman</surname></persName>
		</editor>
		<meeting><address><addrLine>Seoul, South Korea</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015-04-13">2015. April 13-17, 2015</date>
			<biblScope unit="page" from="1023" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Incentive mechanism for reliable federated learning: A joint optimization approach to combining reputation and contract theory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/JIOT.2019.2940820</idno>
		<ptr target="https://doi.org/10.1109/JIOT.2019.2940820" />
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Things J</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="10700" to="10714" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Understanding black-box predictions via influence functions</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v70/koh17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning, ICML 2017</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Precup</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</editor>
		<meeting>the 34th International Conference on Machine Learning, ICML 2017<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11">2017. 6-11 August 2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1885" to="1894" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Querybased data pricing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Koutris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Upadhyaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
		<idno type="DOI">10.1145/2213556.2213582</idno>
		<ptr target="https://doi.org/10.1145/2213556.2213582" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS 2012</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Benedikt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Krötzsch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lenzerini</surname></persName>
		</editor>
		<meeting>the 31st ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS 2012<address><addrLine>Scottsdale, AZ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-05-20">2012. May 20-24, 2012</date>
			<biblScope unit="page" from="167" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Toward practical query pricing with querymarket</title>
		<author>
			<persName><forename type="first">P</forename><surname>Koutris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Upadhyaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
		<idno type="DOI">10.1145/2463676.2465335</idno>
		<ptr target="https://doi.org/10.1145/2463676.2465335" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD International Conference on Management of Data</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Ross</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Papadias</surname></persName>
		</editor>
		<meeting>the ACM SIGMOD International Conference on Management of Data<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013-06-22">2013. 2013. June 22-27, 2013</date>
			<biblScope unit="page" from="613" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Optimal incentive-driven design of participatory sensing systems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Koutsopoulos</surname></persName>
		</author>
		<idno type="DOI">10.1109/INFCOM.2013.6566934</idno>
		<ptr target="https://doi.org/10.1109/INFCOM.2013.6566934" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE INFO-COM 2013</title>
		<meeting>the IEEE INFO-COM 2013<address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013-04-14">2013. April 14-19, 2013</date>
			<biblScope unit="page" from="1402" to="1410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Essentials of Game Theory: A Concise Multidisciplinary Introduction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
		<idno type="DOI">10.2200/S00108ED1V01Y200802AIM003</idno>
		<ptr target="https://doi.org/10.2200/S00108ED1V01Y200802AIM003" />
	</analytic>
	<monogr>
		<title level="m">Synthesis Lectures on Artificial Intelligence and Machine Learning</title>
		<imprint>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A theory of pricing private data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Miklau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
		<idno type="DOI">10.1145/2448496.2448502</idno>
		<ptr target="https://doi.org/10.1145/2448496.2448502" />
	</analytic>
	<monogr>
		<title level="m">Joint 2013 EDBT/ICDT Conferences, ICDT &apos;13 Proceedings</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Tan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Guerrini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Catania</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Gounaris</surname></persName>
		</editor>
		<meeting><address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013-03-18">2013. March 18-22, 2013</date>
			<biblScope unit="page" from="33" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A survey on big data market: Pricing, trading and protection</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><forename type="middle">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="15132" to="15154" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">On arbitrage-free pricing for general data queries</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<idno type="DOI">10.14778/2732939.2732948</idno>
		<ptr target="http://www.vldb.org/pvldb/vol7/p757-lin.pdf" />
	</analytic>
	<monogr>
		<title level="j">Proc VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="757" to="768" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Dependence makes you vulnberable: Differential privacy under dependent tuples</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mittal</surname></persName>
		</author>
		<ptr target="http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2017/09/dependence-makes-you-vulnerable-differential-privacy-under-dependent-tuples.pdf" />
	</analytic>
	<monogr>
		<title level="m">23rd Annual Network and Distributed System Security Symposium, NDSS 2016</title>
		<meeting><address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Internet Society</publisher>
			<date type="published" when="2016-02-21">2016. February 21-24, 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Dealer: An end-toend model marketplace with differential privacy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.14778/3447689.3447700</idno>
		<ptr target="https://doi.org/10.14778/3447689.3447700" />
	</analytic>
	<monogr>
		<title level="j">Proc VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="957" to="969" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Machine-learning aided peer prediction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3033274.3085126</idno>
		<ptr target="https://doi.org/10.1145/3033274.3085126" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM Conference on Economics and Computation, EC &apos;17</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Daskalakis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Babaioff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Moulin</surname></persName>
		</editor>
		<meeting>the 2017 ACM Conference on Economics and Computation, EC &apos;17<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-06-26">2017. June 26-30, 2017</date>
			<biblScope unit="page" from="63" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Sequential peer prediction: Learning to elicit effort using posted prices</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14970" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</editor>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017-02-04">2017. February 4-9, 2017</date>
			<biblScope unit="page" from="607" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Roundup of machine learning forecasts and market estimates</title>
		<author>
			<persName><forename type="first">C</forename><surname>Louis</surname></persName>
		</author>
		<ptr target="https://www.forbes.com/sites/louiscolumbus/2020/01/19/roundup-of-machine-learning-forecasts-and-market-estimates-2020" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="2021" to="2026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Data collection and wireless communication in internet of things (iot) using economic analysis and pricing models: A survey</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2546" to="2590" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Concare: Personalized clinical feature embedding via capturing the healthcare context</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<ptr target="https://aaai.org/ojs/index.php/AAAI/article/view/5428" />
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020-02-07">2020. February 7-12, 2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="833" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Bounding the estimation error of sampling-based shapley value approximation with/without stratifying</title>
		<author>
			<persName><forename type="first">S</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tran-Thanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rahwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rogers</surname></persName>
		</author>
		<idno>1306.4265</idno>
		<ptr target="http://arxiv.org/abs/1306.4265" />
	</analytic>
	<monogr>
		<title level="m">CoRR abs/1306</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">4265</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Arcas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v54/mcmahan17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Artificial Intelligence and Statistics</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><forename type="middle">J</forename><surname>Zhu</surname></persName>
		</editor>
		<meeting>the 20th International Conference on Artificial Intelligence and Statistics<address><addrLine>Fort Lauderdale, FL, USA, PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-22">2017. 2017, 20-22 April 2017</date>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1273" to="1282" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Towards query pricing on incomplete data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Pricing approaches for data markets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Muschalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Stahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Löser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International workshop on business intelligence for the real-time enterprise</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="129" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Optimal auction design</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Myerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of operations research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="73" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<author>
			<persName><forename type="first">J Tt &amp;</forename><surname>Nagle</surname></persName>
		</author>
		<author>
			<persName><surname>Hogan</surname></persName>
		</author>
		<title level="m">The Strategy and Tactics of Pricing: A Guide to Growing More Profitably</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Determinacy and rewriting of conjunctive queries using views: A progress report</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Segoufin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vianu</surname></persName>
		</author>
		<idno type="DOI">10.1007/11965893_5</idno>
		<ptr target="https://doi.org/10.1007/119658935" />
	</analytic>
	<monogr>
		<title level="m">Database Theory -ICDT 2007, 11th International Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Schwentick</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</editor>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007-01-10">2007. January 10-12, 2007</date>
			<biblScope unit="volume">4353</biblScope>
			<biblScope unit="page" from="59" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Equilibrium points in n-person games</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Nash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="48" to="49" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Learning with noisy labels</title>
		<author>
			<persName><forename type="first">N</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tewari</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2013/hash/3871" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting</title>
		<editor>
			<persName><forename type="first">Cjc</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting><address><addrLine>Lake Tahoe, Nevada, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-12-05">2013. December 5-8, 2013</date>
			<biblScope unit="page" from="1196" to="1204" />
		</imprint>
	</monogr>
	<note>bd64012152bfb53fdf04b401193f-Abstract.html</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">The brand flip : why customers now run companiesand how to profit from it</title>
		<author>
			<persName><forename type="first">M</forename><surname>Neumeier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<pubPlace>New Riders,, San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">How to balance privacy and money through pricing mechanism in personal data market</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M ;</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Degenhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kallumadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trotman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2311/paper15.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGIR 2017 Workshop On eCommerce co-located with the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, eCOM@SIGIR 2017</title>
		<meeting>the SIGIR 2017 Workshop On eCommerce co-located with the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, eCOM@SIGIR 2017<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">CEUR-WS.org</note>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Unlocking the value of privacy: Trading aggregate statistics over private correlated data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3219819.3220013</idno>
		<ptr target="https://doi.org/10.1145/3219819.3220013" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Farooq</surname></persName>
		</editor>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018-08-19">2018. August 19-23, 2018</date>
			<biblScope unit="volume">2018</biblScope>
			<biblScope unit="page" from="2031" to="2040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Collaborative machine learning markets with data-replication-robust payments</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ohrimenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tople</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tschiatschek</surname></persName>
		</author>
		<idno>1911.09052</idno>
		<ptr target="http://arxiv.org/abs/1911.09052" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A survey on data pricing: from economics to data science</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2020.3045927</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">PP</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Learning to scale payments in crowdsourcing with properboost</title>
		<author>
			<persName><forename type="first">G</forename><surname>Radanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
		<ptr target="http://aaai.org/ocs/index.php/HCOMP/HCOMP16/paper/view/14033" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth AAAI Conference on Human Computation and Crowdsourcing</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lease</surname></persName>
		</editor>
		<meeting>the Fourth AAAI Conference on Human Computation and Crowdsourcing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016-10-30">2016. 2016. 30 October -3 November, 2016</date>
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Incentives for effort in crowdsourcing using the peer truth serum</title>
		<author>
			<persName><forename type="first">G</forename><surname>Radanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jurca</surname></persName>
		</author>
		<idno type="DOI">10.1145/2856102</idno>
		<ptr target="https://doi.org/10.1145/2856102" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans Intell Syst Technol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Compressive sensing and structured random matrices. Theoretical foundations and numerical methods for sparse recovery</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rauhut</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Rewarding highquality data via influence functions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Filos-Ratsikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
		<idno>CoRR abs/1908.11598</idno>
		<imprint>
			<date type="published" when="1908">2019. 1908</date>
			<biblScope unit="page">11598</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Budget-bounded incentives for federated learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Filos-Ratsikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-63076-8_13</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-63076-813" />
	</analytic>
	<monogr>
		<title level="m">Federated Learning -Privacy and Incentive</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12500</biblScope>
			<biblScope unit="page" from="176" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational and applied mathematics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Marketplaces for data: an initial survey</title>
		<author>
			<persName><forename type="first">F</forename><surname>Schomm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Stahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="26" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Double or nothing: Multiplicative incentive mechanisms for crowdsourcing</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2015/hash/" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-12-07">2015. 2015. December 7-12, 2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>c81e728d9d4c2f636f067f89cc14862c-Abstract.html</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">No oops, you won&apos;t do it again: Mechanisms for self-correction in crowdsourcing</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v48/shaha16.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33nd International Conference on Machine Learning, ICML 2016</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting>the 33nd International Conference on Machine Learning, ICML 2016<address><addrLine>New York City, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-19">2016. June 19-24, 2016</date>
			<biblScope unit="volume">48</biblScope>
		</imprint>
	</monogr>
	<note>JMLR Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Approval voting and incentives in crowdsourcing</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peres</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v37/shaha15.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning, ICML 2015</title>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</editor>
		<meeting>the 32nd International Conference on Machine Learning, ICML 2015<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06-11">2015. 6-11 July 2015</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="10" to="19" />
		</imprint>
	</monogr>
	<note>JMLR.org, JMLR Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">A value for n-person games</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Shapley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Contributions to the Theory of Games</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="307" to="317" />
			<date type="published" when="1953">1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Informed truthfulness in multi-task peer prediction</title>
		<author>
			<persName><forename type="first">V</forename><surname>Shnayder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Frongillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Parkes</surname></persName>
		</author>
		<idno type="DOI">10.1145/2940716.2940790</idno>
		<ptr target="https://doi.org/10.1145/2940716.2940790" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM Conference on Economics and Computation, EC &apos;16</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Conitzer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Bergemann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</editor>
		<meeting>the 2016 ACM Conference on Economics and Computation, EC &apos;16<address><addrLine>Maastricht, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016-07-24">2016. July 24-28, 2016</date>
			<biblScope unit="page" from="179" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Measuring performance of peer prediction mechanisms using replicator dynamics</title>
		<author>
			<persName><forename type="first">V</forename><surname>Shnayder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Frongillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Parkes</surname></persName>
		</author>
		<ptr target="http://www.ijcai.org/Abstract/16/371" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Kambhampati</surname></persName>
		</editor>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IJCAI/AAAI Press</publisher>
			<date type="published" when="2016-07">2016. 9-15 July 2016</date>
			<biblScope unit="page" from="2611" to="2617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Collaborative machine learning with incentive-aware model rewards</title>
		<author>
			<persName><forename type="first">Rhl</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bkh</forename><surname>Low</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="http://proceedings.mlr.press/v119/sim20a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning, ICML 2020</title>
		<meeting>the 37th International Conference on Machine Learning, ICML 2020</meeting>
		<imprint>
			<date type="published" when="2020-07-18">2020. 13-18 July 2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="8927" to="8936" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Budget feasible mechanisms</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<idno type="DOI">10.1109/FOCS.2010.78</idno>
		<ptr target="https://www.snowflake.com/data-marketplace/" />
	</analytic>
	<monogr>
		<title level="m">51th Annual IEEE Symposium on Foundations of Computer Science, FOCS 2010, October 23-26</title>
		<meeting><address><addrLine>Las Vegas, Nevada, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page" from="2021" to="2025" />
		</imprint>
	</monogr>
	<note>FOCS.2010.78 96. Snowflake (2021) Snowflake data marketplace</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Data quality scores for pricing on data marketplaces</title>
		<author>
			<persName><forename type="first">F</forename><surname>Stahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Vossen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-662-49381-6_21</idno>
		<ptr target="https://doi.org/10.1007/978-3-662-49381-621" />
	</analytic>
	<monogr>
		<title level="m">Intelligent Information and Database Systems -8th Asian Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Trawinski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Hong</surname></persName>
		</editor>
		<meeting><address><addrLine>Da Nang, Vietnam</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016-03-14">2016. March 14-16, 2016</date>
			<biblScope unit="volume">9621</biblScope>
			<biblScope unit="page" from="215" to="224" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">The price is rightmodels and algorithms for pricing data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bressan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P ;</forename><surname>Valduriez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lhotská</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Link</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Basl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Tjoa</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-40173-2_31</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-40173-231" />
	</analytic>
	<monogr>
		<title level="m">Database and Expert Systems Applications -24th International Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013-08-26">2013. 2013. August 26-29, 2013</date>
			<biblScope unit="volume">8056</biblScope>
			<biblScope unit="page" from="380" to="394" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Get a sample for a discount -sampling-based XML data pricing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Amarilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bressan</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-10073-9_3</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-10073-93" />
	</analytic>
	<monogr>
		<title level="m">Database and Expert Systems Applications -25th International Conference</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Decker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Lhotská</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Link</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Spies</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Wagner</surname></persName>
		</editor>
		<meeting><address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-09-01">2014. 2014. September 1-4, 2014</date>
			<biblScope unit="volume">8644</biblScope>
			<biblScope unit="page" from="20" to="34" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Stealing machine learning models via prediction apis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tramèr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Juels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
		<ptr target="https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/tramer" />
	</analytic>
	<monogr>
		<title level="m">th USENIX Security Symposium, USENIX Security 16</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Holz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Savage</surname></persName>
		</editor>
		<meeting><address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016-08-10">2016. August 10-12, 2016</date>
			<biblScope unit="page" from="601" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Price-optimal querying with data apis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Upadhyaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
		<idno type="DOI">10.14778/3007328.3007335</idno>
		<ptr target="http://www.vldb.org/pvldb/vol9/p1695-upadhyaya.pdf" />
	</analytic>
	<monogr>
		<title level="j">Proc VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1695" to="1706" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Making better use of the crowd: How crowdsourcing can advance machine learning research</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v18/17-234.html" />
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="193" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">A principled approach to data valuation for federated learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rausch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-63076-8_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-63076-811" />
	</analytic>
	<monogr>
		<title level="m">Federated Learning -Privacy and Incentive</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12500</biblScope>
			<biblScope unit="page" from="153" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">If you like shapley then you&apos;ll love the core</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Procaccia</surname></persName>
		</author>
		<ptr target="https://ojs.aaai.org/index.php/AAAI/article/view/16721" />
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021-02-02">2021. February 2-9, 2021</date>
			<biblScope unit="page" from="5751" to="5759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Crowdsourcing to smartphones: incentive mechanism design for mobile phone sensing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2348543.2348567</idno>
		<ptr target="https://doi.org/10.1145/2348543.2348567" />
	</analytic>
	<monogr>
		<title level="m">The 18th Annual International Conference on Mobile Computing and Networking, Mobicom&apos;12</title>
		<editor>
			<persName><forename type="first">Ö</forename><forename type="middle">B</forename><surname>Akan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Ekici</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Qiu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Snoeren</surname></persName>
		</editor>
		<meeting><address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-08-22">2012. August 22-26, 2012</date>
			<biblScope unit="page" from="173" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Data valuation using reinforcement learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Ö</forename><surname>Arik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="http://proceedings.mlr.press/v119/yoon20a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning, ICML 2020</title>
		<meeting>the 37th International Conference on Machine Learning, ICML 2020</meeting>
		<imprint>
			<date type="published" when="2020-07-18">2020. 13-18 July 2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="10842" to="10851" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Data pricing strategy based on data quality</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cie.2017.08.008</idno>
		<ptr target="https://doi.org/10.1016/j.cie.2017.08.008" />
	</analytic>
	<monogr>
		<title level="j">Comput Ind Eng</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">A sustainable incentive scheme for federated learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1109/MIS.2020.2987774</idno>
		<ptr target="https://doi.org/10.1109/MIS.2020.2987774" />
	</analytic>
	<monogr>
		<title level="j">IEEE Intell Syst</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="58" to="69" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Cloudleak: Large-scale deep learning models stealing through adversarial examples</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Y</forename></persName>
		</author>
		<ptr target="https://www.ndss-symposium.org/ndss-paper/cloudleak-large-scale-deep-learning-models-stealing-through-adversarial-examples/" />
	</analytic>
	<monogr>
		<title level="m">27th Annual Network and Distributed Sys-tem Security Symposium, NDSS 2020</title>
		<meeting><address><addrLine>San Diego, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Internet Society</publisher>
			<date type="published" when="2020-02-23">2020. February 23-26, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">A survey of data pricing methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Beltran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Selling data at an auction under privacy constraints</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Beltrán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v124/zhang20b.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Sixth Conference on Uncertainty in Artificial Intelligence, UAI 2020, virtual online</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Gogate</surname></persName>
		</editor>
		<meeting>the Thirty-Sixth Conference on Uncertainty in Artificial Intelligence, UAI 2020, virtual online</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2020-08-03">2020. August 3-6, 2020</date>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="669" to="678" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Incentives for mobile crowd sensing: A survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<idno type="DOI">10.1109/COMST.2015.2415528</idno>
		<ptr target="https://doi.org/10.1109/COMST.2015.2415528" />
	</analytic>
	<monogr>
		<title level="j">IEEE Commun Surv Tutorials</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="54" to="67" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Trust: A general framework for truthful double spectrum auctions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE INFOCOM</title>
		<imprint>
			<biblScope unit="page" from="999" to="1007" />
			<date type="published" when="2009">2009. 2009</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Parallel feature selection inspired by group testing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Porwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Q</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Govindaraju</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2014/hash/fb" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-08">2014. December 8-13 2014</date>
			<biblScope unit="page" from="3554" to="3562" />
		</imprint>
	</monogr>
	<note>8feff253bb6c834deb61ec76baa893-Abstract.html</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
