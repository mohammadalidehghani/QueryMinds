<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Aspects of Artificial Intelligence: Transforming Machine Learning Systems Naturally</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-02-03">3 Feb 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Xiuzhan</forename><surname>Guo</surname></persName>
							<email>xiuzhan@gmail.com</email>
						</author>
						<title level="a" type="main">Aspects of Artificial Intelligence: Transforming Machine Learning Systems Naturally</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-02-03">3 Feb 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">D5F0B138BA0A595920E13863431DF211</idno>
					<idno type="arXiv">arXiv:2502.01708v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Machine Learning</term>
					<term>Machine Learning System</term>
					<term>Machine Learning System Transformation</term>
					<term>Binary Relation</term>
					<term>Directed Graph</term>
					<term>Category</term>
					<term>Functor</term>
					<term>Transformation</term>
					<term>Quotient</term>
					<term>Adjunction</term>
					<term>Monad</term>
					<term>Descent</term>
					<term>Yoneda Embedding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we study the machine learning elements which we are interested in together as a machine learning system, consisting of a collection of machine learning elements and a collection of relations between the elements. The relations we concern are algebraic operations, binary relations, and binary relations with composition that can be reasoned categorically. A machine learning system transformation between two systems is a map between the systems, which preserves the relations we concern. The system transformations given by quotient or clustering, representable functor, and Yoneda embedding are highlighted and discussed by machine learning examples. An adjunction between machine learning systems, a special machine learning system transformation loop, provides the optimal way of solving problems. Machine learning system transformations are linked and compared by their maps at 2-cell, natural transformations. New insights and structures can be obtained from universal properties and algebraic structures given by monads, which are generated from adjunctions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>• Observed bird nests in trees enduring heavy winds during my morning walking;</p><p>• My cats dash straight to me at the moment they see me taking their lickable treats from the box, without worrying about the optimal path;</p><p>• We steer our cars instinctively, without calculating or measuring the exact degrees to turn the steering wheel;</p><p>• Some people enjoy solving their problems by defining objective functions, constraints, and searching for the optimal solutions;</p><formula xml:id="formula_0">• • • • .</formula><p>People might have different feelings and thoughts after reading the words in these sentences and combining the meanings of words together. The collection W 0 of the words in the sentences is discrete. We connect the words by their interconnections in the sentences to obtain a directed graph W 1 and then understand the meanings and insights of these sentences by transforming W 1 from one state to another.</p><p>understand elements, e.g., M of ML system (M, R), by their representable functors in the category of all set valued functors (presheaves), through Yoneda embedding. We shall show that Yoneda embedding, along with Yoneda lemma, plays a crucial role in ML system transformation and representation.</p><p>An ML system can be transformed by different ways. Let's collect all ML system transformations between two ML systems together. Now it is natural to ask what the relations are between these transformations and how to compare these transformations. In Section 3, the questions are answered categorically: The structure-preserving maps between ML system transformations are categorical natural transformations and these natural transformations are flatted to a preorder on ML system transformations.</p><p>ML intends to understand and summarize the existing knowledge from data to grow, predict, and create (new) insights from data. We employ category theory to format and reason ML systems and ML system transformations naturally. An ML system transformation maps problems from one ML system to another where the problems mapped are easier to solve and then the solutions are mapped back to the original system. Hence an ML transformation loop is needed. Categorical concept "adjunction" describes the most efficient solution to problems involving transforming problems and solutions naturally. A monad T on an ML system (M, R), is an endo system transformation T : (M, R) → (M, R) with monoid like structure. T acts on (M, R) and outputs algebraic structures, T -algebras, to (M, R) and so (M, R) obtains algebraic structures through T . An adjunction gives rise to a monad and every monad arises in this way. Also, andjunctions can be defined by the universal property that confirms the existence and uniqueness of the gap map/link, which can be used to link ML elements. In Section 4, the adjunctions between ML systems we highlight include Yoneda embedding, monad algebras, free structures, change of base functors.</p><p>Finally, we complete the paper with our concluding remarks in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Machine Learning Systems and Transformations</head><p>ML elements are the foundational components and blocks that can be used to build ML systems. Essential ML elements include data, features, algorithms, models, performance metrics, validation, testing, deployment, outputs, etc. Let M be a collection of ML elements one concerns. The elements in M are not isolated but connected by the collection of relations between the elements. For instance, the collection of relations can be specified by algebraic operations, certain dependencies and relations on M so that the elements work together to enable the ML systems to learn, grow, and perform tasks. A collection M of ML elements and a collection of relations we concern form an ML system. Data is flowing. The elements and the relations in an ML system, driven by data, must be updated and transformed to fit the present setting dynamically. The map, preserving the relations concerned, between ML systems is an ML system transformation. Definition 2.1. (Machine learning system and transformation)</p><p>1. An ML system (M, R) consists of a collection M of ML elements and a collection R of relations between the elements. Write e 1 Re 2 or (e 1 , e 2 ) ∈ R or e 1 → e 2 if e 1 and e 2 are related by R, for e 1 , e 2 ∈ M.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Let</head><formula xml:id="formula_1">(M 1 , R 1 ) and (M 2 , R 2 ) be ML systems. An ML system transformation T from (M 1 , R 1 ) to (M 2 , R 2 ) is a function T : M 1 → M 2 that preserves the collection R 1 of relations: e 1 R 1 e 2 implies T (e 1 )R 2 T (e 2 ), denoted by T : (M 1 , R 1 ) → (M 2 , R 2 ). Remark 2.2. Let T : (M 1 , R 1 ) → (M 2 , R 2</formula><p>) be an ML system transformation.</p><p>1. If R 1 is given a (partial) binary operation, e.g., table join on a collection of data tables, then R 1 can be viewed as a ternary relation. Assume that R 1 is given by a (partial) binary operation • and R 2 by ⋆ respectively, T : (M 1 , R 1 ) → (M 2 , R 2 ) can be considered as a homomorphism, a structure preserving function T :</p><formula xml:id="formula_2">M 1 → M 2 , namely, T (e 1 • e 2 ) = T (e 1 ) ⋆ T (e 2 ).</formula><p>2. If ML systems (M 1 , R 1 ) and (M 2 , R 2 ) have only some general relations, e.g., dependencies, similarities, implications, etc., between their elements, then these ML systems can be modelled by (multi)directed graphs and so the ML transformations between the ML systems are given by directed graph homomophisms, namely, a function T : M 1 → M 2 that takes each edge (relation) e 1 → e 2 in M 1 to an edge (relation) T (e 1 ) → T (e 2 ) in M 2 .</p><p>3. If ML systems (M 1 , R 1 ) and (M 2 , R 2 ) have the transitive and associative relations and identity relations, then both (M 1 , R 1 ) and (M 2 , R 2 ) can be modelled by directed graphs with identities and composition, which are categories, a general mathematical structure. An ML system transformation</p><formula xml:id="formula_3">T : (M 1 , R 1 ) → (M 2 , R 2</formula><p>) is a functor. Hence ML systems can be reasoned categorically. See Appendix for the basic notations, concepts, and results of relation, directed graph, and category theory.</p><p>Algebraic or graph transformation between ML systems that have algebraic operations or binary relations, can be factored as a surjective to a quotient space, followed by an injective transformation by the similar process in <ref type="bibr" target="#b9">[10]</ref> at the set level. An ML system that has a compositional relation and forms a category can be quotiented by either a congruence equivalence relation on its hom sets or an equivalence relation on objects. See Subsection B.4 for the quotient category details.</p><p>Let (M, R) be an ML system and ρ an equivalence relation on</p><formula xml:id="formula_4">M. ρ is compatible with R if R can be induced to the equivalence relation R ρ on M/ρ, namely, e 1 Re 2 ⇒ [e 1 ] ρ R ρ [e 2 ] ρ is well-defined.</formula><p>Proposition 2.3. Let (M 1 , R 1 ) be an ML system and ρ an equivalence relation on M 1 . Suppose that ρ is compatible with R 1 . 1. ML system (M 1 , R 1 ) is transformed to its quotient ML system (M 1 /ρ, R 1ρ ) by the obvious canonical ML system transformation</p><formula xml:id="formula_5">Q ρ : M 1 → M 1 /ρ sending f : e 1 → e 2 to [f ] ρ : [e 1 ] ρ → [e 2 ] ρ .</formula><p>2. If σ is an equivalence relation on M 1 and compatible with R 1 such that ρ ⊆ σ, then there is a unique surjective ML system transformation</p><formula xml:id="formula_6">(ρ ≤ σ) * : M 1 /ρ → M 1 /σ such that M1 Qρ } } ④ ④ ④ ④ ④ ④ ④ ④ Qσ 3 3 ❈ ❈ ❈ ❈ ❈ ❈ ❈ ❈ M1/ρ (ρ≤σ) * G G M1/σ commutes.</formula><p>3. Each ML system transformation T : (M 1 , R 1 ) → (M 2 , R 2 ), which preserves the congruence equivalence relation ρ, that is, (f, g) ∈ ρ implies T (f ) = T (g), factors through Q ρ , followed by a unique induced ML system transformation T ρ :</p><formula xml:id="formula_7">M 1 /ρ → M 2 M1 T G G Qρ 3 3 ❈ ❈ ❈ ❈ ❈ ❈ ❈ ❈ M2 M1/ρ Tρ a a ④ ④ ④ ④ ④ ④ ④ ④ 4. If T (ρ) ⊆ σ, then there is a unique ML system transformation T * : M 1 /ρ → M 2 /σ such that M1 T G G Qρ M2 Qσ M1/ρ T * G G M2/σ</formula><p>commutes. If T is surjective and so is T * .</p><p>Example 2.4. Cluster and represent ML elements from multiple points of view: Duplicates or similar ML elements in an ML system are often clustered and quotiented to a new ML system. After transforming an ML system by the clusters, we want to represent each equivalence class (cluster) by an ML element on each cluster.</p><p>For example, given a sequence</p><formula xml:id="formula_8">S = {s 1 , • • • , s n of temporal transaction records},</formula><p>to increase the predictability of the next record or a few next records, one may group the records and compute the average of each cluster, for instance, monthly cluster. Hence the equivalence relation ρ on S is given by: (s i , s j ) ∈ ρ ⇔ s i and s j were transacted at the same month.</p><p>The representation function on clusters, e.g., the average avg ρ can be chosen to represent each cluster. Therefore we have:</p><formula xml:id="formula_9">S Qρ -→ S/ρ avgρ -→ (R, ),</formula><p>where is a partial order on R and compatible with the represent function avg to induce avg ρ . The uncertainty/randomness of an ML element can be viewed from different points of view by clustering and representing. The outcomes of a variable, e.g., coin flip, can be either any point from {head, tail} at the point level or a certain set {head, tail} at the distribution level.</p><p>Let Ω be a sample space of a random variable X and bin an equivalence relation on Ω. bin clusters Ω to a family of disjoint subsets. If dist : Ω → V is a function that is compatible with bin and represents the clusters of bin, then there is a transformation:</p><formula xml:id="formula_10">Ω Q bin -→ Ω/bin dist -→ V.</formula><p>Since equivalence relations (clustering or surjective maps) have the partial order ≤ given by ⊆, we have the following commutative diagrams:</p><formula xml:id="formula_11">S Qρ G G S/ρ (ρ≤σ) * S Qσ G G S/σ</formula><p>and</p><formula xml:id="formula_12">Ω Qρ G G Ω/ρ (ρ≤σ) * Ω Qσ G G Ω/σ</formula><p>Example 2.5. Word2vec, Word2fun: Word embedding intends to map all words in a large corpus to a vector space, with the relations between words, e.g., semantic similarity, syntactic similarity, contextual similarity, analogical relationships, etc., being preserved. Word2vec <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> is a popular machine learning technique for learning word embeddings from a large text corpus. Let W 0 be the set of all words in a corpus. Applying Word2vec to W 0 , one obtains a function w2v 0 : W 0 → R n . Since there exist the relations, e.g., similar meaning, between the words in W 0 , W 0 is enriched to a directed graph W 1 and w2v 0 is lifted to w2v : W 1 → R n , where n is a natural number and R n is ordered partially by the closeness (neighbourhood).</p><p>If the words that have similar meaning are closer in the real vector space R n , then one has an ML system transformation:</p><formula xml:id="formula_13">w2v : W 1 → R n</formula><p>and so NLP problems in W 1 might be solved in a vector space R n using the structures and properties of R n through the transformation w2v. For example, Jiang et al. <ref type="bibr" target="#b10">[11]</ref> showed that the semantic independence structure of language are naturally represented by partial orthogonality in vector space R n . Since R n is a linear vector space and W 1 might have more complex word relations that are difficult to represent in R n , Mani <ref type="bibr" target="#b13">[14]</ref> introduced multi-vectors and geometric algebra to embed words in W 1 .</p><p>Sets are among the most fundamental objects in mathematics and many structures, e.g., graphs, algebras, topologies, geometries, can associate with them. Yuan <ref type="bibr" target="#b20">[21]</ref> considered set valued (representable) functors as tasks. Assume that W 1 is a directed graph. We first transform W 1 using path functor to form a category path(W 1 ) and transform path(W 1 ) to representable functors in the category of presheaves using Yoneda embedding:</p><formula xml:id="formula_14">W1 path G G path(W1) Q∼ G G path(W1)/∼ Y G G Set (path(W 1 )/∼) op</formula><p>where wordchain 1 ∼ wordchain 2 if both have the similar meaning. See B.5 for the descriptions of presheaves, representable functors, and Yoneda embedding. For example, the discrete subset W 0 = {apples, eat, i, like, love} ⊆ W 0 is a set of isolated words but can be directed graph enriched by the sentences of a corpus:</p><formula xml:id="formula_15">W 0 ⊇ ⊆ W 1 ⊇ love 6 6 ❏ ❏ ❏ ❏ ❏ W1 = I G G a a ⑤ ⑤ ⑤ ⑤ ⑤ 3 3 ❇ ❇ ❇ ❇ ❇ eat G G apples like X X t t</formula><p>t t t Applying path to W 1 , we have the path edges from I to apples: I [(I,love),(love,apples)] 6 6 [(I,like),(like,apples)] X X [(I,eat),(eat,apples)]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G G apples</head><p>Quotienting out duplicates, we have:</p><formula xml:id="formula_16">I [(I,love),(love,apples)]<label>9 9</label></formula><p>[(I,eat),(eat,apples)]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>U U apples</head><p>Clustering/Quotient provides multiple points of view on chains of words at different layers. For instance, the following quotient system transformations given by ρ 1 and ρ 2 :</p><formula xml:id="formula_17">GalaApple Honeycrisp I G G love A A ❙ ❙ ❙ ❙ ❙ ❙ ❙ y y S S ❦ ❦ ❦ ❦ ❦ ❦ ❦ G G Plantain SmithApple RedBanana ρ1 apples I G G love A A ❙ ❙ ❙ ❙ ❙ ❙ ❙ S S ❦ ❦ ❦ ❦ ❦ ❦ ❦ bananas ρ2 I G G love G G fruits</formula><p>show how the chains of words are aggregated by clustering/ equivalence relations ρ 1 and ρ 2 , functorially. Set (path(W1)/∼) op (the category of presheaves) has more complicated structure than R n and behaves like sets. Given two representable functors F 1 and F 2 , represented by words w 1 , w 2 in W 1 , respectively, by Yoneda Lemma F 1 and F 2 are the same up to isomorphism if and only if w 1 and w 2 are the same. The process of representing words into their presentable functors, is functorial: for each word corresponding f :</p><formula xml:id="formula_18">W 1 → W 2 , W1 path G G f path(W1) Q∼ G G path(f ) path(W1)/∼ Y G G path(f ) * Set (path(W 1 )/∼) op Y (path(f ) * ) W2 path G G path(W2) Q∼ G G path(W2)/∼ Y G G Set (path(W 2 )/∼) op</formula><p>is commutative, forgetting the categorical composition. Therefore NLP problems in W 1 can be transformed to the category of presheaves naturally, where word relations are enriched by set set valued functors functorially.</p><p>Example 2.6. Data and model loop: Assume that ML models are driven by data. Given a data d, one applies ML system transformations, e.g., clustering or quotienting, summarizing, aggregating, etc., on the data d to learn an ML model m, which builds the relations between inputs and outputs, represents data d and behaves like a mathematical function. On the other hand, given an ML model m, it can be thought as a colimit of repsentable functors and produces new data by inputting data, modelling the relations between inputs and outputs. Let Data be a collection of data sets and Model a collection of ML models. Then one has maps M : Data → Model Example 2.7.</p><p>1. ML entity match and merge: Assume that E is a set of ML entity records, e.g., data sets, data workflows, etc. An ML entity resolution system (E, ≈, ) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9]</ref> consists of a set of ML entity records E, a match function ≈: E × E → {true, f alse}, where ≈ (e 1 , e 2 ) = true means that e 1 matches e 2 , modelling match relations. For instance, e 1 is similar to e 2 if e 1 and e 2 have an overlap. e 1 , e 2 combines e 1 and e 2 together by identifying their overlap when e 1 matches e 2 . Then (E, ≈, ) gives rise to an algebraic system, a partial groupoid (E, •), where e 1 • e 2 = e 1 , e 2 when ≈ (e 1 , e 2 ) = true and undefined, otherwise. Clearly, an ML entity resolution system (E, ≈, ) leads to an ML system (E, •) with a partial algebraic operation •.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Zoom data provenance by clustering:</head><p>Recall that data provenance aims to provide a historical record of data origins and transformations associated with data. Data provenance knowledge can be represented as a collection D of data elements and a collection of relations L between the elements <ref type="bibr" target="#b0">[1]</ref> and so it forms an ML system (D, L). Data element relations can be rolled up or down according to the data hierarchy, by using equivalence relations τ and so data provenance is zoomed, aggregated, queried, and visualized at multiple levels driven by τ :</p><formula xml:id="formula_19">(D, L) Qτ -→ (D/τ, L/τ ) query -→ D.</formula><p>3. World2vec, World2fun: Not only are words connected but also is everything in the World linked, interactive and dynamic. Let W be the collection of elements (things) in the World and R the collection of relations one concerns, between the things. Similar to Word2vec, some subsets of W, e.g., graph, ontology, were represented into vector spaces <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b17">18]</ref>. Since W may have more complex relations than vector spaces, by the similar processes in Example 2.5, we transform W to representable functors in the category of presheaves using Yoneda embedding:</p><formula xml:id="formula_20">W path G G path(W) Q∼ G G path(W)/∼ Y G G Set (path(W )/∼) op</formula><p>4. Slice ML system, coslice ML system: Let (M, R) be an ML sysytem that is a category (directed graph with identities and composition) and N an ML element in M. Define (M/N, R/N ) by</p><formula xml:id="formula_21">• M/N = {x : X → N |x ∈ R }, • a relation from x : X → N to y : Y → N in R/N is a relation e : X → Y in R such that X e G G x 0 0 ❂ ❂ ❂ ❂ ❂ ❂ ❂ Y y Ð Ð ✂ ✂ ✂ ✂ ✂ ✂ ✂ N commutes. Then (M/N, R/N ) is the slice ML system of (M, R) over N . If e : N 1 → N 2 is a relation in R, there are ML system transformations e ! : (M/N 1 , R/N 1 ) → (M/N 2 , R/N 2 ) and e * : (M/N 2 , R/N 2 ) → (M/N 1 , R/N 1 )</formula><p>given by composition and pullback, respectively. Dually, one defines coslice ML systems and their adjunctions. We shall see the details of the change of base functors in C.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>Optimal search: An optimal search (C, ob) over R n , consisting of a feasible space C ⊆ R n and an objective function Ob : R n → R, aims to search the best element(s) in the feasible space C, with respect to certain criteria. One of mathematical optimization problems is as follows.</p><formula xml:id="formula_22">minimize f 0 (x) subject to f i (x) ≤ b i , i = 1, . . . , n,</formula><p>where f j : R n → R, j = 0, 1, . . . , n are functions and b i ∈ R, i = 1, . . . , n, It amounts to the optimal search (C, Ob), where</p><formula xml:id="formula_23">C = {x ∈ R n | f i (x) ≤ b i , i = 1, . . . , n} and Ob : R n → R is defined by f 0 .</formula><p>Optimal search variables from a feasible space, can be discrete, categorical, or continuous. An objective function may have its optimal type, e.g., minimum, maximum, inflection points on the function.</p><p>Let OptS be a collection of optimal searchs over R n . Since 2 R n is a poset with ⊆ and objective functions can be compared point wise. OptS is a poset and so an ML system. An ML system transformation T : OptS 1 → OptS 2 is a poset homomorphism (monotone function) .</p><p>As explained in Examples 2.5 and 2.7, we have Proposition 2.8. Let (M, R) be an ML system. Then there are ML system transformations given by the compositions of the following ML system transformations:</p><formula xml:id="formula_24">path(M,R) Q∼ G G path(M,R)/∼ Y G G Set (path(M,R)/∼) op and (M,R) path G G Upath(M,R) UQ∼ G G U(path(M,R)/∼)) UY G G U(Set (path(M,R)/∼) op )</formula><p>where U : Cat → Grph is the forgetful functor, forgetting categorical composition and identity edges.</p><p>Mathematical objects are determined by-and understood by-the network of relationships they enjoy with all the other objects of their species <ref type="bibr" target="#b14">[15]</ref>. Yoneda embedding represents each ML element E to its hom set system transformation hom(-, E) which maps each element X to the set hom(X, E) of all relations between X and E. Hence we use ML element relations to study ML elements by Yoneda embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Transforming and Comparing ML System Transformations</head><p>In this section and Section 4, we assume that ML systems are categories: directed graphs with identities and composition so that categorical results are applicable. Hence ML system transformations between ML systems are functors and relations/maps between functors are natural transformations categorically. See B.3 for the details of functors and natural transformations.</p><p>Let (M 1 , R 1 ) and (M 2 , R 2 ) be two ML systems and let (M 2 , R 2 ) (M1,R1) be specified by</p><p>• objects: the collection of ML system transformations from (M 1 , R 1 ) to (M 2 , R 2 ),</p><p>• relations: the collection of natural transformations between ML system transformations.</p><p>Then (M 2 , R 2 ) (M1,R1) is an ML system. Recall that a preorder is a reflexive and transitive binary relation. ML system transformations are preordered naturally by flatting natural transformations between two ML system transformation.</p><formula xml:id="formula_25">Proposition 3.1. Let (M 1 , R 1 ) and (M 2 , R 2 ) be two ML systems. 1. (M 2 , R 2 ) (M1,R1</formula><p>) is a category and so an ML system.</p><p>2. All ML transformations from (M 1 , R 1 ) to (M 2 , R 2 ) have a preorder , defined by T 1 T 2 if there is a natural transformation α :</p><formula xml:id="formula_26">T 1 → T 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Adjunctions between ML Systems</head><p>Recall that an adjunction between two categories C and D is given by a pair of functors F : C → B and G : B → C and forms a functor loop, corresponding to a weak form of equivalence between C and D, such that for</p><formula xml:id="formula_27">C ∈ C 0 and B ∈ B 0 C → GB F C → B</formula><p>which is natural in C and B. Adjunction can be defined by universal arrows (See C.1 for the details). Throughout this section, F, G, ϕ</p><formula xml:id="formula_28">: (M 1 , R 1 ) → (M 2 , R 2</formula><p>) is an adjunction between two ML systems (M 1 , R 1 ) and (M 2 , R 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Solve Problems Optimally by Adjunctions</head><p>An ML system transformation T : (M 1 , R 1 ) → (M 2 , R 2 ) transforms problems in ML system (M 1 , R 1 ) to (M 2 , R 2 ) as the problems transformed might be easier to solve in (M 2 , R 2 ). After the transformed problems being solved in (M 2 , R 2 ), one needs to transform the solutions back to (M 1 , R 1 ), with the structures used for the solutions being preserved, so that the original problems are solved in (M 1 , R 1 ). Hence an ML system transformation S : (M 2 , R 2 ) → (M 1 , R 1 ) is needed. If T and S are mutually inverse to each other (isomorphism) or inverse to each other up to natural isomorphism of functors (equivalence), then T and S are just "relabelling" bijectively or adding more copies of objects up to isomorphism and so it is hard to reduce the complexity of the problems by using the ML transformations T and S as an isomorphism could not reduce the complexity of the problem. Categorical concept adjunction, a functor loop, provides a pipeline of transforming problems between ML systems (M 1 , R 1 ) and (M 2 , R 2 ) in optimal ways.</p><p>Since adjunction F, G, ϕ : (M 1 , R 1 ) → (M 2 , R 2 ) provides a loop and F and G determine each other uniquely and naturally, F produces the most efficient solutions to the problem posed by G. Hence we use adjunctions to transform ML systems and obtain optimal ways to solve ML problems.</p><p>Example 4.1.</p><p>1. Yoneda embedding forms part of adjunction generally. Recall that a total category is a small category whose Yoneda embedding has a left adjoint. Totality of a category was studied very extensively <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b4">5]</ref>. Many classes of categories are total, including any category which is monadic over Set, Grothendieck toposes, locally presentable categories and so are Grph and Top. Hence Yoneda embedding of an ML system (M, R) has a left adjoint. To calculate the left adjoint F of Y , we consider</p><formula xml:id="formula_29">X → Y M F X → M ,</formula><p>where X : M op → Set is a set valued functor. Since each presheaf is a colimit of representable set valued functors, one assumes X is reprsentable and F X is the representing object of X. Hence F is defined by the colimit of these reprersenting objects.</p><p>2. A forgetful functor is a functor, defined by forgetting some structure, such that, forgetting composition and identities of a category to get a directed graph, forgetting algebraic structures, e.g., monoid, group, module, to obtain a set, etc. The left adjoint of such a forgetful functor is called free functor, such as, free category functor, free monoid functor, free group functor, and free module functor.</p><p>3. A monad and its T -algebras leads to an adjunction (see C.2) and so an optimal way to solve problems with algebraic structures. 5. Let e : N 1 → N 2 be a relation in an ML system (M, R) which has pullbacks. Then we have the following adjoint pair:</p><formula xml:id="formula_30">(M,R)/N2 e * G G (M,R)/N1 e ! o o</formula><p>where (M, R)/N 2 is the slice ML system over N 2 with all relations to N 2 being objects, e ! (D, s) = es, e * (C, r) = π 1 which is given by the following pullback:</p><formula xml:id="formula_31">N1×N 2 C π2 G G π1 C r N1 e G G N2</formula><p>The unit and counit of e ! ⊣ e * is given by η(s</p><formula xml:id="formula_32">: D → N 1 ) = s, 1 C : C → N 1 × N2 C and ε(r : C → N 2 ) = π 2</formula><p>, where π 2 is defined by the last pullback and s, 1 C by the following pullback:</p><formula xml:id="formula_33">D s 0 0 = 2 2 s,1D 4 4 N1×N 2 C π ′ 1 π ′ 2 G G D s N1 e N1 e</formula><p>G G N2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Extend Machine Learning Systems by Adding Algebra Structures</head><p>ML systems and system transformations were formatted and reasoned categorically. ML objects and pipelines can have other formations other than the categorical way. However, ML aims to not only understand and summarize the existing knowledge from data but also grow and create insights.</p><p>Recall that a monad on a category is an endo functor with monoid-like structure. Monads and their T -algebras can provide algebraic structures to the category. An adjunction gives rise to a monad and every monad arises this way (see C.2 for the details). Definition 4.2. A monad T = T, η, µ on an ML system (M, R) is an ML system transformation T : (M, R) → (M, R) and two natural transformations</p><formula xml:id="formula_34">η : I → T, µ : T 2 → T such that T 3 T µ G G µT T 2 µ T 2 µ G G T and IT ηT G G 1 1 1 ❄ ❄ ❄ ❄ ❄ ❄ ❄ T 2 µ T I T η o o 1 ⑧ ⑧ ⑧ ⑧ ⑧ ⑧ ⑧ T are commutative, where I : (M, R) → (M, R) is the identity functor, sending e : X → Y to e : X → Y . Each adjunction F, G, ϕ : (M 1 , R 1 ) → (M 2 , R 2 )</formula><p>between ML systems gives rise to a monad GF, η, GεF on (M 1 , R 1 ) and very monad on (M 1 , R 1 ) arises this way.</p><p>A monad T : (M, R) → (M, R) generates algebraic structures to (M, R).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Link Machine Learning Objects by Universal Properties</head><p>Universal property characterizes objects by their relations or links to other objects uniquely up to isomorphism. Adjunctions, free objects, limits/colimits, and representable functors are the examples that are determined by their universal property. Universal property confirms the existence and uniqueness of a relation or map to fill in. By the universal property the relation filled in is a best or most efficient solution.</p><p>Hence ML objects can be linked by universal property naturally.</p><p>Example 4.3.</p><p>1. Let A, B, X be tables/neural networks related and A, B the join/merge of A and B. If there are the relations f : X → A and g : X → B then there is a unique relation f, g :</p><formula xml:id="formula_35">X → A, B such that X f,g f 6⑥ ⑥ ⑥ ⑥ ⑥ ⑥ ⑥ g 2 2 ❇ ❇ ❇ ❇ ❇ ❇ ❇ ❇ A A,B π1 o o π2 G G B</formula><p>commutes, where π 1 , π 2 are projections.</p><p>2. Given a representable functor F : C op → Set, if F is represented by X and Y , then there are relations f : X → Y and g : Y → X such that gf = 1 X and f g = 1 Y .</p><p>3. The adjunctions given by Yoneda embedding (see B.5) and change of base (see C.3) are characterized by their universal properties, which can be used to fill out the gap relations between ML elements, e.g., words and chains of words in a corpus.</p><p>Let W 0 be the collection of all words from a set of large corpora and W 1 the directed graph by linking words in W 0 using the ordered pairs of words appearing in the large corpora. Applying path to W 1 , one has a directed graph with composition (category) path(W 1 ). So categorical notions and results are applicable to path(W 1 ). For example, special maps, e.g., epics and monics, are discussed as follows.</p><p>A word chain e : w 1 → w 2 in path(W 1 ) is epic if c 1 e = c 2 e implies c 1 and c 2 the same meaning. Dually, a word chain e : w 1 → w 2 in path(W 1 ) is monic if ec 1 = ec 2 implies c 1 and c 2 have the same meaning.</p><p>e = "The meaning of this sentence is defined by the succeeding chain of words" and m = "The meaning of this sentence is determined by the preceding chain of words" are clearly epic and monic, respectively if these words are in W 0 . s = "I love fruits" is neither epic nor monic since t 1 s = t 2 s, st 1 = st 2 , t 1 = t 2 up to meaning, where t 1 = "I love apples" and t 1 = "I love oranges". Reasoning path(W 1 ) categorically holds independent interest, is beyond the scope of the current paper, and will be addressed separately.</p><p>Since path(W 1 ), we have the Yoneda embedding</p><formula xml:id="formula_36">Y : path(W1) → Set (path(W 1 )) op .</formula><p>The left adjoint L of Y is calculated by representing a presheaf as a colimit of presentable functors.</p><p>When path(W 1 ) has pullbacks, for each chain of word p : w 1 → w 2 , we have an adjunction:</p><formula xml:id="formula_37">path(W1)/w2 p * G G path(W1)/w1 p ! o o</formula><p>where p ! (D, s) = ps, p * (C, r) = π 1 which is given by the following pullback:</p><formula xml:id="formula_38">w1×w 2 C π2 G G π1 C r w1 p G G w2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Data is from various platforms with multiple formats, noisy, and changes constantly. ML elements and systems, driven by data and outputting new data, must be robust to the changes. The relations between ML elements make more sense than the isolated ML elements. We studied the ML elements that we are interested in together as an ML system. The relations between ML elements we concerned are algebraic operations, binary relations, and binary relations with composition that can be reasoned categorically. An ML system transformation between two systems is a map between the systems, which preserves the relations we concerned. The ML system transformations given by quotient or clustering, representable functor and Yoneda embedding were highlighted and discussed by ML examples. ML elements were embedded to set valued functors which provide multiple relation perspectives for each ML element. ML system transformations were linked and compared by their maps at 2-cell, natural transformations. ML transformations lead to fresh perspectives and uncover new insights. Special ML system transformation loops, adjunctions between ML systems, offered the optimal way of solving ML problems. New ML insights and structures can be obtained from universal properties and algebraic structures given by monads, which are generated from adjunctions.</p><p>The minimum requirements of the relation, directed graph, and category theory for the paper include: binary relation, equivalence relation, equivalence class, quotient, category, homomorphism, isomorphism, coproduct, pullback, pushout, monic, epic, injection, initial object, functor, natural transformation, Yoneda lemma and embedding, adjunction, monad, T -algebra. For the related notions, notations, results, and a systematic introduction, the reader may consult, for instance, <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b5">6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Binary Relations and Directed Graphs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Binary Relations</head><p>Recall that a binary relation on a nonempty set S is a subset ρ ⊆ S × S, where S × S = {(s 1 , s 2 )|s 1 , s 2 ∈ S} is the Cartesian product of S and S. A binary relation</p><formula xml:id="formula_39">ρ on S is reflexive if (s, s) ∈ ρ for all s ∈ S, symmetric if (s 1 , s 2 ) ∈ S implies (s 2 , s 1 ) ∈ ρ, transitive if (s 1 , s 2 ) ∈ ρ and (s 2 , s 3 ) ∈ ρ imply (s 1 , s 3 ) ∈ ρ, and antisymmetric if (s 1 , s 2 ) ∈ ρ and (s 2 , s 1 ) ∈ ρ imply s 1 = s 2 .</formula><p>A poset (P, ≤) consists of a nonempty set P and a reflexive, antisymmetric, and transitive binary relation ≤ on P .</p><p>An equivalence relation on S is a reflexive, symmetric, and transitive binary relation on S. Let ρ be an equivalence relation on S and s ∈ S. The equivalence class of s is {x ∈ S | (x, s) ∈ ρ}, denoted by [s] ρ .</p><p>Clustering aims to group a set of the objects in such a way that objects in the same cluster are more similar to each other. In a nonempty set S, clustering the objects (elements) of S amounts to grouping or partitioning them, which turns out to be an equivalence relation on S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Directed Graphs</head><p>Recall that a (multi)directed graph (N, E) consists of a collection N of nodes (or vertices), a collection E of edges, and two functions</p><formula xml:id="formula_40">E from G G to G G N</formula><p>that specify "from" node and "to" node of each edge f ∈ E. Write f ∈ E by f : X → Y , where X = from(f ), Y = to(f ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Categories, Functors, and Natural Transformations B.1 Categories</head><p>A category C is a directed graph (N, E) with identities and associative composition, which are two functions:</p><formula xml:id="formula_41">id : N → E and comp : E × N E → E, where E × N E = {(f, g) | to(f ) = from(g)} ⊆ E × E collects all composable pairs of edges, such that • for all edge f : X → Y , 1 Y f = f 1 X = f , where 1 X = id(X),</formula><p>• for all f : A → B, g</p><formula xml:id="formula_42">: B → C, h : C → D, h(gf ) = (hg)f , where gf = comp(f, g) for each composable .</formula><p>As a category C is a directed graph, write the set of nodes and the set of edges of C by C 0 and C 1 , respectively. Nodes and edges in a category are also called objects and maps of the category, respectively.</p><p>Given a category C, if we flip the directions of all maps in C then we obtain its dual category, denoted by C op . Clearly, (C op ) op = C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Given objects</head><formula xml:id="formula_43">X, Y ∈ C 0 , write hom C (X, Y ) = {f ∈ C 1 | from(f ) = X and to(f ) = Y }.</formula><p>A subcategory C ′ of a category C is given by any subcollections of the objects and maps of C, which is a category under the from, to, composition, and identity operations of C.</p><p>Given a directed graph G = (N, E) and two nodes a, b ∈ N , a path from a to b is a sequence of composable edges [e 1 , e 2 , . . . , e k ] such that from(e 1 ) = a, . . . , to(e i ) = from(e i+1 ), . . . , to(e k ) = b, i = 1, . . . , k -1.</p><p>Each node has an empty path [ ]. Each directed graph G = (N, E) generates a category P ath(G) = P ath(N, E) = (N, {all paths in G}), by considering all paths as edges, empty path as identity, path concatenation as composition. Call P ath(G) the free category on directed graph G.</p><p>On the other hand, given a category C, one has a directed graph F (C) by forgetting identity edges and edge composition.</p><p>Some examples of categories are listed below.</p><p>1. Each poset (P, ≤) is a category with the elements of P as its objects and ≤ as maps.</p><p>2. All sets and functions between sets form a category Set.</p><p>3. All directed graphs and graph homomorphisms between graphs form a category Grph.</p><p>4. All categories and functors between categories form a category Cat. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Limits and Colimits</head><formula xml:id="formula_44">L φI 5⑤ ⑤ ⑤ ⑤ ⑤ ⑤ ⑤ φJ 3 3 ❇ ❇ ❇ ❇ ❇ ❇ ❇ ❇ DI Df G G DJ for each I-map f : I → J. A limit of the diagram D : I → C is a D-cone (L, φ) such that for each other D-cone (J, ψ) there is a unique C 1 element u : J → L making the following diagram J ψI 2 2 ❇ ❇ ❇ ❇ ❇ ❇ ❇ ❇ u DI L φI b b ⑤ ⑤ ⑤ ⑤ ⑤ ⑤ ⑤ ⑤</formula><p>commute for each I-object I. If I is specified by the following graphs</p><formula xml:id="formula_45">• •, • G G G G •, • G G •</formula><p>then the limit of D : I → C is called a terminal object, an equalizer, a pullback (square) in C, respectively. Explicitly, a C-object 1 is a terminal object provided for each C-object X there is a unique C-map ! X : X → 1.</p><p>A commutative square</p><formula xml:id="formula_46">P p1 p2 G G Y g X f G G Z in C is called a pullback (square) provided given any C-maps w 1 : W → X and w 2 : W → Y with f w 1 = gw 2</formula><p>there is a unique C-map w : W → P such that</p><formula xml:id="formula_47">p 1 w = w 1 and p 2 w = w 2 : W w1 0 0 w2 4 4 w 2 2 P p1 p2 G G Y g X f G G Z</formula><p>For two parallel C-maps f, g : X → Y , the equalizer of f and g is a C-map e : E → X such that f e = ge and e is unique with this property: if a C-map z : Z → X is such that f z = gz then there is a unique C-map d : Z → E such that ed = z:</p><formula xml:id="formula_48">Z d z 2 2 ❆ ❆ ❆ ❆ ❆ ❆ ❆ E e G G X f G G g G G Y</formula><p>If maps between D-cones are defined properly, then limits can be characterized as terminal objects in the category of all D-cones.</p><p>The dual notions of cone, limit, terminal object, pullback (square), equalizer are cocone, colimit, initial object, pushout (square), and coequalizer, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Functors and Natural Transformations</head><p>Let C and D be categories. A functor F : C → D is a structure preserving function F between C and D, which maps C i to D i :</p><formula xml:id="formula_49">F C i ⊆ D i , i = 0, 1, such that 1. for each X ∈ C 0 , F 1 X = 1 F X ;</formula><p>2. for each composable edge pair (f, g) in C 1 , (F f, F g) is a composable pair and</p><formula xml:id="formula_50">F (gf ) = F gF f . A functor F : C → D is full (faithful) if each function F : hom C (X, Y ) → hom D (F X, F Y ), sending f : X → Y to F f : F X → F Y , is surjective (injective) for all X, Y ∈ C 0 .</formula><p>Let F, G : C → D be two functors. A natural transformation α from F to G, written as α : F → G, is specified by an operation which assigns each object X of C a map α X : F X → GX such that for each </p><formula xml:id="formula_51">f : X → Y in C 1 F X F f αX G G GX Gf F Y αY G G GY</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Quotient Categories</head><p>Given nonempty category C, one may cluster the maps (edges) or objects (nodes) of C to obtain the new quotient category C/ρ with respect to an equivalence relation ρ on maps or objects such that composition under ρ is well defined.</p><p>Let ρ be an equivalence relation on C 1 . ρ is a congruence if for f, g ∈ hom C (X, Y ) such that kf h and kgh are composable and (f, g) ∈ ρ imply (kf h, kgh) ∈ ρ. Quotient category C/ρ is defined by</p><formula xml:id="formula_52">• (C/ρ) 0 = C 0 , • (C/ρ) 1 = {[f ] ρ | f ∈ C 1 , where [f ] ρ : X → Y as a representative member of the equivalence class of f : X → Y in C, • identities: [1 X ] ρ : X → X, • composition: [g] ρ [f ] ρ = [gf ] ρ .</formula><p>There is an obvious canonical functor</p><formula xml:id="formula_53">Q ρ : C → C/ρ sending f : X → Y to [f ] ρ : X → Y .</formula><p>Each functor F : C → D, which preserves the congruence equivalence relation ρ: (f, g) ∈ ρ implies F f = F g, factors through Q ρ , followed by a unique functor</p><formula xml:id="formula_54">F ρ : C/ρ → D C F G G Qρ 3 3 ❈ ❈ ❈ ❈ ❈ ❈ ❈ ❈ D C/ρ Fρ a a ④ ④ ④ ④ ④ ④ ④ ④</formula><p>Clustering the nodes (objects) of C by an equivalence relation, can be more complicated since new composition on the equivalence classes of edges (maps) needs to be well defined. However, one may first quotient the directed graph by identifying nodes then add all paths to the quotient directed graph to form a category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Presheaves, Representable Functors, and Yoneda Embedding</head><p>A category is small if its objects and maps are sets and so it is Set-enriched as the maps between each pair (X, Y ) of objects form a hom set hom(X, Y ). Let C be s small category.</p><p>A presheaf on a small category C is a set valued functor F : C op → Set.</p><p>Theorem B.1. Given a small category C, each category of presheaves on C is complete and cocomplete and both limits and colimits are computed point wise.</p><p>Since Grph ∼ = Set 2 , one has:</p><p>Corollary B.2. Grph has both limits and colimits, being computed point wise.</p><p>A set valued functor S : C op → Set is representable or represented by A ∈ C 0 if it is naturally isomorphic to a hom functor hom C (-, A) for A ∈ C 0 .</p><p>Theorem B.3. Each presheaf is a colimit of representable set valued functors.</p><p>The Yoneda lemma states that natural transformations from a representable functor hom C (-, X) to a set valued functor S : C op → Set is in natural bijection with SX: Proposition B.4 (Yonneda Lemma). Let C be a small category, S : C op → Set a functor, and X ∈ C 0 . Then there is a natural isomorphism {α : hom C (-, X) → S} → SX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition B.5 (Yonneda Embedding).</head><p>There is a full and faithful embedding</p><formula xml:id="formula_55">Y : C → Set C op , taking f : X → Y to hom C (-, f ) : hom C (-, X) → hom C (-, Y ), where hom C (-, f )(e) = f e.</formula><p>Representing objects of a representable functor are unique up to isomorphic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary B.6. Y A ∼ = Y B if and only if</head><formula xml:id="formula_56">A ∼ = B.</formula><p>Morita theory shows that one can study a ring R by investigating the category of all R-modules, all module structures associated to R. Similarly, we study an ML element E using the relations around E by Yoneda Lemma.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Adjoints and Monads</head><formula xml:id="formula_57">→ F C ′ ∈ D 1 there is a unique f * : C → C ′ in C 1 such that D f 3 3 ❈ ❈ ❈ ❈ ❈ ❈ ❈ ❈ u G G F C F f * C f * F C ′ C ′</formula><formula xml:id="formula_58">′ → C ∈ C 1 there is a unique f ♯ : D ′ → D in D 1 making D ′ f ♯ GD ′ Gf ♯ f 3 3 ❈ ❈ ❈ ❈ ❈ ❈ ❈ ❈ D GD v G G C commute.</formula><p>By [ <ref type="bibr" target="#b12">[13]</ref>, p.83, Theorem 2], each adjunction F, G, ϕ : C → D is completely determined by one of five conditions. Here we only record some of them, which we shall use in this thesis:  and so there is an adjunction:</p><formula xml:id="formula_59">f : C → C ′ to GF (f )η C = η C ′ f .</formula><formula xml:id="formula_60">Grph P ath G G Cat. U o o</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Monads</head><p>In algebra, a monoid M is a semigroup with an identity element. It may be viewed as a set with two operations: unit η : 1 → M and composition µ :</p><formula xml:id="formula_61">M × M → M such that M×M×M 1×µ G G µ×1 M×M µ M×M µ G G M and 1×M η×1 G G π2 @ @ ◗ ◗ ◗ ◗ ◗ ◗ ◗ ◗ ◗ ◗ ◗ ◗ ◗ ◗ M×M µ M×1 π1 v v ♠ ♠ ♠ ♠ ♠ ♠ ♠ ♠ ♠ ♠ ♠ ♠ ♠ ♠ 1×η o o M</formula><p>are commutative, where the object 1 is the one-point set {0}, the morphism 1 is an identity map, and where π 1 and π 2 are projections.</p><p>Definition C.1. A monad T = T, η, µ on a category C consists of an endo functor T : C → C and two natural transformations η :</p><formula xml:id="formula_62">I → T, µ : T 2 → T such that T 3 T µ G G µT T 2 µ T 2 µ G G T and IT ηT G G 1 3 3 ❇ ❇ ❇ ❇ ❇ ❇ ❇ ❇ T 2 µ T I T η o o 1 } } ⑤ ⑤ ⑤ ⑤ ⑤ ⑤ ⑤ ⑤ T are commutative, where I : C → C is the identity functor.</formula><p>If F, G; η, ε : C → B is an adjunction, then GF, η, GεF is a monad on C (see <ref type="bibr" target="#b12">[13]</ref>, p.138). In fact, every monad arises this way. 1. Complete Lattices. The P-algebras are free complete lattice: (X, ξ : PX → X) where ξ(S) is the supremum of S ⊆ X and the the maps are maps which preserve arbitrary suprema. for every abelian group A, give a monad (T R , η, µ) on the category Ab of all abelian groups, and Ab TR is the category Mod-R of right R-modules.</p><p>3. U path : Grph → Grph is a monad and Grph Upath ∼ = Cat.</p><p>4. Group Actions. Let G be a group. Then Set TG is the category Set G of G-sets, where the monad T G , η, µ on Set is defined by</p><formula xml:id="formula_63">T G (X) = G × X, η X : X → G × X : x → (1 G , x),</formula><p>and µ X : G × (G × X) → G × X : (g 1 , (g 2 , x)) → (g 1 g 2 , x).</p><p>More generally, every variety of universal algebra is the category of T -algebras over Set, where T X is the the underlying set of the free algebras over X.</p><p>Theorem C.5 (Beck's Theorem, comparison of adjunctions with algebras). Let F, G; η, ε : C → B be an adjunction and T = GF, η, GεF the induced monad. Then there is a unique functor K : B → C T given by KB = GB, Gε B , Kf = Gf : GB, Gε B → GB ′ , Gε B ′ such that G T K = G and KF = F T :</p><formula xml:id="formula_64">B K G G G 1 1 ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ C T G T 5⑤ ⑤ ⑤ ⑤ ⑤ ⑤ ⑤ C F ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ F T b b ⑤ ⑤ ⑤ ⑤ ⑤ ⑤ ⑤ ⑤</formula><p>Proof. See <ref type="bibr" target="#b12">[13]</ref>, pp.142-143.</p><p>Definition C.6. G is monadic (premonadic) if the comparison functor K, defined in Beck's Theorem, is an equivalence of categories (full and faithful).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Descent and Change of Base</head><p>Descent theory plays an important role in the development of modern algebraic geometry by Grothendieck <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. Generally speaking, it deals with the problem of which morphisms in a given "structured" category allow for change of base under minimal loss of information, and how to compensate for the occurring loss, such morphisms are called effective descent morphisms.</p><p>Let C be a category with pullbacks, and let p : E → B be a morphism in C. Then we have the following adjoint pair:</p><formula xml:id="formula_65">C/B p * G G C/E p ! o o</formula><p>where p ! (D, s) = ps, p * (C, r) = π 1 which is given by the following pullback:</p><formula xml:id="formula_66">E×B C π2 G G π1 C r E p G G B</formula><p>The unit and counit of p ! ⊣ p * is given by η(s : </p><formula xml:id="formula_67">C → E) = s,</formula><formula xml:id="formula_68">C/B K G G p * 4 4 ❊ ❊ ❊ ❊ ❊ ❊ ❊ ❊ (C/E) T (p * ) T z z ✈ ✈ ✈ ✈ ✈ ✈ ✈ ✈ ✈ C/E p ! ❊ ❊ ❊ ❊ ❊ ❊ ❊ ❊ (p ! ) T X X ✈ ✈ ✈ ✈ ✈ ✈ ✈ ✈ ✈</formula><p>where T = p * p ! .</p><p>Definition C.7. p : E → B is effective descent (descent) if the comparison functor K, defined in Beck's Theorem, is an equivalence of categories (full and faithful).</p><p>Dually, one has the dual of the above change of base.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>and P :</head><label>:</label><figDesc>Model → Data. Data has a collection of data relations R D = {join, combine, select, merge, join conditions, match, similarity, • • • } and Model a collection of model relations R M = {compose, combine, match, similarity, • • • }, respectively. Choose proper operations or relations R d ∈ R D and R m ∈ R M , based on the problem one wants to solve, so that (Data,R d ) system transformation loop. We shall study when the loop becomes an adjunction and generates new structures in Subsection 4.1. ML systems and transformations arise everywhere. More examples of ML systems and transformations are listed in the following Example 2.7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>4 .</head><label>4</label><figDesc>Recall that Word2vec transformation w2v :W 1 → R n discusedin Example 2.5. If w2v has a left (or right) adjoint L and so it is part of an adjunction to solve the word representation problem, then for each w ∈ W and each v ∈ R n , v → w2v(w) Lv → w , which is natural in w and v. Similarly, the ML system transformation loop (Data,R d ) 2.6 forms an adjunction if and only if for d ∈ Data and m ∈ Model m → M d P m → d , which is natural in d and m or d → P m M d → m , which is natural in d and m.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc>Limits and colimits are an example of universals. Given a category C, an I-indexed diagram in C is a functor D : I → C, where the category I is thought of as index category. A D-cone is a natural transformation φ : L → D, where L : I → C is a constant functor that sends each I-map f : I → J to a constant 1 L : L → L in C 1 . Each D-cone can be specified by a C-object L together with a family of C 1 elements (φ I : L → DI) I∈ob(I) such that Df φ I = φ J :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>commutes in D. Natural transformations are maps between functors. A natural transformation α is called a natural isomorphism, denoted by α :F ∼ = G, if each component α X is an isomorphism.An equivalence between categories C and D is a pair of functors S : C → D and T : D → C together with natural isomorphisms 1 C ∼ = T S and 1 D ∼ = ST .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>C. 1 Adjoints</head><label>1</label><figDesc>Recall that an adjunction from C to D is a triple F, G, ϕ : C → D, where F and G are functors:C F G G D G o oand ϕ is a function which assigns to each pair of objects C ∈ C, D ∈ D a bijection of sets ϕ = ϕ C,D : D(F C, D) ∼ = C(C, GD) which is natural in C and D: F C → D C → GD . If F : C → D is a functor and D ∈ D 0 , a universal arrow from D to F is a pair (C, u) with C ∈ C 0 and u : D → F C being in D 1 such that for each pair (C ′ , f ) with C ′ ∈ C 0 and f : D</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><figDesc>commutes. Equivalently, u : D → F C is universal from D to F provided that the pair (C, u) is an initial object in the comma category (D ↓ F ) that has maps D → F C as its objects.If G : D → C is a functor and C ∈ C 0 , dually, a universal arrow from G to C is a pair (D, v) with D ∈ D 0 and v : GD → C in C 1 such that for each pair (D ′ , f ) with D ′ ∈ D 0 and f : GD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>(ii) The functor G : D → C and for each C ∈ ob(C) a F 0 (C) ∈ ob(C) and a universal arrow η C : C → GF 0 (C) from C to G. Then the functor F has object function F 0 and is given by sending</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>(</head><figDesc>iv) The functor F : C → D and for each D ∈ ob(D) a G 0 (D) ∈ ob(C) and a universal arrow ε D : F G 0 (D) → D from F to D. (v) Functors F, G and natural transformations η : 1 C → GF and ε : F G → 1 D such that Gε • ηG = 1 G and εF • F η = 1 F . Hence we often denote the adjunction F, G, ϕ : C → D by (η, ε) : F ⊣ G : C → D or by F, G, η, ε : C → D. In this case, we say that F is a left adjoint to G or G is a right adjoint to F and that F has a right adjoint G and G has a left adjoint F . We also say that F ⊣ G is an adjoint pair. Given a directed graph G = (N, E), a category C, one has graph homomorphism G → U (C) category functor P ath(G) → C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Definition C. 2 .</head><label>2</label><figDesc>Let T, η, µ be a monad on C, a T -algebra C, ξ is a pair consisting of an object C ∈ C and a map ξ :T C → C in C such that A map f : C, ξ → D, ζ of T -algebras is a map f : C → D of C such thatEvery monad is determined by its T -algebras, as specified by the following theorem: Theorem C.3. If T, η, µ is a monad in C, then all T -algebras and their maps form a category C T , called the Eilenberg-Moore category of the monad T over the category C. There is an adjunction F T , G T ; η T , ε T : C → C T , where G T : C T → C is the obvious forgetful functor and F T is given by Furthermore, η T = η and ε T C,ξ = ξ for each T -algebra C, ξ . The monad defined in C by this adjunction is T, η, µ . Proof. See [13], pp.140-141. Some examples T -algebras are as follows. Example C.4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>2 .</head><label>2</label><figDesc>Modules. Let R be a unital ring. ThenT R (A) = A ⊗ R, η A : A → A ⊗ R : a → a ⊗ 1 and µ A : (A ⊗ R) ⊗ R → A ⊗ R : (a ⊗ r 1 ) ⊗ r 2 → a ⊗ (r 1 r 2 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><figDesc>1 C : C → E × B C and ε(r : C → B) = π 2 , respectively.Applying Beck's Theorem to the adjunction p ! ⊣ p * : C/E → C/B, one has the following commutative diagram</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A graph model of data and workflow provenance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Umut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Buneman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Van Den Bussche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stijn</forename><surname>Kwasnikowska</surname></persName>
		</author>
		<author>
			<persName><surname>Vansummeren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference on the Theory and Practice of Provenance</title>
		<meeting>the 2nd Conference on the Theory and Practice of Provenance</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Abstract and Concrete Categories: The Joy of Cats</title>
		<author>
			<persName><forename type="first">Jirí</forename><surname>Adámek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horst</forename><surname>Herrlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Strecker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Dover Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Swoosh: A generic approach to entity resolution</title>
		<author>
			<persName><forename type="first">O</forename><surname>Benjelloun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Menestrina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB J</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="255" to="276" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Owl2vec*: Embedding of owl ontologies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jimenez-Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Holter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Antonyrajah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Horrocks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1813" to="1845" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Further criteria for totality</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Day</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cahiers de Topologie et Géométrie Différentielle Catégoriques</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="78" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Spivak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05316</idno>
		<ptr target="https://arxiv.org/pdf/1803.05316" />
		<title level="m">Seven Sketches in Compositionality: An Invitation to Applied Category Theory</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Technique de descente et théoremes d&apos;existence en géometrie algébrique, I. Géneralités. Descente par morphismes fidélement plats</title>
		<author>
			<persName><forename type="first">A</forename><surname>Grothendieck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Séminaire Bourbaki</title>
		<imprint>
			<biblScope unit="volume">190</biblScope>
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Grothendieck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Revêtements Etales et Groupe Fondamental (SGA1)</title>
		<title level="s">Lecture Notes in Mathematics</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1971">1971</date>
			<biblScope unit="volume">224</biblScope>
			<biblScope unit="page" from="145" to="194" />
		</imprint>
	</monogr>
	<note>Catégories fibrées et descente, Exposé VI</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Another generic setting for entity resolution: basic theory</title>
		<author>
			<persName><forename type="first">Xiuzhan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Berrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajinkya</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kostya</forename><surname>Belezko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Luo</surname></persName>
		</author>
		<ptr target="https://arxiv.org/pdf/2303.06629" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Transforming geospatial ontologies by homomorphisms</title>
		<author>
			<persName><forename type="first">Xiuzhan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priya</forename><surname>Rangarajan</surname></persName>
		</author>
		<ptr target="https://ceur-ws.org/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Ontology Workshops</title>
		<meeting>the Joint Ontology Workshops</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">3637</biblScope>
		</imprint>
	</monogr>
	<note>CEUR-WS.org</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Uncovering meanings of embeddings via partial orthogonality</title>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryon</forename><surname>Aragam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Veitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="31988" to="32005" />
			<date type="published" when="2023">NeurIPS 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A survey of totality for enriched and ordinary categories</title>
		<author>
			<persName><forename type="first">Max</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cahiers de Topologie et Géométrie Différentielle Catégoriques</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="132" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Mac</forename><surname>Lane</surname></persName>
		</author>
		<title level="m">Categories for the Working Mathematician</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>the Second Edition</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Representing words in a geometric algebra</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mani</surname></persName>
		</author>
		<ptr target="www.pacm.princeton.edu/sites/default/files/pacm_arjunmani2023" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">When is one thing equal to some other thing?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mazur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proof and other dilemmas: Mathematics and philosophy</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="221" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Kai</surname></persName>
		</author>
		<author>
			<persName><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><surname>Greg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781[cs.CL</idno>
		<ptr target="https://arxiv.org/pdf/1301.3781" />
		<title level="m">Efficient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno>CoRR, abs/1310.4546</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chandramohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jaiswal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.05005</idno>
		<ptr target="https://arxiv.org/pdf/1707.05005" />
		<title level="m">Learning distributed representations of graphs</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The family approach to total cocompleteness and toposes</title>
		<author>
			<persName><forename type="first">Ross</forename><surname>Street</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. A. M. S</title>
		<imprint>
			<biblScope unit="volume">284</biblScope>
			<biblScope unit="page" from="355" to="369" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Note on total categories</title>
		<author>
			<persName><forename type="first">Walter</forename><surname>Tholen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of the Australian Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="169" to="173" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the power of foundation models</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International Conference on Machine Learning ICML</title>
		<meeting>the 40th International Conference on Machine Learning ICML</meeting>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="40519" to="40530" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
