<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">When Machine Learning Meets Multiscale Modeling in Chemical Reactions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-06-01">1 Jun 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wuyue</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Liangrong</forename><surname>Peng</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Mathematics and Data Science</orgName>
								<orgName type="institution">Minjiang University</orgName>
								<address>
									<postCode>350108</postCode>
									<settlement>Fuzhou</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yi</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Liu</forename><surname>Hong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhou</forename><surname>Pei-Yuan</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Center for Applied Mathematics</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Tsinghua Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">When Machine Learning Meets Multiscale Modeling in Chemical Reactions</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-06-01">1 Jun 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">59E20844C41B4DF0D97B8EB70EB4C057</idno>
					<idno type="arXiv">arXiv:2006.00700v1[q-bio.MN]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Due to the intrinsic complexity and nonlinearity of chemical reactions, direct applications of traditional machine learning algorithms may face with many difficulties. In this study, through two concrete examples with biological background, we illustrate how the key ideas of multiscale modeling can help to reduce the computational cost of machine learning a lot, as well as how machine learning algorithms perform model reduction automatically in a time-scale separated system. Our study highlights the necessity and effectiveness of an integration of machine learning algorithms and multiscale modeling during the study of chemical reactions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>of machine learning to chemical reactions, including the supervised and unsupervised learning, see e.g. Refs. <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref> .</p><p>The successful attempts of machine-learning-based modeling pave a new way to understand the complicated dynamics of chemical reactions. However, most chemical reactions involve plenty of reactants, multiple potential reaction routines, diverse reaction rates and so on. Without considering the this intrinsic multi-component and multiscale nature of the system, direct applications of machine learning algorithms may face inevitable difficulties (see examples below for details).</p><p>Motivated by the requirements on a real complex system, especially a simultaneous maintenance of the efficiency of macroscopic models and the accuracy of microscopic models, the view of multiscale modeling is introduced. It focuses on a proper separation of the system or phenomenon into several scales with minimum overlap, a correct characterization of the relation between different levels of physical models, as well as a systematical procedure of coarse-graining <ref type="bibr" target="#b14">15</ref> . Multiscale modeling offers a unified way to examine the system of chemical reactions, by looking into the reactions occurring at different time scales and the relations between them. Therefore, it is expected that a proper integration of machine learning algorithms with ideas and methodology of multiscale modeling and analysis will shed some light into this field. And this leads to the major motivation of our current study.</p><p>To be concrete, we will justify our arguments from two aspects: (1) By using the explicit correspondence between mesoscopic chemical master equations and macroscopic mass-action equations in Kurtz's limit, the challenging task of learning detailed probability distribution function (PDF) is converted into learning low-order moments. Obviously, the latter is much easier. In this case, the computational cost of direct machine learning is greatly reduced by incorporating the multiscale modeling. (2) When fast and slow reactions appear simultaneously in the same system, meaning there is a time-scale separation among the chemical reactions, the ODENet -a kind of machine learning algorithms with sparse identification show an astonishing ability of deriving simplified models under Quasi Steady State Approximation (QSSA) automatically. Therefore, machine learning could help to model multiscale chemical reactions too. These two examples clearly demonstrate that machine learning and multiscale modeling are closely related to each other. A proper integration of two approaches will greatly facilitate our study of chemical reactions.</p><p>The whole paper is organized as follows. A basic architecture of the ODENet, a special kind of machine learning algorithms which is designed to derive the explicit form of ODEs from the pregiven time series data, is introduced in Section II. Along with the basic ideas and techniques for multiscale modeling and analysis for chemical reactions, including the Kurtz's limit from chemical master equations to mass-action equations, and the quasi steady-state approximation. In Section III, we illustrate our key ideas through two examples -the development and differentiation of cells, as well as the self-regulatory gene transcription and translation. The usefulness of an integration of machine learning and multiscale modeling could be clear learned. The last section contains some discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Basic Architecture of ODENet</head><p>The ordinary differential equations network was proposed <ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b15">16</ref> as a continuous version of the famous ResNet <ref type="bibr" target="#b16">17</ref> for dealing with time series data modeled by ordinary differential equations (ODEs). Mathematically, the consecutively repeating building blocks -each layer of a residual network can be expressed as y k+1 = y k + f (y k ; θ k ), where y k is the output of k th hidden layer, y k+1 is the output of (k + 1) th hidden layer and f (y k ; θ k ) represents the function of a network layer parameterized by θ k . After a simple algebraic transformation, we can get</p><formula xml:id="formula_0">y k+1 -y k h = f (y k ;θ k ) h , which</formula><p>is the Euler's discretization scheme of ODEs,</p><formula xml:id="formula_1">dy dt = f (y; θ ) h .<label>(1)</label></formula><p>As a consequence, the forward propagation process of a residue network is actually equivalent to the numerical solvation of a group of corresponding ordinary differential equations. Alternatively, it also means if we use an ODE solver to solve the ODEs directly, the process of forward propagation in a residue network is accomplished too. This significant finding lays down the theoretical foundation of ODENet. The application of ODE solvers could easily cope with input data with unequal time intervals, fight against medium-level noises, control the numerical errors and dynamically adjust its convergence criteria.</p><p>To enhance the ability of learning the explicit governing ODEs from the pre-given time series data, in a previous work we combined the ODENet with symbolic regression and sparse identification <ref type="bibr" target="#b3">4</ref> . Symbolic regression means the explicit form of f (y; θ ) is characterized through parameters θ by expanding f (y) on a complete set of orthogonal basis functions Γ(y), i.e. f (y; θ ) = θ Γ(y). Consequently, the learning of ODEs becomes to determine the unknown parameters θ from the data. In practice, polynomials are the most often used basis functions. Sparse identification means in the loss function L, an additional regulation term θ 1 is added in order to remove redundant free parameters θ as many as possible. So that the loss function contains two parts:</p><formula xml:id="formula_2">L = y -y 1 + ε θ 1 .<label>(2)</label></formula><p>The first part controls the difference between the training data y and the predicted data y by ODENet, while the second part aims at a minimal model according to the Occam's razor. Here ε is a hyperparameter. To obtain the optimal parameters θ , the classical Back Propagation (BP) algorithm <ref type="bibr" target="#b17">18</ref> is adopted to make an update, which will be repeated for many iterations until the loss function converges or is less than the threshold. Please see Fig. <ref type="figure" target="#fig_0">1</ref> on the flowchart of ODENet or refer to Ref. <ref type="bibr" target="#b3">4</ref> for further details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multiscale Modeling of Chemical Reactions</head><p>Without loss of generality, we consider a chemical system with N species and M reactions <ref type="bibr" target="#b18">19</ref> ,</p><formula xml:id="formula_3">ν 1 j S 1 + ν 2 j S 2 + • • • + ν N j S N k j -→ ν 1 j S 1 + ν 2 j S 2 + • • • + ν N j S N , j = 1, 2, • • • , M,<label>(3)</label></formula><p>where k j &gt; 0 denotes the rate constant of the reaction j. The nonnegative integers {ν i j } and {ν i j } denote the stoichiometric coefficients of the reactants and products respectively. The stoichiometric matrix is introduced as U = [(u i j )] N×M with elements being u i j = ν i jν i j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Chemical Master Equations</head><p>We focus on the molecular number of species (S 1 , S 2 , • • • , S N ) represented by a stochas-</p><formula xml:id="formula_4">tic variable n = (n 1 , n 2 , • • • , n N ) T in a reaction vessel of volume V . When the magnitude of (n 1 , n 2 , • • • , n N )</formula><p>T is relatively small compared with the Avogadro's constant, the randomness comes into play due to the intrinsic stochasticity of molecular collisions. From the perspective of ensemble average, we can denote the probability of the system in the state n by p(n,t), where the time-dependence is usually omitted as p(n).</p><p>With respect to the reactions in (3), the probability distribution obeys the following chemical master equations (CMEs), in a compact form as,</p><formula xml:id="formula_5">d dt p(n) = M ∑ j=1 p(n -u j )Φ j (n -u j ) -p(n)Φ j (n) ,<label>(4)</label></formula><p>accompanied by the initial condition p(n)| t=0 = p 0 (n). Here u j is the j-th column of stoichiomet-</p><formula xml:id="formula_6">ric matrix U = (u 1 , u 2 , • • • , u M )</formula><p>, and Φ j (n) is the mesoscopic propensity function characterizing the probability Φ j (n)dt for which the j-th reaction occurs once within the time interval [t,t + dt).</p><p>In general, the state-dependent mesoscopic propensity function Φ j (n) of CMEs is assumed to follow the laws of mass-action,</p><formula xml:id="formula_7">Φ j (n) = k j V N ∏ l=1 V -ν l j C ν l j n l ,<label>(5)</label></formula><p>which is the product of molecular number in a polynomial form and the rate coefficient k j for</p><formula xml:id="formula_8">n l ≥ ν l j , ∀l = 1, 2, • • • , N.</formula><p>When there are not enough particles to form a reactant, saying S l , such that n l &lt; ν l j , the propensity reduces to zero, Φ j (n) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Stochastic Simulations</head><p>In most cases, the chemical master equations in ( <ref type="formula" target="#formula_5">4</ref>) are a huge group of ordinary differential equations, which are quite computational consuming. Alternative efficient sampling algorithms are needed. The Gillespie algorithm (GA) <ref type="bibr" target="#b19">20</ref> , which is able to generate typical time evolutionary trajectories of species according to the reaction mechanisms and reaction rates in a stochastic way, maybe the most famous one.</p><p>Gillespie implemented two stochastic simulation algorithms. The one is the direct method (DM) and the other is the first-reaction method (FRM). These two methods are theoretically equivalent, so we here only implement the first reaction method. The FRM generates putative time for every reaction and chooses a time at which the corresponding reaction would occur while no other reaction occurred before that.</p><p>By independently running the Gillespie algorithm once and again, statistics on the corresponding stochastic trajectories will converge to the corrected probability distribution given by the chemical master equations. They constitute the training data set to feed into the machine learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Moment-Closure Equations in Kurtz's Limit</head><p>Although CMEs provide a relatively accurate way to model general chemical reaction systems, it leads to a heavy burden in both modeling and experiments since the dimensionality of the transition matrix is usually extremely high. Moreover, the time-consuming numerical simulation of CMEs becomes a common bottleneck when the number of species or reactions is large. In order to make a simplification, we turn to look at the mean density of species,</p><formula xml:id="formula_9">c i = ∑ n V -1 n i p(n),<label>(6)</label></formula><p>when the molecular number of reactants becomes large.</p><p>To deduce the macroscopic kinetics of the concentration c i , we multiply (4) by the number density V -1 n i and take the summation over all admissible state {n} on both sides, which yields,</p><formula xml:id="formula_10">d dt ∑ n V -1 n i p(n) = M ∑ j=1 ∑ n V -1 n i p(n -u j )Φ j (n -u j ) -p(n)Φ j (n) = M ∑ j=1 u i j ∑ n V -1 p(n)Φ j (n) ,<label>(7)</label></formula><p>where in the last step we have used the variable substitution nu j = n and have neglected the boundary terms. Direct calculation shows that the volume density of mesoscopic propensity func-</p><formula xml:id="formula_11">tion deduces, V -1 Φ j (n) = φ j (V -1 n) + O(V -1</formula><p>), with φ j (c) = k j ∏ N l=1 c l ν l j /ν l j ! being the usual macroscopic propensity function.</p><p>Taking the limit of V → +∞, n → +∞ while keeping V -1 n finite, we have the following massaction equations (MAEs)</p><formula xml:id="formula_12">d dt c i (t) = M ∑ j=1 (ν i j -ν i j )φ j (c),<label>(8)</label></formula><p>on a nonnegative continuous state space {c|c ∈ R N ≥0 }. The MAEs in ( <ref type="formula" target="#formula_12">8</ref>) is the macroscopic description derived from the mesoscopic CMEs of the reaction system (3). A rigorous mathematical justification of the above limit process was first done by Kurtz in the 1970s <ref type="bibr" target="#b20">21</ref> . Similar procedure can be carried out for high-order moments of PDF, like the second-order variance studied in the first example in Section III.</p><p>Remark II.1 According to the results proved by Kurtz <ref type="bibr" target="#b20">21</ref> , in the limit of V → +∞, for any finite time the solution of CMEs in (4) will converge in probability to the solution of the corresponding MAEs in (8), provided the initial conditions lim V →+∞ V -1 n(t = 0) = c(t = 0), which is a straightforward consequence of the Central Limit Theorem. Our derivation above from the CMEs in (4)   to MAEs in (8) for the reaction system (3) serves as a formal illustration of Kurtz's theorem. </p><formula xml:id="formula_13">1 ε dB dt = G(A, B),<label>(9)</label></formula><p>where A and B respectively stand for slow and fast variables after some kind of proper nondimensionalization. ε 1 is a small parameter characterizing the gap between fast and slow time scales in the dynamics.</p><p>With respect to above dynamics, QSSA states that in the slow time scale dominated by the changes in A, B can be regarded as remaining at a dynamically equilibrium state (quasi steady state) due to their fast reactive nature, meaning approximately we have G(A, B) = 0. If B can be uniquely solved from this algebraic relation, i.e. B = g(A), the original time-scale separated dynamics could be simplified as</p><formula xml:id="formula_14">dA dt = F(A, g(A)), B = g(A).<label>(10)</label></formula><p>QSSA is a very classical model reduction approach and has been widely used in the study of chemical reactions, see e.g. Ref. <ref type="bibr" target="#b21">22</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RESULTS AND DISCUSSION</head><p>In this section, through two concrete examples -the single proliferative compartment model (SPCM) of IFE (interfollicular epidermis) maintenance as well as a gene network with autoregulatory negative feedback, we are going to show how machine learning and multiscale modeling help each other in the study of chemical reactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Single Proliferative Compartment Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">The Basic Model</head><p>In the first example, the SPCM of IFE maintenance considered by Clayton et al. <ref type="bibr" target="#b22">23</ref> is adopted to illustrate how multiscale modeling helps to reduce the computational cost of machine learning during inferring the detailed reaction mechanisms and reaction rates. According to the observations by Clayton et al. <ref type="bibr" target="#b22">23</ref> , the clone fate of proliferating epidermal progenitor cells (EPCs) plays an essential role in adult epidermal homeostasis. And the key clone size distribution is modeled by chemical master equations, whose explicit forms are the major goal of machine learning. By taking the explicit correspondence between mesoscopic chemical master equations and macroscopic mass-action equations in the Kurtz's limit, the challenging task of learning detailed probability distribution function is converted into learning low-order moments. Obviously, the latter is much easier. A similar idea has been previously applied by one of the authors to investigate the kinetics of amyloid aggregation, but without referring to machine learning <ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25</ref> .</p><p>Consider two reactant species in the single-proliferative compartment model, including proliferating EPCs (denoted as A) and post-mitotic cells in the basal layer (B). There are four reactions which involve symmetric cell division and asymmetric cell division. As shown in Fig. <ref type="figure" target="#fig_2">2a</ref> With respect to the SPCM and coefficients given in Fig. <ref type="figure" target="#fig_2">2</ref>, 10 6 times independent stochastic simulations are performed by using the Gillespie algorithm. They constitute the training data set to feed into our following ODENet-based machine learning procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Learning Mass-Action Equations by ODENet</head><p>Here our major goal is to obtain the SPCM in Fig. <ref type="figure" target="#fig_2">2a</ref> and the explicit rate constants. However, </p><formula xml:id="formula_15">     d n A dt = α 11 n A + α 12 n B + α 13 n A 2 + α 14 n A n B + α 15 n B 2 , d n B dt = α 21 n A + α 22 n B + α 23 n A 2 + α 24 n A n B + α 25 n B 2 . (<label>11</label></formula><formula xml:id="formula_16">)</formula><p>Now we implement the ODENet to learn the dynamics in (11). Clearly, not all reaction rate constants will appear in the final model. Those redundant coefficients will be picked out by ODENet and removed through sparse identification. After training and regression, only three non-zero coefficients α 11 = 0.0079, α 21 = 1.0903 and α 22 = -0.3094 are kept in the final results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Learning High-Order Moment Equations</head><p>During the learning procedure of ODENet, since all coefficients in front of quadratic terms in (11) are removed, we can make a conclusion that only first-order reactions are present in the current system. Then with respect to above learned dynamics and coefficients, the desired single</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Deriving Chemical Master equations</head><p>The relations among desired rate constants k 1 , k 2 , r 1 , r 2 , λ , Γ and those learned parameters α's and β 's are stated through the following matrix, i.e.</p><formula xml:id="formula_17">                         1 -1 -1 -1 0 0 -1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 2 -2 -2 -2 0 0 -1 3 0 1 1 0 0 0 0 0 0 1 0 2 0 1 0 0 -1 1 0 1 1 0 1 -1 -1 -1 0 -1                          V              r 1 λ r 2 λ k 1 k 2 λ Γ              û =                          α 11 α 21 -α 22 β 11 β 12 β 21 β 22 -β 31 β 32 β 33                          b .<label>(14)</label></formula><p>Direct calculations show that the rank of the augmented matrix (rank(V | b) = 7) is larger than that of the coefficient matrix (rank(V ) = 6), meaning the linear equations in ( <ref type="formula" target="#formula_17">14</ref>) constitute an overdetermined system, which can be solved through the Least Square Method. The unique leastsquare solution is given by û = V T V -1 V T b, whose relative errors with respect to the true values are less than 8%.</p><p>Parameters</p><formula xml:id="formula_18">k 1 k 2 r 1 r 2 λ Γ</formula><p>true value 0 0 0.0836 0.0764 1.1 0.31 learned value 0.0123 -0.0197 0.0831 0.0824 1.1059 0.3074 relative errors ∼ ∼ 0.60% 7.85% 0.54% 0.84% TABLE I. Comparison on the learned rate constants for (12) by ODENet with the true values.</p><p>Even though k 1 and k 2 are not exactly identified as zero, their values are about one order of magnitude smaller than the others. In this sense, we have successful reconstructed the original SPCM based on the stochastic time trajectories of n A and n B in the training data set. As further validated in Fig. <ref type="figure" target="#fig_4">3</ref>, the joint probability distribution of the desired single-proliferative compartment model is honestly reproduced (see SI for the marginal probability distribution), which highlights the efficiency and effectiveness of our integrated approach of ODENet with multiscale modeling during the study of chemical reactions. B. A Gene Network with Autoregulatory Negative Feedback</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">The Basic Model</head><p>In the second example, we plan to show how machine learning can be used for model reduction, an important aspect of multiscale modeling with vast applications in chemical reactions. To illustrate our ideas, let us consider a gene network with autoregulatory negative feedback, which includes five reactants -the gene (G), mRNA (M), protein (P), and two gene-protein complexes (GP, GP 2 ). Among them, there are eight reactions (see Fig. <ref type="figure" target="#fig_5">4a</ref>). k 0 , k s , k dm are rate constants of transcription from the gene G, translation into the protein P, and mRNA degradation, respectively.</p><p>The gene can bind with either one or two proteins, whose forward and backward reaction rate constants are denoted as k 1 , k -1 , k 2 and k -2 separately. Furthermore, it is assumed that GP produces mRNA at the same rate k 0 as the transcription rate of G alone. Macroscopically, the gene network in Fig. <ref type="figure" target="#fig_5">4a</ref> is described by chemical mass-action equations,</p><formula xml:id="formula_19">                             d dt c P = k s c M -k 1 c G c P + k -1 c GP -k 2 c P c GP + k -2 c GP 2 , d dt c M = k 0 c G + k 0 c GP -k dM c M , d dt c G = -k 1 c G c P + k -1 c GP , d dt c GP = k 1 c G c P -k -1 c GP -k 2 c P c GP + k -2 c GP 2 , d dt c GP 2 = k 2 c P c GP -k -2 c GP 2 .<label>(15)</label></formula><p>It is noted that the total gene concentration is a constant due to the conservation law, i.e. c G + c GP + c GP 2 = c total . To produce a time-scale separation of reactions, we choose </p><formula xml:id="formula_20">k 1 = 3, k -1 = 2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Model Reduction by ODENet</head><p>Due to the existence of time-scale separation, it is possible to make a simplification of the reaction system in (15). Classically, this is done by analytical methods, like Quasi Steady-State Assumption and Partial Equilibrium Assumption <ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26</ref> . Here, we are going to show how the simplification procedure can be carried out automatically by ODENet.</p><p>Pearson's coefficient dc P /dt dc M /dt dc G /dt dc GP /dt dc GP 2 /dt dc P /dt 1 0.9681 0.5020 0.4228 0.4215 dc M /dt 1 0.2743 0.1832 0.1820 dc G /dt 1 0.9892 0.9812 dc GP /dt 1 0.9956 dc GP 2 /dt 1 TABLE II. Pearson's correlation coefficients among time derivatives of five concentration variables in (15). At the first step, with the help of traditional classification algorithms, like the correlation analysis based on the Pearson's coefficient between concentration derivatives (see Table. II), the fast and slow variables can be easily separated into two groups. Inspired by the classical results of Michaelis-Menton kinetics, we suppose three fast variables c G , c GP , c GP 2 (see Fig. 4b-4e) are characterized by fractional functions, whose numerator and denominator are polynomials of c P (up to the second-order in the current study). In contrast, c M does not appear in the fractional functions, since the last three formulas in (15) contain no terms of c M . Consequently, the simplified model we are seeking for is given by</p><formula xml:id="formula_21">                     d dt c P = k s c M -k 1 c P H (c G ) + k -1 H (c GP ) -k 2 c P H (c GP ) + k -2 H (c GP 2 ), d dt c M = -k dM c M + k 0 H (c G ) + k 0 H (c GP ) , H (c G ) = Ω 1 Ω , H (c GP ) = Ω 2 Ω , H (c GP 2 ) = Ω 3 Ω ,<label>(16)</label></formula><p>where</p><formula xml:id="formula_22">Ω = β 1 + β 2 c p + β 3 c 2 P , Ω 1 =</formula><p>α 11 + α 21 c P + α 31 c 2 P , Ω 2 = α 12 + α 22 c P + α 32 c 2 P , Ω 3 = α 13 + α 23 c P + α 33 c 2 P . Parameters β 1 β 2 β 3 α 11 α 21 α 31 QSSA 0.53 0.67 1 0.0159 0 0 ODENet 0.54 0.66 1 0.0163 0 0 Relative error 1.89% 1.49% ∼ 2.52% ∼ ∼ α 12 α 22 α 32 α 13 α 23 α 33 QSSA 0 0.0201 0 0 0 0.03 ODENet 0 0.020 0 0 0 0.03 Relative error ∼ 0.50% ∼ ∼ ∼ 0% TABLE III. Comparison on the learned parameters for (16) by ODENet with those by QSSA. All values are normalized by β 3 . β 1 , • • • , β 3 and α 11 , • • • , α 33 are twelve free parameters to be specified. As summarized in Table.</p><p>III, the simplified model learned by ODENet is very close to that by QSSA (see next section). In particular, terms of α 21 c P , α 31 c 2 P , α 12 , α 32 c 2 P , α 13 and α 23 c P are removed by sparse identification during the learning procedure. A major difference between two simplification methods lies in the extra four underlined terms on the right-hand side of the first formula in (16). In QSSA, these four terms are exactly cancelled by each other. While during the simplification procedure aided by ODENet, we can only conclude that their sum is quite small instead of exactly zero (see SI).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Comparison with QSSA</head><p>Our above ODENet aided model reduction is consistent with the classical quasi steady-state approximation. Since G, GP, GP 2 are considered as the fast intermediates, in contrast to the slow species P and M, a direct application of QSSA to (15) leads to</p><formula xml:id="formula_23">c G c total = K 3 Ω , c GP c total = K 2 c P Ω , c GP 2 c total = c P 2 Ω ,<label>(17)</label></formula><p>where </p><formula xml:id="formula_24">Ω = K 3 + K 2 c P + c P 2 , K 1 = k -1 /k 1 , K 2 = k -2 /k 2 , K 3 = k -1 k -2 /(k 1 k 2 )</formula><p>which has been used to evaluate the performance of our ODENet aided model reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>Nowadays, various machine learning algorithms, like deep learning and reinforcement learning, have found their applications in diverse fields with great success. While in the field of chemical reactions, related studies begin to emerge, yet are still quite few. In the current paper, through two concrete biochemical examples, the single proliferative compartment model and a gene network with autoregulatory negative feedback, we present our key ideas on how machine learning and multiscale modeling can help each other during the study of chemical reactions. And, as we believe, an effective integration of two approaches will be crucial for the success of related studies in this direction.</p><p>Potential generalizations of our current work include but are not limited to:</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIG. 1 .</head><label>1</label><figDesc>FIG. 1. An integration of ODENet with multi-scale modeling in the study of chemical reactions. The upper panel illustrates the ODENet-based learning procedure of reaction mechanism under the help of multiscale modeling, while the lower panel gives the automatic procedure for model reduction aided by ODENet. The flowchart of ODENet is shown in the middle.</figDesc><graphic coords="5,72.00,71.99,466.24,430.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>C</head><figDesc>. Model Reduction by QSSA Consider a very general chemical reaction system with time scale separation, which is written in an abstract matrix form,      dA dt = F(A, B),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIG. 2 .</head><label>2</label><figDesc>FIG. 2. Single proliferative compartment model. (a)The mechanism of single proliferative compartment model. EPCs (red circles) have an unlimited self-division potential to maintain the epidermis at a rate of r 1 λ . Proliferating EPCs cells divide into two post mitotic basal cells (blue stars) at a rate of r 2 λ . Asymmetric divisions of EPCs into itself and post mitotic basal cells are at a rate of 1 -(r 1 + r 2 )λ . After mitosis in the basal layer, the post mitotic basal cells leak at a rate of Γ. k 1 and k 2 represent the rate constants for two additional possible reactions inferred by the ODENet. 10 typical stochastic trajectories for (b) n A and (c) n B are generated by GA. The learned results of ODENet are compared with the training data generated by GA on the (d) average and (e) variance of cell numbers. Here the rate constants in SPCM are set as λ = 1.1, r 1 = 0.0836, r 2 = 0.0764, Γ = 0.31 per week in accordance with<ref type="bibr" target="#b22">23</ref> . The initial PDF is taken as a delta distribution with p 0 (10, 0) = 1.</figDesc><graphic coords="10,72.00,286.36,466.26,217.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>a</head><figDesc>direct application of ODENet to learn the time evolution of p(n A , n B ) (or the chemical master equations) from the training data generated by stochastic simulations is prohibited due to heavy computational cost. Therefore, by taking advantage of the knowledge of multiscale modeling in chemical reactions, especially the explicit correspondence between mesoscopic chemical master equations and macroscopic mass-action equations in the Kurtz's limit, we turn to learn low-order moments instead of the probability distribution function governed by chemical mass-action equations.With respect to training data of nA = ∑ n A p (n A , n B ) and n B = ∑ n B p (n A , n B) by averaging the stochastic trajectories generated through Gillespie algorithms, we need to determine the exact types of chemical reactions involving with these two reactants, their reaction orders and reaction rate constants. Without loss of generality, here we make a cutoff on the chemical reactions up to the second order, corresponding to a combination of A, B, A + A, A + B, B + B, which reads</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIG. 3 .</head><label>3</label><figDesc>FIG. 3. Comparison of PDF generated by GA with the learned results of ODENet. Joint probability distributions p(n A , n B ) are shown in (a,e) 1, (b,f) 5, (c,g) 10 and (d,h) 20 weeks respectively.</figDesc><graphic coords="14,72.00,177.93,466.25,184.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>FIG. 4 .</head><label>4</label><figDesc>FIG. 4. Validation of ODENet aided model reduction. (a) A cartoon illustration of the gene network with negative feedback, including transcription, translation, degradation and a negative feedback loop. Predictions of the reduced model in (16) (blue crosses) are compared with the original model in (15) (red solid lines) on concentrations of (b) protein and mRNA in the slow time scale, and (c) gene and (d-e) gene-protein complexes in the fast time scale.</figDesc><graphic coords="15,95.31,72.00,419.62,419.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>4 ,k 2</head><label>42</label><figDesc>= 9, k -2 = 6, k 0 = 0.05, k s = 0.01, k dm = 0.01, meaning the concentrations of G, GP, GP 2 can quickly reach dynamical balance in comparison with those of mRNA and protein. The initial conditions are set as c G = c GP = c GP 2 = 0.01, c P = 0, c M = 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>, andc total = c G + c GP + c GP 2 is a constant.The corresponding reduced equations are-k dM c M + k 0 (K 3 + K 2 c P )c total /Ω,</figDesc></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>proliferative compartment model as shown in Fig. <ref type="figure">2a</ref> is reconstructed by ODENet. However, the existence of two additional reactions, A k 1 -→ φ and A k 2 -→ B (see orange box in Fig. <ref type="figure">2a</ref>) could not be excluded in principle, which means at the moment the probability distribution of A-type and B-type cells follows</p><p>Here the same notations are borrowed just for simplicity. It should be noted that at the moment we still have no precise knowledge on all six reaction rate constants k 1 , k 2 , r 1 , r 2 , λ and Γ.</p><p>To determine the unknown coefficients, we further go to the second-order of PDF, the variance of cell numbers to be exact. Based on (12), the first-order (average) and second-order moments (variance) of n A and n B evolve according to</p><p>where</p><p>. Furthermore, we have Sample title</p><p>(1) The spacial heterogeneity of chemical reactions. In the current study, all reactions are assumed to proceed under well-mixed conditions, which means we can adopt a relatively simple ODE-based description. However, it is well-known the spacial heterogeneity can produce far more complicated and also interesting phenomena <ref type="bibr" target="#b0">1</ref> , like the Turing pattern, phase separation, active matter, etc. So how to generalize our results to PDEs would be of general interest. Recently, PDE-based machine learning algorithms <ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28</ref> shed light on this aspect.</p><p>(2) Bistability, oscillation, bifurcation of chemical reactions. Even restricted to ODEs, a chemical reaction system can possess very complex dynamical behaviors, like bistability, oscillation, bifurcation, blow-up, etc., than one can imagine <ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30</ref> . In the presence of noise, the situation becomes even more complicated. The high-nonlinearity of chemical reactions puts forward great challenges to our ODENet-based model derivation and model reduction.</p><p>(3) Extension to other model reduction methods. Here we test the possibility and accuracy of ODENet aided model reduction with respect to the QSSA method. Extension of our ideas to partial equilibrium approximation <ref type="bibr" target="#b25">26</ref> , maximum entropy principle <ref type="bibr" target="#b30">31</ref> , maximal likelihood estimation <ref type="bibr" target="#b31">32</ref> , as well as other statistics or probability based approximations would be worthy of further studies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AIP PUBLISHING DATA SHARING POLICY</head><p>All the data in this paper which support the findings of this study are available from the corresponding author upon reasonable request.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Janos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Peter</surname></persName>
		</author>
		<title level="m">Mathematical Models of Chemical Reactions: Theory and Applications of Deterministic and Stochastic Models</title>
		<meeting><address><addrLine>Princeton</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Quantum chemistry</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.pc.26.100175.000351</idno>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Physical Chemistry</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="39" to="57" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Inferring biological networks by sparse identification of nonlinear dynamics</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Mangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Brunton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Proctor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Kutz</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMBMC.2016.2633265</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Molecular, Biological and Multi-Scale Communications</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="52" to="63" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Revealing hidden dynamics from time-series data by odenet</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04849</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning chemical reaction networks from trajectory data</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Conrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schütte</surname></persName>
		</author>
		<idno type="DOI">10.1137/19M1265880</idno>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Applied Dynamical Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<date type="published" when="2000">2000-2046 (2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A machine learning approach to predict metabolic pathway dynamics from time-series multiomics data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Martin</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41540-018-0054-3</idno>
	</analytic>
	<monogr>
		<title level="j">NPJ Systems Biology and Applications</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Prediction of amyloid aggregation rates by machine learning and feature selection</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.5113848</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page">84106</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to predict chemical reactions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Kayala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-A</forename><surname>Azencott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<idno type="DOI">10.1021/ci200207y</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="2209" to="2222" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Revisiting the gaussian process regression for fitting highdimensional potential energy surface and its application to the OH + HO 2 -→ O 2 + H 2 O reaction</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.5143544</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="page">134309</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reverse engineering and identification in systems biology: strategies, perspectives and challenges</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Villaverde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Banga</surname></persName>
		</author>
		<idno type="DOI">10.1098/rsif.2013.0505</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Society Interface</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">20130505</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Discovering governing equations from data by sparse identification of nonlinear dynamical systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Brunton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Proctor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Kutz</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1517384113</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="3932" to="3937" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sparse learning of stochastic dynamical equations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Boninsegna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nüske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clementi</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.5018409</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page">241723</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust approaches to generating reliable predictive models in systems biology</title>
		<author>
			<persName><forename type="first">K</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-92967-5_15</idno>
	</analytic>
	<monogr>
		<title level="m">Systems Biology. RNA Technologies</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Rajewsky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Jurga</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Barciszewski</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="301" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automated adaptive inference of phenomenological dynamical models</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Daniels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nemenman</surname></persName>
		</author>
		<idno type="DOI">10.1038/ncomms9133</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">8133</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Weinan</surname></persName>
		</author>
		<title level="m">Principles of Multiscale Modeling</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural ordinary differential equations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="6571" to="6583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>CVPR</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Backpropagation applied to handwritten zip code recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1989.1.4.541</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Analysis of complex reaction networks</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Othmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes, School of Mathematics</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Minnesota</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exact stochastic simulation of coupled chemical reactions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Gillespie</surname></persName>
		</author>
		<idno type="DOI">10.1021/j100540a008</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Physical Chemistry</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="2340" to="2361" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The relationship between stochastic and deterministic models for chemical reactions</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Kurtz</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.1678692</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="2976" to="2978" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The quasi-steady-state assumption: A case study in perturbation</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Segel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Slemrod</surname></persName>
		</author>
		<idno type="DOI">10.1137/1031091</idno>
	</analytic>
	<monogr>
		<title level="j">Siam Review</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="446" to="477" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A single type of progenitor cell maintains normal epidermis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Doupé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Winton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Simons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature05574</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">446</biblScope>
			<biblScope unit="page" from="185" to="189" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Simple moment-closure model for the self-assembly of breakable amyloid filaments</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-A</forename><surname>Yong</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bpj.2012.12.039</idno>
	</analytic>
	<monogr>
		<title level="j">Biophysical Journal</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="533" to="540" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Modeling fibril fragmentation in real-time</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.4819025</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page">84904</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Partial equilibrium approximations in apoptosis. ii. the death-inducing signaling complex subsystem</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Yong</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.mbs.2015.10.009</idno>
	</analytic>
	<monogr>
		<title level="j">Mathematical Biosciences</title>
		<imprint>
			<biblScope unit="volume">270</biblScope>
			<biblScope unit="page" from="126" to="134" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Data-driven discovery of partial differential equations</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Rudy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Brunton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Proctor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Kutz</surname></persName>
		</author>
		<idno type="DOI">10.1126/sciadv.1602614</idno>
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1602614</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Numerical gaussian processes for time-dependent and nonlinear partial differential equations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Raissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karniadakis</surname></persName>
		</author>
		<idno type="DOI">10.1137/17M1120762</idno>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="172" to="A198" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stochastic bifurcation, slow fluctuations, and bistability as an origin of biochemical complexity</title>
		<author>
			<persName><forename type="first">H</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<idno type="DOI">10.1039/B900335P</idno>
	</analytic>
	<monogr>
		<title level="j">Physical Chemistry Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">4861</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stochastic bistability and bifurcation in a mesoscopic signaling system with autocatalytic kinase</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qian</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bpj.2009.09.055</idno>
	</analytic>
	<monogr>
		<title level="j">Biophysical journal</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Information theory and statistical mechanics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Jaynes</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRev.106.620</idno>
	</analytic>
	<monogr>
		<title level="j">Physical Review</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">620</biblScope>
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Overview of maximum likelihood estimation</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Harrell</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-19425-7_9</idno>
	</analytic>
	<monogr>
		<title level="m">Regression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="181" to="217" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
