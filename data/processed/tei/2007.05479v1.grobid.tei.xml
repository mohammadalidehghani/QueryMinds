<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Impact of Legal Requirements on Explainability in Machine Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-07-10">10 Jul 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Adrien</forename><surname>Bibal</surname></persName>
							<email>&lt;adrien.bibal@unaur.be&gt;</email>
							<affiliation key="aff0">
								<orgName type="institution">Legal Requirements on Explainability * Equal contribution</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">PReCISE</orgName>
								<orgName type="department" key="dep2">Faculty of Computer Sci- ence</orgName>
								<orgName type="institution" key="instit1">NADI</orgName>
								<orgName type="institution" key="instit2">University of Namur</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Lognoul</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Law</orgName>
								<orgName type="laboratory">CRIDS</orgName>
								<orgName type="institution" key="instit1">NADI</orgName>
								<orgName type="institution" key="instit2">University of Namur</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>De Streel</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Law</orgName>
								<orgName type="laboratory">CRIDS</orgName>
								<orgName type="institution" key="instit1">NADI</orgName>
								<orgName type="institution" key="instit2">University of Namur</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benoît</forename><surname>Frénay</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Legal Requirements on Explainability * Equal contribution</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">PReCISE</orgName>
								<orgName type="department" key="dep2">Faculty of Computer Sci- ence</orgName>
								<orgName type="institution" key="instit1">NADI</orgName>
								<orgName type="institution" key="instit2">University of Namur</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Impact of Legal Requirements on Explainability in Machine Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-07-10">10 Jul 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">C1DC7AFB250A5F347E616B699920E15B</idno>
					<idno type="arXiv">arXiv:2007.05479v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The requirements on explainability imposed by European laws and their implications for machine learning (ML) models are not always clear. In that perspective, our research <ref type="bibr">(Bibal et al., Forthcoming)</ref> analyzes explanation obligations imposed for private and public decisionmaking, and how they can be implemented by machine learning techniques.</p><p>For decisions adopted by firms or individuals, we mainly focus on requirements imposed by general European legislation applicable to all the sectors of the economy. The obligations of the General Data Protection Regulation (GDPR) <ref type="bibr">(art. 13-15 and 22)</ref> as interpreted by the European Data Protection Board (EDPB) require the processors of personal data to provide "the rationale behind or the criteria relied on in reaching the decision," under certain circumstances, when a fully automated decision is made (EDPB Guidelines of 3 October 2017 on Automated individual decisionmaking and Profiling, p. 25; see also <ref type="bibr" target="#b2">(Edwards &amp; Veale, 2018;</ref><ref type="bibr" target="#b7">Wachter et al., 2017)</ref>). Consumer protection law imposes to online marketplaces to provide their consumers with "the main parameters determining ranking [...] and the relative importance of those parameters" (art. 6(a) of Directive 2011/83). The Online Platforms Regulation imposes very similar obligations to online intermediation services and search engines towards their professional users (art. 5 of Regulation 2019/1150).</p><p>Sectoral rules are also analyzed. For instance, financial regulators "may require the investment firm to provide [...] a description of the nature of its algorithmic trading strategies, details of the trading parameters or limits to which the system is subject, the key compliance and risk controls that it has in place <ref type="bibr">[...]</ref>. The competent authority [...] may, at any time, request further information from an investment firm about its algorithmic trading and the systems used for that trading" (art. 17 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Financial Instruments).</head><p>For decisions adopted by public authorities, two stronger requirements are studied: motivation obligations for administrations and for judges (imposed by European Convention on Human Rights). For administrative decisions, all factual and legal grounds on which the decision is based should be provided. For judicial decisions, judges have in addition to answer the arguments made by the parties in the litigation.</p><p>The objectives of those explanation requirements are twofold: first, allowing the recipients of a decision to understand it and act accordingly; second, allowing the public authority, before which a decision is contested, to exercise a meaningful effective control on the legality of the decision (European Commission White Paper of 19 February 2020 on Artificial Intelligence, p. 14).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Legal Requirements and Machine Learning</head><p>As explained in the previous section, legal texts do not always clearly identify the focus of the requirements. In private decision making, we identified that the explainability of four levels of machine learning entities or concepts are mentioned in legal texts <ref type="bibr">(Bibal et al., Forthcoming)</ref>: the main features used for a decision, all features used for a decision, how the features are combined for reaching a decision and the whole model (see Table <ref type="table">1</ref>).</p><p>The first and weaker level of requirements is to provide the main features used for a decision. Note that the main parameters mentioned in the legal texts refer to the features used by a ML model. While the main features used are natively provided by interpretable models such as linear models and decision trees, some works go further and provide weakly and strongly relevant features in linear models <ref type="bibr" target="#b4">(John et al., 1994;</ref><ref type="bibr" target="#b5">Kohavi &amp; John, 1997)</ref>. In the context of black-box models, the feature importance provided by the out-of-bag error of random forests can pass these requirements, as well as the feature importance provided through the perturbation of input feature values <ref type="bibr" target="#b3">(Fisher et al., 2019)</ref>.</p><p>The second level of requirements is to provide all features involved in a decision. While providing all features used is again natively proposed by interpretable models, this requirement can be difficult to achieve when the number of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main features</head><p>• Directive 2011/83 on Consumer Rights, art. 6(a): obligation to provide the "main parameters" and their "relative importance" • Regulation 2019/1150 on promoting fairness and transparency for business users of online intermediation services, art. 5: obligation to provide "the main parameters" and "the relative importance of those parameters"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>All features</head><p>• Guidelines on automated individual decision-making and profiling: obligation to provide "the criteria relied on in reaching the decision" • Belgian law of 4 April 2014 on insurances, art. 46: obligation to provide "the segmentation criteria"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Combination of features</head><p>Guidelines on Automated individual decision-making and Profiling: obligation to provide "the rationale behind the decision"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Whole model</head><p>Directive 2014/65 on Markets in Financial Instruments, art. 17: obligation to provide "information [...] about its algorithmic trading and the systems used for that trading" Table <ref type="table">1</ref>.</p><p>Table reproduced from (Bibal et al., Forthcoming) containing the legal texts used as examples in this paper.</p><p>features used by the model is huge. Sparsity penalties such as Lasso may be necessary to satisfy the requirement.</p><p>The third level of explainability requirements is to provide the combination of features that led to a particular decision. Again, interpretable models make it possible to check how the features have been combined to lead to a decision. In the context of black-box models, techniques like LIME <ref type="bibr" target="#b6">(Ribeiro et al., 2016)</ref> have been developed to get insights on how models behave locally, i.e. for a particular decision.</p><p>Finally, the strongest requirement is to provide the whole model. In this case of strong requirement, only interpretable models can be used, as, by definition, black-box models cannot be provided (e.g. if the model is nonparametric) or understood (e.g. in the case of neural networks).</p><p>In addition to these four levels of explainability requirements for private decisions, requirements for public decisions impose two additional constraints. For administrative decisions, the legal motivation should also be provided with the decision. This means that all factual and legal grounds on which the decision is based must be provided. In the case of judicial decisions, in addition to the facts of the case and the motivation, which was already needed for administrative decisions, answers to the arguments of the parties to the litigation must also be provided. While some works try to tackle these requirements (e.g. <ref type="bibr" target="#b0">(Ashley &amp; Brüninghaus, 2009)</ref> explain decisions with facts only; <ref type="bibr" target="#b9">(Zhong et al., 2018)</ref> introduce multi-task learning for dealing with legal articles, as well as facts; and <ref type="bibr" target="#b8">(Ye et al., 2018)</ref> use sequence-to-sequence learning to propose answers to the arguments of the parties), legal requirements on the explainability of public decisions remain a challenge in machine learning, because ML algorithms are not designed to manipulate factual and legal grounds, as well as arguments, directly.</p><p>In conclusion, we call for an interdisciplinary conversation between the legal and AI research communities. In particular, legal scholars could benefit from better understanding the potential and the limitations of ML models and AI scholars from better understanding the objectives and ambiguities of the law.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>(2) of Directive 2014/65 on Markets in Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 108, 2020. Copyright 2020 by the author(s).</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatically classifying case texts and predicting outcomes</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brüninghaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="165" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Legal requirements on explainability in machine learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bibal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lognoul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De Streel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Frénay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Enslaving the algorithm: From a &quot;right to an explanation&quot; to a &quot;right to better decisions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Veale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>IEEE Security &amp; Privacy</publisher>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">All models are wrong, but many are useful: Learning a variable&apos;s importance by studying an entire class of prediction models simultaneously</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dominici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">177</biblScope>
			<biblScope unit="page" from="1" to="81" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Irrelevant features and the subset selection problem</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pfleger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="121" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Wrappers for feature subset selection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="273" to="324" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Why should I trust you?&quot;: Explaining the predictions of any classifier</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGKDD</title>
		<meeting>ACM SIGKDD</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Why a right to explanation of automated decision-making does not exist in the general data protection regulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wachter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mittelstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Floridi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Data Privacy Law</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="76" to="99" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interpretable charge predictions for criminal cases: Learning to generate court views from fact descriptions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1854" to="1864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Legal judgment prediction via topological learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhipeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3540" to="3549" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
