{
  "embedding": {
    "success_examples": [
      {
        "baseline": "embedding",
        "question_id": "q1",
        "question_text": "What main problem or gap in existing machine learning methods is being addressed?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1703.10121v1_introduction_0002",
            "chunk_text_preview": "Introduction In 2007 , a paper named `` Top 10 algorithms in data mining '' identified and presented the top 10 most influential data mining algorithms within the research community [ 1 ] . The selection criteria were created by consolidating direct nominations from award winning researchers , the research community opinions and the number of citations in Google Scholar . The top 10 algorithms in ",
            "label": 1,
            "score": 0.5432628393173218
          },
          {
            "rank": 2,
            "chunk_id": "1504.03874v1_abstract_0001",
            "chunk_text_preview": "Machine learning is a quickly evolving field which now looks really different from what it was 15 years ago , when classification and clustering were major issues . This document proposes several trends to explore the new questions of modern machine learning , with the strong afterthought that the belief function framework has a major role to play .",
            "label": 0,
            "score": 0.5427253842353821
          },
          {
            "rank": 3,
            "chunk_id": "1504.03874v1_introduction_0003",
            "chunk_text_preview": "beyond the BF community . Without any doubt , this can be partly explained by the relative size of the scientific communities under consideration : although quickly growing , the BF one is relatively small with respect to that of statistics , Bayesian networks , neural networks , etc . However , this reason alone is not sufficient : There are indeed other topics , such as for instance , informatio",
            "label": 0,
            "score": 0.507152795791626
          },
          {
            "rank": 4,
            "chunk_id": "1612.07640v1_introduction_0007",
            "chunk_text_preview": "deep learning to address largescale data and learn high-level representation , deep learning can be a powerful and effective solution for machine health monitoring systems ( MHMS ) . Conventional data-driven MHMS usually consists of the following key parts : handcrafted feature design , feature extraction/selection and model training . The right set of features are designed , and then provided to ",
            "label": 1,
            "score": 0.49743279814720154
          },
          {
            "rank": 5,
            "chunk_id": "1501.04309v1_abstract_0001",
            "chunk_text_preview": "In this position paper , I first describe a new perspective on machine learning ( ML ) by four basic problems ( or levels ) , namely , `` What to learn ? `` , `` How to learn ? `` , `` What to evaluate ? `` , and `` What to adjust ? `` . The paper stresses more on the first level of `` What to learn ? `` , or `` Learning Target Selection '' . Towards this primary problem within the four levels , I",
            "label": 1,
            "score": 0.46177107095718384
          }
        ]
      },
      {
        "baseline": "embedding",
        "question_id": "q2",
        "question_text": "What is the central contribution or main idea of the approach being described?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1711.01431v1_introduction_0002",
            "chunk_text_preview": "Introduction Machine learning is often approached from a behaviourist perspective , in which external feedback in the form of a reinforcement signal is the major driving force of improvement . Though this method has lead to many successes , it is confronted with interesting and unsolved challenges like tackling overfitting , providing comprehensibility , building reusable abstractions and concept ",
            "label": 1,
            "score": 0.2822401821613312
          },
          {
            "rank": 2,
            "chunk_id": "1711.01431v1_abstract_0001",
            "chunk_text_preview": "Machine learning is usually defined in behaviourist terms , where external validation is the primary mechanism of learning . In this paper , I argue for a more holistic interpretation in which finding more probable , efficient and abstract representations is as central to learning as performance . In other words , machine learning should be extended with strategies to reason over its own learning ",
            "label": 1,
            "score": 0.24722836911678314
          },
          {
            "rank": 3,
            "chunk_id": "2201.06921v1_introduction_0001",
            "chunk_text_preview": "Introduction The ethics of Machine Learning has become an unavoidable topic in the AI Community . The deployment of machine learning systems in multiple social contexts has resulted in a closer ethical scrutiny of the design , development , and application of these systems . The AI/ML community has come to terms with the imperative to think about the ethical implications of machine learning , not ",
            "label": 1,
            "score": 0.20009855926036835
          },
          {
            "rank": 4,
            "chunk_id": "1501.04309v1_introduction_0003",
            "chunk_text_preview": "to the subjects of psychology , cognitive and brain science , this paper stresses on the exploration of mathematical principles for interpretation of learning mechanisms . Up to now , we human beings are still far away from deep understanding ourself on learning mechanisms in terms of mathematical principles . It is the author 's belief that `` mathematical-principle-based machine '' might be more",
            "label": 1,
            "score": 0.14452044665813446
          },
          {
            "rank": 5,
            "chunk_id": "1907.07543v1_introduction_0009",
            "chunk_text_preview": "laid out as follows . Section 2 details the datasets we use . Section 3 looks at the methodology used to evaluate the optimal paradigm . In section 4 we present the algorithms we use to test , along with related work influencing our choices in selecting those models . Section 5 details our experiments including choosing the optimal configuration of hyperparameters and preprocessing for each algori",
            "label": 0,
            "score": 0.12190233170986176
          }
        ]
      },
      {
        "baseline": "embedding",
        "question_id": "q6",
        "question_text": "Which datasets or types of data are used in the experiments, and for what reasons are they chosen?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "2006.15680v1_introduction_0005",
            "chunk_text_preview": "It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algori",
            "label": 1,
            "score": 0.3251191973686218
          },
          {
            "rank": 2,
            "chunk_id": "1505.06614v1_introduction_0005",
            "chunk_text_preview": "an introduction to the Record Linkage problem ; then the next Section 3 describes the method Electre Tri , used to solved the Record Linkage and in the last Section 4 a preliminary experiment is conducted on simulated data . The paper closes with some final remarks and conclusions . 2 Linked Data : the Record Linkage Generally speaking , in integration of two data sets the objective is the detecti",
            "label": 1,
            "score": 0.3108208179473877
          },
          {
            "rank": 3,
            "chunk_id": "2006.15680v1_introduction_0006",
            "chunk_text_preview": ", we propose to empirically explore the relation between data-set characteristics and effectiveness of standard ML models , in order to obtain a general meta-model able to extrapolate . In order to answer the question , we analyzed 109 publicly available classification data sets from open-access , curated sources . We decided to focus on classification , as supervised ML represents a quite signifi",
            "label": 1,
            "score": 0.2873310148715973
          },
          {
            "rank": 4,
            "chunk_id": "1505.06614v1_introduction_0006",
            "chunk_text_preview": "allows the reconstruction of a unique record of data that contains all the unit information collected from different data sources on that unit . Therefore , record linkage is the methodology of bringing together corresponding records from two or more files or finding duplicates within files [ 16 ] . In the first situation , the definition of record linkage in [ 9 ] is more precise `` Record linkag",
            "label": 0,
            "score": 0.2740864157676697
          },
          {
            "rank": 5,
            "chunk_id": "2006.15680v1_introduction_0004",
            "chunk_text_preview": "solutions are becoming increasingly available to both researchers and the general public [ 7 , 8 , 9 , 10 ] , theoretical questions are suddenly turning into practical issues . Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Inter",
            "label": 0,
            "score": 0.25538134574890137
          }
        ]
      }
    ],
    "failure_examples": [
      {
        "baseline": "embedding",
        "question_id": "q3",
        "question_text": "How are concepts from information theory connected to machine learning objectives or learning targets?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1501.04309v1_title_0000",
            "chunk_text_preview": "Information Theory and its Relation to Machine Learning",
            "label": 0,
            "score": 0.7226787209510803
          },
          {
            "rank": 2,
            "chunk_id": "1501.04309v1_abstract_0001",
            "chunk_text_preview": "In this position paper , I first describe a new perspective on machine learning ( ML ) by four basic problems ( or levels ) , namely , `` What to learn ? `` , `` How to learn ? `` , `` What to evaluate ? `` , and `` What to adjust ? `` . The paper stresses more on the first level of `` What to learn ? `` , or `` Learning Target Selection '' . Towards this primary problem within the four levels , I",
            "label": 1,
            "score": 0.6541186571121216
          },
          {
            "rank": 3,
            "chunk_id": "1711.01431v1_introduction_0006",
            "chunk_text_preview": "that of Ray Kurzweil , who claimed that `` the theory behind deep learning . . . is that you have a model that reflects the hierarchy in the natural phenomenon you 're trying to learn [ Hof , 2013 ] . '' This paper is structured as follows . The theoretical ideas are laid out and the case for a new operational definition of machine learning is made . We put forward the conjecture that the optimiza",
            "label": 1,
            "score": 0.5481186509132385
          },
          {
            "rank": 4,
            "chunk_id": "1711.01431v1_abstract_0001",
            "chunk_text_preview": "Machine learning is usually defined in behaviourist terms , where external validation is the primary mechanism of learning . In this paper , I argue for a more holistic interpretation in which finding more probable , efficient and abstract representations is as central to learning as performance . In other words , machine learning should be extended with strategies to reason over its own learning ",
            "label": 1,
            "score": 0.5364207625389099
          },
          {
            "rank": 5,
            "chunk_id": "1501.04309v1_introduction_0003",
            "chunk_text_preview": "to the subjects of psychology , cognitive and brain science , this paper stresses on the exploration of mathematical principles for interpretation of learning mechanisms . Up to now , we human beings are still far away from deep understanding ourself on learning mechanisms in terms of mathematical principles . It is the author 's belief that `` mathematical-principle-based machine '' might be more",
            "label": 1,
            "score": 0.5314785242080688
          }
        ]
      },
      {
        "baseline": "embedding",
        "question_id": "q4",
        "question_text": "How are uncertainty or probabilistic reasoning used or interpreted in the models or methods described?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1811.11669v1_title_0000",
            "chunk_text_preview": "TOWARDS IDENTIFYING AND MANAGING SOURCES OF UNCERTAINTY IN AI AND MACHINE LEARNING MODELS -AN OVERVIEW",
            "label": 0,
            "score": 0.5503448247909546
          },
          {
            "rank": 2,
            "chunk_id": "1811.11669v1_abstract_0001",
            "chunk_text_preview": "Quantifying and managing uncertainties that occur when data-driven models such as those provided by AI and machine learning methods are applied is crucial . This whitepaper provides a brief motivation and first overview of the state of the art in identifying and quantifying sources of uncertainty for data-driven components as well as means for analyzing their impact .",
            "label": 1,
            "score": 0.5098156332969666
          },
          {
            "rank": 3,
            "chunk_id": "1811.11669v1_introduction_0003",
            "chunk_text_preview": "and managed during design time and runtime . Previous work ( Kl√§s & Vollmer , 2018 ) proposes separating the sources of uncertainty in data-driven components into three major classes , distinguishing between uncertainty caused by limitations in terms of model fit , data quality , and scope compliance . Whereas model fit focuses on the inherent uncertainty in data-driven models , data quality cover",
            "label": 1,
            "score": 0.4386179745197296
          },
          {
            "rank": 4,
            "chunk_id": "1811.11669v1_introduction_0002",
            "chunk_text_preview": "As a consequence , the functional behavior expected from data-driven components can only be specified in part on their intended domain , and we can not assure that they will behave as expected in all cases . Moreover , their processing structure is usually difficult to trace and validate by humans because this structure rarely follows human intuition but is generated to provide the algorithmically",
            "label": 1,
            "score": 0.4034884572029114
          },
          {
            "rank": 5,
            "chunk_id": "1612.04858v1_title_0000",
            "chunk_text_preview": "Bayesian Optimization for Machine Learning A Practical Guidebook",
            "label": 0,
            "score": 0.32697030901908875
          }
        ]
      },
      {
        "baseline": "embedding",
        "question_id": "q5",
        "question_text": "What kinds of benchmarks or evaluation setups are used or discussed for assessing model performance?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "2110.12773v1_introduction_0009",
            "chunk_text_preview": "be based on real-world application examples and relevant data . For instance , demonstrating the success of a specific ML technique on a specific scientific problem will assist researchers in applying the technique to similar problems . We refer to the development of guidelines and best practices as Benchmarking . In our case , this is very specific to ML techniques applied to scientific datasets ",
            "label": 0,
            "score": 0.5620237588882446
          },
          {
            "rank": 2,
            "chunk_id": "2110.12773v1_title_0000",
            "chunk_text_preview": "Scientific Machine Learning Benchmarks",
            "label": 0,
            "score": 0.4907771050930023
          },
          {
            "rank": 3,
            "chunk_id": "2110.12773v1_introduction_0008",
            "chunk_text_preview": "and performance required , and the hardware systems available for training and inferencing . With such a multi-dimensional problem consisting of a choice of ML algorithms , hardware architectures , and a range of scientific problems , selecting an optimal ML algorithm for a given task is not trivial . This constitutes a significant barrier for many scientists wishing to use modern ML methods in th",
            "label": 0,
            "score": 0.48355910181999207
          },
          {
            "rank": 4,
            "chunk_id": "2110.12773v1_abstract_0002",
            "chunk_text_preview": "modelling and simulation on HPC systems such problems have been addressed through benchmarking computer applications , algorithms , and architectures . Extending such a benchmarking approach and identifying metrics for the application of machine learning methods to scientific datasets is a new challenge for both scientists and computer scientists . In this paper , we describe our approach to the d",
            "label": 0,
            "score": 0.4723933935165405
          },
          {
            "rank": 5,
            "chunk_id": "1907.07543v1_introduction_0009",
            "chunk_text_preview": "laid out as follows . Section 2 details the datasets we use . Section 3 looks at the methodology used to evaluate the optimal paradigm . In section 4 we present the algorithms we use to test , along with related work influencing our choices in selecting those models . Section 5 details our experiments including choosing the optimal configuration of hyperparameters and preprocessing for each algori",
            "label": 0,
            "score": 0.4396642744541168
          }
        ]
      }
    ],
    "top_k": 5
  }
}