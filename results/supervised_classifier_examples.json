{
  "supervised_classifier": {
    "success_examples": [
      {
        "baseline": "supervised_classifier",
        "question_id": "q1",
        "question_text": "What main problem or gap in existing machine learning methods is being addressed?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1706.05749v1_abstract_0001",
            "chunk_text_preview": "This paper introduces Dex , a reinforcement learning environment toolkit specialized for training and evaluation of continual learning methods as well as general reinforcement learning problems . We also present the novel continual learning method of incremental learning , where a challenging environment is solved using optimal weight initialization learned from first solving a similar easier envi",
            "label": 1,
            "score": 0.7203145287120624
          },
          {
            "rank": 2,
            "chunk_id": "1505.06614v1_title_0000",
            "chunk_text_preview": "Electre Tri-Machine Learning Approach to the Record Linkage Problem",
            "label": 1,
            "score": 0.709360424147305
          },
          {
            "rank": 3,
            "chunk_id": "1612.07640v1_introduction_0010",
            "chunk_text_preview": "MHMS , DL-based MHMS do not require extensive human labor and knowledge for handcrafted feature design . All model parameters including feature module and pattern classification/regression module can be trained jointly . Therefore , DL-based models can be applied to addressing machine health monitoring in a very general way . For example , it is possible that the model trained for fault diagnosis ",
            "label": 1,
            "score": 0.7030790779403502
          },
          {
            "rank": 4,
            "chunk_id": "1612.07640v1_introduction_0008",
            "chunk_text_preview": "what kind of good features should be designed . To alleviate this issue , feature extraction/selection methods , which can be regarded as a kind of information fusion , are performed between hand-crafted feature design and classification/regression models [ 20 ] , [ 21 ] , [ 22 ] . However , manually designing features for a complex domain requires a great deal of human labor and can not be update",
            "label": 1,
            "score": 0.6539258350329819
          },
          {
            "rank": 5,
            "chunk_id": "1501.04309v1_introduction_0003",
            "chunk_text_preview": "to the subjects of psychology , cognitive and brain science , this paper stresses on the exploration of mathematical principles for interpretation of learning mechanisms . Up to now , we human beings are still far away from deep understanding ourself on learning mechanisms in terms of mathematical principles . It is the author 's belief that `` mathematical-principle-based machine '' might be more",
            "label": 1,
            "score": 0.6222070631146415
          }
        ]
      },
      {
        "baseline": "supervised_classifier",
        "question_id": "q2",
        "question_text": "What is the central contribution or main idea of the approach being described?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1907.07543v1_introduction_0007",
            "chunk_text_preview": "are presented relative to training deep models from scratch , but as mentioned in ( Goodfellow , Bengio , & Courville , 2016 ) , deep learning generally only achieves reasonable performance at about 5000 examples per class and is therefore not necessarily the best paradigm at these scales . This is shown quantitatively in ( Chen , Mckeever , & Delany , 2018 ) where , at scales of 2000+ labels per ",
            "label": 1,
            "score": 0.763455253504492
          },
          {
            "rank": 2,
            "chunk_id": "2006.15680v1_introduction_0006",
            "chunk_text_preview": ", we propose to empirically explore the relation between data-set characteristics and effectiveness of standard ML models , in order to obtain a general meta-model able to extrapolate . In order to answer the question , we analyzed 109 publicly available classification data sets from open-access , curated sources . We decided to focus on classification , as supervised ML represents a quite signifi",
            "label": 1,
            "score": 0.7436320231277819
          },
          {
            "rank": 3,
            "chunk_id": "2006.15680v1_introduction_0007",
            "chunk_text_preview": "metrics , such as accuracy of a ML model on training and test points . Extrapolation is assessed not just by alternatively dividing the data into training and test sets , but by analyzing whether data points fall inside or outside of the convex hull of the training data . After collecting the meta-data on the performance of a state-of-the-art classification algorithm on the data sets , the statist",
            "label": 1,
            "score": 0.727261974496419
          },
          {
            "rank": 4,
            "chunk_id": "1907.07543v1_introduction_0008",
            "chunk_text_preview": "with small quantities of data . In this paper we attempt to answer this question in the context of classification tasks . What is the best paradigm to use in the case where we have 100 -1000 labelled training examples per class -classical machine learning or deep transfer learning ? We seek to compare the best-in-class approaches from both deep transfer learning and classical machine learning by t",
            "label": 1,
            "score": 0.7255021586330296
          },
          {
            "rank": 5,
            "chunk_id": "2006.15680v1_introduction_0005",
            "chunk_text_preview": "It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algori",
            "label": 1,
            "score": 0.709364181911342
          }
        ]
      },
      {
        "baseline": "supervised_classifier",
        "question_id": "q3",
        "question_text": "How are concepts from information theory connected to machine learning objectives or learning targets?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1711.01431v1_abstract_0001",
            "chunk_text_preview": "Machine learning is usually defined in behaviourist terms , where external validation is the primary mechanism of learning . In this paper , I argue for a more holistic interpretation in which finding more probable , efficient and abstract representations is as central to learning as performance . In other words , machine learning should be extended with strategies to reason over its own learning ",
            "label": 1,
            "score": 0.6452726284859234
          },
          {
            "rank": 2,
            "chunk_id": "1711.01431v1_introduction_0004",
            "chunk_text_preview": "to humans , of course , machines are measurable . This provides us with a unique opportunity to study the nature of learning in principle , at the same time improving Machine Intelligence . We are not claiming that model complexity/efficiency has not been subject to past research efforts . On the contrary , many techniques and design principles have attempted to improve exactly these properties -l",
            "label": 1,
            "score": 0.6063205623654678
          },
          {
            "rank": 3,
            "chunk_id": "1711.01431v1_introduction_0005",
            "chunk_text_preview": "lower entropy ) , by organizing and training them in a layer-wise fashion [ Bengio , 2009 ] . The focus has been mainly on training algorithms and designing model architectures that are adapted to these kinds of `` deep '' structures [ Deng and Yu , 2014 ] . Similar to efforts in multiobjective machine learning , these techniques are considered as a means to improve ( externally measured ) perform",
            "label": 1,
            "score": 0.5746640216102464
          },
          {
            "rank": 4,
            "chunk_id": "1501.04309v1_introduction_0003",
            "chunk_text_preview": "to the subjects of psychology , cognitive and brain science , this paper stresses on the exploration of mathematical principles for interpretation of learning mechanisms . Up to now , we human beings are still far away from deep understanding ourself on learning mechanisms in terms of mathematical principles . It is the author 's belief that `` mathematical-principle-based machine '' might be more",
            "label": 1,
            "score": 0.5648962825079427
          },
          {
            "rank": 5,
            "chunk_id": "1711.01431v1_title_0000",
            "chunk_text_preview": "The Case for Meta-Cognitive Machine Learning : On Model Entropy and Concept Formation in Deep Learning",
            "label": 0,
            "score": 0.4999408843103627
          }
        ]
      }
    ],
    "failure_examples": [
      {
        "baseline": "supervised_classifier",
        "question_id": "q4",
        "question_text": "How are uncertainty or probabilistic reasoning used or interpreted in the models or methods described?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1612.07640v1_introduction_0008",
            "chunk_text_preview": "what kind of good features should be designed . To alleviate this issue , feature extraction/selection methods , which can be regarded as a kind of information fusion , are performed between hand-crafted feature design and classification/regression models [ 20 ] , [ 21 ] , [ 22 ] . However , manually designing features for a complex domain requires a great deal of human labor and can not be update",
            "label": 0,
            "score": 0.5764349616801545
          },
          {
            "rank": 2,
            "chunk_id": "1711.01431v1_introduction_0004",
            "chunk_text_preview": "to humans , of course , machines are measurable . This provides us with a unique opportunity to study the nature of learning in principle , at the same time improving Machine Intelligence . We are not claiming that model complexity/efficiency has not been subject to past research efforts . On the contrary , many techniques and design principles have attempted to improve exactly these properties -l",
            "label": 0,
            "score": 0.5644641106798124
          },
          {
            "rank": 3,
            "chunk_id": "1903.00092v2_introduction_0003",
            "chunk_text_preview": "not use future data . By bounding the ratio of these two costs , a guarantee can be made as to how well the online algorithm will perform in terms of the performance of an omniscient algorithm . A classic problem in competitive analysis is the Ski Rental Problem . In this problem , a skier must decide whether to rent skis at a rate of $ 1 per day , or to buy skis at a price of $ B . The uncertaint",
            "label": 1,
            "score": 0.5637388251125937
          },
          {
            "rank": 4,
            "chunk_id": "1903.00092v2_introduction_0002",
            "chunk_text_preview": "Introduction Online decision-making problems fundamentally address the issue of dealing with the uncertainty inherently present in the future . In broad terms , these problems can be addressed in two ways . First , a predictive approach like a machine learning algorithm can be used to guess at future events and to act accordingly . This method , while clearly powerful , has the drawback that it is",
            "label": 1,
            "score": 0.5167367158544178
          },
          {
            "rank": 5,
            "chunk_id": "1706.05749v1_introduction_0004",
            "chunk_text_preview": "as the inherent difficulty of the task . Therefore , some form of prior information must be given to the agent . This can be seen with AlphaGo [ 18 ] , where the agent never learned to play the game without first using supervised learning on human games . While supervised learning certainly has been shown to aid reinforcement learning , it is very costly to obtain sufficient samples and requires t",
            "label": 0,
            "score": 0.5158545384161917
          }
        ]
      },
      {
        "baseline": "supervised_classifier",
        "question_id": "q8",
        "question_text": "In what ways are machine learning methods applied to concrete scientific or engineering problems?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1501.04309v1_introduction_0003",
            "chunk_text_preview": "to the subjects of psychology , cognitive and brain science , this paper stresses on the exploration of mathematical principles for interpretation of learning mechanisms . Up to now , we human beings are still far away from deep understanding ourself on learning mechanisms in terms of mathematical principles . It is the author 's belief that `` mathematical-principle-based machine '' might be more",
            "label": 0,
            "score": 0.5375100533242765
          },
          {
            "rank": 2,
            "chunk_id": "1612.04858v1_introduction_0002",
            "chunk_text_preview": "Introduction Recently , there has been interest in applying Bayesian black-box optimization strategies to better conduct optimization over hyperparameter configurations of machine learning models and systems [ 19 ] [ 21 ] [ 11 ] . Most of these techniques require that the objective be a scalar value depending on the hyperparamter configuration x. x opt = arg max x∈X f ( x ) A more detailed introdu",
            "label": 1,
            "score": 0.5271505254079011
          },
          {
            "rank": 3,
            "chunk_id": "1706.05749v1_introduction_0005",
            "chunk_text_preview": "We present and demonstrate a novel continual learning method we call incremental learning to solve complex environments . In incremental learning , environments are framed as a task to be learned by an agent . This task can be split into a series of subtasks that are solved simultaneously . Similar to how natural language processing and object detection are subtasks of neural image caption generat",
            "label": 0,
            "score": 0.5266644643352044
          },
          {
            "rank": 4,
            "chunk_id": "1711.01431v1_introduction_0002",
            "chunk_text_preview": "Introduction Machine learning is often approached from a behaviourist perspective , in which external feedback in the form of a reinforcement signal is the major driving force of improvement . Though this method has lead to many successes , it is confronted with interesting and unsolved challenges like tackling overfitting , providing comprehensibility , building reusable abstractions and concept ",
            "label": 0,
            "score": 0.510118003435062
          },
          {
            "rank": 5,
            "chunk_id": "1711.01431v1_introduction_0003",
            "chunk_text_preview": "when : • the programme becomes better at the task at hand ; • the programme can perform the task more efficiently ; • the code becomes `` more structured '' and simpler . One possible analogy to better understand the above statements can be found in software engineering . When considering code that performs a specific task , we do not care only about its functionality , but also about its executio",
            "label": 0,
            "score": 0.49158429586785524
          }
        ]
      },
      {
        "baseline": "supervised_classifier",
        "question_id": "q10",
        "question_text": "How is robustness discussed, for example robustness to distribution shifts, adversarial examples, or other perturbations?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1907.07543v1_introduction_0007",
            "chunk_text_preview": "are presented relative to training deep models from scratch , but as mentioned in ( Goodfellow , Bengio , & Courville , 2016 ) , deep learning generally only achieves reasonable performance at about 5000 examples per class and is therefore not necessarily the best paradigm at these scales . This is shown quantitatively in ( Chen , Mckeever , & Delany , 2018 ) where , at scales of 2000+ labels per ",
            "label": 0,
            "score": 0.7154539985101723
          },
          {
            "rank": 2,
            "chunk_id": "1907.07543v1_abstract_0002",
            "chunk_text_preview": "paradigm . We find that BERT , representing the best of deep transfer learning , is the best performing approach , outperforming top classical machine learning algorithms by 9.7 % on average when trained with 100 examples per class , narrowing to 1.8 % at 1000 labels per class . We also show the robustness of deep transfer learning in moving across domains , where the maximum loss in accuracy is o",
            "label": 1,
            "score": 0.6568600513420116
          },
          {
            "rank": 3,
            "chunk_id": "1711.01431v1_introduction_0008",
            "chunk_text_preview": "concepts is problematic , and that the solution to this issue is somehow connected to deep architectures that create ever higher forms of abstraction . Experimental research as well as neurological evidence on the organization of the brain , supports this finding [ Bianchini and Scarselli , 2014 ] . The limitation of architecture complexity is preferred , primarily because their behaviour could be",
            "label": 0,
            "score": 0.5997601862419727
          },
          {
            "rank": 4,
            "chunk_id": "1907.07543v1_introduction_0006",
            "chunk_text_preview": "learning is another usecase for transfer learning in NLP , one of particular interest to companies working with real-world data . Low-shot transfer learning ( also referred to as `` few-shot '' ) is the use of transfer learning in training models where we have little training data available . This is important as many potential real-world applications of machine learning NLP do not have access to ",
            "label": 0,
            "score": 0.5972599614567955
          },
          {
            "rank": 5,
            "chunk_id": "1612.07640v1_introduction_0008",
            "chunk_text_preview": "what kind of good features should be designed . To alleviate this issue , feature extraction/selection methods , which can be regarded as a kind of information fusion , are performed between hand-crafted feature design and classification/regression models [ 20 ] , [ 21 ] , [ 22 ] . However , manually designing features for a complex domain requires a great deal of human labor and can not be update",
            "label": 0,
            "score": 0.5854782013774902
          }
        ]
      }
    ],
    "top_k": 5
  }
}