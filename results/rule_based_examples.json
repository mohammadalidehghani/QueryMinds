{
  "keyword_overlap": {
    "success_examples": [
      {
        "baseline": "keyword_overlap",
        "question_id": "q1",
        "question_text": "What main problem or gap in existing machine learning methods is being addressed?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1612.07640v1_introduction_0008",
            "chunk_text_preview": "what kind of good features should be designed . To alleviate this issue , feature extraction/selection methods , which can be regarded as a kind of information fusion , are performed between hand-crafted feature design and classification/regression models [ 20 ] , [ 21 ] , [ 22 ] . However , manually designing features for a complex domain requires a great deal of human labor and can not be update",
            "label": 1,
            "score": 2.0
          },
          {
            "rank": 2,
            "chunk_id": "1501.04309v1_abstract_0001",
            "chunk_text_preview": "In this position paper , I first describe a new perspective on machine learning ( ML ) by four basic problems ( or levels ) , namely , `` What to learn ? `` , `` How to learn ? `` , `` What to evaluate ? `` , and `` What to adjust ? `` . The paper stresses more on the first level of `` What to learn ? `` , or `` Learning Target Selection '' . Towards this primary problem within the four levels , I",
            "label": 1,
            "score": 1.0
          },
          {
            "rank": 3,
            "chunk_id": "1505.06614v1_title_0000",
            "chunk_text_preview": "Electre Tri-Machine Learning Approach to the Record Linkage Problem",
            "label": 1,
            "score": 1.0
          },
          {
            "rank": 4,
            "chunk_id": "1505.06614v1_abstract_0001",
            "chunk_text_preview": "In this short paper , the Electre Tri-Machine Learning Method , generally used to solve ordinal classification problems , is proposed for solving the Record Linkage problem . Preliminary experimental results show that , using the Electre Tri method , high accuracy can be achieved and more than 99 % of the matches and nonmatches were correctly identified by the procedure .",
            "label": 1,
            "score": 1.0
          },
          {
            "rank": 5,
            "chunk_id": "1505.06614v1_introduction_0003",
            "chunk_text_preview": "semi-supervised learning algorithms : supervised and unsupervised learning information is combined ; • reinforcement learning : actions from observation of the world are generated . Every action has some impact in the environment and the environment provides feedbacks that are translated into a score that guide the learning process . The principal supervised learning techniques currently applied o",
            "label": 1,
            "score": 1.0
          }
        ]
      },
      {
        "baseline": "keyword_overlap",
        "question_id": "q2",
        "question_text": "What is the central contribution or main idea of the approach being described?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1706.05749v1_introduction_0004",
            "chunk_text_preview": "as the inherent difficulty of the task . Therefore , some form of prior information must be given to the agent . This can be seen with AlphaGo [ 18 ] , where the agent never learned to play the game without first using supervised learning on human games . While supervised learning certainly has been shown to aid reinforcement learning , it is very costly to obtain sufficient samples and requires t",
            "label": 1,
            "score": 3.0
          },
          {
            "rank": 2,
            "chunk_id": "1811.04871v1_abstract_0001",
            "chunk_text_preview": "Academic literature on machine learning modeling fails to address how to make machine learning models work for enterprises . For example , existing machine learning processes can not address how to define business use cases for an AI application , how to convert business requirements from offering managers into data requirements for data scientists , and how to continuously improve AI applications",
            "label": 1,
            "score": 2.0
          },
          {
            "rank": 3,
            "chunk_id": "1907.07543v1_introduction_0007",
            "chunk_text_preview": "are presented relative to training deep models from scratch , but as mentioned in ( Goodfellow , Bengio , & Courville , 2016 ) , deep learning generally only achieves reasonable performance at about 5000 examples per class and is therefore not necessarily the best paradigm at these scales . This is shown quantitatively in ( Chen , Mckeever , & Delany , 2018 ) where , at scales of 2000+ labels per ",
            "label": 1,
            "score": 2.0
          },
          {
            "rank": 4,
            "chunk_id": "1907.07543v1_introduction_0008",
            "chunk_text_preview": "with small quantities of data . In this paper we attempt to answer this question in the context of classification tasks . What is the best paradigm to use in the case where we have 100 -1000 labelled training examples per class -classical machine learning or deep transfer learning ? We seek to compare the best-in-class approaches from both deep transfer learning and classical machine learning by t",
            "label": 1,
            "score": 2.0
          },
          {
            "rank": 5,
            "chunk_id": "2110.12773v1_abstract_0002",
            "chunk_text_preview": "modelling and simulation on HPC systems such problems have been addressed through benchmarking computer applications , algorithms , and architectures . Extending such a benchmarking approach and identifying metrics for the application of machine learning methods to scientific datasets is a new challenge for both scientists and computer scientists . In this paper , we describe our approach to the d",
            "label": 1,
            "score": 2.0
          }
        ]
      },
      {
        "baseline": "keyword_overlap",
        "question_id": "q5",
        "question_text": "What kinds of benchmarks or evaluation setups are used or discussed for assessing model performance?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1706.05749v1_abstract_0001",
            "chunk_text_preview": "This paper introduces Dex , a reinforcement learning environment toolkit specialized for training and evaluation of continual learning methods as well as general reinforcement learning problems . We also present the novel continual learning method of incremental learning , where a challenging environment is solved using optimal weight initialization learned from first solving a similar easier envi",
            "label": 1,
            "score": 2.0
          },
          {
            "rank": 2,
            "chunk_id": "1501.04309v1_abstract_0001",
            "chunk_text_preview": "In this position paper , I first describe a new perspective on machine learning ( ML ) by four basic problems ( or levels ) , namely , `` What to learn ? `` , `` How to learn ? `` , `` What to evaluate ? `` , and `` What to adjust ? `` . The paper stresses more on the first level of `` What to learn ? `` , or `` Learning Target Selection '' . Towards this primary problem within the four levels , I",
            "label": 0,
            "score": 1.0
          },
          {
            "rank": 3,
            "chunk_id": "1703.10121v1_introduction_0002",
            "chunk_text_preview": "Introduction In 2007 , a paper named `` Top 10 algorithms in data mining '' identified and presented the top 10 most influential data mining algorithms within the research community [ 1 ] . The selection criteria were created by consolidating direct nominations from award winning researchers , the research community opinions and the number of citations in Google Scholar . The top 10 algorithms in ",
            "label": 0,
            "score": 1.0
          },
          {
            "rank": 4,
            "chunk_id": "1703.10121v1_introduction_0003",
            "chunk_text_preview": "popular fields of active research in machine learning , as they emerged from the quantitative analysis of leading journals and conferences . This work sees some topics in the broader sense including not only models but also concepts like data sets , features , optimization techniques and evaluation metrics . This wider view on the entire machine learning field is largely ignored in the literature ",
            "label": 0,
            "score": 1.0
          },
          {
            "rank": 5,
            "chunk_id": "1907.07543v1_introduction_0007",
            "chunk_text_preview": "are presented relative to training deep models from scratch , but as mentioned in ( Goodfellow , Bengio , & Courville , 2016 ) , deep learning generally only achieves reasonable performance at about 5000 examples per class and is therefore not necessarily the best paradigm at these scales . This is shown quantitatively in ( Chen , Mckeever , & Delany , 2018 ) where , at scales of 2000+ labels per ",
            "label": 1,
            "score": 1.0
          }
        ]
      }
    ],
    "failure_examples": [
      {
        "baseline": "keyword_overlap",
        "question_id": "q3",
        "question_text": "How are concepts from information theory connected to machine learning objectives or learning targets?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1501.04309v1_title_0000",
            "chunk_text_preview": "Information Theory and its Relation to Machine Learning",
            "label": 0,
            "score": 1.0
          },
          {
            "rank": 2,
            "chunk_id": "1711.01431v1_title_0000",
            "chunk_text_preview": "The Case for Meta-Cognitive Machine Learning : On Model Entropy and Concept Formation in Deep Learning",
            "label": 0,
            "score": 1.0
          },
          {
            "rank": 3,
            "chunk_id": "1711.01431v1_abstract_0001",
            "chunk_text_preview": "Machine learning is usually defined in behaviourist terms , where external validation is the primary mechanism of learning . In this paper , I argue for a more holistic interpretation in which finding more probable , efficient and abstract representations is as central to learning as performance . In other words , machine learning should be extended with strategies to reason over its own learning ",
            "label": 1,
            "score": 1.0
          },
          {
            "rank": 4,
            "chunk_id": "1711.01431v1_introduction_0004",
            "chunk_text_preview": "to humans , of course , machines are measurable . This provides us with a unique opportunity to study the nature of learning in principle , at the same time improving Machine Intelligence . We are not claiming that model complexity/efficiency has not been subject to past research efforts . On the contrary , many techniques and design principles have attempted to improve exactly these properties -l",
            "label": 1,
            "score": 1.0
          },
          {
            "rank": 5,
            "chunk_id": "1711.01431v1_introduction_0005",
            "chunk_text_preview": "lower entropy ) , by organizing and training them in a layer-wise fashion [ Bengio , 2009 ] . The focus has been mainly on training algorithms and designing model architectures that are adapted to these kinds of `` deep '' structures [ Deng and Yu , 2014 ] . Similar to efforts in multiobjective machine learning , these techniques are considered as a means to improve ( externally measured ) perform",
            "label": 1,
            "score": 1.0
          }
        ]
      },
      {
        "baseline": "keyword_overlap",
        "question_id": "q4",
        "question_text": "How are uncertainty or probabilistic reasoning used or interpreted in the models or methods described?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1504.03874v1_introduction_0002",
            "chunk_text_preview": "Introduction In an age of user generated web-contents and of portable devices with embedded computer vision capabilities , machine learning ( ML ) and big data mining questions are fundamental . As a result , these questions naturally penetrate neighboring research fields , including belief function theory ( BFT ) , so that it is now usual to attend a `` Classification '' session [ 26 ] or a `` Ma",
            "label": 0,
            "score": 1.0
          },
          {
            "rank": 2,
            "chunk_id": "1504.03874v1_introduction_0003",
            "chunk_text_preview": "beyond the BF community . Without any doubt , this can be partly explained by the relative size of the scientific communities under consideration : although quickly growing , the BF one is relatively small with respect to that of statistics , Bayesian networks , neural networks , etc . However , this reason alone is not sufficient : There are indeed other topics , such as for instance , informatio",
            "label": 0,
            "score": 1.0
          },
          {
            "rank": 3,
            "chunk_id": "1612.04858v1_title_0000",
            "chunk_text_preview": "Bayesian Optimization for Machine Learning A Practical Guidebook",
            "label": 0,
            "score": 1.0
          },
          {
            "rank": 4,
            "chunk_id": "1612.04858v1_abstract_0001",
            "chunk_text_preview": "The engineering of machine learning systems is still a nascent field ; relying on a seemingly daunting collection of quickly evolving tools and best practices . It is our hope that this guidebook will serve as a useful resource for machine learning practitioners looking to take advantage of Bayesian optimization techniques . We outline four example machine learning problems that can be solved usin",
            "label": 0,
            "score": 1.0
          },
          {
            "rank": 5,
            "chunk_id": "1612.04858v1_introduction_0002",
            "chunk_text_preview": "Introduction Recently , there has been interest in applying Bayesian black-box optimization strategies to better conduct optimization over hyperparameter configurations of machine learning models and systems [ 19 ] [ 21 ] [ 11 ] . Most of these techniques require that the objective be a scalar value depending on the hyperparamter configuration x. x opt = arg max x∈X f ( x ) A more detailed introdu",
            "label": 0,
            "score": 1.0
          }
        ]
      },
      {
        "baseline": "keyword_overlap",
        "question_id": "q7",
        "question_text": "How is the relationship between theoretical analysis and empirical experiments described?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1501.04309v1_abstract_0001",
            "chunk_text_preview": "In this position paper , I first describe a new perspective on machine learning ( ML ) by four basic problems ( or levels ) , namely , `` What to learn ? `` , `` How to learn ? `` , `` What to evaluate ? `` , and `` What to adjust ? `` . The paper stresses more on the first level of `` What to learn ? `` , or `` Learning Target Selection '' . Towards this primary problem within the four levels , I",
            "label": 0,
            "score": 2.0
          },
          {
            "rank": 2,
            "chunk_id": "1501.04309v1_introduction_0003",
            "chunk_text_preview": "to the subjects of psychology , cognitive and brain science , this paper stresses on the exploration of mathematical principles for interpretation of learning mechanisms . Up to now , we human beings are still far away from deep understanding ourself on learning mechanisms in terms of mathematical principles . It is the author 's belief that `` mathematical-principle-based machine '' might be more",
            "label": 0,
            "score": 2.0
          },
          {
            "rank": 3,
            "chunk_id": "1505.06614v1_introduction_0002",
            "chunk_text_preview": "Introduction Machine Learning is a scientific discipline that is concerned with the design and development of algorithms that allow computers to `` learn data '' . More precisely , `` learn '' is here intended as the possibility to automatically recognize complex patterns and make `` intelligent '' decisions , based on information data . Hence , machine learning is closely related to fields such a",
            "label": 0,
            "score": 2.0
          },
          {
            "rank": 4,
            "chunk_id": "1711.01431v1_introduction_0006",
            "chunk_text_preview": "that of Ray Kurzweil , who claimed that `` the theory behind deep learning . . . is that you have a model that reflects the hierarchy in the natural phenomenon you 're trying to learn [ Hof , 2013 ] . '' This paper is structured as follows . The theoretical ideas are laid out and the case for a new operational definition of machine learning is made . We put forward the conjecture that the optimiza",
            "label": 0,
            "score": 2.0
          },
          {
            "rank": 5,
            "chunk_id": "1807.10681v1_abstract_0001",
            "chunk_text_preview": "Two different views on machine learning problem : Applied learning ( machine learning with business applications ) and Agnostic PAC learning are formalized and compared here . I show that , under some conditions , the theory of PAC Learnable provides a way to solve the Applied learning problem . However , the theory requires to have the training sets so large , that it would make the learning prac",
            "label": 1,
            "score": 2.0
          }
        ]
      }
    ],
    "top_k": 5
  },
  "tfidf_cosine": {
    "success_examples": [
      {
        "baseline": "tfidf_cosine",
        "question_id": "q1",
        "question_text": "What main problem or gap in existing machine learning methods is being addressed?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1501.04309v1_abstract_0001",
            "chunk_text_preview": "In this position paper , I first describe a new perspective on machine learning ( ML ) by four basic problems ( or levels ) , namely , `` What to learn ? `` , `` How to learn ? `` , `` What to evaluate ? `` , and `` What to adjust ? `` . The paper stresses more on the first level of `` What to learn ? `` , or `` Learning Target Selection '' . Towards this primary problem within the four levels , I",
            "label": 1,
            "score": 0.11412172575695112
          },
          {
            "rank": 2,
            "chunk_id": "1505.06614v1_title_0000",
            "chunk_text_preview": "Electre Tri-Machine Learning Approach to the Record Linkage Problem",
            "label": 1,
            "score": 0.11286372139915932
          },
          {
            "rank": 3,
            "chunk_id": "1501.04309v1_introduction_0003",
            "chunk_text_preview": "to the subjects of psychology , cognitive and brain science , this paper stresses on the exploration of mathematical principles for interpretation of learning mechanisms . Up to now , we human beings are still far away from deep understanding ourself on learning mechanisms in terms of mathematical principles . It is the author 's belief that `` mathematical-principle-based machine '' might be more",
            "label": 1,
            "score": 0.09192003898998583
          },
          {
            "rank": 4,
            "chunk_id": "1505.06614v1_introduction_0003",
            "chunk_text_preview": "semi-supervised learning algorithms : supervised and unsupervised learning information is combined ; • reinforcement learning : actions from observation of the world are generated . Every action has some impact in the environment and the environment provides feedbacks that are translated into a score that guide the learning process . The principal supervised learning techniques currently applied o",
            "label": 1,
            "score": 0.08532181071801148
          },
          {
            "rank": 5,
            "chunk_id": "1706.05749v1_abstract_0001",
            "chunk_text_preview": "This paper introduces Dex , a reinforcement learning environment toolkit specialized for training and evaluation of continual learning methods as well as general reinforcement learning problems . We also present the novel continual learning method of incremental learning , where a challenging environment is solved using optimal weight initialization learned from first solving a similar easier envi",
            "label": 1,
            "score": 0.07115800813879274
          }
        ]
      },
      {
        "baseline": "tfidf_cosine",
        "question_id": "q2",
        "question_text": "What is the central contribution or main idea of the approach being described?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "2110.12773v1_abstract_0002",
            "chunk_text_preview": "modelling and simulation on HPC systems such problems have been addressed through benchmarking computer applications , algorithms , and architectures . Extending such a benchmarking approach and identifying metrics for the application of machine learning methods to scientific datasets is a new challenge for both scientists and computer scientists . In this paper , we describe our approach to the d",
            "label": 1,
            "score": 0.07490849689957935
          },
          {
            "rank": 2,
            "chunk_id": "2006.15680v1_introduction_0007",
            "chunk_text_preview": "metrics , such as accuracy of a ML model on training and test points . Extrapolation is assessed not just by alternatively dividing the data into training and test sets , but by analyzing whether data points fall inside or outside of the convex hull of the training data . After collecting the meta-data on the performance of a state-of-the-art classification algorithm on the data sets , the statist",
            "label": 1,
            "score": 0.046351512848636055
          },
          {
            "rank": 3,
            "chunk_id": "1711.01431v1_abstract_0001",
            "chunk_text_preview": "Machine learning is usually defined in behaviourist terms , where external validation is the primary mechanism of learning . In this paper , I argue for a more holistic interpretation in which finding more probable , efficient and abstract representations is as central to learning as performance . In other words , machine learning should be extended with strategies to reason over its own learning ",
            "label": 1,
            "score": 0.036528968143542374
          },
          {
            "rank": 4,
            "chunk_id": "1711.01431v1_introduction_0002",
            "chunk_text_preview": "Introduction Machine learning is often approached from a behaviourist perspective , in which external feedback in the form of a reinforcement signal is the major driving force of improvement . Though this method has lead to many successes , it is confronted with interesting and unsolved challenges like tackling overfitting , providing comprehensibility , building reusable abstractions and concept ",
            "label": 1,
            "score": 0.03377450981644666
          },
          {
            "rank": 5,
            "chunk_id": "2103.11249v1_abstract_0001",
            "chunk_text_preview": "One of the pillars of any machine learning model is its concepts . Using software engineering , we can engineer these concepts and then develop and expand them . In this article , we present a SELM framework for Software Engineering of machine Learning Models . We then evaluate this framework through a case study . Using the SELM framework , we can improve a machine learning process efficiency and",
            "label": 1,
            "score": 0.02932592342121102
          }
        ]
      },
      {
        "baseline": "tfidf_cosine",
        "question_id": "q7",
        "question_text": "How is the relationship between theoretical analysis and empirical experiments described?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1807.10681v1_abstract_0001",
            "chunk_text_preview": "Two different views on machine learning problem : Applied learning ( machine learning with business applications ) and Agnostic PAC learning are formalized and compared here . I show that , under some conditions , the theory of PAC Learnable provides a way to solve the Applied learning problem . However , the theory requires to have the training sets so large , that it would make the learning prac",
            "label": 1,
            "score": 0.03884307405976364
          },
          {
            "rank": 2,
            "chunk_id": "1711.01431v1_introduction_0006",
            "chunk_text_preview": "that of Ray Kurzweil , who claimed that `` the theory behind deep learning . . . is that you have a model that reflects the hierarchy in the natural phenomenon you 're trying to learn [ Hof , 2013 ] . '' This paper is structured as follows . The theoretical ideas are laid out and the case for a new operational definition of machine learning is made . We put forward the conjecture that the optimiza",
            "label": 0,
            "score": 0.03686874841004013
          },
          {
            "rank": 3,
            "chunk_id": "1501.04309v1_abstract_0001",
            "chunk_text_preview": "In this position paper , I first describe a new perspective on machine learning ( ML ) by four basic problems ( or levels ) , namely , `` What to learn ? `` , `` How to learn ? `` , `` What to evaluate ? `` , and `` What to adjust ? `` . The paper stresses more on the first level of `` What to learn ? `` , or `` Learning Target Selection '' . Towards this primary problem within the four levels , I",
            "label": 0,
            "score": 0.036335103712646186
          },
          {
            "rank": 4,
            "chunk_id": "1501.04309v1_introduction_0003",
            "chunk_text_preview": "to the subjects of psychology , cognitive and brain science , this paper stresses on the exploration of mathematical principles for interpretation of learning mechanisms . Up to now , we human beings are still far away from deep understanding ourself on learning mechanisms in terms of mathematical principles . It is the author 's belief that `` mathematical-principle-based machine '' might be more",
            "label": 0,
            "score": 0.0290656547105955
          },
          {
            "rank": 5,
            "chunk_id": "1505.06614v1_introduction_0002",
            "chunk_text_preview": "Introduction Machine Learning is a scientific discipline that is concerned with the design and development of algorithms that allow computers to `` learn data '' . More precisely , `` learn '' is here intended as the possibility to automatically recognize complex patterns and make `` intelligent '' decisions , based on information data . Hence , machine learning is closely related to fields such a",
            "label": 0,
            "score": 0.02600168917149415
          }
        ]
      }
    ],
    "failure_examples": [
      {
        "baseline": "tfidf_cosine",
        "question_id": "q3",
        "question_text": "How are concepts from information theory connected to machine learning objectives or learning targets?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1501.04309v1_title_0000",
            "chunk_text_preview": "Information Theory and its Relation to Machine Learning",
            "label": 0,
            "score": 0.34975930082533535
          },
          {
            "rank": 2,
            "chunk_id": "1711.01431v1_abstract_0001",
            "chunk_text_preview": "Machine learning is usually defined in behaviourist terms , where external validation is the primary mechanism of learning . In this paper , I argue for a more holistic interpretation in which finding more probable , efficient and abstract representations is as central to learning as performance . In other words , machine learning should be extended with strategies to reason over its own learning ",
            "label": 1,
            "score": 0.1425844074386356
          },
          {
            "rank": 3,
            "chunk_id": "1711.01431v1_introduction_0006",
            "chunk_text_preview": "that of Ray Kurzweil , who claimed that `` the theory behind deep learning . . . is that you have a model that reflects the hierarchy in the natural phenomenon you 're trying to learn [ Hof , 2013 ] . '' This paper is structured as follows . The theoretical ideas are laid out and the case for a new operational definition of machine learning is made . We put forward the conjecture that the optimiza",
            "label": 1,
            "score": 0.12409549252376506
          },
          {
            "rank": 4,
            "chunk_id": "1501.04309v1_introduction_0003",
            "chunk_text_preview": "to the subjects of psychology , cognitive and brain science , this paper stresses on the exploration of mathematical principles for interpretation of learning mechanisms . Up to now , we human beings are still far away from deep understanding ourself on learning mechanisms in terms of mathematical principles . It is the author 's belief that `` mathematical-principle-based machine '' might be more",
            "label": 1,
            "score": 0.10498915629738274
          },
          {
            "rank": 5,
            "chunk_id": "1501.04309v1_abstract_0001",
            "chunk_text_preview": "In this position paper , I first describe a new perspective on machine learning ( ML ) by four basic problems ( or levels ) , namely , `` What to learn ? `` , `` How to learn ? `` , `` What to evaluate ? `` , and `` What to adjust ? `` . The paper stresses more on the first level of `` What to learn ? `` , or `` Learning Target Selection '' . Towards this primary problem within the four levels , I",
            "label": 1,
            "score": 0.10407748706184206
          }
        ]
      },
      {
        "baseline": "tfidf_cosine",
        "question_id": "q4",
        "question_text": "How are uncertainty or probabilistic reasoning used or interpreted in the models or methods described?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "1811.11669v1_title_0000",
            "chunk_text_preview": "TOWARDS IDENTIFYING AND MANAGING SOURCES OF UNCERTAINTY IN AI AND MACHINE LEARNING MODELS -AN OVERVIEW",
            "label": 0,
            "score": 0.1611699503651657
          },
          {
            "rank": 2,
            "chunk_id": "1811.11669v1_introduction_0002",
            "chunk_text_preview": "As a consequence , the functional behavior expected from data-driven components can only be specified in part on their intended domain , and we can not assure that they will behave as expected in all cases . Moreover , their processing structure is usually difficult to trace and validate by humans because this structure rarely follows human intuition but is generated to provide the algorithmically",
            "label": 1,
            "score": 0.1337411668081229
          },
          {
            "rank": 3,
            "chunk_id": "1811.11669v1_introduction_0003",
            "chunk_text_preview": "and managed during design time and runtime . Previous work ( Kläs & Vollmer , 2018 ) proposes separating the sources of uncertainty in data-driven components into three major classes , distinguishing between uncertainty caused by limitations in terms of model fit , data quality , and scope compliance . Whereas model fit focuses on the inherent uncertainty in data-driven models , data quality cover",
            "label": 1,
            "score": 0.12940704152821444
          },
          {
            "rank": 4,
            "chunk_id": "1811.11669v1_abstract_0001",
            "chunk_text_preview": "Quantifying and managing uncertainties that occur when data-driven models such as those provided by AI and machine learning methods are applied is crucial . This whitepaper provides a brief motivation and first overview of the state of the art in identifying and quantifying sources of uncertainty for data-driven components as well as means for analyzing their impact .",
            "label": 1,
            "score": 0.09844245651528347
          },
          {
            "rank": 5,
            "chunk_id": "1504.03874v1_introduction_0003",
            "chunk_text_preview": "beyond the BF community . Without any doubt , this can be partly explained by the relative size of the scientific communities under consideration : although quickly growing , the BF one is relatively small with respect to that of statistics , Bayesian networks , neural networks , etc . However , this reason alone is not sufficient : There are indeed other topics , such as for instance , informatio",
            "label": 0,
            "score": 0.05213785948863613
          }
        ]
      },
      {
        "baseline": "tfidf_cosine",
        "question_id": "q5",
        "question_text": "What kinds of benchmarks or evaluation setups are used or discussed for assessing model performance?",
        "top_k": [
          {
            "rank": 1,
            "chunk_id": "2110.12773v1_title_0000",
            "chunk_text_preview": "Scientific Machine Learning Benchmarks",
            "label": 0,
            "score": 0.25872303386483614
          },
          {
            "rank": 2,
            "chunk_id": "2110.12773v1_introduction_0009",
            "chunk_text_preview": "be based on real-world application examples and relevant data . For instance , demonstrating the success of a specific ML technique on a specific scientific problem will assist researchers in applying the technique to similar problems . We refer to the development of guidelines and best practices as Benchmarking . In our case , this is very specific to ML techniques applied to scientific datasets ",
            "label": 0,
            "score": 0.1088921622933878
          },
          {
            "rank": 3,
            "chunk_id": "2110.12773v1_abstract_0002",
            "chunk_text_preview": "modelling and simulation on HPC systems such problems have been addressed through benchmarking computer applications , algorithms , and architectures . Extending such a benchmarking approach and identifying metrics for the application of machine learning methods to scientific datasets is a new challenge for both scientists and computer scientists . In this paper , we describe our approach to the d",
            "label": 0,
            "score": 0.0537903205094263
          },
          {
            "rank": 4,
            "chunk_id": "2006.15680v1_abstract_0002",
            "chunk_text_preview": "to F 1 evaluated on test samples falling outside the convex hull of the training set . Experimental results demonstrate the relevance of using the concept of the convex hull of the training data in assessing machine learning generalization , by emphasizing the difference between interpolated and extrapolated predictions . Besides several predictable correlations , we observe unexpectedly weak asso",
            "label": 1,
            "score": 0.04874450793684788
          },
          {
            "rank": 5,
            "chunk_id": "1907.07543v1_introduction_0008",
            "chunk_text_preview": "with small quantities of data . In this paper we attempt to answer this question in the context of classification tasks . What is the best paradigm to use in the case where we have 100 -1000 labelled training examples per class -classical machine learning or deep transfer learning ? We seek to compare the best-in-class approaches from both deep transfer learning and classical machine learning by t",
            "label": 1,
            "score": 0.045928563142871734
          }
        ]
      }
    ],
    "top_k": 5
  }
}