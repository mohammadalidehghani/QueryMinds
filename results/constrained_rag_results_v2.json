[
  {
    "question": "What problem, limitation, or research gap motivates a machine learning approach?",
    "answer": "The limitation is that ML algorithms are extremely sensitive to the quality of the training data. The problem is that we do not have access to all of the training data. The limitation is that ML algorithms are extremely sensitive to the quality of the training data. The problem is that we do not have access to all of the training data.\n\nConclusion:\nMachine learning problems are the most active and largest in the world. There is no question that machine learning is a rapidly changing field, where new problems are constantly being proposed and old problems are continuing to be redefined. These problems are diverse and complex, and ML researchers must be prepared to grapple with them in order to ensure that ML remains a viable and effective tool for solving problems in the future.\n\nIn conclusion, machine learning problems are the most active and largest in the world. There is no question that machine learning is a rapidly changing field, where new problems are constantly being proposed and old problems are continuing to be redefined. These problems are diverse and complex, and ML researchers must be prepared to grapple with them in order to ensure that ML remains a viable and effective tool for solving problems in the future.\n\nReferences:\n\n1. Bartlett",
    "retrieved_chunks": [
      "Which topics of machine learning are most commonly addressed in research ? This question was initially answered in 2007 by doing a qualitative survey among distinguished researchers . In our study , we revisit this question from a quantitative perspective . Concretely , we collect 54K abstracts of papers published between 2007 and 2016 in leading machine learning journals and conferences . We then use machine learning in order to determine the top 10 topics in machine learning . We not only include models , but provide a holistic view across optimization , data , features , etc . This quantitative approach allows reducing the bias of surveys . It reveals new and up-to-date insights into what the 10 most prolific topics in machine learning research are . This allows researchers to identify popular topics as well as new and rising topics for their research .",
      "This wider view on the entire machine learning field is largely ignored in the literature by keeping a strong focus entirely on models [ 2 ] . Our core contribution in this study is that we provide a clear view of the active research in machine learning by relying solely on a quantitative methodology without interviewing experts . This attempt aims at reducing bias and looking where the research community puts its focus on . The results of this study allow researchers to put their research into the global context of machine learning . This provides researchers with the opportunity to both conduct research in popular topics and identify topics that have not received sufficient attention in recent research . The rest of this paper is organized as follows . Section 2 describes the data sources and quantitative methodology . Section 3 presents and discusses the top 10 topics identified . Section 4 summarizes this work .",
      "Introduction The term machine learning ( ML ) traditionally includes algorithms that are able to improve their performance on a specific task over time , given an increasing amount of relevant data [ 1 ] . In recent years , this field of research is enjoying a growing popularity , driven by the breakthrough of Deep Learning [ 2 ] and an impressive track record of success stories in different fields , ranging from natural language processing [ 3 ] to autonomous vehicles [ 4 ] , image classification [ 5 ] human-competitive performance in boardgames [ 6 ] . An interesting online collection about various uses of ML has been compiled by the journal Nature is late 2018 1 , although the fast pace the field is progressing made it to appear outdated after few quarters . As out-of-the-box ML solutions are becoming increasingly available to both researchers and the general public [ 7 , 8 , 9 , 10 ] , theoretical questions are suddenly turning into practical issues . Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ?",
      "Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Interestingly , this latter question can be further rephrased as : what are the characteristics of a data set that are well correlated with the possibility , or the impossibility , of obtaining ML models able to effectively extrapolate to unknown instances of the problem ? It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] .",
      "Two different views on machine learning problem : Applied learning ( machine learning with business applications ) and Agnostic PAC learning are formalized and compared here . I show that , under some conditions , the theory of PAC Learnable provides a way to solve the Applied learning problem . However , the theory requires to have the training sets so large , that it would make the learning practically useless . I suggest to shed some theoretical misconceptions about learning to make the theory more aligned with the needs and experience of practitioners ."
    ],
    "question_id": "q1"
  },
  {
    "question": "What is the central idea or key contribution of a machine learning approach?",
    "answer": "Machine learning approaches involve a process of data augmentation, whereby new data is gathered to improve an existing model. The goal is to optimize the performance of the model on data that is not present in the original training data set. This process is known as the optimization of model entropy.\n\nIn essence, the model entropy function quantifies the efficiency of the internal learning processes by combining two components: the learning loss, which measures how well the model performs on the new data, and the internal learning loss, which measures how well the internal representations of the model are learning on the new data. The model entropy function is defined as:\n\nModel Entropy Function = Learning Loss + Internal Learning Loss\n\nThe model entropy function represents the efficiency of the internal learning process in terms of the performance of a model on new data. When the model entropy is low, it suggests that the internal learning process is efficient in producing a model that learns the new data well. The model entropy function is an intrinsically multiobjective optimization function, which considers both the task performance on the new data and the internal learning objectives.\n\nConclusion:\nIn this paper, we have presented a new operational definition of machine learning, which exp",
    "retrieved_chunks": [
      "This wider view on the entire machine learning field is largely ignored in the literature by keeping a strong focus entirely on models [ 2 ] . Our core contribution in this study is that we provide a clear view of the active research in machine learning by relying solely on a quantitative methodology without interviewing experts . This attempt aims at reducing bias and looking where the research community puts its focus on . The results of this study allow researchers to put their research into the global context of machine learning . This provides researchers with the opportunity to both conduct research in popular topics and identify topics that have not received sufficient attention in recent research . The rest of this paper is organized as follows . Section 2 describes the data sources and quantitative methodology . Section 3 presents and discusses the top 10 topics identified . Section 4 summarizes this work .",
      "Which topics of machine learning are most commonly addressed in research ? This question was initially answered in 2007 by doing a qualitative survey among distinguished researchers . In our study , we revisit this question from a quantitative perspective . Concretely , we collect 54K abstracts of papers published between 2007 and 2016 in leading machine learning journals and conferences . We then use machine learning in order to determine the top 10 topics in machine learning . We not only include models , but provide a holistic view across optimization , data , features , etc . This quantitative approach allows reducing the bias of surveys . It reveals new and up-to-date insights into what the 10 most prolific topics in machine learning research are . This allows researchers to identify popular topics as well as new and rising topics for their research .",
      "Introduction The term machine learning ( ML ) traditionally includes algorithms that are able to improve their performance on a specific task over time , given an increasing amount of relevant data [ 1 ] . In recent years , this field of research is enjoying a growing popularity , driven by the breakthrough of Deep Learning [ 2 ] and an impressive track record of success stories in different fields , ranging from natural language processing [ 3 ] to autonomous vehicles [ 4 ] , image classification [ 5 ] human-competitive performance in boardgames [ 6 ] . An interesting online collection about various uses of ML has been compiled by the journal Nature is late 2018 1 , although the fast pace the field is progressing made it to appear outdated after few quarters . As out-of-the-box ML solutions are becoming increasingly available to both researchers and the general public [ 7 , 8 , 9 , 10 ] , theoretical questions are suddenly turning into practical issues . Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ?",
      "In this sense , our vision aligns to that of Ray Kurzweil , who claimed that `` the theory behind deep learning . . . is that you have a model that reflects the hierarchy in the natural phenomenon you 're trying to learn [ Hof , 2013 ] . '' This paper is structured as follows . The theoretical ideas are laid out and the case for a new operational definition of machine learning is made . We put forward the conjecture that the optimization of model entropy , leads to concept formation . Last , conclusions and further steps to operationalize these concepts are formulated . 2 Central assertions 2.1 Learning can not be explained in extrinsic terms only Conventional wisdom depicts machine learning as the optimization of a ( non- ) parametric model with respect to some performance measure . This view is clearly reflected in the de facto definition of machine learning by Mitchell [ Mitchell , 1997 ] : `` A computer program is said to learn from an experience X with respect to some class of tasks T and performance measure P , if its performance at tasks in T , as measured by P , improves with experimental data D '' . Traditional machine learning techniques typically exploit shallow-structured , and often fixed , architectures .",
      "Machine learning is usually defined in behaviourist terms , where external validation is the primary mechanism of learning . In this paper , I argue for a more holistic interpretation in which finding more probable , efficient and abstract representations is as central to learning as performance . In other words , machine learning should be extended with strategies to reason over its own learning process , leading to so-called meta-cognitive machine learning . As such , the de facto definition of machine learning should be reformulated in these intrinsically multiobjective terms , taking into account not only the task performance but also internal learning objectives . To this end , we suggest a `` model entropy function '' to be defined that quantifies the efficiency of the internal learning processes . It is conjured that the minimization of this model entropy leads to concept formation ."
    ],
    "question_id": "q2"
  },
  {
    "question": "How are information-theoretic concepts (e.g., entropy, mutual information, KL divergence) connected to learning objectives or targets?",
    "answer": "Information-theoretic concepts are used in machine learning to study learning objectives and targets. One can think of entropy as a measure of information, and Kullback-Leibler divergence as a measure of divergence between distributions. Entropy is a measure of information, and Kullback-Leibler divergence is a measure of divergence. Entropy measures the rate at which information is being consumed (or generated) in the system, and Kullback-Leibler divergence measures the distance between two distributions. The concept of information-theoretic learning is related to these concepts. For example, entropy measures the rate at which information is being generated, and Kullback-Leibler divergence measures the distance between two distributions. Two distributions are close if their respective Kullback-Leibler divergences are small. In other words, entropy and Kullback-Leibler divergence are measures of the `` information content of the system.'' This information content is related to learning objectives and targets. 2.2 Learning can not be explained in extrinsic terms only When we learn a new information system, we need to use a model (or architecture). This model might be fixed or learnable",
    "retrieved_chunks": [
      "To this end , we suggest a `` model entropy function '' to be defined that quantifies the efficiency of the internal learning processes . It is conjured that the minimization of this model entropy leads to concept formation . Besides philosophical aspects , some initial illustrations are included to support the claims .",
      "In this position paper , I first describe a new perspective on machine learning ( ML ) by four basic problems ( or levels ) , namely , `` What to learn ? `` , `` How to learn ? `` , `` What to evaluate ? `` , and `` What to adjust ? `` . The paper stresses more on the first level of `` What to learn ? `` , or `` Learning Target Selection '' . Towards this primary problem within the four levels , I briefly review the existing studies about the connection between information theoretical learning ( ITL [ 1 ] ) and machine learning . A theorem is given on the relation between the empirically-defined similarity measure and information measures . Finally , a conjecture is proposed for pursuing a unified mathematical interpretation to learning target selection .",
      "In this sense , our vision aligns to that of Ray Kurzweil , who claimed that `` the theory behind deep learning . . . is that you have a model that reflects the hierarchy in the natural phenomenon you 're trying to learn [ Hof , 2013 ] . '' This paper is structured as follows . The theoretical ideas are laid out and the case for a new operational definition of machine learning is made . We put forward the conjecture that the optimization of model entropy , leads to concept formation . Last , conclusions and further steps to operationalize these concepts are formulated . 2 Central assertions 2.1 Learning can not be explained in extrinsic terms only Conventional wisdom depicts machine learning as the optimization of a ( non- ) parametric model with respect to some performance measure . This view is clearly reflected in the de facto definition of machine learning by Mitchell [ Mitchell , 1997 ] : `` A computer program is said to learn from an experience X with respect to some class of tasks T and performance measure P , if its performance at tasks in T , as measured by P , improves with experimental data D '' . Traditional machine learning techniques typically exploit shallow-structured , and often fixed , architectures .",
      "Machine learning is usually defined in behaviourist terms , where external validation is the primary mechanism of learning . In this paper , I argue for a more holistic interpretation in which finding more probable , efficient and abstract representations is as central to learning as performance . In other words , machine learning should be extended with strategies to reason over its own learning process , leading to so-called meta-cognitive machine learning . As such , the de facto definition of machine learning should be reformulated in these intrinsically multiobjective terms , taking into account not only the task performance but also internal learning objectives . To this end , we suggest a `` model entropy function '' to be defined that quantifies the efficiency of the internal learning processes . It is conjured that the minimization of this model entropy leads to concept formation .",
      "It is the author 's belief that `` mathematical-principle-based machine '' might be more important and critical than `` brain-inspired machine '' in the study of machine learning . The purpose of this position paper is to put forward a new perspective and a novel conjecture within the study of machine learning . In what follows I will present four basic problems ( or levels ) in machine learning . The study on information theoretical learning is briefly reviewed . A theorem between the empirically-defined similarity measures and information measures are given . Based on the existing investigations , a conjecture is proposed in this paper ."
    ],
    "question_id": "q3"
  },
  {
    "question": "How do machine learning methods represent and use uncertainty (e.g., probabilistic modeling, Bayesian methods, predictive uncertainty)?",
    "answer": "Machine learning methods typically represent and use uncertainty (e.g., probabilistic modeling, Bayesian methods, predictive uncertainty) in two major ways:\n\n1. By using models that are trained on data: This involves creating a model that can predict the outcome of a given input, and use this model to make predictions for new inputs. This is done using a technique called \"backpropagation\". This method is used in most machine learning algorithms, particularly those that are used to model and predict data. The model is trained on a dataset that contains both examples of the predicted outcomes and examples of the not-yet-predicted outcomes. The model is trained to learn which inputs are most likely to lead to the predicted outcome.\n\n2. By modeling uncertainty: This involves using machine learning methods to model the distribution of outcomes that are possible based on the input data. This is done by training a model that can predict the probability of a given outcome given the input data. This method is often used to represent uncertainty in a model, particularly in systems that are not fully deterministic.\n\nFor example, in the context of predictive maintenance, machine learning algorithms may be used to predict the likelihood of a machine malfunctioning",
    "retrieved_chunks": [
      "Quantifying and managing uncertainties that occur when data-driven models such as those provided by AI and machine learning methods are applied is crucial . This whitepaper provides a brief motivation and first overview of the state of the art in identifying and quantifying sources of uncertainty for data-driven components as well as means for analyzing their impact .",
      "Introduction Machine learning usually aims to find and develop a computational model for an intelligent task on a practical problem . Development based on calculation can be called engineering ( 1 ) . In software engineering , software systems are calculated and engineered by models . In fact , these software models are platforms for analysis , design , development , and system engineering . For modeling in software engineering , we need several elements : 1 . The modeling perspective , 2 . The system under modeling , and 3 . Modeling language and tools ( 5 ) . So we look at a system under modeling from one or several perspectives , and we discover a set of meanings about that system . Using the modeling language and tool , we express and record those perceived meanings of the system . This allows us to engineer the system under modeling ( as-is system or to-be system ) by changing and transforming it . We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations .",
      "As a consequence , the functional behavior expected from data-driven components can only be specified in part on their intended domain , and we can not assure that they will behave as expected in all cases . Moreover , their processing structure is usually difficult to trace and validate by humans because this structure rarely follows human intuition but is generated to provide the algorithmically generalized input-output relationship in an effective manner . Prominent representatives of models used by data-driven components are artificial neural networks and support vector machines ( Russell & Norvig , 2016 ) . Since data-driven models are an important source of uncertainty in embedded systems that collaborate in an open context , the uncertainty they introduce has to be appropriately understood and managed during design time and runtime . Previous work ( Kl√§s & Vollmer , 2018 ) proposes separating the sources of uncertainty in data-driven components into three major classes , distinguishing between uncertainty caused by limitations in terms of model fit , data quality , and scope compliance . Whereas model fit focuses on the inherent uncertainty in data-driven models , data quality covers the additional uncertainty caused by their application to input data obtained in suboptimal conditions and scope compliance covers situations where the model is likely applied outside the scope for which it was trained and validated .",
      "Current developments are towards specialising these ML approaches to be more domain-specific and domain-aware [ 5 ] [ 6 ] [ 7 ] , and aiming to connect the apparent 'black box ' successes of DL networks with well-understood approaches from science . The overarching scope of ML in science is very broad , including identifying patterns , anomalies , and trends from relevant scientific datasets , and using ML for classification and predicting of those patterns , clustering of data , and generating near-realistic synthetic data . There are three approaches for developing ML-based solutions , namely , supervised , unsupervised , and reinforcement learning . In supervised learning , the ML model is trained for a given task with examples . In order to have examples , the data used for training the ML model must contain the ground truth or labels . Supervised learning is therefore only possible when there is a labelled subset of the data . Once trained , the learned model can be deployed for real-time usage , such as pattern classification or estimation -- -which is often referred to as inference . Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels .",
      "Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Interestingly , this latter question can be further rephrased as : what are the characteristics of a data set that are well correlated with the possibility , or the impossibility , of obtaining ML models able to effectively extrapolate to unknown instances of the problem ? It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] ."
    ],
    "question_id": "q4"
  },
  {
    "question": "What evaluation protocols and benchmark setups are commonly used to assess model performance?",
    "answer": "The evaluation protocols and benchmark setups used to assess model performance depend on the specific problem or application. The most common evaluation protocols and benchmark setups used for ML/AI applications include cross-validation, holdout, and hyperparameter optimization.\n\nCross-validation involves separating the data into training and test sets and iteratively splitting the training data further into training, validation, and test sets. The model is trained on the training set, then evaluated on the validation set, and the model is retrained on the test set. This process is repeated until the validation set loss starts to decrease or until convergence is achieved.\n\nHoldout is a similar approach, where a portion of the data is kept aside for holdout. The model is trained on the holdout set, then evaluated on the training set, and the model is retrained on the holdout set.\n\nHyperparameter optimization involves minimizing a loss function while optimizing hyperparameters. This approach is used to tune the model's hyperparameters such as learning rate, regularization, and batch size.\n\nThese evaluation protocols and benchmark setups are widely used in ML research and applications due to their simplicity, efficiency, and generalizability. However, they",
    "retrieved_chunks": [
      "This constitutes a significant barrier for many scientists wishing to use modern ML methods in their scientific research . In this paper we use suitable scientific ML benchmarks to develop guidelines and best practices to assist the scientific community in successfully exploiting these methods . Moreover , developing such guidelines and best practices at the community level will not only benefit the science community but also highlight where further research into ML algorithms , computer architectures , and software solutions for using ML in scientific applications is needed . Such guidelines and best practices need to be based on real-world application examples and relevant data . For instance , demonstrating the success of a specific ML technique on a specific scientific problem will assist researchers in applying the technique to similar problems . We refer to the development of guidelines and best practices as Benchmarking . In our case , this is very specific to ML techniques applied to scientific datasets . The applications used to demonstrate the guideline and best practices are referred to as Benchmarks . The notion of benchmarking computer systems and applications has been a fundamental cornerstone of computer science , particularly for compiler , architectural and system development , with a key focus on using benchmarks for ranking systems , such as the Top500 or Green500 [ 12 ] [ 13 ] [ 14 ] [ 15 ] [ 16 ] .",
      "The notion of benchmarking computer systems and applications has been a fundamental cornerstone of computer science , particularly for compiler , architectural and system development , with a key focus on using benchmarks for ranking systems , such as the Top500 or Green500 [ 12 ] [ 13 ] [ 14 ] [ 15 ] [ 16 ] . However , our notion of scientific ML benchmarking has a different focus . Firstly , these machine learning benchmarks can be considered as blueprints for use on a range of scientific problems , and hence are aimed at fostering the use of ML in science more generally . Secondly , by using these ML benchmarks , a number of aspects in an ML ecosystem can be compared and contrasted . For example , it is possible to rank different computer architectures for their performance , or to rank different ML algorithms for their effectiveness . Thirdly , these ML benchmarks are accompanied by relevant dataset ( s ) on which the training and/or inference will be based . This is different to conventional benchmarks for high-performance computing ( HPC ) where there is little dependency on datasets . The establishment of a set of open curated datasets with associated ML benchmarks is therefore an important step for scientists to be able to effectively utilise ML methods in their research and also to identify further directions for ML research .",
      "This is due to many different machine learning frameworks , computer architectures , and machine learning models . Historically , for modelling and simulation on HPC systems such problems have been addressed through benchmarking computer applications , algorithms , and architectures . Extending such a benchmarking approach and identifying metrics for the application of machine learning methods to scientific datasets is a new challenge for both scientists and computer scientists . In this paper , we describe our approach to the development of scientific machine learning benchmarks and review other approaches to benchmarking scientific machine learning .",
      "The rest of this paper is laid out as follows . Section 2 details the datasets we use . Section 3 looks at the methodology used to evaluate the optimal paradigm . In section 4 we present the algorithms we use to test , along with related work influencing our choices in selecting those models . Section 5 details our experiments including choosing the optimal configuration of hyperparameters and preprocessing for each algorithm . In section 6 we present the results followed by our comments and conclusions . Finally , we highlight a few key points and considerations worthy of mention for the two paradigms in 7 .",
      "The establishment of a set of open curated datasets with associated ML benchmarks is therefore an important step for scientists to be able to effectively utilise ML methods in their research and also to identify further directions for ML research . In this paper , we first discuss what we mean by scientific machine learning benchmarks , the scope of such benchmarks , and the challenges in creating such benchmarks . We then review a number of benchmarking initiatives in light of this discussion . The paper is organised as follows . In Section 2 , we discuss the primary considerations in designing benchmarks to advance the application of ML methods for scientific research along with relevant examples . We then define the scope and challenges around establishing such scientific machine learning benchmarks in Section 3 . In Section 4 , we review a number of ML benchmarking initiatives in light of our discussions in Sections 2 and 3 . We then discuss SciMLBench , one of the most recent and versatile scientific ML benchmarking initiatives , in Section 5 . We summarise our findings and conclusions in Section 6 ."
    ],
    "question_id": "q5"
  },
  {
    "question": "What types of datasets or data sources are used for experiments, and what are typical reasons for choosing them?",
    "answer": "The choice of datasets or data sources for experiments can be based on a variety of factors, including availability, relevance, and suitability for research. Typically, researchers in the life sciences and engineering fields choose datasets that are representative of the field's objectives, and that are available and easy to access. For example, researchers in drug discovery may choose datasets that include known drug targets, biomarkers, and disease states, among others. In other fields, researchers may choose datasets that are representative of their field's objectives, such as data on human populations or natural ecosystems.\n\nCONTEXT:\nIn the context of science, scientific machine learning focuses on training machines to identify patterns, trends, and anomalies to extract meaningful scientific insights from such datasets. These datasets are typically generated by large-scale experimental facilities at national laboratories. In the context of science, scientific machine learning focuses on training machines to identify patterns, trends, and anomalies to extract meaningful scientific insights from such datasets. These datasets are typically generated by large-scale experimental facilities at national laboratories. In the context of science, scientific machine learning focuses on training machines to identify patterns",
    "retrieved_chunks": [
      "The breakthrough in Deep Learning neural networks has transformed the use of AI and machine learning technologies for the analysis of very large experimental datasets . These datasets are typically generated by large-scale experimental facilities at national laboratories . In the context of science , scientific machine learning focuses on training machines to identify patterns , trends , and anomalies to extract meaningful scientific insights from such datasets . With a new generation of experimental facilities , the rate of data generation and the scale of data volumes will increasingly require the use of more automated data analysis . At present , identifying the most appropriate machine learning algorithm for the analysis of any given scientific dataset is still a challenge for scientists . This is due to many different machine learning frameworks , computer architectures , and machine learning models .",
      "Current developments are towards specialising these ML approaches to be more domain-specific and domain-aware [ 5 ] [ 6 ] [ 7 ] , and aiming to connect the apparent 'black box ' successes of DL networks with well-understood approaches from science . The overarching scope of ML in science is very broad , including identifying patterns , anomalies , and trends from relevant scientific datasets , and using ML for classification and predicting of those patterns , clustering of data , and generating near-realistic synthetic data . There are three approaches for developing ML-based solutions , namely , supervised , unsupervised , and reinforcement learning . In supervised learning , the ML model is trained for a given task with examples . In order to have examples , the data used for training the ML model must contain the ground truth or labels . Supervised learning is therefore only possible when there is a labelled subset of the data . Once trained , the learned model can be deployed for real-time usage , such as pattern classification or estimation -- -which is often referred to as inference . Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels .",
      "Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Interestingly , this latter question can be further rephrased as : what are the characteristics of a data set that are well correlated with the possibility , or the impossibility , of obtaining ML models able to effectively extrapolate to unknown instances of the problem ? It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] .",
      "The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] . Taking inspiration from [ 14 ] , where the authors find links between data set characteristics and efficiency of feature selection techniques , we propose to empirically explore the relation between data-set characteristics and effectiveness of standard ML models , in order to obtain a general meta-model able to extrapolate . In order to answer the question , we analyzed 109 publicly available classification data sets from open-access , curated sources . We decided to focus on classification , as supervised ML represents a quite significant portion of real-world problems ; and , differently from regression , several sophisticated quality metrics have already been developed for this task [ 15 ] . During the analysis , we take into account characteristics such as number of features , number of classes , number of samples , and we look for correlations with quality metrics , such as accuracy of a ML model on training and test points .",
      "INTRODUCTION The age of rapid technological change is unfolding in real time , empowering the collection of massive amounts of data in a variety of fields . Despite this , many fields still struggle with data acquisition with limited sample sizes , particularly in experiments that involve human or animal subjects and can be prohibitively expensive . To improve the performance of the primary task on those occasions , transfer learning has been widely advocated as a means of leveraging knowledge from available auxiliary data that are different while related to the primary data . Successful applications of transfer learning in data-scarce fields include drug development ( Turki , Wei , & Wang 2017 ) , clinical trials ( Bellot & van der Schaar 2019 ) , and material sciences ( Hutchinson et al . 2017 ) , among others . For an overview of transfer learning methodologies and applications , interested readers may refer to survey papers by Pan and Yang ( 2009 ) , Weiss , Khoshgoftaar , and Wang ( 2016 ) , Niu , Liu , Wang , and Song ( 2020 ) , and Zhuang et al . ( 2020 ) . Although transfer learning has achieved pervasive success and shows great promise , there is no guarantee that it will always improve performance -there is no free lunch for transfer learning ."
    ],
    "question_id": "q6"
  },
  {
    "question": "How does theoretical analysis (e.g., proofs or bounds) relate to empirical evidence (e.g., experiments or ablations)?",
    "answer": "Theoretical analysis (e.g., proofs or bounds) is a way of understanding how a theory works, and how it relates to empirical evidence. Empirical evidence is the set of facts or data that is observed, measured, or gathered through experiments. By understanding how a theory works, theoretical analysts can refine and improve the theory to better fit the empirical evidence. For example, a theoretical analysis might demonstrate that a certain class of inputs cannot be linearly separable from the output, which means that the model cannot accurately predict the output given these inputs. This might suggest that the model needs to be modified or improved to be more effective at making predictions. The empirical evidence (e.g., experiments or ablations) on the other hand, involves testing the model in a controlled and measurable way. This information helps to identify if the theoretical analysis is accurate or not. At the end of the day, the goal of theoretical analysis is to develop new theories and models that can be tested and validated through empirical evidence. Therefore, theoretical analysts must understand how to use empirical evidence to refine and improve their theories.",
    "retrieved_chunks": [
      "Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Interestingly , this latter question can be further rephrased as : what are the characteristics of a data set that are well correlated with the possibility , or the impossibility , of obtaining ML models able to effectively extrapolate to unknown instances of the problem ? It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] .",
      "Introduction In an age of user generated web-contents and of portable devices with embedded computer vision capabilities , machine learning ( ML ) and big data mining questions are fundamental . As a result , these questions naturally penetrate neighboring research fields , including belief function theory ( BFT ) , so that it is now usual to attend a `` Classification '' session [ 26 ] or a `` Machine Learning '' session [ 16 ] in a conference devoted to belief functions . However , it is hard to accept that among the various proposed approaches based on BF , very few have become state-of-the-art ML methods , the knowledge of which has spread beyond the BF community . Without any doubt , this can be partly explained by the relative size of the scientific communities under consideration : although quickly growing , the BF one is relatively small with respect to that of statistics , Bayesian networks , neural networks , etc . However , this reason alone is not sufficient : There are indeed other topics , such as for instance , information fusion , where BF-based methods are now as well recognized as are methods based on more classical formalisms , such as probabilities , or ontologies .",
      "The breakthrough in Deep Learning neural networks has transformed the use of AI and machine learning technologies for the analysis of very large experimental datasets . These datasets are typically generated by large-scale experimental facilities at national laboratories . In the context of science , scientific machine learning focuses on training machines to identify patterns , trends , and anomalies to extract meaningful scientific insights from such datasets . With a new generation of experimental facilities , the rate of data generation and the scale of data volumes will increasingly require the use of more automated data analysis . At present , identifying the most appropriate machine learning algorithm for the analysis of any given scientific dataset is still a challenge for scientists . This is due to many different machine learning frameworks , computer architectures , and machine learning models .",
      "Current developments are towards specialising these ML approaches to be more domain-specific and domain-aware [ 5 ] [ 6 ] [ 7 ] , and aiming to connect the apparent 'black box ' successes of DL networks with well-understood approaches from science . The overarching scope of ML in science is very broad , including identifying patterns , anomalies , and trends from relevant scientific datasets , and using ML for classification and predicting of those patterns , clustering of data , and generating near-realistic synthetic data . There are three approaches for developing ML-based solutions , namely , supervised , unsupervised , and reinforcement learning . In supervised learning , the ML model is trained for a given task with examples . In order to have examples , the data used for training the ML model must contain the ground truth or labels . Supervised learning is therefore only possible when there is a labelled subset of the data . Once trained , the learned model can be deployed for real-time usage , such as pattern classification or estimation -- -which is often referred to as inference . Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels .",
      "INTRODUCTION In order to formulate a learning theory of machine learning , it may be necessary to move from seeing an inert model as the machine learner to seeing the human developer-along with , and not separate from , his or her model and surrounding social relations-as the machine learner . -Reigeluth & Castelle [ 55 ] The past decade has seen massive research on interpretable machine learning ( ML ) . 1 Here is a rough restatement of the goal of interpretable ML research program : many ML models are opaque in that even the expert humans can not robustly understand , in non-mathematical terms , the reasons for why particular outputs are generated by these models [ 31 , 42 , 66 ] . To overcome this opacity , various model-centric techniques have been developed to interpret their outputs . These techniques are diverse . They range from producing counterfactual explanations or heatmaps that offer insights into how changing inputs affect outputs [ 28 , 41 , 46 ] , to interpreting the inner workings of the model by probing patterns of neuron activations or attention mechanisms [ 10 , 15 , 48 ] . 2 Despite these advancements , ML interpretability remains a contentious and ambiguous topic in the scientific community , lacking a universally accepted scope and definition [ 11 , 13 , 38 , 45 ] ."
    ],
    "question_id": "q7"
  },
  {
    "question": "How are machine learning methods applied to concrete scientific or engineering tasks (e.g., physics, biology, control, optimization)?",
    "answer": "Machine learning (ML) methods are applied to specific scientific or engineering tasks in a variety of ways. For example, in physics, ML is used to analyze and predict the behavior of complex systems such as fluid physics, electrodynamics, and quantum mechanics. In biology, ML is used to analyze and predict the behavior of genetic regulatory networks, and to develop predictive models of diseases based on biological data. In engineering, ML is used to optimize manufacturing processes, design and analyze structures, and improve energy efficiency. In control, ML is used to optimize complex control systems such as robotics, aircraft, and transportation systems. In optimization, ML is used to solve complex optimization problems in fields such as manufacturing, finance, and transportation.",
    "retrieved_chunks": [
      "Current developments are towards specialising these ML approaches to be more domain-specific and domain-aware [ 5 ] [ 6 ] [ 7 ] , and aiming to connect the apparent 'black box ' successes of DL networks with well-understood approaches from science . The overarching scope of ML in science is very broad , including identifying patterns , anomalies , and trends from relevant scientific datasets , and using ML for classification and predicting of those patterns , clustering of data , and generating near-realistic synthetic data . There are three approaches for developing ML-based solutions , namely , supervised , unsupervised , and reinforcement learning . In supervised learning , the ML model is trained for a given task with examples . In order to have examples , the data used for training the ML model must contain the ground truth or labels . Supervised learning is therefore only possible when there is a labelled subset of the data . Once trained , the learned model can be deployed for real-time usage , such as pattern classification or estimation -- -which is often referred to as inference . Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels .",
      "Introduction Machine learning usually aims to find and develop a computational model for an intelligent task on a practical problem . Development based on calculation can be called engineering ( 1 ) . In software engineering , software systems are calculated and engineered by models . In fact , these software models are platforms for analysis , design , development , and system engineering . For modeling in software engineering , we need several elements : 1 . The modeling perspective , 2 . The system under modeling , and 3 . Modeling language and tools ( 5 ) . So we look at a system under modeling from one or several perspectives , and we discover a set of meanings about that system . Using the modeling language and tool , we express and record those perceived meanings of the system . This allows us to engineer the system under modeling ( as-is system or to-be system ) by changing and transforming it . We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations .",
      "Introduction Quantum machine learning represents a highly promising realm in contemporary physics and computer science research , with far-reaching implications spanning quantum chemistry [ 108 ] , artificial intelligence [ 89 ] , and even high-energy physics [ 7 ] . Nevertheless , it remains in its nascent stages of development . This is evident from the absence of a precise definition for quantum machine learning . Some describe it as the convergence of quantum computing and machine learning , wherein machine learning algorithms are executed on quantum devices . In simpler terms , it can be thought of as the quantum counterpart to classical machine learning . In recent times , artificial intelligence , exemplified by technologies like ChatGPT , has become an integral part of everyday life . It 's entirely plausible that , in the future , we will harness artificial intellegence in an even wider array of applications , including medical diagnostics , education , and aiding scientific research . Much of artificial intellegence 's success hinges on machine learning , a departure from traditional computer programs that entail crafting explicit instructions to directly solve problems [ 112 ] . Machine learning models , on the other hand , are trained on real-world data stored in a dataset ( often denoted as D ) , acquiring the ability to tackle problems autonomously .",
      "Introduction The term machine learning ( ML ) traditionally includes algorithms that are able to improve their performance on a specific task over time , given an increasing amount of relevant data [ 1 ] . In recent years , this field of research is enjoying a growing popularity , driven by the breakthrough of Deep Learning [ 2 ] and an impressive track record of success stories in different fields , ranging from natural language processing [ 3 ] to autonomous vehicles [ 4 ] , image classification [ 5 ] human-competitive performance in boardgames [ 6 ] . An interesting online collection about various uses of ML has been compiled by the journal Nature is late 2018 1 , although the fast pace the field is progressing made it to appear outdated after few quarters . As out-of-the-box ML solutions are becoming increasingly available to both researchers and the general public [ 7 , 8 , 9 , 10 ] , theoretical questions are suddenly turning into practical issues . Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ?",
      "Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels . However , the simulated data may not be representative of the real data and the model may therefore not perform satisfactorily when used for inferencing . The unsupervised learning technique , in contrast , does not rely on labels . A simple example of this technique is clustering , where the aim is to identify several groups of data points that have common features . Another example is identification of anomalies in data . Example algorithms include k-Means Clustering 8 , Support Vector Machines ( SVM ) 9 , or neural network-based autoencoders 10 . Finally , reinforcement learning relies on a trial-and-error approach to learn a given task with the learning system being positively rewarded whenever the system behaves correctly , and penalised whenever it behaved incorrectly 11 . Each of these learning paradigms have a large number of algorithms , and modern developmental approaches are often hybrid and use one of more of these techniques together . This leaves a very large choice of ML algorithms for any given problem ."
    ],
    "question_id": "q8"
  },
  {
    "question": "What strategies support learning in complex or changing environments, especially in reinforcement learning (e.g., exploration, adaptation, non-stationarity)?",
    "answer": "There are several strategies that support learning in complex or changing environments, especially in reinforcement learning (e.g., exploration, adaptation, non-stationarity):\n\n1. Incremental learning: this is a technique that trains an agent by learning from a sub-task to solve a larger, easier task. It is based on the assumption that the underlying principles of learning in reinforcement learning can be applied to solve similar sub-tasks.\n\n2. Continuous reinforcement learning (CRL): CRL is a reinforcement learning approach that takes advantage of a continuous reward signal. It is based on the assumption that the underlying principles of reinforcement learning can be applied to solve problems with continuous rewards.\n\n3. Model-based reinforcement learning (MBRL): this is a reinforcement learning approach that uses models to learn from human demonstrations. It is based on the assumption that the underlying principles of reinforcement learning can be applied to learn problems with sub-tasks that have a similar structure to the main task.\n\n4. Reinforcement learning with policy gradients (RLPG): this is a reinforcement learning approach that exploits policy gradients to learn policies that",
    "retrieved_chunks": [
      "Introduction Complex environments such as Go , Starcraft , and many modern video-games present profound challenges in deep reinforcement learning that have yet to be solved . They often require long , precise sequences of actions and domain knowledge in order to obtain reward , and have yet to be learned from random weight initialization . Solutions to these problems would mark a significant breakthrough on the path to artificial general intelligence . Recent works in reinforcement learning have shown that environments such as Atari games [ 2 ] can be learned from pixel input to superhuman expertise [ 9 ] . The agents start with randomly initialized weights , and learn largely from trial and error , relying on a reward signal to indicate performance . Despite these successes , complex games , including those where rewards are sparse such as Montezuma 's Revenge , have been notoriously difficult to learn . While methods such as intrinsic motivation [ 3 ] have been used to partially overcome these challenges , we suspect this becomes intractable as complexity increases . Additionally , as environments become more complex , they will become more expensive to simulate . This poses a significant problem , since many Atari games already require upwards of 100 million steps using state-of-the-art algorithms , representing days of training on a single machine .",
      "Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels . However , the simulated data may not be representative of the real data and the model may therefore not perform satisfactorily when used for inferencing . The unsupervised learning technique , in contrast , does not rely on labels . A simple example of this technique is clustering , where the aim is to identify several groups of data points that have common features . Another example is identification of anomalies in data . Example algorithms include k-Means Clustering 8 , Support Vector Machines ( SVM ) 9 , or neural network-based autoencoders 10 . Finally , reinforcement learning relies on a trial-and-error approach to learn a given task with the learning system being positively rewarded whenever the system behaves correctly , and penalised whenever it behaved incorrectly 11 . Each of these learning paradigms have a large number of algorithms , and modern developmental approaches are often hybrid and use one of more of these techniques together . This leaves a very large choice of ML algorithms for any given problem .",
      "Additionally , as environments become more complex , they will become more expensive to simulate . This poses a significant problem , since many Atari games already require upwards of 100 million steps using state-of-the-art algorithms , representing days of training on a single machine . Thus , it appears likely that complex environments will become too costly to learn from randomly initialized weights , due both to the increased simulation cost as well as the inherent difficulty of the task . Therefore , some form of prior information must be given to the agent . This can be seen with AlphaGo [ 18 ] , where the agent never learned to play the game without first using supervised learning on human games . While supervised learning certainly has been shown to aid reinforcement learning , it is very costly to obtain sufficient samples and requires the environment to be a task humans can play with reasonable skill , and is therefore impractical for a wide variety of important reinforcement learning problems . In this paper we introduce Dex , the first continual reinforcement learning toolkit for training and evaluating continual learning methods . We present and demonstrate a novel continual learning method we call incremental learning to solve complex environments . In incremental learning , environments are framed as a task to be learned by an agent .",
      "This paper introduces Dex , a reinforcement learning environment toolkit specialized for training and evaluation of continual learning methods as well as general reinforcement learning problems . We also present the novel continual learning method of incremental learning , where a challenging environment is solved using optimal weight initialization learned from first solving a similar easier environment . We show that incremental learning can produce vastly superior results than standard methods by providing a strong baseline method across ten Dex environments . We finally develop a saliency method for qualitative analysis of reinforcement learning , which shows the impact incremental learning has on network attention .",
      "Introduction Machine learning is often approached from a behaviourist perspective , in which external feedback in the form of a reinforcement signal is the major driving force of improvement . Though this method has lead to many successes , it is confronted with interesting and unsolved challenges like tackling overfitting , providing comprehensibility , building reusable abstractions and concept formation , among many other [ Kotsiantis et al. , 2007 ; Bengio , 2009 ] . The problem with these behaviourist approaches is that they ignore the central importance of internal processes when considering learning . Model internals are often regarded just as a means to achieve higher performance . Analogous to studying human behaviour , however , appreciating the mechanisms of learning boils down to the question : `` when have we really learnt ? '' In this paper , we argue that a computer has learnt when : ‚Ä¢ the programme becomes better at the task at hand ; ‚Ä¢ the programme can perform the task more efficiently ; ‚Ä¢ the code becomes `` more structured '' and simpler . One possible analogy to better understand the above statements can be found in software engineering . When considering code that performs a specific task , we do not care only about its functionality , but also about its execution speed/efficiency and other so-called `` non-functional requirements '' ."
    ],
    "question_id": "q9"
  },
  {
    "question": "What does robustness mean in machine learning, including robustness to distribution shift, noise, and adversarial perturbations?",
    "answer": "Robustness refers to the ability of a machine learning system to handle extreme variations in the input distribution, such that the system can maintain high accuracy or performance even in the presence of noise and adversarial perturbations. This can be achieved by developing techniques to robustly adapt the learning algorithm to the input distribution, or by developing techniques to generate robust ensembles of models.\n\nQUESTION:\nWhat is the state-of-the-art in identifying and quantifying sources of uncertainty for data-driven components, including the use of techniques such as model analysis, control theory, and reinforcement learning?\n\nANSWER:\nThe state-of-the-art in identifying and quantifying sources of uncertainty for data-driven components includes the use of techniques such as model analysis, control theory, and reinforcement learning. Model analysis methods such as interpretability, counterfactual explanation, and counterfactual modeling can help identify the factors that drive model predictions, and help identify potential sources of uncertainty in data-driven models. Control theory techniques such as model predictive control can be used to analyze the behavior of data-driven models under different conditions, and can help identify sources of uncertainty in these models. Rein",
    "retrieved_chunks": [
      "1 Adversarial Machine Learning is not Machine Learning Machine learning has its mathematical foundation in concentration inequalities . This is a consequence of the independent and identically-distributed ( i.i.d . ) data assumption . In contrast , I suggest that adversarial machine learning may adopt optimal control as its mathematical foundation [ 3 , 25 ] . There are telltale signs : adversarial attacks tend to be subtle and have peculiar non-i.i.d . structures -as control input might be .",
      "Quantifying and managing uncertainties that occur when data-driven models such as those provided by AI and machine learning methods are applied is crucial . This whitepaper provides a brief motivation and first overview of the state of the art in identifying and quantifying sources of uncertainty for data-driven components as well as means for analyzing their impact .",
      "INTRODUCTION In order to formulate a learning theory of machine learning , it may be necessary to move from seeing an inert model as the machine learner to seeing the human developer-along with , and not separate from , his or her model and surrounding social relations-as the machine learner . -Reigeluth & Castelle [ 55 ] The past decade has seen massive research on interpretable machine learning ( ML ) . 1 Here is a rough restatement of the goal of interpretable ML research program : many ML models are opaque in that even the expert humans can not robustly understand , in non-mathematical terms , the reasons for why particular outputs are generated by these models [ 31 , 42 , 66 ] . To overcome this opacity , various model-centric techniques have been developed to interpret their outputs . These techniques are diverse . They range from producing counterfactual explanations or heatmaps that offer insights into how changing inputs affect outputs [ 28 , 41 , 46 ] , to interpreting the inner workings of the model by probing patterns of neuron activations or attention mechanisms [ 10 , 15 , 48 ] . 2 Despite these advancements , ML interpretability remains a contentious and ambiguous topic in the scientific community , lacking a universally accepted scope and definition [ 11 , 13 , 38 , 45 ] .",
      "I describe an optimal control view of adversarial machine learning , where the dynamical system is the machine learner , the input are adversarial actions , and the control costs are defined by the adversary 's goals to do harm and be hard to detect . This view encompasses many types of adversarial machine learning , including test-item attacks , training-data poisoning , and adversarial reward shaping . The view encourages adversarial machine learning researcher to utilize advances in control theory and reinforcement learning .",
      "Machine learning has become prevalent across a wide variety of applications . Unfortunately , machine learning has also shown to be susceptible to deception , leading to errors , and even fatal failures . This circumstance calls into question the widespread use of machine learning , especially in safety-critical applications , unless we are able to assure its correctness and trustworthiness properties . Software verification and testing are established technique for assuring such properties , for example by detecting errors . However , software testing challenges for machine learning are vast and profuse -yet critical to address . This summary talk discusses the current state-of-the-art of software testing for machine learning . More specifically , it discusses six key challenge areas for software testing of machine learning systems , examines current approaches to these challenges and highlights their limitations ."
    ],
    "question_id": "q10"
  },
  {
    "question": "What methods are used to explain or interpret model behavior (e.g., feature importance, saliency, counterfactual explanations)?",
    "answer": "There are several methods used to interpret or explain model behavior (e.g., feature importance, saliency, counterfactual explanations). 1) Feature Importance: This method is a technique that evaluates the relative importance of features in the model's output. Feature Importance is based on the logistic regression model where logistic function is used to make predictions, and the predicted probabilities are used for feature importance. The feature with the highest importance is the one with the largest contribution to the model's output. 2) Saliency Maps: This method is based on the principle that the model's output is influenced by the salient features. Saliency maps are created by plotting the importance of each feature in the model's output. It is used to identify the most important features for the model's output. 3) Confusion Matrices: This method is a technique used to evaluate the model's output for each class. It helps to understand how the model is classifying the data. 4) Counterfactual Explanations: This method is used to explain how a change in input could have influenced the output of the model. Counterfactual explanations are used to demonstrate how a change in",
    "retrieved_chunks": [
      "2 Despite these advancements , ML interpretability remains a contentious and ambiguous topic in the scientific community , lacking a universally accepted scope and definition [ 11 , 13 , 38 , 45 ] . This ambiguity complicates the evaluation and regulation of opaque ML systems , raising questions about what constitutes sufficient interpretation and how it should be assessed . A pragmatic and pluralistic approach to interpretability has gained traction , viewing explanations as context-dependent responses to why-questions [ 12 , 31 , 42 , 43 ] . On this pluralistic approach , the adequacy of an explanation depends on the specific inquiry . For simple classification tasks , techniques like saliency maps or feature importance may suffice . For instance , if a model is differentiating between images of cats and dogs , saliency maps could highlight the pixels most influential in the decision-making process . However , for complex and socially-embedded topics -such as biased healthcare algorithms -these model-centric explanations can fall short . Consider an algorithm that predicts hospital readmission risk but systematically underestimates it for certain racial groups . A model-centric explanation might highlight `` total healthcare costs incurred in the past year '' as an important feature . However , this alone might not fully reveal why the algorithm underestimates risk for a specific racial group .",
      "INTRODUCTION In order to formulate a learning theory of machine learning , it may be necessary to move from seeing an inert model as the machine learner to seeing the human developer-along with , and not separate from , his or her model and surrounding social relations-as the machine learner . -Reigeluth & Castelle [ 55 ] The past decade has seen massive research on interpretable machine learning ( ML ) . 1 Here is a rough restatement of the goal of interpretable ML research program : many ML models are opaque in that even the expert humans can not robustly understand , in non-mathematical terms , the reasons for why particular outputs are generated by these models [ 31 , 42 , 66 ] . To overcome this opacity , various model-centric techniques have been developed to interpret their outputs . These techniques are diverse . They range from producing counterfactual explanations or heatmaps that offer insights into how changing inputs affect outputs [ 28 , 41 , 46 ] , to interpreting the inner workings of the model by probing patterns of neuron activations or attention mechanisms [ 10 , 15 , 48 ] . 2 Despite these advancements , ML interpretability remains a contentious and ambiguous topic in the scientific community , lacking a universally accepted scope and definition [ 11 , 13 , 38 , 45 ] .",
      "What is it to interpret the outputs of an opaque machine learning model ? One approach is to develop interpretable machine learning techniques . These techniques aim to show how machine learning models function by providing either model-centric local or global explanations , which can be based on mechanistic interpretations ( revealing the inner working mechanisms of models ) or non-mechanistic approximations ( showing input feature-output data relationships ) . In this paper , we draw on social philosophy to argue that interpreting machine learning outputs in certain normatively-salient domains could require appealing to a third type of explanation that we call `` socio-structural '' explanation . The relevance of this explanation type is motivated by the fact that machine learning models are not isolated entities but are embedded within and shaped by social structures . Socio-structural explanations aim to illustrate how social structures contribute to and partially explain the outputs of machine learning models .",
      "Introduction Machine learning usually aims to find and develop a computational model for an intelligent task on a practical problem . Development based on calculation can be called engineering ( 1 ) . In software engineering , software systems are calculated and engineered by models . In fact , these software models are platforms for analysis , design , development , and system engineering . For modeling in software engineering , we need several elements : 1 . The modeling perspective , 2 . The system under modeling , and 3 . Modeling language and tools ( 5 ) . So we look at a system under modeling from one or several perspectives , and we discover a set of meanings about that system . Using the modeling language and tool , we express and record those perceived meanings of the system . This allows us to engineer the system under modeling ( as-is system or to-be system ) by changing and transforming it . We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations .",
      "We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations . To obtain the proper perspective or perspectives of a system , we need human intuition of that system , meaning there is a deep connection between the modeler 's intuition and system engineering ( including software , hardware , and intelligence ) . Therefore , we can consider human intuition as the infrastructure for system engineering activities ."
    ],
    "question_id": "q11"
  },
  {
    "question": "What fairness or bias risks arise in machine learning systems, and what mitigation approaches are used?",
    "answer": "Responsibility and tensions between aggregate and individual risk and the risk of data privacy in machine learning systems are intertwined and often present challenges to the fairness and robustness of these systems. Insurance, on the other hand, has a long history of addressing social-technical issues, including risk assessment and distribution. Insurance fairness principles are linked to independence in fair machine learning, while actuarial fairness contrasts with calibration. The proposed bridge between insurance and machine learning draws from the rich and interdisciplinary literature on insurance, and offers fresh perspectives on the social situatedness of machine learning. This essay argues that insurance can serve as an analogon for the social situatedness of machine learning, providing a fresh perspective on fairness in machine learning.\n\nIntroduction Insurance is an analogon of machine learning. This essay argues that insurance can serve as an analogon for the social situatedness of machine learning. While machine learning is a relatively recent technology, debates regarding social issues in the context of insurance have been ongoing for a long time. This essay emphasizes two interrelated themes within the context of machine learning: responsibility and",
    "retrieved_chunks": [
      "We argue that insurance can act as an analogon for the social situatedness of machine learning systems , hence allowing machine learning scholars to take insights from the rich and interdisciplinary insurance literature . Tracing the interaction of uncertainty , fairness and responsibility in insurance provides a fresh perspective on fairness in machine learning . We link insurance fairness conceptions to their machine learning relatives , and use this bridge to problematize fairness as calibration . In this process , we bring to the forefront two themes that have been largely overlooked in the machine learning literature : responsibility and aggregate-individual tensions . See Baker ( , p .",
      "Introduction The ethics of Machine Learning has become an unavoidable topic in the AI Community . The deployment of machine learning systems in multiple social contexts has resulted in a closer ethical scrutiny of the design , development , and application of these systems . The AI/ML community has come to terms with the imperative to think about the ethical implications of machine learning , not only as a product but also as a practice ( Birhane , 2021 ; Shen et al . 2021 ) . The critical question that is troubling many debates is what can constitute an ethically accountable machine learning system . In this paper we explore possibilities for ethical evaluation of machine learning methodologies . We scrutinize techniques , methods and technical practices in machine learning from a relational ethics perspective , taking into consideration how machine learning systems are part of the world and how they relate to different forms of agency . Taking a page from Phil Agre ( 1997 ) we use the notion of a critical technical practice as a means of analysis of machine learning approaches . Our radical proposal is that supervised learning appears to be the only machine learning method that is ethically defensible .",
      "Briefly , actuarial fairness demands that each policyholder should pay only for their own risk , that is , mutualization should occur only between individuals with the same 'true ' risk . In contrast , solidarity calls for equal contribution to the pool . On one level of this text , we problematize actuarial fairness ( by extension , calibration ) as a notion of fairness in the normative sense by taking inspiration from insurance . This perspective is aligned with recent proposals that stress the discrepancy of formal algorithmic fairness and `` substantive '' fairness ( Green , ) , which some prefer to call justice ( Vredenburgh , ) . Parallel to this runs a distinct textual level , where we emphasize two intricately interacting themes : responsibility and tensions between aggregate and individual . Both entail criticism of actuarial fairness , but we suggest that they additionally provide much broader , fruitful lessons for machine learning from insurance . At the highest level of abstraction , our goal is to establish a general conceptual bridge between insurance and machine learning . Traversing this bridge , machine learning scholars can obtain new perspectives on the social situatedness of a probabilistic , statistical technology -we attempt to offer a new 'cognitive toolkit ' for thinking about the social situatedness of machine learning .",
      "In other words , who is to be mutualized in the pool . Some form of segmentation is found in many insurantial arrangements : the pool of policyholders can be stratified by separating high and low risk individuals . But the specific nature that such segmentation McFall et al . ( ) call insurance `` interestingly uninteresting '' , referring to how insurance is `` hugely underresearched '' given its societal importance , which is typically not recognized ( Ewald , ) . takes typically depends not only on risk assessment , but on further considerations such as assignment of responsibility , modulated by social context ; in this way , insurance is not a neutral technology ( Baker & Simon , ; Glenn , a ) . Our non-comprehensive outline of the history of insurance illustrates how uncertainty , fairness and responsibility interact , and can be entangled and disentangled . From this background , we can extract conceptual insights which also apply to machine learning . The tension between risk assessment and distribution is mirrored in formal fairness principles : solidarity , which can be linked to independence in fair machine learning , contrasts with actuarial fairness , linked to calibration . Briefly , actuarial fairness demands that each policyholder should pay only for their own risk , that is , mutualization should occur only between individuals with the same 'true ' risk .",
      "Introduction Insurance is `` interestingly uninteresting '' . In this work , we argue that in fact insurance is far from uninteresting and indeed a rich source of inspiration and insight to scholarship interested in social issues surrounding machine learning , specifically the field now known as fair machine learning . Our proposal is that insurance can be viewed as an analogon to machine learning with respect to these issues arising from the social situatedness . While machine learning is a relatively recent technology , debates regarding social issues in the context of insurance have been ongoing for a long time . Thus , we argue that taking inspiration from studies of insurance can contribute to a more integrative view of machine learning systems as socio-technical systems ( Selbst et al. , ) . Both machine learning and insurance are firmly based on a statistical , probabilistic mode of reasoningan actuarial mode . Indeed , insurance can be viewed as the first commercial test of probability theory ( Gigerenzer et al. , ; McFall , ) . Insurance , a technology for doing risk , transforms uncertainty into calculable risk ( Lehtonen & Van Hoyweghen , ) ."
    ],
    "question_id": "q12"
  },
  {
    "question": "What limitations are commonly identified, and what future directions or open problems follow from them?",
    "answer": "Limitations:\n- The current state of quantum technology is still very much in the developmental phase, and we do not know the limits of what can be achieved using the technology. - The current technology is limited by the size and complexity of quantum systems, which means that quantum computers are still far from being able to solve the problems that we face in the real world. - Error-correction is a crucial aspect of quantum computing, and it is still difficult to achieve a high error rate. Future directions:\n- Continued progress in the development of quantum error correction circuits, which will allow for the construction of more sophisticated quantum computers. - Better understanding of the interactions between quantum systems and their environments ( quantum entanglement, decoherence, etc.). - The design of quantum algorithms that can be used in practical systems, not just in theoretical research. - Improvements in the efficiency and scalability of quantum algorithms. - The use of quantum algorithms in quantum cryptography. - The development of quantum algorithms for problems like machine learning, quantum teleportation, and quantum cryptography. - The creation of quantum computing platforms that can be used in practical situations, such as in industries like aerospace, electronics,",
    "retrieved_chunks": [
      "Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Interestingly , this latter question can be further rephrased as : what are the characteristics of a data set that are well correlated with the possibility , or the impossibility , of obtaining ML models able to effectively extrapolate to unknown instances of the problem ? It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] .",
      "As more and more machine learnt services make their way into software applications , which themselves are part of business processes , robust life cycle management of these machine learnt models becomes critical for ensuring the integrity of business processes that rely on them . We argue that two reasons necessitate a new maturity framework for machine learning models . First , the lifecycle of machine learning models is significantly different from that of the traditional software and therefore a reinterpretation of the software capability maturity model ( CMM ) maturity framework for building and managing the lifecycle of machine learning models is called for . Second , building machine learning models that work for enterprises requires solutions to a very different set of problems than the academic literature on machine learning typically focuses on . We explain these two reasons below a bit more in detail .",
      "However , to my knowledge , no recent referenced article is available for any reader seeking for a starting point to question the links between ML and BFT . This document is structured as follow : In Section 2 , a brief recall of the evolution of the mainstream in the BF community is provided . Then , in Section 3 , a short summary of the earlier ages of ML up to the mid-90s , is sketched , as well as a coarse description of the successful interactions between ML and BFT in those times . Afterward , I provide in Section 4 a synthetic overview of the revolution that blew over ML around the early 2000s , and which modified its goals and the organization of its supporting community . As BFT does not seem to fit in this new picture of the ML world , I list in Section 5 a few problems that may still be of interest for the current mainstream of BFT , as well as some potential interesting evolutions for the community to adapt to the newly raised questions .",
      "As a consequence , the functional behavior expected from data-driven components can only be specified in part on their intended domain , and we can not assure that they will behave as expected in all cases . Moreover , their processing structure is usually difficult to trace and validate by humans because this structure rarely follows human intuition but is generated to provide the algorithmically generalized input-output relationship in an effective manner . Prominent representatives of models used by data-driven components are artificial neural networks and support vector machines ( Russell & Norvig , 2016 ) . Since data-driven models are an important source of uncertainty in embedded systems that collaborate in an open context , the uncertainty they introduce has to be appropriately understood and managed during design time and runtime . Previous work ( Kl√§s & Vollmer , 2018 ) proposes separating the sources of uncertainty in data-driven components into three major classes , distinguishing between uncertainty caused by limitations in terms of model fit , data quality , and scope compliance . Whereas model fit focuses on the inherent uncertainty in data-driven models , data quality covers the additional uncertainty caused by their application to input data obtained in suboptimal conditions and scope compliance covers situations where the model is likely applied outside the scope for which it was trained and validated .",
      "In addition to discussing the current applications of quantum capabilities for machine learning , we should also let our imaginations soar . The era of fault-tolerant quantum computing ( FTQC ) is a foreseeable future , and it 's crucial to look ahead at what challenges we can tackle with quantum machine learning on FTQC devices . One of the most renowned and valuable algorithms in this context is the Harrow-Hassidim-Lloyd ( HHL ) algorithm [ 58 ] . Additionally , there are other algorithms that can be deployed to address a range of problems , such as principal component analysis [ 18 ] . Beside the optimistic future that quantum machine learning has , there are also a number of controversial issues with the subject . For example , some might argue that the variational quantum algorithm will not work in some circumstance . People working on quantum landscapes theory observed the famous barren plateau phenomena which leads to a kind of no-go theorem [ 27 , 86 ] . It amounts to situations that are hard to find minimum when we optimizes our objective function by gradient descent with randomized variational circuits . Debates indeed exist regarding whether quantum algorithms can consistently deliver exponential speedups . Some argue that quantum speedup is only guaranteed when dealing with quantum information ."
    ],
    "question_id": "q13"
  },
  {
    "question": "How do real-world constraints (e.g., deployment, cost, latency, privacy, safety) shape machine learning systems used for decision-making?",
    "answer": "Real-world constraints shape machine learning systems in several ways:\n- Deployment: Machine learning algorithms are typically deployed in production environments, where they are subject to the limitations of the system they are trained on. These limitations can include hardware, software, and networking constraints, as well as security and privacy constraints. - Cost: Machine learning systems can be expensive to build and maintain, especially if they require sophisticated hardware, specialized software, or complex data integration. - Latency: Machine learning systems typically require real-time or near-real-time responses, which can place a strain on latency-sensitive systems such as finance, healthcare, and transportation. - Privacy: Machine learning systems can collect and process data that is sensitive to personal and sensitive data. - Safety: Machine learning systems are often used in safety-critical applications, where failure or misuse of the system can have severe consequences. - Security: Machine learning systems are frequently used in defense and intelligence systems, where they are subject to strict security requirements.\n- Deployment: Machine learning algorithms are typically deployed in production environments, where they are subject to the limitations of the system they are trained on. These limitations can include hardware, software, and",
    "retrieved_chunks": [
      "As more and more machine learnt services make their way into software applications , which themselves are part of business processes , robust life cycle management of these machine learnt models becomes critical for ensuring the integrity of business processes that rely on them . We argue that two reasons necessitate a new maturity framework for machine learning models . First , the lifecycle of machine learning models is significantly different from that of the traditional software and therefore a reinterpretation of the software capability maturity model ( CMM ) maturity framework for building and managing the lifecycle of machine learning models is called for . Second , building machine learning models that work for enterprises requires solutions to a very different set of problems than the academic literature on machine learning typically focuses on . We explain these two reasons below a bit more in detail .",
      "As a consequence , the functional behavior expected from data-driven components can only be specified in part on their intended domain , and we can not assure that they will behave as expected in all cases . Moreover , their processing structure is usually difficult to trace and validate by humans because this structure rarely follows human intuition but is generated to provide the algorithmically generalized input-output relationship in an effective manner . Prominent representatives of models used by data-driven components are artificial neural networks and support vector machines ( Russell & Norvig , 2016 ) . Since data-driven models are an important source of uncertainty in embedded systems that collaborate in an open context , the uncertainty they introduce has to be appropriately understood and managed during design time and runtime . Previous work ( Kl√§s & Vollmer , 2018 ) proposes separating the sources of uncertainty in data-driven components into three major classes , distinguishing between uncertainty caused by limitations in terms of model fit , data quality , and scope compliance . Whereas model fit focuses on the inherent uncertainty in data-driven models , data quality covers the additional uncertainty caused by their application to input data obtained in suboptimal conditions and scope compliance covers situations where the model is likely applied outside the scope for which it was trained and validated .",
      "Introduction The term machine learning ( ML ) traditionally includes algorithms that are able to improve their performance on a specific task over time , given an increasing amount of relevant data [ 1 ] . In recent years , this field of research is enjoying a growing popularity , driven by the breakthrough of Deep Learning [ 2 ] and an impressive track record of success stories in different fields , ranging from natural language processing [ 3 ] to autonomous vehicles [ 4 ] , image classification [ 5 ] human-competitive performance in boardgames [ 6 ] . An interesting online collection about various uses of ML has been compiled by the journal Nature is late 2018 1 , although the fast pace the field is progressing made it to appear outdated after few quarters . As out-of-the-box ML solutions are becoming increasingly available to both researchers and the general public [ 7 , 8 , 9 , 10 ] , theoretical questions are suddenly turning into practical issues . Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ?",
      "Academic literature on machine learning modeling fails to address how to make machine learning models work for enterprises . For example , existing machine learning processes can not address how to define business use cases for an AI application , how to convert business requirements from offering managers into data requirements for data scientists , and how to continuously improve AI applications in term of accuracy and fairness , how to customize general purpose machine learning models with industry , domain , and use case specific data to make them more accurate for specific situations etc . Making AI work for enterprises requires special considerations , tools , methods and processes . In this paper we present a maturity framework for machine learning model lifecycle management for enterprises . Our framework is a re-interpretation of the software Capability Maturity Model ( CMM ) for machine learning model development process .",
      "In this sense , our vision aligns to that of Ray Kurzweil , who claimed that `` the theory behind deep learning . . . is that you have a model that reflects the hierarchy in the natural phenomenon you 're trying to learn [ Hof , 2013 ] . '' This paper is structured as follows . The theoretical ideas are laid out and the case for a new operational definition of machine learning is made . We put forward the conjecture that the optimization of model entropy , leads to concept formation . Last , conclusions and further steps to operationalize these concepts are formulated . 2 Central assertions 2.1 Learning can not be explained in extrinsic terms only Conventional wisdom depicts machine learning as the optimization of a ( non- ) parametric model with respect to some performance measure . This view is clearly reflected in the de facto definition of machine learning by Mitchell [ Mitchell , 1997 ] : `` A computer program is said to learn from an experience X with respect to some class of tasks T and performance measure P , if its performance at tasks in T , as measured by P , improves with experimental data D '' . Traditional machine learning techniques typically exploit shallow-structured , and often fixed , architectures ."
    ],
    "question_id": "q14"
  },
  {
    "question": "Which modeling and architectural design choices are especially important, and why?",
    "answer": "The most important modeling and architectural design choices are based on the following:\n\n1. Modeling Perspective: The modeling perspective determines the focus of the model and the way it is used. The perspective should correspond to the problem being solved in the context.\n\n2. System Under Modeling: The system under modeling is the set of variables, actions, and constraints that form the basis for the problem. The model should accurately represent the underlying system and its behavior.\n\n3. Modeling Language and Tools: The chosen modeling language and tools should be appropriate for the problem being modeled. The chosen language and tools should enable efficient modeling, simulation, and debugging.\n\n4. Model Refinement: The model should be refined as new information becomes available. This includes data augmentation, feature extraction, and the development of new modeling techniques.\n\n5. Model Refinement: The model should follow the principles of efficient computing (e.g., sparse coding, deep learning, weight sharing).\n\n6. Model Refinement: The model should be flexible enough to handle changing input data and/or model configurations.\n\nThe importance of these modeling and architectural design choices lie",
    "retrieved_chunks": [
      "We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations . To obtain the proper perspective or perspectives of a system , we need human intuition of that system , meaning there is a deep connection between the modeler 's intuition and system engineering ( including software , hardware , and intelligence ) . Therefore , we can consider human intuition as the infrastructure for system engineering activities .",
      "Though the organization and complexity of model topologies is acknowledged to be crucial , current approaches are mainly limited to analysing the data space , i.e . the implemented regression functions or decision boundaries [ Bianchini and Scarselli , 2014 ] . There is a problem with this approach . Consider an neural network algorithm that needs to learn a simple concept like an `` XOR '' function depicted in Fig . 1 . An infinite number of neural networks with very similar or identical decision boundaries can be constructed -of which two are shown in Fig . 2 . From an external point of view , there is no way to discriminate between these two models : describing the difference between these two models can only occur in terms of the model internals . Of course the weight space , which represents the model of a neural network , is related to the data space , as it performs calculations on the data . In other words : Data representation and model computation should be considered as two sides of the same coin . As a result the structural properties of both the model and data space are key to the modelling of higher abstractions . Sparse coding is a perfect example of this .",
      "One possible analogy to better understand the above statements can be found in software engineering . When considering code that performs a specific task , we do not care only about its functionality , but also about its execution speed/efficiency and other so-called `` non-functional requirements '' . Furthermore , a carefully modularized design probably reflects more understanding than an endless enumeration of IF-ELSE clauses . In other words , finding a more efficient and structured way to represent/reproduce information and to perform a learning task , is as central to machine learning as the reproduction of results . Different to humans , of course , machines are measurable . This provides us with a unique opportunity to study the nature of learning in principle , at the same time improving Machine Intelligence . We are not claiming that model complexity/efficiency has not been subject to past research efforts . On the contrary , many techniques and design principles have attempted to improve exactly these properties -like Occam 's razor , Bayesian structure learning , pruning , the use of prototypes to compact information , regularization as a strategy to reduce energy , weight sharing in RNNs or CNNs to decrease model complexity , etc . Indeed , the whole evolution of Deep Learning can be seen as one specific approach in the quest to find models that are more structured ( i.e .",
      "Introduction Machine learning usually aims to find and develop a computational model for an intelligent task on a practical problem . Development based on calculation can be called engineering ( 1 ) . In software engineering , software systems are calculated and engineered by models . In fact , these software models are platforms for analysis , design , development , and system engineering . For modeling in software engineering , we need several elements : 1 . The modeling perspective , 2 . The system under modeling , and 3 . Modeling language and tools ( 5 ) . So we look at a system under modeling from one or several perspectives , and we discover a set of meanings about that system . Using the modeling language and tool , we express and record those perceived meanings of the system . This allows us to engineer the system under modeling ( as-is system or to-be system ) by changing and transforming it . We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations .",
      "Traditional machine learning techniques typically exploit shallow-structured , and often fixed , architectures . Nevertheless , there is a general consensus that the learning of `` higherorder '' concepts is problematic , and that the solution to this issue is somehow connected to deep architectures that create ever higher forms of abstraction . Experimental research as well as neurological evidence on the organization of the brain , supports this finding [ Bianchini and Scarselli , 2014 ] . The limitation of architecture complexity is preferred , primarily because their behaviour could be understood and the training of more complex or adaptive architectures leads to a explosion of complexity . That was until recently . The recent advanced in so-called `` Deep Learning '' , have focused on training algorithms that are adapted to new kinds of deep architectures [ Deng and Yu , 2014 ] , and heuristic strategies to attain specific structural properties like sparse coding that lead to higher forms of abstractions . With the exception of studies on `` interpretability '' [ Jin and Sendhoff , 2008 ] , structural properties are mainly considered a by-product , a ( desirable ) side effect of the applied training mechanisms . Though the organization and complexity of model topologies is acknowledged to be crucial , current approaches are mainly limited to analysing the data space , i.e ."
    ],
    "question_id": "q15"
  }
]