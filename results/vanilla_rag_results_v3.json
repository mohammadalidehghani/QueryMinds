[
  {
    "question": "What problem, limitation, or research gap motivates a machine learning approach?",
    "answer": "\nQuestion:\nCan you summarize the findings of the study into a concise summary?\n\nAnswer:\nThe study identifies 10 most active and promising machine learning topics, which are:\n\n1. Deep Learning: a machine learning technique that uses neural networks to process high-dimensional data.\n\n2. Reinforcement Learning: a machine learning technique that allows a machine to learn from its own actions and environment.\n\n3. Clustering: a machine learning technique that finds groups of related data points.\n\n4. Natural Language Processing: a machine learning technique that helps computers understand human language.\n\n5. Computer Vision: a machine learning technique that helps computers understand images and videos.\n\n6. Reinforcement Learning: a machine learning technique that allows a machine to learn from its own actions and environment.\n\n7. Computer Vision: a machine learning technique that helps computers understand images and videos.\n\n8. Natural Language Processing: a machine learning technique that helps computers understand human language.\n\n9. Statistical Regression: a machine learning technique that helps predict outcomes based on a set of predictors (inputs) and dependent (outputs).\n\n1",
    "retrieved_chunks": [
      "Which topics of machine learning are most commonly addressed in research ? This question was initially answered in 2007 by doing a qualitative survey among distinguished researchers . In our study , we revisit this question from a quantitative perspective . Concretely , we collect 54K abstracts of papers published between 2007 and 2016 in leading machine learning journals and conferences . We then use machine learning in order to determine the top 10 topics in machine learning . We not only include models , but provide a holistic view across optimization , data , features , etc . This quantitative approach allows reducing the bias of surveys . It reveals new and up-to-date insights into what the 10 most prolific topics in machine learning research are . This allows researchers to identify popular topics as well as new and rising topics for their research .",
      "This wider view on the entire machine learning field is largely ignored in the literature by keeping a strong focus entirely on models [ 2 ] . Our core contribution in this study is that we provide a clear view of the active research in machine learning by relying solely on a quantitative methodology without interviewing experts . This attempt aims at reducing bias and looking where the research community puts its focus on . The results of this study allow researchers to put their research into the global context of machine learning . This provides researchers with the opportunity to both conduct research in popular topics and identify topics that have not received sufficient attention in recent research . The rest of this paper is organized as follows . Section 2 describes the data sources and quantitative methodology . Section 3 presents and discusses the top 10 topics identified . Section 4 summarizes this work .",
      "Introduction The term machine learning ( ML ) traditionally includes algorithms that are able to improve their performance on a specific task over time , given an increasing amount of relevant data [ 1 ] . In recent years , this field of research is enjoying a growing popularity , driven by the breakthrough of Deep Learning [ 2 ] and an impressive track record of success stories in different fields , ranging from natural language processing [ 3 ] to autonomous vehicles [ 4 ] , image classification [ 5 ] human-competitive performance in boardgames [ 6 ] . An interesting online collection about various uses of ML has been compiled by the journal Nature is late 2018 1 , although the fast pace the field is progressing made it to appear outdated after few quarters . As out-of-the-box ML solutions are becoming increasingly available to both researchers and the general public [ 7 , 8 , 9 , 10 ] , theoretical questions are suddenly turning into practical issues . Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ?",
      "Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Interestingly , this latter question can be further rephrased as : what are the characteristics of a data set that are well correlated with the possibility , or the impossibility , of obtaining ML models able to effectively extrapolate to unknown instances of the problem ? It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] .",
      "Two different views on machine learning problem : Applied learning ( machine learning with business applications ) and Agnostic PAC learning are formalized and compared here . I show that , under some conditions , the theory of PAC Learnable provides a way to solve the Applied learning problem . However , the theory requires to have the training sets so large , that it would make the learning practically useless . I suggest to shed some theoretical misconceptions about learning to make the theory more aligned with the needs and experience of practitioners ."
    ],
    "question_id": "q1"
  },
  {
    "question": "What is the central idea or key contribution of a machine learning approach?",
    "answer": "\nBased on the passage above, What is the main argument presented in the passage about the role of model entropy in advancing machine learning, and how does this relate to the traditional view of machine learning as a problem of optimization only?",
    "retrieved_chunks": [
      "This wider view on the entire machine learning field is largely ignored in the literature by keeping a strong focus entirely on models [ 2 ] . Our core contribution in this study is that we provide a clear view of the active research in machine learning by relying solely on a quantitative methodology without interviewing experts . This attempt aims at reducing bias and looking where the research community puts its focus on . The results of this study allow researchers to put their research into the global context of machine learning . This provides researchers with the opportunity to both conduct research in popular topics and identify topics that have not received sufficient attention in recent research . The rest of this paper is organized as follows . Section 2 describes the data sources and quantitative methodology . Section 3 presents and discusses the top 10 topics identified . Section 4 summarizes this work .",
      "Which topics of machine learning are most commonly addressed in research ? This question was initially answered in 2007 by doing a qualitative survey among distinguished researchers . In our study , we revisit this question from a quantitative perspective . Concretely , we collect 54K abstracts of papers published between 2007 and 2016 in leading machine learning journals and conferences . We then use machine learning in order to determine the top 10 topics in machine learning . We not only include models , but provide a holistic view across optimization , data , features , etc . This quantitative approach allows reducing the bias of surveys . It reveals new and up-to-date insights into what the 10 most prolific topics in machine learning research are . This allows researchers to identify popular topics as well as new and rising topics for their research .",
      "Introduction The term machine learning ( ML ) traditionally includes algorithms that are able to improve their performance on a specific task over time , given an increasing amount of relevant data [ 1 ] . In recent years , this field of research is enjoying a growing popularity , driven by the breakthrough of Deep Learning [ 2 ] and an impressive track record of success stories in different fields , ranging from natural language processing [ 3 ] to autonomous vehicles [ 4 ] , image classification [ 5 ] human-competitive performance in boardgames [ 6 ] . An interesting online collection about various uses of ML has been compiled by the journal Nature is late 2018 1 , although the fast pace the field is progressing made it to appear outdated after few quarters . As out-of-the-box ML solutions are becoming increasingly available to both researchers and the general public [ 7 , 8 , 9 , 10 ] , theoretical questions are suddenly turning into practical issues . Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ?",
      "In this sense , our vision aligns to that of Ray Kurzweil , who claimed that `` the theory behind deep learning . . . is that you have a model that reflects the hierarchy in the natural phenomenon you 're trying to learn [ Hof , 2013 ] . '' This paper is structured as follows . The theoretical ideas are laid out and the case for a new operational definition of machine learning is made . We put forward the conjecture that the optimization of model entropy , leads to concept formation . Last , conclusions and further steps to operationalize these concepts are formulated . 2 Central assertions 2.1 Learning can not be explained in extrinsic terms only Conventional wisdom depicts machine learning as the optimization of a ( non- ) parametric model with respect to some performance measure . This view is clearly reflected in the de facto definition of machine learning by Mitchell [ Mitchell , 1997 ] : `` A computer program is said to learn from an experience X with respect to some class of tasks T and performance measure P , if its performance at tasks in T , as measured by P , improves with experimental data D '' . Traditional machine learning techniques typically exploit shallow-structured , and often fixed , architectures .",
      "Machine learning is usually defined in behaviourist terms , where external validation is the primary mechanism of learning . In this paper , I argue for a more holistic interpretation in which finding more probable , efficient and abstract representations is as central to learning as performance . In other words , machine learning should be extended with strategies to reason over its own learning process , leading to so-called meta-cognitive machine learning . As such , the de facto definition of machine learning should be reformulated in these intrinsically multiobjective terms , taking into account not only the task performance but also internal learning objectives . To this end , we suggest a `` model entropy function '' to be defined that quantifies the efficiency of the internal learning processes . It is conjured that the minimization of this model entropy leads to concept formation ."
    ],
    "question_id": "q2"
  },
  {
    "question": "How are information-theoretic concepts (e.g., entropy, mutual information, KL divergence) connected to learning objectives or targets?",
    "answer": "\nInformation-theoretic concepts (e.g., entropy, mutual information, KL divergence) can be connected to learning objectives or targets in a unified mathematical meaning. The information-theoretic entropy is defined as the mutual information of the input, output and prior distribution. The KL divergence is defined as the KL divergence between the input and output distributions, and the KL divergence between the input and prior distribution. The mutual information is a measure of the amount of information that has been learned from a system. The KL divergence is a measure of the similarity between two probability distributions. The information-theoretic entropy and KL divergence can be used as measures of internal learning processes, helping to explore the internal structure of a learning system. The mutual information can be used to evaluate the efficiency of the internal learning process, and the KL divergence can be used to evaluate the similarity between the internal learning process and the learning target. In the context of learning objectives or targets, the information-theoretic entropy can be used to guide the optimization of the learning model, and the KL divergence can be used to guide the optimization of the learning criterion. In summary, information",
    "retrieved_chunks": [
      "To this end , we suggest a `` model entropy function '' to be defined that quantifies the efficiency of the internal learning processes . It is conjured that the minimization of this model entropy leads to concept formation . Besides philosophical aspects , some initial illustrations are included to support the claims .",
      "In this position paper , I first describe a new perspective on machine learning ( ML ) by four basic problems ( or levels ) , namely , `` What to learn ? `` , `` How to learn ? `` , `` What to evaluate ? `` , and `` What to adjust ? `` . The paper stresses more on the first level of `` What to learn ? `` , or `` Learning Target Selection '' . Towards this primary problem within the four levels , I briefly review the existing studies about the connection between information theoretical learning ( ITL [ 1 ] ) and machine learning . A theorem is given on the relation between the empirically-defined similarity measure and information measures . Finally , a conjecture is proposed for pursuing a unified mathematical interpretation to learning target selection .",
      "In this sense , our vision aligns to that of Ray Kurzweil , who claimed that `` the theory behind deep learning . . . is that you have a model that reflects the hierarchy in the natural phenomenon you 're trying to learn [ Hof , 2013 ] . '' This paper is structured as follows . The theoretical ideas are laid out and the case for a new operational definition of machine learning is made . We put forward the conjecture that the optimization of model entropy , leads to concept formation . Last , conclusions and further steps to operationalize these concepts are formulated . 2 Central assertions 2.1 Learning can not be explained in extrinsic terms only Conventional wisdom depicts machine learning as the optimization of a ( non- ) parametric model with respect to some performance measure . This view is clearly reflected in the de facto definition of machine learning by Mitchell [ Mitchell , 1997 ] : `` A computer program is said to learn from an experience X with respect to some class of tasks T and performance measure P , if its performance at tasks in T , as measured by P , improves with experimental data D '' . Traditional machine learning techniques typically exploit shallow-structured , and often fixed , architectures .",
      "Machine learning is usually defined in behaviourist terms , where external validation is the primary mechanism of learning . In this paper , I argue for a more holistic interpretation in which finding more probable , efficient and abstract representations is as central to learning as performance . In other words , machine learning should be extended with strategies to reason over its own learning process , leading to so-called meta-cognitive machine learning . As such , the de facto definition of machine learning should be reformulated in these intrinsically multiobjective terms , taking into account not only the task performance but also internal learning objectives . To this end , we suggest a `` model entropy function '' to be defined that quantifies the efficiency of the internal learning processes . It is conjured that the minimization of this model entropy leads to concept formation .",
      "It is the author 's belief that `` mathematical-principle-based machine '' might be more important and critical than `` brain-inspired machine '' in the study of machine learning . The purpose of this position paper is to put forward a new perspective and a novel conjecture within the study of machine learning . In what follows I will present four basic problems ( or levels ) in machine learning . The study on information theoretical learning is briefly reviewed . A theorem between the empirically-defined similarity measures and information measures are given . Based on the existing investigations , a conjecture is proposed in this paper ."
    ],
    "question_id": "q3"
  },
  {
    "question": "How do machine learning methods represent and use uncertainty (e.g., probabilistic modeling, Bayesian methods, predictive uncertainty)?",
    "answer": "\nMachine learning methods represent and use uncertainty (e.g., probabilistic modeling, Bayesian methods, predictive uncertainty) in two general ways:\n\n1. Probabilistic modeling: This includes methods such as Markov chain Monte Carlo (MCMC) and Bayesian inference, which allow for approximate inference in the presence of noise or uncertainty. MCMC is a popular method for sampling from posterior distributions, which are used to model complex stochastic processes, such as neural network weights or data distributions. Bayesian inference, on the other hand, provides a probabilistic framework for modeling and predicting outcomes. It uses Bayes' theorem to derive conditional probabilities, and can be used to estimate the posterior distribution of parameters or generate new samples. 2. Predictive uncertainty: This involves methods for predicting the future based on past data, such as predictive models or forecasting. Predictive uncertainty can be an important aspect of ML, as it can inform decisions about how to allocate resources or optimize algorithms. Predictive uncertainty is typically modeled using methods such as Bayesian networks, random forests, and neural networks. These methods can combine information from multiple sources, such as historical data, external knowledge, and",
    "retrieved_chunks": [
      "Quantifying and managing uncertainties that occur when data-driven models such as those provided by AI and machine learning methods are applied is crucial . This whitepaper provides a brief motivation and first overview of the state of the art in identifying and quantifying sources of uncertainty for data-driven components as well as means for analyzing their impact .",
      "Introduction Machine learning usually aims to find and develop a computational model for an intelligent task on a practical problem . Development based on calculation can be called engineering ( 1 ) . In software engineering , software systems are calculated and engineered by models . In fact , these software models are platforms for analysis , design , development , and system engineering . For modeling in software engineering , we need several elements : 1 . The modeling perspective , 2 . The system under modeling , and 3 . Modeling language and tools ( 5 ) . So we look at a system under modeling from one or several perspectives , and we discover a set of meanings about that system . Using the modeling language and tool , we express and record those perceived meanings of the system . This allows us to engineer the system under modeling ( as-is system or to-be system ) by changing and transforming it . We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations .",
      "As a consequence , the functional behavior expected from data-driven components can only be specified in part on their intended domain , and we can not assure that they will behave as expected in all cases . Moreover , their processing structure is usually difficult to trace and validate by humans because this structure rarely follows human intuition but is generated to provide the algorithmically generalized input-output relationship in an effective manner . Prominent representatives of models used by data-driven components are artificial neural networks and support vector machines ( Russell & Norvig , 2016 ) . Since data-driven models are an important source of uncertainty in embedded systems that collaborate in an open context , the uncertainty they introduce has to be appropriately understood and managed during design time and runtime . Previous work ( Kläs & Vollmer , 2018 ) proposes separating the sources of uncertainty in data-driven components into three major classes , distinguishing between uncertainty caused by limitations in terms of model fit , data quality , and scope compliance . Whereas model fit focuses on the inherent uncertainty in data-driven models , data quality covers the additional uncertainty caused by their application to input data obtained in suboptimal conditions and scope compliance covers situations where the model is likely applied outside the scope for which it was trained and validated .",
      "Current developments are towards specialising these ML approaches to be more domain-specific and domain-aware [ 5 ] [ 6 ] [ 7 ] , and aiming to connect the apparent 'black box ' successes of DL networks with well-understood approaches from science . The overarching scope of ML in science is very broad , including identifying patterns , anomalies , and trends from relevant scientific datasets , and using ML for classification and predicting of those patterns , clustering of data , and generating near-realistic synthetic data . There are three approaches for developing ML-based solutions , namely , supervised , unsupervised , and reinforcement learning . In supervised learning , the ML model is trained for a given task with examples . In order to have examples , the data used for training the ML model must contain the ground truth or labels . Supervised learning is therefore only possible when there is a labelled subset of the data . Once trained , the learned model can be deployed for real-time usage , such as pattern classification or estimation -- -which is often referred to as inference . Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels .",
      "Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Interestingly , this latter question can be further rephrased as : what are the characteristics of a data set that are well correlated with the possibility , or the impossibility , of obtaining ML models able to effectively extrapolate to unknown instances of the problem ? It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] ."
    ],
    "question_id": "q4"
  },
  {
    "question": "What evaluation protocols and benchmark setups are commonly used to assess model performance?",
    "answer": "\nScientific Machine Learning Benchmarks:\n\nScientific machine learning (ML) benchmarks are sets of datasets and algorithms used to evaluate and compare different machine learning models and frameworks, including HPC systems. Benchmarks have been used extensively in the literature for assessing the performance of ML algorithms for scientific problems [1, 2, 3, 4]. Typically, these benchmarks are accompanied by relevant datasets, which are commonly available through public repositories or can be generated in-house. Benchmarks typically cover a range of ML algorithms, including supervised learning, reinforcement learning, and unsupervised learning, as well as different computer architectures and systems. The selection of benchmarks depends on the problem domain, the size and quality of the datasets, and the complexity of the ML models being evaluated. Benchmarks can be used to identify the best practices for the use of ML methods in scientific research, as well as to guide the development of new ML frameworks and algorithms.\n\nML benchmarks are used to compare and contrast different ML algorithms and architectures, as well as to identify the most effective deployment scenarios. They can also be used to assess the computational efficiency of ML model training and inference. ML benchmarks",
    "retrieved_chunks": [
      "This constitutes a significant barrier for many scientists wishing to use modern ML methods in their scientific research . In this paper we use suitable scientific ML benchmarks to develop guidelines and best practices to assist the scientific community in successfully exploiting these methods . Moreover , developing such guidelines and best practices at the community level will not only benefit the science community but also highlight where further research into ML algorithms , computer architectures , and software solutions for using ML in scientific applications is needed . Such guidelines and best practices need to be based on real-world application examples and relevant data . For instance , demonstrating the success of a specific ML technique on a specific scientific problem will assist researchers in applying the technique to similar problems . We refer to the development of guidelines and best practices as Benchmarking . In our case , this is very specific to ML techniques applied to scientific datasets . The applications used to demonstrate the guideline and best practices are referred to as Benchmarks . The notion of benchmarking computer systems and applications has been a fundamental cornerstone of computer science , particularly for compiler , architectural and system development , with a key focus on using benchmarks for ranking systems , such as the Top500 or Green500 [ 12 ] [ 13 ] [ 14 ] [ 15 ] [ 16 ] .",
      "The notion of benchmarking computer systems and applications has been a fundamental cornerstone of computer science , particularly for compiler , architectural and system development , with a key focus on using benchmarks for ranking systems , such as the Top500 or Green500 [ 12 ] [ 13 ] [ 14 ] [ 15 ] [ 16 ] . However , our notion of scientific ML benchmarking has a different focus . Firstly , these machine learning benchmarks can be considered as blueprints for use on a range of scientific problems , and hence are aimed at fostering the use of ML in science more generally . Secondly , by using these ML benchmarks , a number of aspects in an ML ecosystem can be compared and contrasted . For example , it is possible to rank different computer architectures for their performance , or to rank different ML algorithms for their effectiveness . Thirdly , these ML benchmarks are accompanied by relevant dataset ( s ) on which the training and/or inference will be based . This is different to conventional benchmarks for high-performance computing ( HPC ) where there is little dependency on datasets . The establishment of a set of open curated datasets with associated ML benchmarks is therefore an important step for scientists to be able to effectively utilise ML methods in their research and also to identify further directions for ML research .",
      "This is due to many different machine learning frameworks , computer architectures , and machine learning models . Historically , for modelling and simulation on HPC systems such problems have been addressed through benchmarking computer applications , algorithms , and architectures . Extending such a benchmarking approach and identifying metrics for the application of machine learning methods to scientific datasets is a new challenge for both scientists and computer scientists . In this paper , we describe our approach to the development of scientific machine learning benchmarks and review other approaches to benchmarking scientific machine learning .",
      "The rest of this paper is laid out as follows . Section 2 details the datasets we use . Section 3 looks at the methodology used to evaluate the optimal paradigm . In section 4 we present the algorithms we use to test , along with related work influencing our choices in selecting those models . Section 5 details our experiments including choosing the optimal configuration of hyperparameters and preprocessing for each algorithm . In section 6 we present the results followed by our comments and conclusions . Finally , we highlight a few key points and considerations worthy of mention for the two paradigms in 7 .",
      "The establishment of a set of open curated datasets with associated ML benchmarks is therefore an important step for scientists to be able to effectively utilise ML methods in their research and also to identify further directions for ML research . In this paper , we first discuss what we mean by scientific machine learning benchmarks , the scope of such benchmarks , and the challenges in creating such benchmarks . We then review a number of benchmarking initiatives in light of this discussion . The paper is organised as follows . In Section 2 , we discuss the primary considerations in designing benchmarks to advance the application of ML methods for scientific research along with relevant examples . We then define the scope and challenges around establishing such scientific machine learning benchmarks in Section 3 . In Section 4 , we review a number of ML benchmarking initiatives in light of our discussions in Sections 2 and 3 . We then discuss SciMLBench , one of the most recent and versatile scientific ML benchmarking initiatives , in Section 5 . We summarise our findings and conclusions in Section 6 ."
    ],
    "question_id": "q5"
  },
  {
    "question": "What types of datasets or data sources are used for experiments, and what are typical reasons for choosing them?",
    "answer": "\nContext: Scientific applications of machine learning (ML) are used in a variety of fields, including but not limited to: climate modeling, drug discovery, finance, and medical diagnosis. Here, we use the term \"climate modeling\" to refer to the study of the interactions between the Earth’s atmosphere, oceans, and land surfaces. The data sets used in this case study were selected from the NASA/Goddard Institute for Space Studies (GISS) Atmospheric Model Ensemble Data (AMED) archive, which contains reanalyses of past decades of atmospheric temperature and precipitation data. The dataset comprises 30 reanalyses, each of which provides a spatial resolution of 0.25 degrees latitude and longitude.\n\nA typical reason for choosing a dataset is the availability of data from a specific location or region, which can be difficult to access or expensive to obtain. For example, the AMED dataset was selected because it was based on data from a specific location, the southeastern United States, which has been studied extensively in climate science research. The dataset also had high-resolution spatial resolution, which was useful for modeling the",
    "retrieved_chunks": [
      "The breakthrough in Deep Learning neural networks has transformed the use of AI and machine learning technologies for the analysis of very large experimental datasets . These datasets are typically generated by large-scale experimental facilities at national laboratories . In the context of science , scientific machine learning focuses on training machines to identify patterns , trends , and anomalies to extract meaningful scientific insights from such datasets . With a new generation of experimental facilities , the rate of data generation and the scale of data volumes will increasingly require the use of more automated data analysis . At present , identifying the most appropriate machine learning algorithm for the analysis of any given scientific dataset is still a challenge for scientists . This is due to many different machine learning frameworks , computer architectures , and machine learning models .",
      "Current developments are towards specialising these ML approaches to be more domain-specific and domain-aware [ 5 ] [ 6 ] [ 7 ] , and aiming to connect the apparent 'black box ' successes of DL networks with well-understood approaches from science . The overarching scope of ML in science is very broad , including identifying patterns , anomalies , and trends from relevant scientific datasets , and using ML for classification and predicting of those patterns , clustering of data , and generating near-realistic synthetic data . There are three approaches for developing ML-based solutions , namely , supervised , unsupervised , and reinforcement learning . In supervised learning , the ML model is trained for a given task with examples . In order to have examples , the data used for training the ML model must contain the ground truth or labels . Supervised learning is therefore only possible when there is a labelled subset of the data . Once trained , the learned model can be deployed for real-time usage , such as pattern classification or estimation -- -which is often referred to as inference . Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels .",
      "Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Interestingly , this latter question can be further rephrased as : what are the characteristics of a data set that are well correlated with the possibility , or the impossibility , of obtaining ML models able to effectively extrapolate to unknown instances of the problem ? It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] .",
      "The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] . Taking inspiration from [ 14 ] , where the authors find links between data set characteristics and efficiency of feature selection techniques , we propose to empirically explore the relation between data-set characteristics and effectiveness of standard ML models , in order to obtain a general meta-model able to extrapolate . In order to answer the question , we analyzed 109 publicly available classification data sets from open-access , curated sources . We decided to focus on classification , as supervised ML represents a quite significant portion of real-world problems ; and , differently from regression , several sophisticated quality metrics have already been developed for this task [ 15 ] . During the analysis , we take into account characteristics such as number of features , number of classes , number of samples , and we look for correlations with quality metrics , such as accuracy of a ML model on training and test points .",
      "INTRODUCTION The age of rapid technological change is unfolding in real time , empowering the collection of massive amounts of data in a variety of fields . Despite this , many fields still struggle with data acquisition with limited sample sizes , particularly in experiments that involve human or animal subjects and can be prohibitively expensive . To improve the performance of the primary task on those occasions , transfer learning has been widely advocated as a means of leveraging knowledge from available auxiliary data that are different while related to the primary data . Successful applications of transfer learning in data-scarce fields include drug development ( Turki , Wei , & Wang 2017 ) , clinical trials ( Bellot & van der Schaar 2019 ) , and material sciences ( Hutchinson et al . 2017 ) , among others . For an overview of transfer learning methodologies and applications , interested readers may refer to survey papers by Pan and Yang ( 2009 ) , Weiss , Khoshgoftaar , and Wang ( 2016 ) , Niu , Liu , Wang , and Song ( 2020 ) , and Zhuang et al . ( 2020 ) . Although transfer learning has achieved pervasive success and shows great promise , there is no guarantee that it will always improve performance -there is no free lunch for transfer learning ."
    ],
    "question_id": "q6"
  },
  {
    "question": "How does theoretical analysis (e.g., proofs or bounds) relate to empirical evidence (e.g., experiments or ablations)?",
    "answer": "\nExplanation:\nTheoretical analysis is a crucial component of machine learning research, providing a framework for understanding and predicting the behavior of algorithms. However, theoretical analysis often focuses on abstract, mathematical concepts that are difficult to apply to real-world applications. In contrast, empirical evidence often provides a more realistic picture of how algorithms work in practice. By coupling theory with empirical evidence, we can gain insights into the performance of algorithms and identify areas where improvements can be made. For example, theoretical analysis may reveal that a particular algorithm is over- or under-fitting the data, which could affect its performance in real-world applications. Similarly, empirical evidence may suggest that a particular algorithm is over- or under-specified, which could affect its ability to generalize to new datasets. In this position paper, we propose a novel approach to combining theory and empirical evidence in machine learning. Our approach is based on the idea of `` mathematical-principle-based machine '' (MPBM), which represents a machine learning algorithm as a set of mathematical principles that guide its behavior. We argue that by applying mathematical principles to machine learning models, we can gain insights into the fundamental principles that govern the behavior of",
    "retrieved_chunks": [
      "Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Interestingly , this latter question can be further rephrased as : what are the characteristics of a data set that are well correlated with the possibility , or the impossibility , of obtaining ML models able to effectively extrapolate to unknown instances of the problem ? It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] .",
      "Introduction In an age of user generated web-contents and of portable devices with embedded computer vision capabilities , machine learning ( ML ) and big data mining questions are fundamental . As a result , these questions naturally penetrate neighboring research fields , including belief function theory ( BFT ) , so that it is now usual to attend a `` Classification '' session [ 26 ] or a `` Machine Learning '' session [ 16 ] in a conference devoted to belief functions . However , it is hard to accept that among the various proposed approaches based on BF , very few have become state-of-the-art ML methods , the knowledge of which has spread beyond the BF community . Without any doubt , this can be partly explained by the relative size of the scientific communities under consideration : although quickly growing , the BF one is relatively small with respect to that of statistics , Bayesian networks , neural networks , etc . However , this reason alone is not sufficient : There are indeed other topics , such as for instance , information fusion , where BF-based methods are now as well recognized as are methods based on more classical formalisms , such as probabilities , or ontologies .",
      "The breakthrough in Deep Learning neural networks has transformed the use of AI and machine learning technologies for the analysis of very large experimental datasets . These datasets are typically generated by large-scale experimental facilities at national laboratories . In the context of science , scientific machine learning focuses on training machines to identify patterns , trends , and anomalies to extract meaningful scientific insights from such datasets . With a new generation of experimental facilities , the rate of data generation and the scale of data volumes will increasingly require the use of more automated data analysis . At present , identifying the most appropriate machine learning algorithm for the analysis of any given scientific dataset is still a challenge for scientists . This is due to many different machine learning frameworks , computer architectures , and machine learning models .",
      "Current developments are towards specialising these ML approaches to be more domain-specific and domain-aware [ 5 ] [ 6 ] [ 7 ] , and aiming to connect the apparent 'black box ' successes of DL networks with well-understood approaches from science . The overarching scope of ML in science is very broad , including identifying patterns , anomalies , and trends from relevant scientific datasets , and using ML for classification and predicting of those patterns , clustering of data , and generating near-realistic synthetic data . There are three approaches for developing ML-based solutions , namely , supervised , unsupervised , and reinforcement learning . In supervised learning , the ML model is trained for a given task with examples . In order to have examples , the data used for training the ML model must contain the ground truth or labels . Supervised learning is therefore only possible when there is a labelled subset of the data . Once trained , the learned model can be deployed for real-time usage , such as pattern classification or estimation -- -which is often referred to as inference . Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels .",
      "Introduction Machine learning is the study and construction of systems that can learn from data . The systems are called learning machines . When Big Data emerges increasingly , more learning machines are developed and applied in different domains . However , the ultimate goal of machine learning study is insight , not machine itself . By the term insight I mean learning mechanisms in descriptions of mathematical principles . In a loose sense , learning mechanisms can be regarded as the natural entity . As the `` Tao ( 道 ) '' reflects the most fundamental of the universe by Lao Tzu ( 老子 ) , Einstein suggests that we should pursue the simplest mathematical interpretations to the nature . Although learning mechanisms are related to the subjects of psychology , cognitive and brain science , this paper stresses on the exploration of mathematical principles for interpretation of learning mechanisms . Up to now , we human beings are still far away from deep understanding ourself on learning mechanisms in terms of mathematical principles . It is the author 's belief that `` mathematical-principle-based machine '' might be more important and critical than `` brain-inspired machine '' in the study of machine learning . The purpose of this position paper is to put forward a new perspective and a novel conjecture within the study of machine learning ."
    ],
    "question_id": "q7"
  },
  {
    "question": "How are machine learning methods applied to concrete scientific or engineering tasks (e.g., physics, biology, control, optimization)?",
    "answer": "\nIn this document, we will provide an overview of machine learning methods applied to a specific scientific or technical task. Our focus will be on physics, biology, control, optimization, or other fields where machine learning is commonly used.\n\nPhysics:\n\n1. Classical machine learning for physics: This is the classical approach to machine learning in physics, where classical physics models are used to predict physical properties of systems. These models often involve a small number of parameters that can be learned from data sets. This approach has been used in applications such as fluid dynamics and condensed matter physics.\n\n2. Quantum machine learning for physics: This is the quantum counterpart to classical machine learning, which involves quantum computers and machine learning algorithms. Quantum machine learning has the potential to be more efficient than classical machine learning, but it is still in its nascent stages.\n\nBiology:\n\n1. Genome-wide association studies (GWAS): GWAS is a statistical approach to identify genetic variants that are associated with complex traits. Machine learning can be used to analyze large-scale GWAS data sets to identify potential signal genes and predict phenotypes based on gene expression patterns.\n\n2. Prote",
    "retrieved_chunks": [
      "Current developments are towards specialising these ML approaches to be more domain-specific and domain-aware [ 5 ] [ 6 ] [ 7 ] , and aiming to connect the apparent 'black box ' successes of DL networks with well-understood approaches from science . The overarching scope of ML in science is very broad , including identifying patterns , anomalies , and trends from relevant scientific datasets , and using ML for classification and predicting of those patterns , clustering of data , and generating near-realistic synthetic data . There are three approaches for developing ML-based solutions , namely , supervised , unsupervised , and reinforcement learning . In supervised learning , the ML model is trained for a given task with examples . In order to have examples , the data used for training the ML model must contain the ground truth or labels . Supervised learning is therefore only possible when there is a labelled subset of the data . Once trained , the learned model can be deployed for real-time usage , such as pattern classification or estimation -- -which is often referred to as inference . Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels .",
      "Introduction Machine learning usually aims to find and develop a computational model for an intelligent task on a practical problem . Development based on calculation can be called engineering ( 1 ) . In software engineering , software systems are calculated and engineered by models . In fact , these software models are platforms for analysis , design , development , and system engineering . For modeling in software engineering , we need several elements : 1 . The modeling perspective , 2 . The system under modeling , and 3 . Modeling language and tools ( 5 ) . So we look at a system under modeling from one or several perspectives , and we discover a set of meanings about that system . Using the modeling language and tool , we express and record those perceived meanings of the system . This allows us to engineer the system under modeling ( as-is system or to-be system ) by changing and transforming it . We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations .",
      "Introduction Quantum machine learning represents a highly promising realm in contemporary physics and computer science research , with far-reaching implications spanning quantum chemistry [ 108 ] , artificial intelligence [ 89 ] , and even high-energy physics [ 7 ] . Nevertheless , it remains in its nascent stages of development . This is evident from the absence of a precise definition for quantum machine learning . Some describe it as the convergence of quantum computing and machine learning , wherein machine learning algorithms are executed on quantum devices . In simpler terms , it can be thought of as the quantum counterpart to classical machine learning . In recent times , artificial intelligence , exemplified by technologies like ChatGPT , has become an integral part of everyday life . It 's entirely plausible that , in the future , we will harness artificial intellegence in an even wider array of applications , including medical diagnostics , education , and aiding scientific research . Much of artificial intellegence 's success hinges on machine learning , a departure from traditional computer programs that entail crafting explicit instructions to directly solve problems [ 112 ] . Machine learning models , on the other hand , are trained on real-world data stored in a dataset ( often denoted as D ) , acquiring the ability to tackle problems autonomously .",
      "Introduction The term machine learning ( ML ) traditionally includes algorithms that are able to improve their performance on a specific task over time , given an increasing amount of relevant data [ 1 ] . In recent years , this field of research is enjoying a growing popularity , driven by the breakthrough of Deep Learning [ 2 ] and an impressive track record of success stories in different fields , ranging from natural language processing [ 3 ] to autonomous vehicles [ 4 ] , image classification [ 5 ] human-competitive performance in boardgames [ 6 ] . An interesting online collection about various uses of ML has been compiled by the journal Nature is late 2018 1 , although the fast pace the field is progressing made it to appear outdated after few quarters . As out-of-the-box ML solutions are becoming increasingly available to both researchers and the general public [ 7 , 8 , 9 , 10 ] , theoretical questions are suddenly turning into practical issues . Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ?",
      "Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels . However , the simulated data may not be representative of the real data and the model may therefore not perform satisfactorily when used for inferencing . The unsupervised learning technique , in contrast , does not rely on labels . A simple example of this technique is clustering , where the aim is to identify several groups of data points that have common features . Another example is identification of anomalies in data . Example algorithms include k-Means Clustering 8 , Support Vector Machines ( SVM ) 9 , or neural network-based autoencoders 10 . Finally , reinforcement learning relies on a trial-and-error approach to learn a given task with the learning system being positively rewarded whenever the system behaves correctly , and penalised whenever it behaved incorrectly 11 . Each of these learning paradigms have a large number of algorithms , and modern developmental approaches are often hybrid and use one of more of these techniques together . This leaves a very large choice of ML algorithms for any given problem ."
    ],
    "question_id": "q8"
  },
  {
    "question": "What strategies support learning in complex or changing environments, especially in reinforcement learning (e.g., exploration, adaptation, non-stationarity)?",
    "answer": "\nContext:\nReinforcement learning (RL) is a state-of-the-art machine learning approach that enables autonomous agents to learn from feedback and to make decisions in complex and changing environments. While RL has shown impressive results in a wide range of applications, such as navigation, decision-making, and robotics, it still faces significant challenges in domains that are difficult to simulate and that change over time. To overcome these challenges, RL algorithms can use a variety of methods, including exploration, adaptation, and adaptation-based exploration (ABE), to adapt to the changing environment. Exploration is the process of searching for the best possible actions or policies in the environment. Abe-based reinforcement learning (abrl) is a recent extension of rl that aims to make decisions adaptively over time, taking into account the environment's changes. In this work, we introduce a novel abrl algorithm, called Dex, which is trained using a novel continual reinforcement learning toolkit called Dex. Dex is designed to be scalable, efficient, and flexible, and can be used with any RL algorithm. Our experiments show that Dex can learn to solve",
    "retrieved_chunks": [
      "Introduction Complex environments such as Go , Starcraft , and many modern video-games present profound challenges in deep reinforcement learning that have yet to be solved . They often require long , precise sequences of actions and domain knowledge in order to obtain reward , and have yet to be learned from random weight initialization . Solutions to these problems would mark a significant breakthrough on the path to artificial general intelligence . Recent works in reinforcement learning have shown that environments such as Atari games [ 2 ] can be learned from pixel input to superhuman expertise [ 9 ] . The agents start with randomly initialized weights , and learn largely from trial and error , relying on a reward signal to indicate performance . Despite these successes , complex games , including those where rewards are sparse such as Montezuma 's Revenge , have been notoriously difficult to learn . While methods such as intrinsic motivation [ 3 ] have been used to partially overcome these challenges , we suspect this becomes intractable as complexity increases . Additionally , as environments become more complex , they will become more expensive to simulate . This poses a significant problem , since many Atari games already require upwards of 100 million steps using state-of-the-art algorithms , representing days of training on a single machine .",
      "Because of the difficulty in generating labelled data for supervised learning , particularly for experimental datasets , it is often difficult to apply supervised learning directly . To circumvent this limitation , training is often performed on simulated data , which provides an opportunity to have relevant labels . However , the simulated data may not be representative of the real data and the model may therefore not perform satisfactorily when used for inferencing . The unsupervised learning technique , in contrast , does not rely on labels . A simple example of this technique is clustering , where the aim is to identify several groups of data points that have common features . Another example is identification of anomalies in data . Example algorithms include k-Means Clustering 8 , Support Vector Machines ( SVM ) 9 , or neural network-based autoencoders 10 . Finally , reinforcement learning relies on a trial-and-error approach to learn a given task with the learning system being positively rewarded whenever the system behaves correctly , and penalised whenever it behaved incorrectly 11 . Each of these learning paradigms have a large number of algorithms , and modern developmental approaches are often hybrid and use one of more of these techniques together . This leaves a very large choice of ML algorithms for any given problem .",
      "Additionally , as environments become more complex , they will become more expensive to simulate . This poses a significant problem , since many Atari games already require upwards of 100 million steps using state-of-the-art algorithms , representing days of training on a single machine . Thus , it appears likely that complex environments will become too costly to learn from randomly initialized weights , due both to the increased simulation cost as well as the inherent difficulty of the task . Therefore , some form of prior information must be given to the agent . This can be seen with AlphaGo [ 18 ] , where the agent never learned to play the game without first using supervised learning on human games . While supervised learning certainly has been shown to aid reinforcement learning , it is very costly to obtain sufficient samples and requires the environment to be a task humans can play with reasonable skill , and is therefore impractical for a wide variety of important reinforcement learning problems . In this paper we introduce Dex , the first continual reinforcement learning toolkit for training and evaluating continual learning methods . We present and demonstrate a novel continual learning method we call incremental learning to solve complex environments . In incremental learning , environments are framed as a task to be learned by an agent .",
      "This paper introduces Dex , a reinforcement learning environment toolkit specialized for training and evaluation of continual learning methods as well as general reinforcement learning problems . We also present the novel continual learning method of incremental learning , where a challenging environment is solved using optimal weight initialization learned from first solving a similar easier environment . We show that incremental learning can produce vastly superior results than standard methods by providing a strong baseline method across ten Dex environments . We finally develop a saliency method for qualitative analysis of reinforcement learning , which shows the impact incremental learning has on network attention .",
      "Introduction Machine learning is often approached from a behaviourist perspective , in which external feedback in the form of a reinforcement signal is the major driving force of improvement . Though this method has lead to many successes , it is confronted with interesting and unsolved challenges like tackling overfitting , providing comprehensibility , building reusable abstractions and concept formation , among many other [ Kotsiantis et al. , 2007 ; Bengio , 2009 ] . The problem with these behaviourist approaches is that they ignore the central importance of internal processes when considering learning . Model internals are often regarded just as a means to achieve higher performance . Analogous to studying human behaviour , however , appreciating the mechanisms of learning boils down to the question : `` when have we really learnt ? '' In this paper , we argue that a computer has learnt when : • the programme becomes better at the task at hand ; • the programme can perform the task more efficiently ; • the code becomes `` more structured '' and simpler . One possible analogy to better understand the above statements can be found in software engineering . When considering code that performs a specific task , we do not care only about its functionality , but also about its execution speed/efficiency and other so-called `` non-functional requirements '' ."
    ],
    "question_id": "q9"
  },
  {
    "question": "What does robustness mean in machine learning, including robustness to distribution shift, noise, and adversarial perturbations?",
    "answer": "\nTo ensure the robustness of machine learning models, in the absence of labelled data, an essential approach is to estimate the model's robustness to distribution shift and noise. While this approach has been used by some researchers to train models, it is not always practical as training data is often scarce, and the computational power required to perform such analysis is high. A more practical strategy is to design predictive models with high predictive performance, and then use techniques such as feature engineering to extract relevant features that are robust to the types of noise and perturbations that affect the dataset. This approach is not limited to machine learning but can apply to other areas of computer science, such as image processing and natural language processing.\n\nFor instance, in image processing, we use the Residual Networks (RN) model, which combines a convolutional neural network (CNN) with a residual network (RN), to detect and remove patterns that are distracting in image datasets. To apply this model to an image dataset with noisy pixels, we identify features that are the most relevant to the image dataset, such as edges, texture, and texture features, and we train the RN model to predict the most relevant features. This",
    "retrieved_chunks": [
      "1 Adversarial Machine Learning is not Machine Learning Machine learning has its mathematical foundation in concentration inequalities . This is a consequence of the independent and identically-distributed ( i.i.d . ) data assumption . In contrast , I suggest that adversarial machine learning may adopt optimal control as its mathematical foundation [ 3 , 25 ] . There are telltale signs : adversarial attacks tend to be subtle and have peculiar non-i.i.d . structures -as control input might be .",
      "Quantifying and managing uncertainties that occur when data-driven models such as those provided by AI and machine learning methods are applied is crucial . This whitepaper provides a brief motivation and first overview of the state of the art in identifying and quantifying sources of uncertainty for data-driven components as well as means for analyzing their impact .",
      "INTRODUCTION In order to formulate a learning theory of machine learning , it may be necessary to move from seeing an inert model as the machine learner to seeing the human developer-along with , and not separate from , his or her model and surrounding social relations-as the machine learner . -Reigeluth & Castelle [ 55 ] The past decade has seen massive research on interpretable machine learning ( ML ) . 1 Here is a rough restatement of the goal of interpretable ML research program : many ML models are opaque in that even the expert humans can not robustly understand , in non-mathematical terms , the reasons for why particular outputs are generated by these models [ 31 , 42 , 66 ] . To overcome this opacity , various model-centric techniques have been developed to interpret their outputs . These techniques are diverse . They range from producing counterfactual explanations or heatmaps that offer insights into how changing inputs affect outputs [ 28 , 41 , 46 ] , to interpreting the inner workings of the model by probing patterns of neuron activations or attention mechanisms [ 10 , 15 , 48 ] . 2 Despite these advancements , ML interpretability remains a contentious and ambiguous topic in the scientific community , lacking a universally accepted scope and definition [ 11 , 13 , 38 , 45 ] .",
      "I describe an optimal control view of adversarial machine learning , where the dynamical system is the machine learner , the input are adversarial actions , and the control costs are defined by the adversary 's goals to do harm and be hard to detect . This view encompasses many types of adversarial machine learning , including test-item attacks , training-data poisoning , and adversarial reward shaping . The view encourages adversarial machine learning researcher to utilize advances in control theory and reinforcement learning .",
      "Machine learning has become prevalent across a wide variety of applications . Unfortunately , machine learning has also shown to be susceptible to deception , leading to errors , and even fatal failures . This circumstance calls into question the widespread use of machine learning , especially in safety-critical applications , unless we are able to assure its correctness and trustworthiness properties . Software verification and testing are established technique for assuring such properties , for example by detecting errors . However , software testing challenges for machine learning are vast and profuse -yet critical to address . This summary talk discusses the current state-of-the-art of software testing for machine learning . More specifically , it discusses six key challenge areas for software testing of machine learning systems , examines current approaches to these challenges and highlights their limitations ."
    ],
    "question_id": "q10"
  },
  {
    "question": "What methods are used to explain or interpret model behavior (e.g., feature importance, saliency, counterfactual explanations)?",
    "answer": "\n1. Feature Importance: Feature Importance is a technique used to interpret the effects of features on a model's predictions by providing a ranking of each feature. This ranking can be based on the feature's importance in explaining the model's predictions. Feature Importance is used to identify under- and over-represented features in the model's prediction.\n\n2. Saliency: Saliency maps show the importance of individual features in predicting the model's output. Saliency maps help identify the features that have the most significant influence on the model's output.\n\n3. Counterfactual Explanations: Counterfactual explanations offer a way to interpret the inputs that lead to a specific output. Counterfactual explanations help explain how the model's output would have been different if the inputs were changed.\n\n4. Attention Mechanisms: Attention mechanisms are used to interpret the model's output by analyzing the neuron activations responsible for generating the output. Attention mechanisms can also help interpret the model's behavior in terms of its ability to learn from input.\n\n5. Non-mechanistic Approximations: Non-mechan",
    "retrieved_chunks": [
      "2 Despite these advancements , ML interpretability remains a contentious and ambiguous topic in the scientific community , lacking a universally accepted scope and definition [ 11 , 13 , 38 , 45 ] . This ambiguity complicates the evaluation and regulation of opaque ML systems , raising questions about what constitutes sufficient interpretation and how it should be assessed . A pragmatic and pluralistic approach to interpretability has gained traction , viewing explanations as context-dependent responses to why-questions [ 12 , 31 , 42 , 43 ] . On this pluralistic approach , the adequacy of an explanation depends on the specific inquiry . For simple classification tasks , techniques like saliency maps or feature importance may suffice . For instance , if a model is differentiating between images of cats and dogs , saliency maps could highlight the pixels most influential in the decision-making process . However , for complex and socially-embedded topics -such as biased healthcare algorithms -these model-centric explanations can fall short . Consider an algorithm that predicts hospital readmission risk but systematically underestimates it for certain racial groups . A model-centric explanation might highlight `` total healthcare costs incurred in the past year '' as an important feature . However , this alone might not fully reveal why the algorithm underestimates risk for a specific racial group .",
      "INTRODUCTION In order to formulate a learning theory of machine learning , it may be necessary to move from seeing an inert model as the machine learner to seeing the human developer-along with , and not separate from , his or her model and surrounding social relations-as the machine learner . -Reigeluth & Castelle [ 55 ] The past decade has seen massive research on interpretable machine learning ( ML ) . 1 Here is a rough restatement of the goal of interpretable ML research program : many ML models are opaque in that even the expert humans can not robustly understand , in non-mathematical terms , the reasons for why particular outputs are generated by these models [ 31 , 42 , 66 ] . To overcome this opacity , various model-centric techniques have been developed to interpret their outputs . These techniques are diverse . They range from producing counterfactual explanations or heatmaps that offer insights into how changing inputs affect outputs [ 28 , 41 , 46 ] , to interpreting the inner workings of the model by probing patterns of neuron activations or attention mechanisms [ 10 , 15 , 48 ] . 2 Despite these advancements , ML interpretability remains a contentious and ambiguous topic in the scientific community , lacking a universally accepted scope and definition [ 11 , 13 , 38 , 45 ] .",
      "What is it to interpret the outputs of an opaque machine learning model ? One approach is to develop interpretable machine learning techniques . These techniques aim to show how machine learning models function by providing either model-centric local or global explanations , which can be based on mechanistic interpretations ( revealing the inner working mechanisms of models ) or non-mechanistic approximations ( showing input feature-output data relationships ) . In this paper , we draw on social philosophy to argue that interpreting machine learning outputs in certain normatively-salient domains could require appealing to a third type of explanation that we call `` socio-structural '' explanation . The relevance of this explanation type is motivated by the fact that machine learning models are not isolated entities but are embedded within and shaped by social structures . Socio-structural explanations aim to illustrate how social structures contribute to and partially explain the outputs of machine learning models .",
      "Introduction Machine learning usually aims to find and develop a computational model for an intelligent task on a practical problem . Development based on calculation can be called engineering ( 1 ) . In software engineering , software systems are calculated and engineered by models . In fact , these software models are platforms for analysis , design , development , and system engineering . For modeling in software engineering , we need several elements : 1 . The modeling perspective , 2 . The system under modeling , and 3 . Modeling language and tools ( 5 ) . So we look at a system under modeling from one or several perspectives , and we discover a set of meanings about that system . Using the modeling language and tool , we express and record those perceived meanings of the system . This allows us to engineer the system under modeling ( as-is system or to-be system ) by changing and transforming it . We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations .",
      "We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations . To obtain the proper perspective or perspectives of a system , we need human intuition of that system , meaning there is a deep connection between the modeler 's intuition and system engineering ( including software , hardware , and intelligence ) . Therefore , we can consider human intuition as the infrastructure for system engineering activities ."
    ],
    "question_id": "q11"
  },
  {
    "question": "What fairness or bias risks arise in machine learning systems, and what mitigation approaches are used?",
    "answer": "\nIntroduction The ethics of Machine Learning has become an unavoidable topic in the AI Community. The deployment of machine learning systems in multiple social contexts has resulted in a closer ethical scrutiny of the design, development, and application of these systems. The AI/ML community has come to terms with the imperative to think about the ethical implications of machine learning, not only as a product but also as a practice. While machine learning is a relatively recent technology, debates on social issues in the context of insurance have been ongoing for a long time. This paper explores possibilities for ethical evaluation of machine learning methodologies. The critical question that is troubling many debates is what can constitute an ethically accountable machine learning system. In this paper, we explore possibilities for ethical evaluation of machine learning methodologies. We scrutinize techniques and methods in machine learning from a relational ethics perspective, taking into consideration how machine learning systems are part of the world and how they relate to different forms of agency. Taking a page from phil Agre ( 1997 ) we use the notion of a critical technical practice as a means of analysis of machine learning approaches. Our radical proposal",
    "retrieved_chunks": [
      "We argue that insurance can act as an analogon for the social situatedness of machine learning systems , hence allowing machine learning scholars to take insights from the rich and interdisciplinary insurance literature . Tracing the interaction of uncertainty , fairness and responsibility in insurance provides a fresh perspective on fairness in machine learning . We link insurance fairness conceptions to their machine learning relatives , and use this bridge to problematize fairness as calibration . In this process , we bring to the forefront two themes that have been largely overlooked in the machine learning literature : responsibility and aggregate-individual tensions . See Baker ( , p .",
      "Introduction The ethics of Machine Learning has become an unavoidable topic in the AI Community . The deployment of machine learning systems in multiple social contexts has resulted in a closer ethical scrutiny of the design , development , and application of these systems . The AI/ML community has come to terms with the imperative to think about the ethical implications of machine learning , not only as a product but also as a practice ( Birhane , 2021 ; Shen et al . 2021 ) . The critical question that is troubling many debates is what can constitute an ethically accountable machine learning system . In this paper we explore possibilities for ethical evaluation of machine learning methodologies . We scrutinize techniques , methods and technical practices in machine learning from a relational ethics perspective , taking into consideration how machine learning systems are part of the world and how they relate to different forms of agency . Taking a page from Phil Agre ( 1997 ) we use the notion of a critical technical practice as a means of analysis of machine learning approaches . Our radical proposal is that supervised learning appears to be the only machine learning method that is ethically defensible .",
      "Briefly , actuarial fairness demands that each policyholder should pay only for their own risk , that is , mutualization should occur only between individuals with the same 'true ' risk . In contrast , solidarity calls for equal contribution to the pool . On one level of this text , we problematize actuarial fairness ( by extension , calibration ) as a notion of fairness in the normative sense by taking inspiration from insurance . This perspective is aligned with recent proposals that stress the discrepancy of formal algorithmic fairness and `` substantive '' fairness ( Green , ) , which some prefer to call justice ( Vredenburgh , ) . Parallel to this runs a distinct textual level , where we emphasize two intricately interacting themes : responsibility and tensions between aggregate and individual . Both entail criticism of actuarial fairness , but we suggest that they additionally provide much broader , fruitful lessons for machine learning from insurance . At the highest level of abstraction , our goal is to establish a general conceptual bridge between insurance and machine learning . Traversing this bridge , machine learning scholars can obtain new perspectives on the social situatedness of a probabilistic , statistical technology -we attempt to offer a new 'cognitive toolkit ' for thinking about the social situatedness of machine learning .",
      "In other words , who is to be mutualized in the pool . Some form of segmentation is found in many insurantial arrangements : the pool of policyholders can be stratified by separating high and low risk individuals . But the specific nature that such segmentation McFall et al . ( ) call insurance `` interestingly uninteresting '' , referring to how insurance is `` hugely underresearched '' given its societal importance , which is typically not recognized ( Ewald , ) . takes typically depends not only on risk assessment , but on further considerations such as assignment of responsibility , modulated by social context ; in this way , insurance is not a neutral technology ( Baker & Simon , ; Glenn , a ) . Our non-comprehensive outline of the history of insurance illustrates how uncertainty , fairness and responsibility interact , and can be entangled and disentangled . From this background , we can extract conceptual insights which also apply to machine learning . The tension between risk assessment and distribution is mirrored in formal fairness principles : solidarity , which can be linked to independence in fair machine learning , contrasts with actuarial fairness , linked to calibration . Briefly , actuarial fairness demands that each policyholder should pay only for their own risk , that is , mutualization should occur only between individuals with the same 'true ' risk .",
      "Introduction Insurance is `` interestingly uninteresting '' . In this work , we argue that in fact insurance is far from uninteresting and indeed a rich source of inspiration and insight to scholarship interested in social issues surrounding machine learning , specifically the field now known as fair machine learning . Our proposal is that insurance can be viewed as an analogon to machine learning with respect to these issues arising from the social situatedness . While machine learning is a relatively recent technology , debates regarding social issues in the context of insurance have been ongoing for a long time . Thus , we argue that taking inspiration from studies of insurance can contribute to a more integrative view of machine learning systems as socio-technical systems ( Selbst et al. , ) . Both machine learning and insurance are firmly based on a statistical , probabilistic mode of reasoningan actuarial mode . Indeed , insurance can be viewed as the first commercial test of probability theory ( Gigerenzer et al. , ; McFall , ) . Insurance , a technology for doing risk , transforms uncertainty into calculable risk ( Lehtonen & Van Hoyweghen , ) ."
    ],
    "question_id": "q12"
  },
  {
    "question": "What limitations are commonly identified, and what future directions or open problems follow from them?",
    "answer": "\nSection 2:\nThe evolution of the mainstream in the BF community\n\nThe first era of BFT was marked by a focus on the study of distributed consensus protocols. This study involved developing protocols that could distribute an agreement between a group of nodes in a decentralized fashion. The study of consensus protocols during the 1980s and the early 1990s focused on the development of decentralized consensus mechanisms that could operate without requiring a central authority. The most widespread consensus mechanism during this era was the proof-of-work mechanism. The Bitcoin network, for example, is based on this mechanism. This consensus mechanism relies on solving a mathematical puzzle that must be solved on a computer in order to validate a new block. This puzzle can be solved using a variety of techniques, including proof-of-work, block rewards, and proof-of-stake.\n\nThe second era of BFT, which began around 2000, focused on developing consensus protocols that could operate over a network made up of thousands of nodes. This era saw the emergence of a number of consensus protocols,",
    "retrieved_chunks": [
      "Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ? Interestingly , this latter question can be further rephrased as : what are the characteristics of a data set that are well correlated with the possibility , or the impossibility , of obtaining ML models able to effectively extrapolate to unknown instances of the problem ? It is well known that ML algorithms are affected by the curse of dimensionality [ 11 ] , but ML practitioners also know that it could be possible to obtain reliable models even for high-dimensional data sets , and with a relatively small number of samples [ 12 ] . The common approach among practitioners in the field , when dealing with a new data set , seems to be : try as many different ML algorithms as possible in a cross-validation , and evaluate the outcomes ; then focus on the techniques that provided the best results , possibly applying them in an ensemble [ 13 ] .",
      "As more and more machine learnt services make their way into software applications , which themselves are part of business processes , robust life cycle management of these machine learnt models becomes critical for ensuring the integrity of business processes that rely on them . We argue that two reasons necessitate a new maturity framework for machine learning models . First , the lifecycle of machine learning models is significantly different from that of the traditional software and therefore a reinterpretation of the software capability maturity model ( CMM ) maturity framework for building and managing the lifecycle of machine learning models is called for . Second , building machine learning models that work for enterprises requires solutions to a very different set of problems than the academic literature on machine learning typically focuses on . We explain these two reasons below a bit more in detail .",
      "As a consequence , the functional behavior expected from data-driven components can only be specified in part on their intended domain , and we can not assure that they will behave as expected in all cases . Moreover , their processing structure is usually difficult to trace and validate by humans because this structure rarely follows human intuition but is generated to provide the algorithmically generalized input-output relationship in an effective manner . Prominent representatives of models used by data-driven components are artificial neural networks and support vector machines ( Russell & Norvig , 2016 ) . Since data-driven models are an important source of uncertainty in embedded systems that collaborate in an open context , the uncertainty they introduce has to be appropriately understood and managed during design time and runtime . Previous work ( Kläs & Vollmer , 2018 ) proposes separating the sources of uncertainty in data-driven components into three major classes , distinguishing between uncertainty caused by limitations in terms of model fit , data quality , and scope compliance . Whereas model fit focuses on the inherent uncertainty in data-driven models , data quality covers the additional uncertainty caused by their application to input data obtained in suboptimal conditions and scope compliance covers situations where the model is likely applied outside the scope for which it was trained and validated .",
      "However , to my knowledge , no recent referenced article is available for any reader seeking for a starting point to question the links between ML and BFT . This document is structured as follow : In Section 2 , a brief recall of the evolution of the mainstream in the BF community is provided . Then , in Section 3 , a short summary of the earlier ages of ML up to the mid-90s , is sketched , as well as a coarse description of the successful interactions between ML and BFT in those times . Afterward , I provide in Section 4 a synthetic overview of the revolution that blew over ML around the early 2000s , and which modified its goals and the organization of its supporting community . As BFT does not seem to fit in this new picture of the ML world , I list in Section 5 a few problems that may still be of interest for the current mainstream of BFT , as well as some potential interesting evolutions for the community to adapt to the newly raised questions .",
      "In addition to discussing the current applications of quantum capabilities for machine learning , we should also let our imaginations soar . The era of fault-tolerant quantum computing ( FTQC ) is a foreseeable future , and it 's crucial to look ahead at what challenges we can tackle with quantum machine learning on FTQC devices . One of the most renowned and valuable algorithms in this context is the Harrow-Hassidim-Lloyd ( HHL ) algorithm [ 58 ] . Additionally , there are other algorithms that can be deployed to address a range of problems , such as principal component analysis [ 18 ] . Beside the optimistic future that quantum machine learning has , there are also a number of controversial issues with the subject . For example , some might argue that the variational quantum algorithm will not work in some circumstance . People working on quantum landscapes theory observed the famous barren plateau phenomena which leads to a kind of no-go theorem [ 27 , 86 ] . It amounts to situations that are hard to find minimum when we optimizes our objective function by gradient descent with randomized variational circuits . Debates indeed exist regarding whether quantum algorithms can consistently deliver exponential speedups . Some argue that quantum speedup is only guaranteed when dealing with quantum information ."
    ],
    "question_id": "q13"
  },
  {
    "question": "How do real-world constraints (e.g., deployment, cost, latency, privacy, safety) shape machine learning systems used for decision-making?",
    "answer": "\nQuestion:\nHow can a maturity framework for machine learning model lifecycle management help businesses manage risk associated with adopting machine learning models?\n\nAnswer in a clear and concise way.\n\nQuestion:\nHow can a re-interpretation of the software Capability Maturity Model for machine learning model development process help businesses make better decisions when using machine learning models?\n\nAnswer in a clear and concise way.\n\nConclusion:\nThis guidebook presents a re-interpretation of the software Capability Maturity Model ( CMM ) for the development process of machine learning models. The framework is based on the premise that machine learning models are fundamentally different from traditional software and require more maturity than traditional software. Examples of machine learning models include artificial neural networks and support vector machines, and the framework is applicable to both research and industry settings. The framework is designed to be re-interpreted using the CMM framework for software development and provides a common way to manage the lifecycle of machine learning models. The framework is applicable to all machine learning systems, and its maturity levels are used to guide the design, development, and maintenance of machine learning models. The",
    "retrieved_chunks": [
      "As more and more machine learnt services make their way into software applications , which themselves are part of business processes , robust life cycle management of these machine learnt models becomes critical for ensuring the integrity of business processes that rely on them . We argue that two reasons necessitate a new maturity framework for machine learning models . First , the lifecycle of machine learning models is significantly different from that of the traditional software and therefore a reinterpretation of the software capability maturity model ( CMM ) maturity framework for building and managing the lifecycle of machine learning models is called for . Second , building machine learning models that work for enterprises requires solutions to a very different set of problems than the academic literature on machine learning typically focuses on . We explain these two reasons below a bit more in detail .",
      "As a consequence , the functional behavior expected from data-driven components can only be specified in part on their intended domain , and we can not assure that they will behave as expected in all cases . Moreover , their processing structure is usually difficult to trace and validate by humans because this structure rarely follows human intuition but is generated to provide the algorithmically generalized input-output relationship in an effective manner . Prominent representatives of models used by data-driven components are artificial neural networks and support vector machines ( Russell & Norvig , 2016 ) . Since data-driven models are an important source of uncertainty in embedded systems that collaborate in an open context , the uncertainty they introduce has to be appropriately understood and managed during design time and runtime . Previous work ( Kläs & Vollmer , 2018 ) proposes separating the sources of uncertainty in data-driven components into three major classes , distinguishing between uncertainty caused by limitations in terms of model fit , data quality , and scope compliance . Whereas model fit focuses on the inherent uncertainty in data-driven models , data quality covers the additional uncertainty caused by their application to input data obtained in suboptimal conditions and scope compliance covers situations where the model is likely applied outside the scope for which it was trained and validated .",
      "Introduction The term machine learning ( ML ) traditionally includes algorithms that are able to improve their performance on a specific task over time , given an increasing amount of relevant data [ 1 ] . In recent years , this field of research is enjoying a growing popularity , driven by the breakthrough of Deep Learning [ 2 ] and an impressive track record of success stories in different fields , ranging from natural language processing [ 3 ] to autonomous vehicles [ 4 ] , image classification [ 5 ] human-competitive performance in boardgames [ 6 ] . An interesting online collection about various uses of ML has been compiled by the journal Nature is late 2018 1 , although the fast pace the field is progressing made it to appear outdated after few quarters . As out-of-the-box ML solutions are becoming increasingly available to both researchers and the general public [ 7 , 8 , 9 , 10 ] , theoretical questions are suddenly turning into practical issues . Among all common inquiries , perhaps the most basic is : can ML work on a specific problem ? Or , in other words : given the characteristics of a target data set , can the effectiveness of a ML approach be predicted ?",
      "Academic literature on machine learning modeling fails to address how to make machine learning models work for enterprises . For example , existing machine learning processes can not address how to define business use cases for an AI application , how to convert business requirements from offering managers into data requirements for data scientists , and how to continuously improve AI applications in term of accuracy and fairness , how to customize general purpose machine learning models with industry , domain , and use case specific data to make them more accurate for specific situations etc . Making AI work for enterprises requires special considerations , tools , methods and processes . In this paper we present a maturity framework for machine learning model lifecycle management for enterprises . Our framework is a re-interpretation of the software Capability Maturity Model ( CMM ) for machine learning model development process .",
      "The engineering of machine learning systems is still a nascent field ; relying on a seemingly daunting collection of quickly evolving tools and best practices . It is our hope that this guidebook will serve as a useful resource for machine learning practitioners looking to take advantage of Bayesian optimization techniques . We outline four example machine learning problems that can be solved using open source machine learning libraries , and highlight the benefits of using Bayesian optimization in the context of these common machine learning applications ."
    ],
    "question_id": "q14"
  },
  {
    "question": "Which modeling and architectural design choices are especially important, and why?",
    "answer": "\nContext:\nWe could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture. Because if we do not use a proper perspective or perspectives to look at the meanings of a system, it is practically impossible for us to achieve a model, start modeling, and ultimately develop through engineering calculations. To obtain the proper perspective or perspectives of a system, we need human intuition as the infrastructure for system engineering activities.\n\nThough the organization and complexity of model topologies is acknowledged to be crucial, current approaches are mainly limited to analysing the data space, i.e. The implemented regression functions or decision boundaries [ Bianchini and Scarselli, 2014 ]. There is a problem with this approach. Consider an neural network algorithm that needs to learn a simple concept like an \" XOR \" function depicted in Fig. 1. An infinite number of neural networks with very similar or identical decision boundaries can be constructed -of which two are shown in Fig. 2. From an external point of view, there is no way to discriminate between these two models : describing the difference between these two models can only occur in terms of the model intern",
    "retrieved_chunks": [
      "We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations . To obtain the proper perspective or perspectives of a system , we need human intuition of that system , meaning there is a deep connection between the modeler 's intuition and system engineering ( including software , hardware , and intelligence ) . Therefore , we can consider human intuition as the infrastructure for system engineering activities .",
      "Though the organization and complexity of model topologies is acknowledged to be crucial , current approaches are mainly limited to analysing the data space , i.e . the implemented regression functions or decision boundaries [ Bianchini and Scarselli , 2014 ] . There is a problem with this approach . Consider an neural network algorithm that needs to learn a simple concept like an `` XOR '' function depicted in Fig . 1 . An infinite number of neural networks with very similar or identical decision boundaries can be constructed -of which two are shown in Fig . 2 . From an external point of view , there is no way to discriminate between these two models : describing the difference between these two models can only occur in terms of the model internals . Of course the weight space , which represents the model of a neural network , is related to the data space , as it performs calculations on the data . In other words : Data representation and model computation should be considered as two sides of the same coin . As a result the structural properties of both the model and data space are key to the modelling of higher abstractions . Sparse coding is a perfect example of this .",
      "One possible analogy to better understand the above statements can be found in software engineering . When considering code that performs a specific task , we do not care only about its functionality , but also about its execution speed/efficiency and other so-called `` non-functional requirements '' . Furthermore , a carefully modularized design probably reflects more understanding than an endless enumeration of IF-ELSE clauses . In other words , finding a more efficient and structured way to represent/reproduce information and to perform a learning task , is as central to machine learning as the reproduction of results . Different to humans , of course , machines are measurable . This provides us with a unique opportunity to study the nature of learning in principle , at the same time improving Machine Intelligence . We are not claiming that model complexity/efficiency has not been subject to past research efforts . On the contrary , many techniques and design principles have attempted to improve exactly these properties -like Occam 's razor , Bayesian structure learning , pruning , the use of prototypes to compact information , regularization as a strategy to reduce energy , weight sharing in RNNs or CNNs to decrease model complexity , etc . Indeed , the whole evolution of Deep Learning can be seen as one specific approach in the quest to find models that are more structured ( i.e .",
      "Introduction Machine learning usually aims to find and develop a computational model for an intelligent task on a practical problem . Development based on calculation can be called engineering ( 1 ) . In software engineering , software systems are calculated and engineered by models . In fact , these software models are platforms for analysis , design , development , and system engineering . For modeling in software engineering , we need several elements : 1 . The modeling perspective , 2 . The system under modeling , and 3 . Modeling language and tools ( 5 ) . So we look at a system under modeling from one or several perspectives , and we discover a set of meanings about that system . Using the modeling language and tool , we express and record those perceived meanings of the system . This allows us to engineer the system under modeling ( as-is system or to-be system ) by changing and transforming it . We could perhaps consider the modeling perspective as the most crucial part of this conceptual architecture . Because if we do not use a proper perspective or perspectives to look at the meanings of a system , it is practically impossible for us to achieve a model , start modeling , and ultimately develop through engineering calculations .",
      "Traditional machine learning techniques typically exploit shallow-structured , and often fixed , architectures . Nevertheless , there is a general consensus that the learning of `` higherorder '' concepts is problematic , and that the solution to this issue is somehow connected to deep architectures that create ever higher forms of abstraction . Experimental research as well as neurological evidence on the organization of the brain , supports this finding [ Bianchini and Scarselli , 2014 ] . The limitation of architecture complexity is preferred , primarily because their behaviour could be understood and the training of more complex or adaptive architectures leads to a explosion of complexity . That was until recently . The recent advanced in so-called `` Deep Learning '' , have focused on training algorithms that are adapted to new kinds of deep architectures [ Deng and Yu , 2014 ] , and heuristic strategies to attain specific structural properties like sparse coding that lead to higher forms of abstractions . With the exception of studies on `` interpretability '' [ Jin and Sendhoff , 2008 ] , structural properties are mainly considered a by-product , a ( desirable ) side effect of the applied training mechanisms . Though the organization and complexity of model topologies is acknowledged to be crucial , current approaches are mainly limited to analysing the data space , i.e ."
    ],
    "question_id": "q15"
  }
]