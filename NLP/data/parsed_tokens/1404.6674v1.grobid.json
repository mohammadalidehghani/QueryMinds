{
  "title": [
    {
      "sentence": "A Comparison of First-order Algorithms for Machine Learning",
      "tokens": [
        "A",
        "Comparison",
        "of",
        "First-order",
        "Algorithms",
        "for",
        "Machine",
        "Learning"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "Using an optimization algorithm to solve a machine learning problem is one of mainstreams in the field of science.",
      "tokens": [
        "Using",
        "an",
        "optimization",
        "algorithm",
        "to",
        "solve",
        "a",
        "machine",
        "learning",
        "problem",
        "is",
        "one",
        "of",
        "mainstreams",
        "in",
        "the",
        "field",
        "of",
        "science",
        "."
      ]
    },
    {
      "sentence": "In this work, we demonstrate a comprehensive comparison of some state-of-the-art firstorder optimization algorithms for convex optimization problems in machine learning.",
      "tokens": [
        "In",
        "this",
        "work",
        ",",
        "we",
        "demonstrate",
        "a",
        "comprehensive",
        "comparison",
        "of",
        "some",
        "state-of-the-art",
        "firstorder",
        "optimization",
        "algorithms",
        "for",
        "convex",
        "optimization",
        "problems",
        "in",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "We concentrate on several smooth and non-smooth machine learning problems with a loss function plus a regularizer.",
      "tokens": [
        "We",
        "concentrate",
        "on",
        "several",
        "smooth",
        "and",
        "non-smooth",
        "machine",
        "learning",
        "problems",
        "with",
        "a",
        "loss",
        "function",
        "plus",
        "a",
        "regularizer",
        "."
      ]
    },
    {
      "sentence": "The overall experimental results show the superiority of primal-dual algorithms in solving a machine learning problem from the perspectives of the ease to construct, running time and accuracy.",
      "tokens": [
        "The",
        "overall",
        "experimental",
        "results",
        "show",
        "the",
        "superiority",
        "of",
        "primal-dual",
        "algorithms",
        "in",
        "solving",
        "a",
        "machine",
        "learning",
        "problem",
        "from",
        "the",
        "perspectives",
        "of",
        "the",
        "ease",
        "to",
        "construct",
        ",",
        "running",
        "time",
        "and",
        "accuracy",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "Introduction Optimization is the key of machine learning.",
      "tokens": [
        "Introduction",
        "Optimization",
        "is",
        "the",
        "key",
        "of",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "Most machine learning problems can be cast as optimization problems.",
      "tokens": [
        "Most",
        "machine",
        "learning",
        "problems",
        "can",
        "be",
        "cast",
        "as",
        "optimization",
        "problems",
        "."
      ]
    },
    {
      "sentence": "Furthermore, practical applications of machine learning usually involve a massive and complex data set.",
      "tokens": [
        "Furthermore",
        ",",
        "practical",
        "applications",
        "of",
        "machine",
        "learning",
        "usually",
        "involve",
        "a",
        "massive",
        "and",
        "complex",
        "data",
        "set",
        "."
      ]
    },
    {
      "sentence": "Thus, efficiency, accuracy and generalization of the optimization algorithm (solver) should be regarded as a crucial issue [2] .",
      "tokens": [
        "Thus",
        ",",
        "efficiency",
        ",",
        "accuracy",
        "and",
        "generalization",
        "of",
        "the",
        "optimization",
        "algorithm",
        "(",
        "solver",
        ")",
        "should",
        "be",
        "regarded",
        "as",
        "a",
        "crucial",
        "issue",
        "[",
        "2",
        "]",
        "."
      ]
    },
    {
      "sentence": "Many papers present dedicated optimization algorithms for specific machine learning problems.",
      "tokens": [
        "Many",
        "papers",
        "present",
        "dedicated",
        "optimization",
        "algorithms",
        "for",
        "specific",
        "machine",
        "learning",
        "problems",
        "."
      ]
    },
    {
      "sentence": "However, little attention has been devoted to the ability of a solver for a specific class of machine learning problems.",
      "tokens": [
        "However",
        ",",
        "little",
        "attention",
        "has",
        "been",
        "devoted",
        "to",
        "the",
        "ability",
        "of",
        "a",
        "solver",
        "for",
        "a",
        "specific",
        "class",
        "of",
        "machine",
        "learning",
        "problems",
        "."
      ]
    },
    {
      "sentence": "The most common structure of machine learning problems is a loss function plus a regularizer.",
      "tokens": [
        "The",
        "most",
        "common",
        "structure",
        "of",
        "machine",
        "learning",
        "problems",
        "is",
        "a",
        "loss",
        "function",
        "plus",
        "a",
        "regularizer",
        "."
      ]
    },
    {
      "sentence": "The loss function calculates the disparity between the prediction of a solution and the ground truth.",
      "tokens": [
        "The",
        "loss",
        "function",
        "calculates",
        "the",
        "disparity",
        "between",
        "the",
        "prediction",
        "of",
        "a",
        "solution",
        "and",
        "the",
        "ground",
        "truth",
        "."
      ]
    },
    {
      "sentence": "This term usually involves the training data set.",
      "tokens": [
        "This",
        "term",
        "usually",
        "involves",
        "the",
        "training",
        "data",
        "set",
        "."
      ]
    },
    {
      "sentence": "For example, the well known square loss is for the purpose of regression problems and hinge loss is for the purpose of maximum margin classification.",
      "tokens": [
        "For",
        "example",
        ",",
        "the",
        "well",
        "known",
        "square",
        "loss",
        "is",
        "for",
        "the",
        "purpose",
        "of",
        "regression",
        "problems",
        "and",
        "hinge",
        "loss",
        "is",
        "for",
        "the",
        "purpose",
        "of",
        "maximum",
        "margin",
        "classification",
        "."
      ]
    },
    {
      "sentence": "The regularizer usually uses a norm function.",
      "tokens": [
        "The",
        "regularizer",
        "usually",
        "uses",
        "a",
        "norm",
        "function",
        "."
      ]
    },
    {
      "sentence": "For example, group lasso is an extension of the lasso for feature selection.",
      "tokens": [
        "For",
        "example",
        ",",
        "group",
        "lasso",
        "is",
        "an",
        "extension",
        "of",
        "the",
        "lasso",
        "for",
        "feature",
        "selection",
        "."
      ]
    },
    {
      "sentence": "It can lead to a sparse solution within a group.",
      "tokens": [
        "It",
        "can",
        "lead",
        "to",
        "a",
        "sparse",
        "solution",
        "within",
        "a",
        "group",
        "."
      ]
    },
    {
      "sentence": "In general, we consider convex optimization problems of the following form minimize E(x) = F (x) + λG(x) such that x ∈ C where F and G are continuous, convex functions and C is a convex set.",
      "tokens": [
        "In",
        "general",
        ",",
        "we",
        "consider",
        "convex",
        "optimization",
        "problems",
        "of",
        "the",
        "following",
        "form",
        "minimize",
        "E",
        "(",
        "x",
        ")",
        "=",
        "F",
        "(",
        "x",
        ")",
        "+",
        "λG",
        "(",
        "x",
        ")",
        "such",
        "that",
        "x",
        "∈",
        "C",
        "where",
        "F",
        "and",
        "G",
        "are",
        "continuous",
        ",",
        "convex",
        "functions",
        "and",
        "C",
        "is",
        "a",
        "convex",
        "set",
        "."
      ]
    },
    {
      "sentence": "E denotes the energy of a machine learning problem.",
      "tokens": [
        "E",
        "denotes",
        "the",
        "energy",
        "of",
        "a",
        "machine",
        "learning",
        "problem",
        "."
      ]
    },
    {
      "sentence": "By convention, F usually denotes a loss function and G denotes a regularization term.",
      "tokens": [
        "By",
        "convention",
        ",",
        "F",
        "usually",
        "denotes",
        "a",
        "loss",
        "function",
        "and",
        "G",
        "denotes",
        "a",
        "regularization",
        "term",
        "."
      ]
    },
    {
      "sentence": "λ is a parameter controlling the tradeoff between a good generalization performance and overfitting.",
      "tokens": [
        "λ",
        "is",
        "a",
        "parameter",
        "controlling",
        "the",
        "tradeoff",
        "between",
        "a",
        "good",
        "generalization",
        "performance",
        "and",
        "overfitting",
        "."
      ]
    },
    {
      "sentence": "This kind of problems frequently arise in machine learning.",
      "tokens": [
        "This",
        "kind",
        "of",
        "problems",
        "frequently",
        "arise",
        "in",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "A substantial amount of literature assumes that either F or G is smooth and cannot be used to optimize the case where F and G are both non-smooth.",
      "tokens": [
        "A",
        "substantial",
        "amount",
        "of",
        "literature",
        "assumes",
        "that",
        "either",
        "F",
        "or",
        "G",
        "is",
        "smooth",
        "and",
        "can",
        "not",
        "be",
        "used",
        "to",
        "optimize",
        "the",
        "case",
        "where",
        "F",
        "and",
        "G",
        "are",
        "both",
        "non-smooth",
        "."
      ]
    },
    {
      "sentence": "Some solvers provide an upper bound N on the number of iterations n such that E n -E ≤ e, n ≥ N , where e is an error tolerance and E is the minimum of E. Sometimes this estimation is too pessimistic which means the resultant N is excessive large.",
      "tokens": [
        "Some",
        "solvers",
        "provide",
        "an",
        "upper",
        "bound",
        "N",
        "on",
        "the",
        "number",
        "of",
        "iterations",
        "n",
        "such",
        "that",
        "E",
        "n",
        "-E",
        "≤",
        "e",
        ",",
        "n",
        "≥",
        "N",
        ",",
        "where",
        "e",
        "is",
        "an",
        "error",
        "tolerance",
        "and",
        "E",
        "is",
        "the",
        "minimum",
        "of",
        "E.",
        "Sometimes",
        "this",
        "estimation",
        "is",
        "too",
        "pessimistic",
        "which",
        "means",
        "the",
        "resultant",
        "N",
        "is",
        "excessive",
        "large",
        "."
      ]
    },
    {
      "sentence": "In this case, it is hard to evaluate the performance of a solver by this upper bound.",
      "tokens": [
        "In",
        "this",
        "case",
        ",",
        "it",
        "is",
        "hard",
        "to",
        "evaluate",
        "the",
        "performance",
        "of",
        "a",
        "solver",
        "by",
        "this",
        "upper",
        "bound",
        "."
      ]
    },
    {
      "sentence": "On the other side, convergence rate describes the speed of converging when a solver approaches the optimal solution.",
      "tokens": [
        "On",
        "the",
        "other",
        "side",
        ",",
        "convergence",
        "rate",
        "describes",
        "the",
        "speed",
        "of",
        "converging",
        "when",
        "a",
        "solver",
        "approaches",
        "the",
        "optimal",
        "solution",
        "."
      ]
    },
    {
      "sentence": "But it is unpredictable to know when n is large enough.",
      "tokens": [
        "But",
        "it",
        "is",
        "unpredictable",
        "to",
        "know",
        "when",
        "n",
        "is",
        "large",
        "enough",
        "."
      ]
    },
    {
      "sentence": "Therefore, the performance of solvers is still difficult to tractable.",
      "tokens": [
        "Therefore",
        ",",
        "the",
        "performance",
        "of",
        "solvers",
        "is",
        "still",
        "difficult",
        "to",
        "tractable",
        "."
      ]
    },
    {
      "sentence": "In this paper, we compare four state-of-the-art first-order solvers (Fobos [5] , FISTA [1] , OSGA [7] and primal-dual algorithms [3] ) by the following properties: convergence rate, running time, theoretically known parameters, robustness in practice for machine learning problems.",
      "tokens": [
        "In",
        "this",
        "paper",
        ",",
        "we",
        "compare",
        "four",
        "state-of-the-art",
        "first-order",
        "solvers",
        "(",
        "Fobos",
        "[",
        "5",
        "]",
        ",",
        "FISTA",
        "[",
        "1",
        "]",
        ",",
        "OSGA",
        "[",
        "7",
        "]",
        "and",
        "primal-dual",
        "algorithms",
        "[",
        "3",
        "]",
        ")",
        "by",
        "the",
        "following",
        "properties",
        ":",
        "convergence",
        "rate",
        ",",
        "running",
        "time",
        ",",
        "theoretically",
        "known",
        "parameters",
        ",",
        "robustness",
        "in",
        "practice",
        "for",
        "machine",
        "learning",
        "problems",
        "."
      ]
    },
    {
      "sentence": "We present tasks within dimensionality reduction via compressive sensing, SVMs, group lasso regularizer for grouped feature selection, ℓ 1,∞ regularization for multi-task learning, trace norm regularization for max-margin matrix factorization.",
      "tokens": [
        "We",
        "present",
        "tasks",
        "within",
        "dimensionality",
        "reduction",
        "via",
        "compressive",
        "sensing",
        ",",
        "SVMs",
        ",",
        "group",
        "lasso",
        "regularizer",
        "for",
        "grouped",
        "feature",
        "selection",
        ",",
        "ℓ",
        "1",
        ",",
        "∞",
        "regularization",
        "for",
        "multi-task",
        "learning",
        ",",
        "trace",
        "norm",
        "regularization",
        "for",
        "max-margin",
        "matrix",
        "factorization",
        "."
      ]
    },
    {
      "sentence": "The last three machine learning problems are chosen from [10] .",
      "tokens": [
        "The",
        "last",
        "three",
        "machine",
        "learning",
        "problems",
        "are",
        "chosen",
        "from",
        "[",
        "10",
        "]",
        "."
      ]
    },
    {
      "sentence": "Unlike other literature which plots energy versus the number of iterations, in this paper we illustrate the results by log-log figures which clearly show the convergence rate in applications of machine learning.",
      "tokens": [
        "Unlike",
        "other",
        "literature",
        "which",
        "plots",
        "energy",
        "versus",
        "the",
        "number",
        "of",
        "iterations",
        ",",
        "in",
        "this",
        "paper",
        "we",
        "illustrate",
        "the",
        "results",
        "by",
        "log-log",
        "figures",
        "which",
        "clearly",
        "show",
        "the",
        "convergence",
        "rate",
        "in",
        "applications",
        "of",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "The paper is organized as follows.",
      "tokens": [
        "The",
        "paper",
        "is",
        "organized",
        "as",
        "follows",
        "."
      ]
    },
    {
      "sentence": "Section 2 introduces four solvers.",
      "tokens": [
        "Section",
        "2",
        "introduces",
        "four",
        "solvers",
        "."
      ]
    },
    {
      "sentence": "Then it summarizes primal-dual algorithm of Chambolle and Pock [3] and describes heuristic observations.",
      "tokens": [
        "Then",
        "it",
        "summarizes",
        "primal-dual",
        "algorithm",
        "of",
        "Chambolle",
        "and",
        "Pock",
        "[",
        "3",
        "]",
        "and",
        "describes",
        "heuristic",
        "observations",
        "."
      ]
    },
    {
      "sentence": "Section 3 gives an introduction about the general structure (a loss function plus a regularizer) of machine learning problems we focus on in this paper.",
      "tokens": [
        "Section",
        "3",
        "gives",
        "an",
        "introduction",
        "about",
        "the",
        "general",
        "structure",
        "(",
        "a",
        "loss",
        "function",
        "plus",
        "a",
        "regularizer",
        ")",
        "of",
        "machine",
        "learning",
        "problems",
        "we",
        "focus",
        "on",
        "in",
        "this",
        "paper",
        "."
      ]
    },
    {
      "sentence": "Section 4 demonstrates the performance of different solvers and the conclusion is presented at the end.",
      "tokens": [
        "Section",
        "4",
        "demonstrates",
        "the",
        "performance",
        "of",
        "different",
        "solvers",
        "and",
        "the",
        "conclusion",
        "is",
        "presented",
        "at",
        "the",
        "end",
        "."
      ]
    }
  ]
}