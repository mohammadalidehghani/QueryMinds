{
  "title": [
    {
      "sentence": "Automated Graph Machine Learning: Approaches, Libraries, Benchmarks and Directions",
      "tokens": [
        "Automated",
        "Graph",
        "Machine",
        "Learning",
        ":",
        "Approaches",
        ",",
        "Libraries",
        ",",
        "Benchmarks",
        "and",
        "Directions"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "Graph machine learning has been extensively studied in both academic and industry.",
      "tokens": [
        "Graph",
        "machine",
        "learning",
        "has",
        "been",
        "extensively",
        "studied",
        "in",
        "both",
        "academic",
        "and",
        "industry",
        "."
      ]
    },
    {
      "sentence": "However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difficult to manually design the optimal machine learning algorithm for different graph-related tasks.",
      "tokens": [
        "However",
        ",",
        "as",
        "the",
        "literature",
        "on",
        "graph",
        "learning",
        "booms",
        "with",
        "a",
        "vast",
        "number",
        "of",
        "emerging",
        "methods",
        "and",
        "techniques",
        ",",
        "it",
        "becomes",
        "increasingly",
        "difficult",
        "to",
        "manually",
        "design",
        "the",
        "optimal",
        "machine",
        "learning",
        "algorithm",
        "for",
        "different",
        "graph-related",
        "tasks",
        "."
      ]
    },
    {
      "sentence": "To tackle the challenge, automated graph machine learning, which aims at discovering the best hyper-parameter and neural architecture configuration for different graph tasks/data without manual design, is gaining an increasing number of attentions from the research community.",
      "tokens": [
        "To",
        "tackle",
        "the",
        "challenge",
        ",",
        "automated",
        "graph",
        "machine",
        "learning",
        ",",
        "which",
        "aims",
        "at",
        "discovering",
        "the",
        "best",
        "hyper-parameter",
        "and",
        "neural",
        "architecture",
        "configuration",
        "for",
        "different",
        "graph",
        "tasks/data",
        "without",
        "manual",
        "design",
        ",",
        "is",
        "gaining",
        "an",
        "increasing",
        "number",
        "of",
        "attentions",
        "from",
        "the",
        "research",
        "community",
        "."
      ]
    },
    {
      "sentence": "In this paper, we extensively discuss automated graph machine learning approaches, covering hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning.",
      "tokens": [
        "In",
        "this",
        "paper",
        ",",
        "we",
        "extensively",
        "discuss",
        "automated",
        "graph",
        "machine",
        "learning",
        "approaches",
        ",",
        "covering",
        "hyper-parameter",
        "optimization",
        "(",
        "HPO",
        ")",
        "and",
        "neural",
        "architecture",
        "search",
        "(",
        "NAS",
        ")",
        "for",
        "graph",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "We briefly overview existing libraries designed for either graph machine learning or automated machine learning respectively, and further in depth introduce AutoGL, our dedicated and the world's first open-source library for automated graph machine learning.",
      "tokens": [
        "We",
        "briefly",
        "overview",
        "existing",
        "libraries",
        "designed",
        "for",
        "either",
        "graph",
        "machine",
        "learning",
        "or",
        "automated",
        "machine",
        "learning",
        "respectively",
        ",",
        "and",
        "further",
        "in",
        "depth",
        "introduce",
        "AutoGL",
        ",",
        "our",
        "dedicated",
        "and",
        "the",
        "world",
        "'s",
        "first",
        "open-source",
        "library",
        "for",
        "automated",
        "graph",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "Also, we describe a tailored benchmark that supports unified, reproducible, and efficient evaluations.",
      "tokens": [
        "Also",
        ",",
        "we",
        "describe",
        "a",
        "tailored",
        "benchmark",
        "that",
        "supports",
        "unified",
        ",",
        "reproducible",
        ",",
        "and",
        "efficient",
        "evaluations",
        "."
      ]
    },
    {
      "sentence": "Last but not least, we share our insights on future research directions for automated graph machine learning.",
      "tokens": [
        "Last",
        "but",
        "not",
        "least",
        ",",
        "we",
        "share",
        "our",
        "insights",
        "on",
        "future",
        "research",
        "directions",
        "for",
        "automated",
        "graph",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "This paper is the first systematic and comprehensive discussion of approaches, libraries as well as directions for automated graph machine learning.",
      "tokens": [
        "This",
        "paper",
        "is",
        "the",
        "first",
        "systematic",
        "and",
        "comprehensive",
        "discussion",
        "of",
        "approaches",
        ",",
        "libraries",
        "as",
        "well",
        "as",
        "directions",
        "for",
        "automated",
        "graph",
        "machine",
        "learning",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "INTRODUCTION G RAPH data is ubiquitous in our daily life.",
      "tokens": [
        "INTRODUCTION",
        "G",
        "RAPH",
        "data",
        "is",
        "ubiquitous",
        "in",
        "our",
        "daily",
        "life",
        "."
      ]
    },
    {
      "sentence": "We can use graphs to model the complex relationships and dependencies between entities ranging from small molecules in proteins and particles in physical simulations to large national-wide power grids and global airlines.",
      "tokens": [
        "We",
        "can",
        "use",
        "graphs",
        "to",
        "model",
        "the",
        "complex",
        "relationships",
        "and",
        "dependencies",
        "between",
        "entities",
        "ranging",
        "from",
        "small",
        "molecules",
        "in",
        "proteins",
        "and",
        "particles",
        "in",
        "physical",
        "simulations",
        "to",
        "large",
        "national-wide",
        "power",
        "grids",
        "and",
        "global",
        "airlines",
        "."
      ]
    },
    {
      "sentence": "Therefore, graph machine learning, i.e., machine learning on graphs, has long been an important research direction for both academics and industry [1] .",
      "tokens": [
        "Therefore",
        ",",
        "graph",
        "machine",
        "learning",
        ",",
        "i.e.",
        ",",
        "machine",
        "learning",
        "on",
        "graphs",
        ",",
        "has",
        "long",
        "been",
        "an",
        "important",
        "research",
        "direction",
        "for",
        "both",
        "academics",
        "and",
        "industry",
        "[",
        "1",
        "]",
        "."
      ]
    },
    {
      "sentence": "In particular, network embedding [2] , [3] , [4] , [5] and graph neural networks (GNNs) [6] , [7] , [8] have drawn increasing attention in the last decade.",
      "tokens": [
        "In",
        "particular",
        ",",
        "network",
        "embedding",
        "[",
        "2",
        "]",
        ",",
        "[",
        "3",
        "]",
        ",",
        "[",
        "4",
        "]",
        ",",
        "[",
        "5",
        "]",
        "and",
        "graph",
        "neural",
        "networks",
        "(",
        "GNNs",
        ")",
        "[",
        "6",
        "]",
        ",",
        "[",
        "7",
        "]",
        ",",
        "[",
        "8",
        "]",
        "have",
        "drawn",
        "increasing",
        "attention",
        "in",
        "the",
        "last",
        "decade",
        "."
      ]
    },
    {
      "sentence": "They are successfully applied to recommendation systems [9] , [10] , [11] , [12] , information retrieval [13] , [14] , [15] , [16] , fraud detection [17] , bioinformatics [18] , [19] , physical simulation [20] , traffic forecasting [21] , [22] , knowledge representation [23] , drug re-purposing [24] , [25] and pandemic prediction [26] for Covid-19.",
      "tokens": [
        "They",
        "are",
        "successfully",
        "applied",
        "to",
        "recommendation",
        "systems",
        "[",
        "9",
        "]",
        ",",
        "[",
        "10",
        "]",
        ",",
        "[",
        "11",
        "]",
        ",",
        "[",
        "12",
        "]",
        ",",
        "information",
        "retrieval",
        "[",
        "13",
        "]",
        ",",
        "[",
        "14",
        "]",
        ",",
        "[",
        "15",
        "]",
        ",",
        "[",
        "16",
        "]",
        ",",
        "fraud",
        "detection",
        "[",
        "17",
        "]",
        ",",
        "bioinformatics",
        "[",
        "18",
        "]",
        ",",
        "[",
        "19",
        "]",
        ",",
        "physical",
        "simulation",
        "[",
        "20",
        "]",
        ",",
        "traffic",
        "forecasting",
        "[",
        "21",
        "]",
        ",",
        "[",
        "22",
        "]",
        ",",
        "knowledge",
        "representation",
        "[",
        "23",
        "]",
        ",",
        "drug",
        "re-purposing",
        "[",
        "24",
        "]",
        ",",
        "[",
        "25",
        "]",
        "and",
        "pandemic",
        "prediction",
        "[",
        "26",
        "]",
        "for",
        "Covid-19",
        "."
      ]
    },
    {
      "sentence": "Despite the popularity of graph machine learning algorithms, the existing literature heavily relies on manual hyper-parameter or architecture design to achieve the best performance, resulting in costly human efforts when a vast number of models emerge for various graph tasks.",
      "tokens": [
        "Despite",
        "the",
        "popularity",
        "of",
        "graph",
        "machine",
        "learning",
        "algorithms",
        ",",
        "the",
        "existing",
        "literature",
        "heavily",
        "relies",
        "on",
        "manual",
        "hyper-parameter",
        "or",
        "architecture",
        "design",
        "to",
        "achieve",
        "the",
        "best",
        "performance",
        ",",
        "resulting",
        "in",
        "costly",
        "human",
        "efforts",
        "when",
        "a",
        "vast",
        "number",
        "of",
        "models",
        "emerge",
        "for",
        "various",
        "graph",
        "tasks",
        "."
      ]
    },
    {
      "sentence": "Take GNNs as an example, at least one hundred new general-purpose architectures have been published in top-tier machine learning and data mining conferences in the year of 2021 alone, not to mention cross-disciplinary researches of task-specific designs.",
      "tokens": [
        "Take",
        "GNNs",
        "as",
        "an",
        "example",
        ",",
        "at",
        "least",
        "one",
        "hundred",
        "new",
        "general-purpose",
        "architectures",
        "have",
        "been",
        "published",
        "in",
        "top-tier",
        "machine",
        "learning",
        "and",
        "data",
        "mining",
        "conferences",
        "in",
        "the",
        "year",
        "of",
        "2021",
        "alone",
        ",",
        "not",
        "to",
        "mention",
        "cross-disciplinary",
        "researches",
        "of",
        "task-specific",
        "designs",
        "."
      ]
    },
    {
      "sentence": "More and more human efforts are inevitably needed if we stick to the manual try-and-error paradigm in designing the optimal algorithms for targeted tasks.",
      "tokens": [
        "More",
        "and",
        "more",
        "human",
        "efforts",
        "are",
        "inevitably",
        "needed",
        "if",
        "we",
        "stick",
        "to",
        "the",
        "manual",
        "try-and-error",
        "paradigm",
        "in",
        "designing",
        "the",
        "optimal",
        "algorithms",
        "for",
        "targeted",
        "tasks",
        "."
      ]
    },
    {
      "sentence": "On the other hand, automated machine learning (AutoML) has been extensively studied to reduce human efforts in developing and deploying machine learning models [27] , [28] .",
      "tokens": [
        "On",
        "the",
        "other",
        "hand",
        ",",
        "automated",
        "machine",
        "learning",
        "(",
        "AutoML",
        ")",
        "has",
        "been",
        "extensively",
        "studied",
        "to",
        "reduce",
        "human",
        "efforts",
        "in",
        "developing",
        "and",
        "deploying",
        "machine",
        "learning",
        "models",
        "[",
        "27",
        "]",
        ",",
        "[",
        "28",
        "]",
        "."
      ]
    },
    {
      "sentence": "Complete AutoML pipelines have the potential to automate every step of machine learning, including auto data collection and cleaning, auto feature engineering, and auto model selection and optimization, etc.",
      "tokens": [
        "Complete",
        "AutoML",
        "pipelines",
        "have",
        "the",
        "potential",
        "to",
        "automate",
        "every",
        "step",
        "of",
        "machine",
        "learning",
        ",",
        "including",
        "auto",
        "data",
        "collection",
        "and",
        "cleaning",
        ",",
        "auto",
        "feature",
        "engineering",
        ",",
        "and",
        "auto",
        "model",
        "selection",
        "and",
        "optimization",
        ",",
        "etc",
        "."
      ]
    },
    {
      "sentence": "Due to the popularity of deep learning models, hyperparameter optimization (HPO) [29] , [30] , [31] , [32] and neural architecture search (NAS) [33] , [34] are most widely studied.",
      "tokens": [
        "Due",
        "to",
        "the",
        "popularity",
        "of",
        "deep",
        "learning",
        "models",
        ",",
        "hyperparameter",
        "optimization",
        "(",
        "HPO",
        ")",
        "[",
        "29",
        "]",
        ",",
        "[",
        "30",
        "]",
        ",",
        "[",
        "31",
        "]",
        ",",
        "[",
        "32",
        "]",
        "and",
        "neural",
        "architecture",
        "search",
        "(",
        "NAS",
        ")",
        "[",
        "33",
        "]",
        ",",
        "[",
        "34",
        "]",
        "are",
        "most",
        "widely",
        "studied",
        "."
      ]
    },
    {
      "sentence": "AutoML has achieved or surpassed human-level performance [35] , [36] , [37] with little human guidance in areas such as computer vision [38] , [39] .",
      "tokens": [
        "AutoML",
        "has",
        "achieved",
        "or",
        "surpassed",
        "human-level",
        "performance",
        "[",
        "35",
        "]",
        ",",
        "[",
        "36",
        "]",
        ",",
        "[",
        "37",
        "]",
        "with",
        "little",
        "human",
        "guidance",
        "in",
        "areas",
        "such",
        "as",
        "computer",
        "vision",
        "[",
        "38",
        "]",
        ",",
        "[",
        "39",
        "]",
        "."
      ]
    },
    {
      "sentence": "Automated graph machine learning, combining advantages of AutoML and graph machine learning, naturally serves as a promising research direction to further boost the model performance, which has attracted an increasing number of interests from the community.",
      "tokens": [
        "Automated",
        "graph",
        "machine",
        "learning",
        ",",
        "combining",
        "advantages",
        "of",
        "AutoML",
        "and",
        "graph",
        "machine",
        "learning",
        ",",
        "naturally",
        "serves",
        "as",
        "a",
        "promising",
        "research",
        "direction",
        "to",
        "further",
        "boost",
        "the",
        "model",
        "performance",
        ",",
        "which",
        "has",
        "attracted",
        "an",
        "increasing",
        "number",
        "of",
        "interests",
        "from",
        "the",
        "community",
        "."
      ]
    },
    {
      "sentence": "In this paper, we provide a systematic overview of approaches for automated graph machine learning 1 , introduce related public libraries as well as our AutoGL, the world's first open-source library for automated graph machine learning, describe a tailored benchmark that supports unified, reproducible, and efficient evaluations, and share our insights on challenges and future research directions.",
      "tokens": [
        "In",
        "this",
        "paper",
        ",",
        "we",
        "provide",
        "a",
        "systematic",
        "overview",
        "of",
        "approaches",
        "for",
        "automated",
        "graph",
        "machine",
        "learning",
        "1",
        ",",
        "introduce",
        "related",
        "public",
        "libraries",
        "as",
        "well",
        "as",
        "our",
        "AutoGL",
        ",",
        "the",
        "world",
        "'s",
        "first",
        "open-source",
        "library",
        "for",
        "automated",
        "graph",
        "machine",
        "learning",
        ",",
        "describe",
        "a",
        "tailored",
        "benchmark",
        "that",
        "supports",
        "unified",
        ",",
        "reproducible",
        ",",
        "and",
        "efficient",
        "evaluations",
        ",",
        "and",
        "share",
        "our",
        "insights",
        "on",
        "challenges",
        "and",
        "future",
        "research",
        "directions",
        "."
      ]
    },
    {
      "sentence": "Particularly, we focus on two major topics: HPO and NAS of graph machine learning.",
      "tokens": [
        "Particularly",
        ",",
        "we",
        "focus",
        "on",
        "two",
        "major",
        "topics",
        ":",
        "HPO",
        "and",
        "NAS",
        "of",
        "graph",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "For HPO, we focus on how to de-velop scalable methods.",
      "tokens": [
        "For",
        "HPO",
        ",",
        "we",
        "focus",
        "on",
        "how",
        "to",
        "de-velop",
        "scalable",
        "methods",
        "."
      ]
    },
    {
      "sentence": "For NAS, we follow the literature and compare different methods from search spaces, search strategies, and performance estimation strategies.",
      "tokens": [
        "For",
        "NAS",
        ",",
        "we",
        "follow",
        "the",
        "literature",
        "and",
        "compare",
        "different",
        "methods",
        "from",
        "search",
        "spaces",
        ",",
        "search",
        "strategies",
        ",",
        "and",
        "performance",
        "estimation",
        "strategies",
        "."
      ]
    },
    {
      "sentence": "We also briefly discuss several recent automated graph learning works that feature in different aspects such as architecture pooling, structure learning, accelerator and joint software-hardware design etc.",
      "tokens": [
        "We",
        "also",
        "briefly",
        "discuss",
        "several",
        "recent",
        "automated",
        "graph",
        "learning",
        "works",
        "that",
        "feature",
        "in",
        "different",
        "aspects",
        "such",
        "as",
        "architecture",
        "pooling",
        ",",
        "structure",
        "learning",
        ",",
        "accelerator",
        "and",
        "joint",
        "software-hardware",
        "design",
        "etc",
        "."
      ]
    },
    {
      "sentence": "Besides, how different methods tackle the challenges of AutoML on graphs are discussed along the way as well.",
      "tokens": [
        "Besides",
        ",",
        "how",
        "different",
        "methods",
        "tackle",
        "the",
        "challenges",
        "of",
        "AutoML",
        "on",
        "graphs",
        "are",
        "discussed",
        "along",
        "the",
        "way",
        "as",
        "well",
        "."
      ]
    },
    {
      "sentence": "Then, we review libraries related to automated graph machine learning and discuss AutoGL, the first dedicated framework and open-source library for automated graph machine learning.",
      "tokens": [
        "Then",
        ",",
        "we",
        "review",
        "libraries",
        "related",
        "to",
        "automated",
        "graph",
        "machine",
        "learning",
        "and",
        "discuss",
        "AutoGL",
        ",",
        "the",
        "first",
        "dedicated",
        "framework",
        "and",
        "open-source",
        "library",
        "for",
        "automated",
        "graph",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "We highlight the design principles of AutoGL and briefly introduce its usages, which are all specially designed for AutoML on graphs.",
      "tokens": [
        "We",
        "highlight",
        "the",
        "design",
        "principles",
        "of",
        "AutoGL",
        "and",
        "briefly",
        "introduce",
        "its",
        "usages",
        ",",
        "which",
        "are",
        "all",
        "specially",
        "designed",
        "for",
        "AutoML",
        "on",
        "graphs",
        "."
      ]
    },
    {
      "sentence": "Last but not least, we point out the potential research directions for both graph HPO and graph NAS, including but not limited to Scalability, Explainability, Outof-distribution generalization, Robustness, and Hardware-aware design etc.",
      "tokens": [
        "Last",
        "but",
        "not",
        "least",
        ",",
        "we",
        "point",
        "out",
        "the",
        "potential",
        "research",
        "directions",
        "for",
        "both",
        "graph",
        "HPO",
        "and",
        "graph",
        "NAS",
        ",",
        "including",
        "but",
        "not",
        "limited",
        "to",
        "Scalability",
        ",",
        "Explainability",
        ",",
        "Outof-distribution",
        "generalization",
        ",",
        "Robustness",
        ",",
        "and",
        "Hardware-aware",
        "design",
        "etc",
        "."
      ]
    },
    {
      "sentence": "We believe this paper will greatly facilitate and further promote the studies and applications of automated graph machine learning in both academia and industry.",
      "tokens": [
        "We",
        "believe",
        "this",
        "paper",
        "will",
        "greatly",
        "facilitate",
        "and",
        "further",
        "promote",
        "the",
        "studies",
        "and",
        "applications",
        "of",
        "automated",
        "graph",
        "machine",
        "learning",
        "in",
        "both",
        "academia",
        "and",
        "industry",
        "."
      ]
    },
    {
      "sentence": "The rest of the paper is organized as follows.",
      "tokens": [
        "The",
        "rest",
        "of",
        "the",
        "paper",
        "is",
        "organized",
        "as",
        "follows",
        "."
      ]
    },
    {
      "sentence": "In Section 2, we intoduce the fundamentals and preliminaries for automated graph machine learning by briefly introducing basic formulations of graph machine learning and AutoML.",
      "tokens": [
        "In",
        "Section",
        "2",
        ",",
        "we",
        "intoduce",
        "the",
        "fundamentals",
        "and",
        "preliminaries",
        "for",
        "automated",
        "graph",
        "machine",
        "learning",
        "by",
        "briefly",
        "introducing",
        "basic",
        "formulations",
        "of",
        "graph",
        "machine",
        "learning",
        "and",
        "AutoML",
        "."
      ]
    },
    {
      "sentence": "We comprehensively discuss HPO based approaches on graph machine learning in Section 3 and NAS based methods for graph machine learning in Section 4.",
      "tokens": [
        "We",
        "comprehensively",
        "discuss",
        "HPO",
        "based",
        "approaches",
        "on",
        "graph",
        "machine",
        "learning",
        "in",
        "Section",
        "3",
        "and",
        "NAS",
        "based",
        "methods",
        "for",
        "graph",
        "machine",
        "learning",
        "in",
        "Section",
        "4",
        "."
      ]
    },
    {
      "sentence": "Then, in Section 5.1, we overview related libraries for graph machine learning and automated machine learning and in depth introduce AutoGL, our dedicated and the world's first open-source library tailored for automated graph machine learning.",
      "tokens": [
        "Then",
        ",",
        "in",
        "Section",
        "5.1",
        ",",
        "we",
        "overview",
        "related",
        "libraries",
        "for",
        "graph",
        "machine",
        "learning",
        "and",
        "automated",
        "machine",
        "learning",
        "and",
        "in",
        "depth",
        "introduce",
        "AutoGL",
        ",",
        "our",
        "dedicated",
        "and",
        "the",
        "world",
        "'s",
        "first",
        "open-source",
        "library",
        "tailored",
        "for",
        "automated",
        "graph",
        "machine",
        "learning",
        "."
      ]
    },
    {
      "sentence": "We discuss the tailored benchmark that enables fair, fully reproducible, and efficient empirical comparisons in Section 6.",
      "tokens": [
        "We",
        "discuss",
        "the",
        "tailored",
        "benchmark",
        "that",
        "enables",
        "fair",
        ",",
        "fully",
        "reproducible",
        ",",
        "and",
        "efficient",
        "empirical",
        "comparisons",
        "in",
        "Section",
        "6",
        "."
      ]
    },
    {
      "sentence": "Last but not least, we outline future research opportunities in Section 7 and conclude the whole paper in Section 8.",
      "tokens": [
        "Last",
        "but",
        "not",
        "least",
        ",",
        "we",
        "outline",
        "future",
        "research",
        "opportunities",
        "in",
        "Section",
        "7",
        "and",
        "conclude",
        "the",
        "whole",
        "paper",
        "in",
        "Section",
        "8",
        "."
      ]
    }
  ]
}