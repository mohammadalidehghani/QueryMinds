{
  "title": [
    {
      "sentence": "Optimizing for Generalization in Machine Learning with Cross-Validation Gradients",
      "tokens": [
        "Optimizing",
        "for",
        "Generalization",
        "in",
        "Machine",
        "Learning",
        "with",
        "Cross-Validation",
        "Gradients"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "Cross-validation is the workhorse of modern applied statistics and machine learning, as it provides a principled framework for selecting the model that maximizes generalization performance.",
      "tokens": [
        "Cross-validation",
        "is",
        "the",
        "workhorse",
        "of",
        "modern",
        "applied",
        "statistics",
        "and",
        "machine",
        "learning",
        ",",
        "as",
        "it",
        "provides",
        "a",
        "principled",
        "framework",
        "for",
        "selecting",
        "the",
        "model",
        "that",
        "maximizes",
        "generalization",
        "performance",
        "."
      ]
    },
    {
      "sentence": "In this paper, we show that the cross-validation risk is differentiable with respect to the hyperparameters and training data for many common machine learning algorithms, including logistic regression, elastic-net regression, and support vector machines.",
      "tokens": [
        "In",
        "this",
        "paper",
        ",",
        "we",
        "show",
        "that",
        "the",
        "cross-validation",
        "risk",
        "is",
        "differentiable",
        "with",
        "respect",
        "to",
        "the",
        "hyperparameters",
        "and",
        "training",
        "data",
        "for",
        "many",
        "common",
        "machine",
        "learning",
        "algorithms",
        ",",
        "including",
        "logistic",
        "regression",
        ",",
        "elastic-net",
        "regression",
        ",",
        "and",
        "support",
        "vector",
        "machines",
        "."
      ]
    },
    {
      "sentence": "Leveraging this property of differentiability, we propose a cross-validation gradient method (CVGM) for hyperparameter optimization.",
      "tokens": [
        "Leveraging",
        "this",
        "property",
        "of",
        "differentiability",
        ",",
        "we",
        "propose",
        "a",
        "cross-validation",
        "gradient",
        "method",
        "(",
        "CVGM",
        ")",
        "for",
        "hyperparameter",
        "optimization",
        "."
      ]
    },
    {
      "sentence": "Our method enables efficient optimization in high-dimensional hyperparameter spaces of the cross-validation risk, the best surrogate of the true generalization ability of our learning algorithm.",
      "tokens": [
        "Our",
        "method",
        "enables",
        "efficient",
        "optimization",
        "in",
        "high-dimensional",
        "hyperparameter",
        "spaces",
        "of",
        "the",
        "cross-validation",
        "risk",
        ",",
        "the",
        "best",
        "surrogate",
        "of",
        "the",
        "true",
        "generalization",
        "ability",
        "of",
        "our",
        "learning",
        "algorithm",
        "."
      ]
    },
    {
      "sentence": "1 Nonparametric learning algorithms exist, e.g., k-nearest neighbor, but are challenging to analyze with our method.",
      "tokens": [
        "1",
        "Nonparametric",
        "learning",
        "algorithms",
        "exist",
        ",",
        "e.g.",
        ",",
        "k-nearest",
        "neighbor",
        ",",
        "but",
        "are",
        "challenging",
        "to",
        "analyze",
        "with",
        "our",
        "method",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "Introduction The ultimate aim of a supervised learning method is generalization, that is, achieving good prediction ability on unseen test data given only a finite set of training data.",
      "tokens": [
        "Introduction",
        "The",
        "ultimate",
        "aim",
        "of",
        "a",
        "supervised",
        "learning",
        "method",
        "is",
        "generalization",
        ",",
        "that",
        "is",
        ",",
        "achieving",
        "good",
        "prediction",
        "ability",
        "on",
        "unseen",
        "test",
        "data",
        "given",
        "only",
        "a",
        "finite",
        "set",
        "of",
        "training",
        "data",
        "."
      ]
    },
    {
      "sentence": "The generalization capability of learning algorithms should be the primary criterion for model selection, yet an algorithm's generalization capability is a somewhat elusive quantity that is challenging to optimize for.",
      "tokens": [
        "The",
        "generalization",
        "capability",
        "of",
        "learning",
        "algorithms",
        "should",
        "be",
        "the",
        "primary",
        "criterion",
        "for",
        "model",
        "selection",
        ",",
        "yet",
        "an",
        "algorithm",
        "'s",
        "generalization",
        "capability",
        "is",
        "a",
        "somewhat",
        "elusive",
        "quantity",
        "that",
        "is",
        "challenging",
        "to",
        "optimize",
        "for",
        "."
      ]
    },
    {
      "sentence": "In this paper we introduce a method to optimize directly for the closest available proxy to generalization performance: cross-validation loss.",
      "tokens": [
        "In",
        "this",
        "paper",
        "we",
        "introduce",
        "a",
        "method",
        "to",
        "optimize",
        "directly",
        "for",
        "the",
        "closest",
        "available",
        "proxy",
        "to",
        "generalization",
        "performance",
        ":",
        "cross-validation",
        "loss",
        "."
      ]
    },
    {
      "sentence": "We begin with a formal description of the overall goal in predictive learning, which also serves as an introduction to notation used throughout the paper.",
      "tokens": [
        "We",
        "begin",
        "with",
        "a",
        "formal",
        "description",
        "of",
        "the",
        "overall",
        "goal",
        "in",
        "predictive",
        "learning",
        ",",
        "which",
        "also",
        "serves",
        "as",
        "an",
        "introduction",
        "to",
        "notation",
        "used",
        "throughout",
        "the",
        "paper",
        "."
      ]
    },
    {
      "sentence": "The task of predictive learning involves deriving a prediction function from a finite set of training data.",
      "tokens": [
        "The",
        "task",
        "of",
        "predictive",
        "learning",
        "involves",
        "deriving",
        "a",
        "prediction",
        "function",
        "from",
        "a",
        "finite",
        "set",
        "of",
        "training",
        "data",
        "."
      ]
    },
    {
      "sentence": "More formally, suppose that (x, y) ∈ X × Y have some joint probability distribution.",
      "tokens": [
        "More",
        "formally",
        ",",
        "suppose",
        "that",
        "(",
        "x",
        ",",
        "y",
        ")",
        "∈",
        "X",
        "×",
        "Y",
        "have",
        "some",
        "joint",
        "probability",
        "distribution",
        "."
      ]
    },
    {
      "sentence": "We have access to a finite dataset of N training examples z i ∈ Z = X × Y drawn i.i.d.",
      "tokens": [
        "We",
        "have",
        "access",
        "to",
        "a",
        "finite",
        "dataset",
        "of",
        "N",
        "training",
        "examples",
        "z",
        "i",
        "∈",
        "Z",
        "=",
        "X",
        "×",
        "Y",
        "drawn",
        "i.i.d",
        "."
      ]
    },
    {
      "sentence": "from the joint distribution, denoted S = {z 1 , z 2 , .",
      "tokens": [
        "from",
        "the",
        "joint",
        "distribution",
        ",",
        "denoted",
        "S",
        "=",
        "{",
        "z",
        "1",
        ",",
        "z",
        "2",
        ",",
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ", z N }.",
      "tokens": [
        ",",
        "z",
        "N",
        "}",
        "."
      ]
    },
    {
      "sentence": "We are given (or specify ourselves) a cost function c(ŷ, y) : Y × Y → R + that quantifies the displeasure incurred when ŷ is predicted instead of y. Denoting the function space from input to outputs as F = Y X , we define the loss of a function on a training example z = (x, y) as l(f, z) = c(f (x), y).",
      "tokens": [
        "We",
        "are",
        "given",
        "(",
        "or",
        "specify",
        "ourselves",
        ")",
        "a",
        "cost",
        "function",
        "c",
        "(",
        "ŷ",
        ",",
        "y",
        ")",
        ":",
        "Y",
        "×",
        "Y",
        "→",
        "R",
        "+",
        "that",
        "quantifies",
        "the",
        "displeasure",
        "incurred",
        "when",
        "ŷ",
        "is",
        "predicted",
        "instead",
        "of",
        "y.",
        "Denoting",
        "the",
        "function",
        "space",
        "from",
        "input",
        "to",
        "outputs",
        "as",
        "F",
        "=",
        "Y",
        "X",
        ",",
        "we",
        "define",
        "the",
        "loss",
        "of",
        "a",
        "function",
        "on",
        "a",
        "training",
        "example",
        "z",
        "=",
        "(",
        "x",
        ",",
        "y",
        ")",
        "as",
        "l",
        "(",
        "f",
        ",",
        "z",
        ")",
        "=",
        "c",
        "(",
        "f",
        "(",
        "x",
        ")",
        ",",
        "y",
        ")",
        "."
      ]
    },
    {
      "sentence": "Then, given a prediction function f ∈ F, we define the population risk as E z [l(f, z)], and the target function f * ∈ F as the function that minimizes the population risk.",
      "tokens": [
        "Then",
        ",",
        "given",
        "a",
        "prediction",
        "function",
        "f",
        "∈",
        "F",
        ",",
        "we",
        "define",
        "the",
        "population",
        "risk",
        "as",
        "E",
        "z",
        "[",
        "l",
        "(",
        "f",
        ",",
        "z",
        ")",
        "]",
        ",",
        "and",
        "the",
        "target",
        "function",
        "f",
        "*",
        "∈",
        "F",
        "as",
        "the",
        "function",
        "that",
        "minimizes",
        "the",
        "population",
        "risk",
        "."
      ]
    },
    {
      "sentence": "The population risk represents how much loss we incur, on average, on the full joint distribution, and is the quantity we would like as small as possible.",
      "tokens": [
        "The",
        "population",
        "risk",
        "represents",
        "how",
        "much",
        "loss",
        "we",
        "incur",
        ",",
        "on",
        "average",
        ",",
        "on",
        "the",
        "full",
        "joint",
        "distribution",
        ",",
        "and",
        "is",
        "the",
        "quantity",
        "we",
        "would",
        "like",
        "as",
        "small",
        "as",
        "possible",
        "."
      ]
    },
    {
      "sentence": "In this paper, we consider parametric prediction functions, that is, f is parameterized by a vector θ, denoted f (x; θ) 1 .",
      "tokens": [
        "In",
        "this",
        "paper",
        ",",
        "we",
        "consider",
        "parametric",
        "prediction",
        "functions",
        ",",
        "that",
        "is",
        ",",
        "f",
        "is",
        "parameterized",
        "by",
        "a",
        "vector",
        "θ",
        ",",
        "denoted",
        "f",
        "(",
        "x",
        ";",
        "θ",
        ")",
        "1",
        "."
      ]
    },
    {
      "sentence": "For example, in linear regression, X = R n , Y = R, c(ŷ, y) = (ŷ -y) 2 , and F is the set of all affine functions parameterized as f (x; θ) = θ T x + θ 0 .",
      "tokens": [
        "For",
        "example",
        ",",
        "in",
        "linear",
        "regression",
        ",",
        "X",
        "=",
        "R",
        "n",
        ",",
        "Y",
        "=",
        "R",
        ",",
        "c",
        "(",
        "ŷ",
        ",",
        "y",
        ")",
        "=",
        "(",
        "ŷ",
        "-y",
        ")",
        "2",
        ",",
        "and",
        "F",
        "is",
        "the",
        "set",
        "of",
        "all",
        "affine",
        "functions",
        "parameterized",
        "as",
        "f",
        "(",
        "x",
        ";",
        "θ",
        ")",
        "=",
        "θ",
        "T",
        "x",
        "+",
        "θ",
        "0",
        "."
      ]
    },
    {
      "sentence": "We are then tasked with designing a learning algorithm A : Z N → F, which is a function that maps a dataset S to a prediction function.",
      "tokens": [
        "We",
        "are",
        "then",
        "tasked",
        "with",
        "designing",
        "a",
        "learning",
        "algorithm",
        "A",
        ":",
        "Z",
        "N",
        "→",
        "F",
        ",",
        "which",
        "is",
        "a",
        "function",
        "that",
        "maps",
        "a",
        "dataset",
        "S",
        "to",
        "a",
        "prediction",
        "function",
        "."
      ]
    },
    {
      "sentence": "Without substantial knowledge of the actual joint distribution, or assumptions about the target function f * , it is extremely unlikely that A will ever reproduce the exact target function.",
      "tokens": [
        "Without",
        "substantial",
        "knowledge",
        "of",
        "the",
        "actual",
        "joint",
        "distribution",
        ",",
        "or",
        "assumptions",
        "about",
        "the",
        "target",
        "function",
        "f",
        "*",
        ",",
        "it",
        "is",
        "extremely",
        "unlikely",
        "that",
        "A",
        "will",
        "ever",
        "reproduce",
        "the",
        "exact",
        "target",
        "function",
        "."
      ]
    },
    {
      "sentence": "However, our goal is to minimize the population risk of the learning algorithm R(A, S) = E z [l(A(S), z)] (1) which is a random variable that depends on S, our dataset.",
      "tokens": [
        "However",
        ",",
        "our",
        "goal",
        "is",
        "to",
        "minimize",
        "the",
        "population",
        "risk",
        "of",
        "the",
        "learning",
        "algorithm",
        "R",
        "(",
        "A",
        ",",
        "S",
        ")",
        "=",
        "E",
        "z",
        "[",
        "l",
        "(",
        "A",
        "(",
        "S",
        ")",
        ",",
        "z",
        ")",
        "]",
        "(",
        "1",
        ")",
        "which",
        "is",
        "a",
        "random",
        "variable",
        "that",
        "depends",
        "on",
        "S",
        ",",
        "our",
        "dataset",
        "."
      ]
    },
    {
      "sentence": "To make this problem of searching for learning algorithms tractable, we similarly parameterize our learning algorithm A by a vector α ∈ R d , denoted A α .",
      "tokens": [
        "To",
        "make",
        "this",
        "problem",
        "of",
        "searching",
        "for",
        "learning",
        "algorithms",
        "tractable",
        ",",
        "we",
        "similarly",
        "parameterize",
        "our",
        "learning",
        "algorithm",
        "A",
        "by",
        "a",
        "vector",
        "α",
        "∈",
        "R",
        "d",
        ",",
        "denoted",
        "A",
        "α",
        "."
      ]
    },
    {
      "sentence": "These are known as the \"hyperparameters\" or \"meta-parameters\" of the learning algorithm, and can play many important roles: they can perform regularization, enforce sparsity, or even guide feature selection [1] .",
      "tokens": [
        "These",
        "are",
        "known",
        "as",
        "the",
        "``",
        "hyperparameters",
        "''",
        "or",
        "``",
        "meta-parameters",
        "''",
        "of",
        "the",
        "learning",
        "algorithm",
        ",",
        "and",
        "can",
        "play",
        "many",
        "important",
        "roles",
        ":",
        "they",
        "can",
        "perform",
        "regularization",
        ",",
        "enforce",
        "sparsity",
        ",",
        "or",
        "even",
        "guide",
        "feature",
        "selection",
        "[",
        "1",
        "]",
        "."
      ]
    },
    {
      "sentence": "The quantity we would then like to optimize is the expected population risk, or L(α) = E S [R(A α , S)] .",
      "tokens": [
        "The",
        "quantity",
        "we",
        "would",
        "then",
        "like",
        "to",
        "optimize",
        "is",
        "the",
        "expected",
        "population",
        "risk",
        ",",
        "or",
        "L",
        "(",
        "α",
        ")",
        "=",
        "E",
        "S",
        "[",
        "R",
        "(",
        "A",
        "α",
        ",",
        "S",
        ")",
        "]",
        "."
      ]
    },
    {
      "sentence": "(2) It is impossible to exactly calculate (2) with a finite dataset S, as there are two expectations that both involve an unknown probability distribution.",
      "tokens": [
        "(",
        "2",
        ")",
        "It",
        "is",
        "impossible",
        "to",
        "exactly",
        "calculate",
        "(",
        "2",
        ")",
        "with",
        "a",
        "finite",
        "dataset",
        "S",
        ",",
        "as",
        "there",
        "are",
        "two",
        "expectations",
        "that",
        "both",
        "involve",
        "an",
        "unknown",
        "probability",
        "distribution",
        "."
      ]
    },
    {
      "sentence": "What we can do is construct a Monte Carlo estimate of the an algorithm's expected population risk using a technique known as cross-validation.",
      "tokens": [
        "What",
        "we",
        "can",
        "do",
        "is",
        "construct",
        "a",
        "Monte",
        "Carlo",
        "estimate",
        "of",
        "the",
        "an",
        "algorithm",
        "'s",
        "expected",
        "population",
        "risk",
        "using",
        "a",
        "technique",
        "known",
        "as",
        "cross-validation",
        "."
      ]
    },
    {
      "sentence": "We first partition S into K partitions T j , V j , j = 1, .",
      "tokens": [
        "We",
        "first",
        "partition",
        "S",
        "into",
        "K",
        "partitions",
        "T",
        "j",
        ",",
        "V",
        "j",
        ",",
        "j",
        "=",
        "1",
        ",",
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ", K (that is, T j ∩ V j = ∅ and T j ∪ V j = [n]).",
      "tokens": [
        ",",
        "K",
        "(",
        "that",
        "is",
        ",",
        "T",
        "j",
        "∩",
        "V",
        "j",
        "=",
        "∅",
        "and",
        "T",
        "j",
        "∪",
        "V",
        "j",
        "=",
        "[",
        "n",
        "]",
        ")",
        "."
      ]
    },
    {
      "sentence": "Then our cross-validation risk, as a function of α, is L cv (α) = 1 K K j=1 1 |V j | i∈Vj l(A α (T j ), z i ) (3) and is readily calculated.",
      "tokens": [
        "Then",
        "our",
        "cross-validation",
        "risk",
        ",",
        "as",
        "a",
        "function",
        "of",
        "α",
        ",",
        "is",
        "L",
        "cv",
        "(",
        "α",
        ")",
        "=",
        "1",
        "K",
        "K",
        "j=1",
        "1",
        "|V",
        "j",
        "|",
        "i∈Vj",
        "l",
        "(",
        "A",
        "α",
        "(",
        "T",
        "j",
        ")",
        ",",
        "z",
        "i",
        ")",
        "(",
        "3",
        ")",
        "and",
        "is",
        "readily",
        "calculated",
        "."
      ]
    },
    {
      "sentence": "We first apply the algorithm to each training set and then average the loss on each corresponding validation set.",
      "tokens": [
        "We",
        "first",
        "apply",
        "the",
        "algorithm",
        "to",
        "each",
        "training",
        "set",
        "and",
        "then",
        "average",
        "the",
        "loss",
        "on",
        "each",
        "corresponding",
        "validation",
        "set",
        "."
      ]
    },
    {
      "sentence": "The first sum in (3) corresponds to the expectation in (2) , and the second sum corresponds to the expectation in (1) .",
      "tokens": [
        "The",
        "first",
        "sum",
        "in",
        "(",
        "3",
        ")",
        "corresponds",
        "to",
        "the",
        "expectation",
        "in",
        "(",
        "2",
        ")",
        ",",
        "and",
        "the",
        "second",
        "sum",
        "corresponds",
        "to",
        "the",
        "expectation",
        "in",
        "(",
        "1",
        ")",
        "."
      ]
    },
    {
      "sentence": "Setting K = 1 reduces to simple out-of-sample validation and an arbitrary K reduces to the common K-fold cross-validation estimate (provided T j form a partition of {1, .",
      "tokens": [
        "Setting",
        "K",
        "=",
        "1",
        "reduces",
        "to",
        "simple",
        "out-of-sample",
        "validation",
        "and",
        "an",
        "arbitrary",
        "K",
        "reduces",
        "to",
        "the",
        "common",
        "K-fold",
        "cross-validation",
        "estimate",
        "(",
        "provided",
        "T",
        "j",
        "form",
        "a",
        "partition",
        "of",
        "{",
        "1",
        ",",
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ", N } and |T j | = N -N K ).",
      "tokens": [
        ",",
        "N",
        "}",
        "and",
        "|T",
        "j",
        "|",
        "=",
        "N",
        "-N",
        "K",
        ")",
        "."
      ]
    },
    {
      "sentence": "Thus, this formulation can be viewed as a generalization of cross-validation.",
      "tokens": [
        "Thus",
        ",",
        "this",
        "formulation",
        "can",
        "be",
        "viewed",
        "as",
        "a",
        "generalization",
        "of",
        "cross-validation",
        "."
      ]
    },
    {
      "sentence": "(See [2] for a longer discussion about this general framework.)",
      "tokens": [
        "(",
        "See",
        "[",
        "2",
        "]",
        "for",
        "a",
        "longer",
        "discussion",
        "about",
        "this",
        "general",
        "framework",
        ".",
        ")"
      ]
    },
    {
      "sentence": "In cases where the class of models to be used for learning are known, we have reduced the predictive learning problem to the problem of selecting of a hyperparameter vector α to minimize the cross-validation loss.",
      "tokens": [
        "In",
        "cases",
        "where",
        "the",
        "class",
        "of",
        "models",
        "to",
        "be",
        "used",
        "for",
        "learning",
        "are",
        "known",
        ",",
        "we",
        "have",
        "reduced",
        "the",
        "predictive",
        "learning",
        "problem",
        "to",
        "the",
        "problem",
        "of",
        "selecting",
        "of",
        "a",
        "hyperparameter",
        "vector",
        "α",
        "to",
        "minimize",
        "the",
        "cross-validation",
        "loss",
        "."
      ]
    },
    {
      "sentence": "Even in the simplest cases, however, the objective in (3) is nonconvex in α, and in many cases not even continuous (e.g., the 0 -1 classification loss), which can make optimization of this quantity tricky.",
      "tokens": [
        "Even",
        "in",
        "the",
        "simplest",
        "cases",
        ",",
        "however",
        ",",
        "the",
        "objective",
        "in",
        "(",
        "3",
        ")",
        "is",
        "nonconvex",
        "in",
        "α",
        ",",
        "and",
        "in",
        "many",
        "cases",
        "not",
        "even",
        "continuous",
        "(",
        "e.g.",
        ",",
        "the",
        "0",
        "-1",
        "classification",
        "loss",
        ")",
        ",",
        "which",
        "can",
        "make",
        "optimization",
        "of",
        "this",
        "quantity",
        "tricky",
        "."
      ]
    }
  ]
}