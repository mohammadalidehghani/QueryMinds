{
  "title": [
    {
      "sentence": "Mathematical Perspective of Machine Learning",
      "tokens": [
        "Mathematical",
        "Perspective",
        "of",
        "Machine",
        "Learning"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "We take a closer look at some theoretical challenges of Machine Learning as a function approximation, gradient descent as the default optimization algorithm, limitations of fixed length and width networks and a different approach to RNNs from a mathematical perspective.",
      "tokens": [
        "We",
        "take",
        "a",
        "closer",
        "look",
        "at",
        "some",
        "theoretical",
        "challenges",
        "of",
        "Machine",
        "Learning",
        "as",
        "a",
        "function",
        "approximation",
        ",",
        "gradient",
        "descent",
        "as",
        "the",
        "default",
        "optimization",
        "algorithm",
        ",",
        "limitations",
        "of",
        "fixed",
        "length",
        "and",
        "width",
        "networks",
        "and",
        "a",
        "different",
        "approach",
        "to",
        "RNNs",
        "from",
        "a",
        "mathematical",
        "perspective",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "Introduction In the nutshell the idea of training a neural network (NN) is equivalent to the problem approximation of a given function, f, with the domain, D, and codomain, C, f : D → C (1) which depends on some data of size N ∈ N of k-dimensional input vectors, x j ∈ D ⊆ R k and l-dimensional output (label) vectors, y j ∈ C ⊆ R l , by a composition of functions of the form P i ( z i-1 • w i ) = (P i ( z i-1 • w i ) , ... , P i ( z i-1 • w i )) , (2) where P i is called an activation function of layer i, z i-1 is an output vector of the layer i -1, and w i is called the weight vector of layer i.",
      "tokens": [
        "Introduction",
        "In",
        "the",
        "nutshell",
        "the",
        "idea",
        "of",
        "training",
        "a",
        "neural",
        "network",
        "(",
        "NN",
        ")",
        "is",
        "equivalent",
        "to",
        "the",
        "problem",
        "approximation",
        "of",
        "a",
        "given",
        "function",
        ",",
        "f",
        ",",
        "with",
        "the",
        "domain",
        ",",
        "D",
        ",",
        "and",
        "codomain",
        ",",
        "C",
        ",",
        "f",
        ":",
        "D",
        "→",
        "C",
        "(",
        "1",
        ")",
        "which",
        "depends",
        "on",
        "some",
        "data",
        "of",
        "size",
        "N",
        "∈",
        "N",
        "of",
        "k-dimensional",
        "input",
        "vectors",
        ",",
        "x",
        "j",
        "∈",
        "D",
        "⊆",
        "R",
        "k",
        "and",
        "l-dimensional",
        "output",
        "(",
        "label",
        ")",
        "vectors",
        ",",
        "y",
        "j",
        "∈",
        "C",
        "⊆",
        "R",
        "l",
        ",",
        "by",
        "a",
        "composition",
        "of",
        "functions",
        "of",
        "the",
        "form",
        "P",
        "i",
        "(",
        "z",
        "i-1",
        "•",
        "w",
        "i",
        ")",
        "=",
        "(",
        "P",
        "i",
        "(",
        "z",
        "i-1",
        "•",
        "w",
        "i",
        ")",
        ",",
        "...",
        ",",
        "P",
        "i",
        "(",
        "z",
        "i-1",
        "•",
        "w",
        "i",
        ")",
        ")",
        ",",
        "(",
        "2",
        ")",
        "where",
        "P",
        "i",
        "is",
        "called",
        "an",
        "activation",
        "function",
        "of",
        "layer",
        "i",
        ",",
        "z",
        "i-1",
        "is",
        "an",
        "output",
        "vector",
        "of",
        "the",
        "layer",
        "i",
        "-1",
        ",",
        "and",
        "w",
        "i",
        "is",
        "called",
        "the",
        "weight",
        "vector",
        "of",
        "layer",
        "i",
        "."
      ]
    },
    {
      "sentence": "Once the size of each layer and the choice of each activation function is made, one usually uses, so called, back propagation algorithm, adjusting the values of each weight vector according to some type of gradient descent rule.",
      "tokens": [
        "Once",
        "the",
        "size",
        "of",
        "each",
        "layer",
        "and",
        "the",
        "choice",
        "of",
        "each",
        "activation",
        "function",
        "is",
        "made",
        ",",
        "one",
        "usually",
        "uses",
        ",",
        "so",
        "called",
        ",",
        "back",
        "propagation",
        "algorithm",
        ",",
        "adjusting",
        "the",
        "values",
        "of",
        "each",
        "weight",
        "vector",
        "according",
        "to",
        "some",
        "type",
        "of",
        "gradient",
        "descent",
        "rule",
        "."
      ]
    },
    {
      "sentence": "In other words, one is trying to solve an optimization problem, minimizing the \"difference norm\" C := f -f d , where f = P r P r-1 (.",
      "tokens": [
        "In",
        "other",
        "words",
        ",",
        "one",
        "is",
        "trying",
        "to",
        "solve",
        "an",
        "optimization",
        "problem",
        ",",
        "minimizing",
        "the",
        "``",
        "difference",
        "norm",
        "''",
        "C",
        ":",
        "=",
        "f",
        "-f",
        "d",
        ",",
        "where",
        "f",
        "=",
        "P",
        "r",
        "P",
        "r-1",
        "(",
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": "P 1 ) (3) and r ∈ N is the number of layers of the neural network.",
      "tokens": [
        "P",
        "1",
        ")",
        "(",
        "3",
        ")",
        "and",
        "r",
        "∈",
        "N",
        "is",
        "the",
        "number",
        "of",
        "layers",
        "of",
        "the",
        "neural",
        "network",
        "."
      ]
    },
    {
      "sentence": "So apriori, we are making a choice of the function f of weights w 1 , .",
      "tokens": [
        "So",
        "apriori",
        ",",
        "we",
        "are",
        "making",
        "a",
        "choice",
        "of",
        "the",
        "function",
        "f",
        "of",
        "weights",
        "w",
        "1",
        ",",
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ", w r .",
      "tokens": [
        ",",
        "w",
        "r",
        "."
      ]
    },
    {
      "sentence": "Note that the dimension of each vector w i is the size of the layer i.",
      "tokens": [
        "Note",
        "that",
        "the",
        "dimension",
        "of",
        "each",
        "vector",
        "w",
        "i",
        "is",
        "the",
        "size",
        "of",
        "the",
        "layer",
        "i",
        "."
      ]
    },
    {
      "sentence": "To simplify the problem we may always find the maximum, m, of the size layers, and assume that each w i ∈ R m .",
      "tokens": [
        "To",
        "simplify",
        "the",
        "problem",
        "we",
        "may",
        "always",
        "find",
        "the",
        "maximum",
        ",",
        "m",
        ",",
        "of",
        "the",
        "size",
        "layers",
        ",",
        "and",
        "assume",
        "that",
        "each",
        "w",
        "i",
        "∈",
        "R",
        "m",
        "."
      ]
    },
    {
      "sentence": "We are implicitly assuming that for each i = 1, ..., r, P i ( 0) = 0. foot_0 2 Existence of function f and the toll of cost function C First thing to consider, given a labeled data set {( x j , y j ) : j = 1, .",
      "tokens": [
        "We",
        "are",
        "implicitly",
        "assuming",
        "that",
        "for",
        "each",
        "i",
        "=",
        "1",
        ",",
        "...",
        ",",
        "r",
        ",",
        "P",
        "i",
        "(",
        "0",
        ")",
        "=",
        "0.",
        "foot_0",
        "2",
        "Existence",
        "of",
        "function",
        "f",
        "and",
        "the",
        "toll",
        "of",
        "cost",
        "function",
        "C",
        "First",
        "thing",
        "to",
        "consider",
        ",",
        "given",
        "a",
        "labeled",
        "data",
        "set",
        "{",
        "(",
        "x",
        "j",
        ",",
        "y",
        "j",
        ")",
        ":",
        "j",
        "=",
        "1",
        ",",
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ", N }, if there is a representation function f such that f( x j ) = y j for all j = 1, .",
      "tokens": [
        ",",
        "N",
        "}",
        ",",
        "if",
        "there",
        "is",
        "a",
        "representation",
        "function",
        "f",
        "such",
        "that",
        "f",
        "(",
        "x",
        "j",
        ")",
        "=",
        "y",
        "j",
        "for",
        "all",
        "j",
        "=",
        "1",
        ",",
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ".",
      "tokens": [
        "."
      ]
    },
    {
      "sentence": ", N .",
      "tokens": [
        ",",
        "N",
        "."
      ]
    },
    {
      "sentence": "This important step is often overlooked in practice.",
      "tokens": [
        "This",
        "important",
        "step",
        "is",
        "often",
        "overlooked",
        "in",
        "practice",
        "."
      ]
    },
    {
      "sentence": "In theory, if there is x j = x k such that y j = y k (4) then no such function exist.",
      "tokens": [
        "In",
        "theory",
        ",",
        "if",
        "there",
        "is",
        "x",
        "j",
        "=",
        "x",
        "k",
        "such",
        "that",
        "y",
        "j",
        "=",
        "y",
        "k",
        "(",
        "4",
        ")",
        "then",
        "no",
        "such",
        "function",
        "exist",
        "."
      ]
    },
    {
      "sentence": "In other words f is a function of more variables than provided in the data set and the idea approximation by f is meaningless.",
      "tokens": [
        "In",
        "other",
        "words",
        "f",
        "is",
        "a",
        "function",
        "of",
        "more",
        "variables",
        "than",
        "provided",
        "in",
        "the",
        "data",
        "set",
        "and",
        "the",
        "idea",
        "approximation",
        "by",
        "f",
        "is",
        "meaningless",
        "."
      ]
    },
    {
      "sentence": "One may always assume some measurement error ε > 0 (noise) of the data set and consider instead a weaker condition x j = x k =⇒ y j -y k l 2 < ε (5) necessary for existence of a function f. In such case one may look at the average values of duplicate points f ave = x j = x k y k x j = x k 1 (6) and choose to approximate f ave instead of f. There is no guarantee that a good approximation f of function f ave is a good approximation of f itself.",
      "tokens": [
        "One",
        "may",
        "always",
        "assume",
        "some",
        "measurement",
        "error",
        "ε",
        ">",
        "0",
        "(",
        "noise",
        ")",
        "of",
        "the",
        "data",
        "set",
        "and",
        "consider",
        "instead",
        "a",
        "weaker",
        "condition",
        "x",
        "j",
        "=",
        "x",
        "k",
        "=⇒",
        "y",
        "j",
        "-y",
        "k",
        "l",
        "2",
        "<",
        "ε",
        "(",
        "5",
        ")",
        "necessary",
        "for",
        "existence",
        "of",
        "a",
        "function",
        "f.",
        "In",
        "such",
        "case",
        "one",
        "may",
        "look",
        "at",
        "the",
        "average",
        "values",
        "of",
        "duplicate",
        "points",
        "f",
        "ave",
        "=",
        "x",
        "j",
        "=",
        "x",
        "k",
        "y",
        "k",
        "x",
        "j",
        "=",
        "x",
        "k",
        "1",
        "(",
        "6",
        ")",
        "and",
        "choose",
        "to",
        "approximate",
        "f",
        "ave",
        "instead",
        "of",
        "f.",
        "There",
        "is",
        "no",
        "guarantee",
        "that",
        "a",
        "good",
        "approximation",
        "f",
        "of",
        "function",
        "f",
        "ave",
        "is",
        "a",
        "good",
        "approximation",
        "of",
        "f",
        "itself",
        "."
      ]
    },
    {
      "sentence": "One should also consider the norm • d of the approximation function f. It is well known that various classes of \"nice\" functions are dense in L p spaces.",
      "tokens": [
        "One",
        "should",
        "also",
        "consider",
        "the",
        "norm",
        "•",
        "d",
        "of",
        "the",
        "approximation",
        "function",
        "f.",
        "It",
        "is",
        "well",
        "known",
        "that",
        "various",
        "classes",
        "of",
        "``",
        "nice",
        "''",
        "functions",
        "are",
        "dense",
        "in",
        "L",
        "p",
        "spaces",
        "."
      ]
    },
    {
      "sentence": "In particular, the class of functions f defined in (3) are dense with respect to convergence in measure and L p norm (see [1] ).",
      "tokens": [
        "In",
        "particular",
        ",",
        "the",
        "class",
        "of",
        "functions",
        "f",
        "defined",
        "in",
        "(",
        "3",
        ")",
        "are",
        "dense",
        "with",
        "respect",
        "to",
        "convergence",
        "in",
        "measure",
        "and",
        "L",
        "p",
        "norm",
        "(",
        "see",
        "[",
        "1",
        "]",
        ")",
        "."
      ]
    },
    {
      "sentence": "This important fact implies that given any functions f and any ε > 0, there is a function f s.t.",
      "tokens": [
        "This",
        "important",
        "fact",
        "implies",
        "that",
        "given",
        "any",
        "functions",
        "f",
        "and",
        "any",
        "ε",
        ">",
        "0",
        ",",
        "there",
        "is",
        "a",
        "function",
        "f",
        "s.t",
        "."
      ]
    },
    {
      "sentence": "f -f L p < ε.",
      "tokens": [
        "f",
        "-f",
        "L",
        "p",
        "<",
        "ε",
        "."
      ]
    },
    {
      "sentence": "(7) The approximation function f is a function of weights vectors w i .",
      "tokens": [
        "(",
        "7",
        ")",
        "The",
        "approximation",
        "function",
        "f",
        "is",
        "a",
        "function",
        "of",
        "weights",
        "vectors",
        "w",
        "i",
        "."
      ]
    },
    {
      "sentence": "The pursuit of such function f is a two part problem.",
      "tokens": [
        "The",
        "pursuit",
        "of",
        "such",
        "function",
        "f",
        "is",
        "a",
        "two",
        "part",
        "problem",
        "."
      ]
    },
    {
      "sentence": "The first part, defining the structure of the neural network, is done by a human.",
      "tokens": [
        "The",
        "first",
        "part",
        ",",
        "defining",
        "the",
        "structure",
        "of",
        "the",
        "neural",
        "network",
        ",",
        "is",
        "done",
        "by",
        "a",
        "human",
        "."
      ]
    },
    {
      "sentence": "The methodology behind the choice of NN structures is at the stage of experimental science.",
      "tokens": [
        "The",
        "methodology",
        "behind",
        "the",
        "choice",
        "of",
        "NN",
        "structures",
        "is",
        "at",
        "the",
        "stage",
        "of",
        "experimental",
        "science",
        "."
      ]
    },
    {
      "sentence": "The second part, weights optimization, is done by a computer, usually capable of trillions of operations per second.",
      "tokens": [
        "The",
        "second",
        "part",
        ",",
        "weights",
        "optimization",
        ",",
        "is",
        "done",
        "by",
        "a",
        "computer",
        ",",
        "usually",
        "capable",
        "of",
        "trillions",
        "of",
        "operations",
        "per",
        "second",
        "."
      ]
    },
    {
      "sentence": "Needless to say that the effectiveness of latter part depends heavily on the former.",
      "tokens": [
        "Needless",
        "to",
        "say",
        "that",
        "the",
        "effectiveness",
        "of",
        "latter",
        "part",
        "depends",
        "heavily",
        "on",
        "the",
        "former",
        "."
      ]
    },
    {
      "sentence": "In practice one usually does not use an approximation with respect to L p norm.",
      "tokens": [
        "In",
        "practice",
        "one",
        "usually",
        "does",
        "not",
        "use",
        "an",
        "approximation",
        "with",
        "respect",
        "to",
        "L",
        "p",
        "norm",
        "."
      ]
    },
    {
      "sentence": "Computationally one may only evaluate the function f at finitely many points and approximate it by f at such points, often with respect to the • l p norm.",
      "tokens": [
        "Computationally",
        "one",
        "may",
        "only",
        "evaluate",
        "the",
        "function",
        "f",
        "at",
        "finitely",
        "many",
        "points",
        "and",
        "approximate",
        "it",
        "by",
        "f",
        "at",
        "such",
        "points",
        ",",
        "often",
        "with",
        "respect",
        "to",
        "the",
        "•",
        "l",
        "p",
        "norm",
        "."
      ]
    },
    {
      "sentence": "Since for all 0 < p < q < ∞, f(y j ) -f (y j ) l q f(y j ) -f (y j ) l p , (8) one can choose any p > 0 to obtain the approximation for all q p. foot_1 Here is an interesting question.",
      "tokens": [
        "Since",
        "for",
        "all",
        "0",
        "<",
        "p",
        "<",
        "q",
        "<",
        "∞",
        ",",
        "f",
        "(",
        "y",
        "j",
        ")",
        "-f",
        "(",
        "y",
        "j",
        ")",
        "l",
        "q",
        "f",
        "(",
        "y",
        "j",
        ")",
        "-f",
        "(",
        "y",
        "j",
        ")",
        "l",
        "p",
        ",",
        "(",
        "8",
        ")",
        "one",
        "can",
        "choose",
        "any",
        "p",
        ">",
        "0",
        "to",
        "obtain",
        "the",
        "approximation",
        "for",
        "all",
        "q",
        "p.",
        "foot_1",
        "Here",
        "is",
        "an",
        "interesting",
        "question",
        "."
      ]
    },
    {
      "sentence": "Given f ∈ L p (R k ), does it follow that the sequence {f ( y j )} ∞ j=1 ∈ l p for any choice y j ∈ R k ?",
      "tokens": [
        "Given",
        "f",
        "∈",
        "L",
        "p",
        "(",
        "R",
        "k",
        ")",
        ",",
        "does",
        "it",
        "follow",
        "that",
        "the",
        "sequence",
        "{",
        "f",
        "(",
        "y",
        "j",
        ")",
        "}",
        "∞",
        "j=1",
        "∈",
        "l",
        "p",
        "for",
        "any",
        "choice",
        "y",
        "j",
        "∈",
        "R",
        "k",
        "?"
      ]
    },
    {
      "sentence": "One can easily show it is not the case.",
      "tokens": [
        "One",
        "can",
        "easily",
        "show",
        "it",
        "is",
        "not",
        "the",
        "case",
        "."
      ]
    },
    {
      "sentence": "What about a sequence of randomly chosen points y j ∈ R k ?",
      "tokens": [
        "What",
        "about",
        "a",
        "sequence",
        "of",
        "randomly",
        "chosen",
        "points",
        "y",
        "j",
        "∈",
        "R",
        "k",
        "?"
      ]
    },
    {
      "sentence": "In this case the answer is affirmative.",
      "tokens": [
        "In",
        "this",
        "case",
        "the",
        "answer",
        "is",
        "affirmative",
        "."
      ]
    },
    {
      "sentence": "What about the converse statement?",
      "tokens": [
        "What",
        "about",
        "the",
        "converse",
        "statement",
        "?"
      ]
    },
    {
      "sentence": "Given a sequence {f ( y j )} ∞ j=1 ∈ l p , does it follow that f ∈ L p (R k )?",
      "tokens": [
        "Given",
        "a",
        "sequence",
        "{",
        "f",
        "(",
        "y",
        "j",
        ")",
        "}",
        "∞",
        "j=1",
        "∈",
        "l",
        "p",
        ",",
        "does",
        "it",
        "follow",
        "that",
        "f",
        "∈",
        "L",
        "p",
        "(",
        "R",
        "k",
        ")",
        "?"
      ]
    },
    {
      "sentence": "What if for any sequence of points { y j } ∞ j=1 in the domain of f , the sequence {f ( y j )} ∞ j=1 belongs to l p ?",
      "tokens": [
        "What",
        "if",
        "for",
        "any",
        "sequence",
        "of",
        "points",
        "{",
        "y",
        "j",
        "}",
        "∞",
        "j=1",
        "in",
        "the",
        "domain",
        "of",
        "f",
        ",",
        "the",
        "sequence",
        "{",
        "f",
        "(",
        "y",
        "j",
        ")",
        "}",
        "∞",
        "j=1",
        "belongs",
        "to",
        "l",
        "p",
        "?"
      ]
    },
    {
      "sentence": "What if the measure µ of the domain D of f is not a Lebesgue measure?",
      "tokens": [
        "What",
        "if",
        "the",
        "measure",
        "µ",
        "of",
        "the",
        "domain",
        "D",
        "of",
        "f",
        "is",
        "not",
        "a",
        "Lebesgue",
        "measure",
        "?"
      ]
    },
    {
      "sentence": "Things get even more bizarre if the set function µ is only finitely additive.",
      "tokens": [
        "Things",
        "get",
        "even",
        "more",
        "bizarre",
        "if",
        "the",
        "set",
        "function",
        "µ",
        "is",
        "only",
        "finitely",
        "additive",
        "."
      ]
    },
    {
      "sentence": "In some cases L p spaces may not be complete for any p > 0.",
      "tokens": [
        "In",
        "some",
        "cases",
        "L",
        "p",
        "spaces",
        "may",
        "not",
        "be",
        "complete",
        "for",
        "any",
        "p",
        ">",
        "0",
        "."
      ]
    },
    {
      "sentence": "In Measure Theory, \"functions\" that agree almost everywhere are indistinguishable.",
      "tokens": [
        "In",
        "Measure",
        "Theory",
        ",",
        "``",
        "functions",
        "''",
        "that",
        "agree",
        "almost",
        "everywhere",
        "are",
        "indistinguishable",
        "."
      ]
    },
    {
      "sentence": "In case of finitely additive measures the equivalence classes of a \"function\" are often more complex.",
      "tokens": [
        "In",
        "case",
        "of",
        "finitely",
        "additive",
        "measures",
        "the",
        "equivalence",
        "classes",
        "of",
        "a",
        "``",
        "function",
        "''",
        "are",
        "often",
        "more",
        "complex",
        "."
      ]
    },
    {
      "sentence": "Why would anyone care about finitely (and not countably) additive measure on D?",
      "tokens": [
        "Why",
        "would",
        "anyone",
        "care",
        "about",
        "finitely",
        "(",
        "and",
        "not",
        "countably",
        ")",
        "additive",
        "measure",
        "on",
        "D",
        "?"
      ]
    },
    {
      "sentence": "From the point of view of Constructive Mathematics, it is impossible to verify countable additivity of µ in the first place.",
      "tokens": [
        "From",
        "the",
        "point",
        "of",
        "view",
        "of",
        "Constructive",
        "Mathematics",
        ",",
        "it",
        "is",
        "impossible",
        "to",
        "verify",
        "countable",
        "additivity",
        "of",
        "µ",
        "in",
        "the",
        "first",
        "place",
        "."
      ]
    }
  ]
}