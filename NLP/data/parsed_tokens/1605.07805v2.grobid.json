{
  "title": [
    {
      "sentence": "Learning Moore Machines from Input-Output Traces",
      "tokens": [
        "Learning",
        "Moore",
        "Machines",
        "from",
        "Input-Output",
        "Traces"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "The problem of learning automata from example traces (but no equivalence or membership queries) is fundamental in automata learning theory and practice.",
      "tokens": [
        "The",
        "problem",
        "of",
        "learning",
        "automata",
        "from",
        "example",
        "traces",
        "(",
        "but",
        "no",
        "equivalence",
        "or",
        "membership",
        "queries",
        ")",
        "is",
        "fundamental",
        "in",
        "automata",
        "learning",
        "theory",
        "and",
        "practice",
        "."
      ]
    },
    {
      "sentence": "In this paper we study this problem for finite state machines with inputs and outputs, and in particular for Moore machines.",
      "tokens": [
        "In",
        "this",
        "paper",
        "we",
        "study",
        "this",
        "problem",
        "for",
        "finite",
        "state",
        "machines",
        "with",
        "inputs",
        "and",
        "outputs",
        ",",
        "and",
        "in",
        "particular",
        "for",
        "Moore",
        "machines",
        "."
      ]
    },
    {
      "sentence": "We develop three algorithms for solving this problem: (1) the PTAP algorithm, which transforms a set of input-output traces into an incomplete Moore machine and then completes the machine with self-loops; (2) the PRPNI algorithm, which uses the well-known RPNI algorithm for automata learning to learn a product of automata encoding a Moore machine; and (3) the MooreMI algorithm, which directly learns a Moore machine using PTAP extended with state merging.",
      "tokens": [
        "We",
        "develop",
        "three",
        "algorithms",
        "for",
        "solving",
        "this",
        "problem",
        ":",
        "(",
        "1",
        ")",
        "the",
        "PTAP",
        "algorithm",
        ",",
        "which",
        "transforms",
        "a",
        "set",
        "of",
        "input-output",
        "traces",
        "into",
        "an",
        "incomplete",
        "Moore",
        "machine",
        "and",
        "then",
        "completes",
        "the",
        "machine",
        "with",
        "self-loops",
        ";",
        "(",
        "2",
        ")",
        "the",
        "PRPNI",
        "algorithm",
        ",",
        "which",
        "uses",
        "the",
        "well-known",
        "RPNI",
        "algorithm",
        "for",
        "automata",
        "learning",
        "to",
        "learn",
        "a",
        "product",
        "of",
        "automata",
        "encoding",
        "a",
        "Moore",
        "machine",
        ";",
        "and",
        "(",
        "3",
        ")",
        "the",
        "MooreMI",
        "algorithm",
        ",",
        "which",
        "directly",
        "learns",
        "a",
        "Moore",
        "machine",
        "using",
        "PTAP",
        "extended",
        "with",
        "state",
        "merging",
        "."
      ]
    },
    {
      "sentence": "We prove that MooreMI has the fundamental identification in the limit property.",
      "tokens": [
        "We",
        "prove",
        "that",
        "MooreMI",
        "has",
        "the",
        "fundamental",
        "identification",
        "in",
        "the",
        "limit",
        "property",
        "."
      ]
    },
    {
      "sentence": "We also compare the algorithms experimentally in terms of the size of the learned machine and several notions of accuracy, introduced in this paper.",
      "tokens": [
        "We",
        "also",
        "compare",
        "the",
        "algorithms",
        "experimentally",
        "in",
        "terms",
        "of",
        "the",
        "size",
        "of",
        "the",
        "learned",
        "machine",
        "and",
        "several",
        "notions",
        "of",
        "accuracy",
        ",",
        "introduced",
        "in",
        "this",
        "paper",
        "."
      ]
    },
    {
      "sentence": "Finally, we compare with OSTIA, an algorithm that learns a more general class of transducers, and find that OSTIA generally does not learn a Moore machine, even when fed with a characteristic sample.",
      "tokens": [
        "Finally",
        ",",
        "we",
        "compare",
        "with",
        "OSTIA",
        ",",
        "an",
        "algorithm",
        "that",
        "learns",
        "a",
        "more",
        "general",
        "class",
        "of",
        "transducers",
        ",",
        "and",
        "find",
        "that",
        "OSTIA",
        "generally",
        "does",
        "not",
        "learn",
        "a",
        "Moore",
        "machine",
        ",",
        "even",
        "when",
        "fed",
        "with",
        "a",
        "characteristic",
        "sample",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "Introduction An abundance of data from the internet and from other sources (e.g., sensors) is revolutionizing many sectors of science, technology, and ultimately our society.",
      "tokens": [
        "Introduction",
        "An",
        "abundance",
        "of",
        "data",
        "from",
        "the",
        "internet",
        "and",
        "from",
        "other",
        "sources",
        "(",
        "e.g.",
        ",",
        "sensors",
        ")",
        "is",
        "revolutionizing",
        "many",
        "sectors",
        "of",
        "science",
        ",",
        "technology",
        ",",
        "and",
        "ultimately",
        "our",
        "society",
        "."
      ]
    },
    {
      "sentence": "At the heart of this revolution lies machine learning, a broad spectrum of techniques to derive information from data.",
      "tokens": [
        "At",
        "the",
        "heart",
        "of",
        "this",
        "revolution",
        "lies",
        "machine",
        "learning",
        ",",
        "a",
        "broad",
        "spectrum",
        "of",
        "techniques",
        "to",
        "derive",
        "information",
        "from",
        "data",
        "."
      ]
    },
    {
      "sentence": "Traditionally, objects studied by machine learning include classifiers, decision trees, and neural networks, with applications to fields as diverse as artificial intelligence, marketing, finance, or medicine [38] .",
      "tokens": [
        "Traditionally",
        ",",
        "objects",
        "studied",
        "by",
        "machine",
        "learning",
        "include",
        "classifiers",
        ",",
        "decision",
        "trees",
        ",",
        "and",
        "neural",
        "networks",
        ",",
        "with",
        "applications",
        "to",
        "fields",
        "as",
        "diverse",
        "as",
        "artificial",
        "intelligence",
        ",",
        "marketing",
        ",",
        "finance",
        ",",
        "or",
        "medicine",
        "[",
        "38",
        "]",
        "."
      ]
    },
    {
      "sentence": "In the context of system design, an important problem, with numerous applications, is automatically generating models from data.",
      "tokens": [
        "In",
        "the",
        "context",
        "of",
        "system",
        "design",
        ",",
        "an",
        "important",
        "problem",
        ",",
        "with",
        "numerous",
        "applications",
        ",",
        "is",
        "automatically",
        "generating",
        "models",
        "from",
        "data",
        "."
      ]
    },
    {
      "sentence": "There are many variants of this problem, depending on what types of models and data are considered, as well as other assumptions or restrictions.",
      "tokens": [
        "There",
        "are",
        "many",
        "variants",
        "of",
        "this",
        "problem",
        ",",
        "depending",
        "on",
        "what",
        "types",
        "of",
        "models",
        "and",
        "data",
        "are",
        "considered",
        ",",
        "as",
        "well",
        "as",
        "other",
        "assumptions",
        "or",
        "restrictions",
        "."
      ]
    },
    {
      "sentence": "Examples include, but are by no means limited to, the classic field of system identification [35] , as well as more recent works on synthesizing programs, controllers, or other artifacts from examples [44, 21, 42, 41, 5] .",
      "tokens": [
        "Examples",
        "include",
        ",",
        "but",
        "are",
        "by",
        "no",
        "means",
        "limited",
        "to",
        ",",
        "the",
        "classic",
        "field",
        "of",
        "system",
        "identification",
        "[",
        "35",
        "]",
        ",",
        "as",
        "well",
        "as",
        "more",
        "recent",
        "works",
        "on",
        "synthesizing",
        "programs",
        ",",
        "controllers",
        ",",
        "or",
        "other",
        "artifacts",
        "from",
        "examples",
        "[",
        "44",
        ",",
        "21",
        ",",
        "42",
        ",",
        "41",
        ",",
        "5",
        "]",
        "."
      ]
    },
    {
      "sentence": "In this paper we consider a basic problem, that of learning a Moore machine from a set of input-output traces.",
      "tokens": [
        "In",
        "this",
        "paper",
        "we",
        "consider",
        "a",
        "basic",
        "problem",
        ",",
        "that",
        "of",
        "learning",
        "a",
        "Moore",
        "machine",
        "from",
        "a",
        "set",
        "of",
        "input-output",
        "traces",
        "."
      ]
    },
    {
      "sentence": "A Moore machine is a type of finite-state machine (FSM) with inputs and outputs, where the output always depends on the current state, but not on the current input [30] .",
      "tokens": [
        "A",
        "Moore",
        "machine",
        "is",
        "a",
        "type",
        "of",
        "finite-state",
        "machine",
        "(",
        "FSM",
        ")",
        "with",
        "inputs",
        "and",
        "outputs",
        ",",
        "where",
        "the",
        "output",
        "always",
        "depends",
        "on",
        "the",
        "current",
        "state",
        ",",
        "but",
        "not",
        "on",
        "the",
        "current",
        "input",
        "[",
        "30",
        "]",
        "."
      ]
    },
    {
      "sentence": "Moore machines are typically deterministic and complete, meaning that for given state and input, the next state is always defined and is unique; and for given state, the output is also always uniquely defined.",
      "tokens": [
        "Moore",
        "machines",
        "are",
        "typically",
        "deterministic",
        "and",
        "complete",
        ",",
        "meaning",
        "that",
        "for",
        "given",
        "state",
        "and",
        "input",
        ",",
        "the",
        "next",
        "state",
        "is",
        "always",
        "defined",
        "and",
        "is",
        "unique",
        ";",
        "and",
        "for",
        "given",
        "state",
        ",",
        "the",
        "output",
        "is",
        "also",
        "always",
        "uniquely",
        "defined",
        "."
      ]
    },
    {
      "sentence": "Such machines are useful in many applications, for instance, for representing digital circuits or controllers.",
      "tokens": [
        "Such",
        "machines",
        "are",
        "useful",
        "in",
        "many",
        "applications",
        ",",
        "for",
        "instance",
        ",",
        "for",
        "representing",
        "digital",
        "circuits",
        "or",
        "controllers",
        "."
      ]
    },
    {
      "sentence": "In this paper we are interested in learning deterministic and complete Moore machines.",
      "tokens": [
        "In",
        "this",
        "paper",
        "we",
        "are",
        "interested",
        "in",
        "learning",
        "deterministic",
        "and",
        "complete",
        "Moore",
        "machines",
        "."
      ]
    },
    {
      "sentence": "We want to learn a Moore machine from a given set of input-output traces.",
      "tokens": [
        "We",
        "want",
        "to",
        "learn",
        "a",
        "Moore",
        "machine",
        "from",
        "a",
        "given",
        "set",
        "of",
        "input-output",
        "traces",
        "."
      ]
    },
    {
      "sentence": "One such trace is a sequence of inputs, ρ in , and the corresponding sequence of outputs, ρ out , that the machine must produce when fed with ρ in .",
      "tokens": [
        "One",
        "such",
        "trace",
        "is",
        "a",
        "sequence",
        "of",
        "inputs",
        ",",
        "ρ",
        "in",
        ",",
        "and",
        "the",
        "corresponding",
        "sequence",
        "of",
        "outputs",
        ",",
        "ρ",
        "out",
        ",",
        "that",
        "the",
        "machine",
        "must",
        "produce",
        "when",
        "fed",
        "with",
        "ρ",
        "in",
        "."
      ]
    },
    {
      "sentence": "As in standard machine learning methods, we call the set of traces given to the learning algorithm the training set.",
      "tokens": [
        "As",
        "in",
        "standard",
        "machine",
        "learning",
        "methods",
        ",",
        "we",
        "call",
        "the",
        "set",
        "of",
        "traces",
        "given",
        "to",
        "the",
        "learning",
        "algorithm",
        "the",
        "training",
        "set",
        "."
      ]
    },
    {
      "sentence": "Obviously, we would like the learned machine M to be consistent w.r.t.",
      "tokens": [
        "Obviously",
        ",",
        "we",
        "would",
        "like",
        "the",
        "learned",
        "machine",
        "M",
        "to",
        "be",
        "consistent",
        "w.r.t",
        "."
      ]
    },
    {
      "sentence": "the training set R, meaning that for every pair (ρ in , ρ out ) ∈ R, M must output ρ out when fed with ρ in .",
      "tokens": [
        "the",
        "training",
        "set",
        "R",
        ",",
        "meaning",
        "that",
        "for",
        "every",
        "pair",
        "(",
        "ρ",
        "in",
        ",",
        "ρ",
        "out",
        ")",
        "∈",
        "R",
        ",",
        "M",
        "must",
        "output",
        "ρ",
        "out",
        "when",
        "fed",
        "with",
        "ρ",
        "in",
        "."
      ]
    },
    {
      "sentence": "But in addition to consistency, we would like M to behave well w.r.t.",
      "tokens": [
        "But",
        "in",
        "addition",
        "to",
        "consistency",
        ",",
        "we",
        "would",
        "like",
        "M",
        "to",
        "behave",
        "well",
        "w.r.t",
        "."
      ]
    },
    {
      "sentence": "several performance criteria, including complexity of the learning algorithm, size of the learned machine M (its number of states), and accuracy of M , which captures how well M performs on a testing set of traces, different from the training set.",
      "tokens": [
        "several",
        "performance",
        "criteria",
        ",",
        "including",
        "complexity",
        "of",
        "the",
        "learning",
        "algorithm",
        ",",
        "size",
        "of",
        "the",
        "learned",
        "machine",
        "M",
        "(",
        "its",
        "number",
        "of",
        "states",
        ")",
        ",",
        "and",
        "accuracy",
        "of",
        "M",
        ",",
        "which",
        "captures",
        "how",
        "well",
        "M",
        "performs",
        "on",
        "a",
        "testing",
        "set",
        "of",
        "traces",
        ",",
        "different",
        "from",
        "the",
        "training",
        "set",
        "."
      ]
    },
    {
      "sentence": "Even though this is a basic problem, it appears not to have received much attention in the literature.",
      "tokens": [
        "Even",
        "though",
        "this",
        "is",
        "a",
        "basic",
        "problem",
        ",",
        "it",
        "appears",
        "not",
        "to",
        "have",
        "received",
        "much",
        "attention",
        "in",
        "the",
        "literature",
        "."
      ]
    },
    {
      "sentence": "In fact, to the best of our knowledge, this is the first paper which formalizes and studies this problem.",
      "tokens": [
        "In",
        "fact",
        ",",
        "to",
        "the",
        "best",
        "of",
        "our",
        "knowledge",
        ",",
        "this",
        "is",
        "the",
        "first",
        "paper",
        "which",
        "formalizes",
        "and",
        "studies",
        "this",
        "problem",
        "."
      ]
    },
    {
      "sentence": "This is despite a large body of All algorithms developed in this paper belong in the heuristic category in the sense that we do not attempt to find a smallest machine.",
      "tokens": [
        "This",
        "is",
        "despite",
        "a",
        "large",
        "body",
        "of",
        "All",
        "algorithms",
        "developed",
        "in",
        "this",
        "paper",
        "belong",
        "in",
        "the",
        "heuristic",
        "category",
        "in",
        "the",
        "sense",
        "that",
        "we",
        "do",
        "not",
        "attempt",
        "to",
        "find",
        "a",
        "smallest",
        "machine",
        "."
      ]
    },
    {
      "sentence": "However, we would still like to learn a small machine.",
      "tokens": [
        "However",
        ",",
        "we",
        "would",
        "still",
        "like",
        "to",
        "learn",
        "a",
        "small",
        "machine",
        "."
      ]
    },
    {
      "sentence": "Thus, size is an important performance criterion, as explained in Section 5.1.",
      "tokens": [
        "Thus",
        ",",
        "size",
        "is",
        "an",
        "important",
        "performance",
        "criterion",
        ",",
        "as",
        "explained",
        "in",
        "Section",
        "5.1",
        "."
      ]
    },
    {
      "sentence": "Like RPNI and other algorithms, MooreMI is also a state-merging algorithm.",
      "tokens": [
        "Like",
        "RPNI",
        "and",
        "other",
        "algorithms",
        ",",
        "MooreMI",
        "is",
        "also",
        "a",
        "state-merging",
        "algorithm",
        "."
      ]
    },
    {
      "sentence": "[46] is close to our work, but the algorithm described there does not always yield a deterministic Moore machine, while our algorithms do.",
      "tokens": [
        "[",
        "46",
        "]",
        "is",
        "close",
        "to",
        "our",
        "work",
        ",",
        "but",
        "the",
        "algorithm",
        "described",
        "there",
        "does",
        "not",
        "always",
        "yield",
        "a",
        "deterministic",
        "Moore",
        "machine",
        ",",
        "while",
        "our",
        "algorithms",
        "do",
        "."
      ]
    },
    {
      "sentence": "This is important because we want to learn systems like digital circuits, embedded controllers (e.g.",
      "tokens": [
        "This",
        "is",
        "important",
        "because",
        "we",
        "want",
        "to",
        "learn",
        "systems",
        "like",
        "digital",
        "circuits",
        ",",
        "embedded",
        "controllers",
        "(",
        "e.g",
        "."
      ]
    },
    {
      "sentence": "modeled in Simulink), etc., and such systems are typically deterministic.",
      "tokens": [
        "modeled",
        "in",
        "Simulink",
        ")",
        ",",
        "etc.",
        ",",
        "and",
        "such",
        "systems",
        "are",
        "typically",
        "deterministic",
        "."
      ]
    },
    {
      "sentence": "The k-tails algorithm for finite state machine inference [9] may also result in non-deterministic machines.",
      "tokens": [
        "The",
        "k-tails",
        "algorithm",
        "for",
        "finite",
        "state",
        "machine",
        "inference",
        "[",
        "9",
        "]",
        "may",
        "also",
        "result",
        "in",
        "non-deterministic",
        "machines",
        "."
      ]
    },
    {
      "sentence": "Moreover, this algorithm does not generally yield smallest machines, since the initial partition of the input words into equivalence classes (which then become the states of the learned machine) can be overly conservative .",
      "tokens": [
        "Moreover",
        ",",
        "this",
        "algorithm",
        "does",
        "not",
        "generally",
        "yield",
        "smallest",
        "machines",
        ",",
        "since",
        "the",
        "initial",
        "partition",
        "of",
        "the",
        "input",
        "words",
        "into",
        "equivalence",
        "classes",
        "(",
        "which",
        "then",
        "become",
        "the",
        "states",
        "of",
        "the",
        "learned",
        "machine",
        ")",
        "can",
        "be",
        "overly",
        "conservative",
        "."
      ]
    },
    {
      "sentence": "4 The work in [29] deals with learning finite state machine abstractions of non-linear analog circuits.",
      "tokens": [
        "4",
        "The",
        "work",
        "in",
        "[",
        "29",
        "]",
        "deals",
        "with",
        "learning",
        "finite",
        "state",
        "machine",
        "abstractions",
        "of",
        "non-linear",
        "analog",
        "circuits",
        "."
      ]
    },
    {
      "sentence": "The algorithm described in [29] is very different from ours, and uses the circuit's number of inputs to determine a subset of the states in the learned abstraction.",
      "tokens": [
        "The",
        "algorithm",
        "described",
        "in",
        "[",
        "29",
        "]",
        "is",
        "very",
        "different",
        "from",
        "ours",
        ",",
        "and",
        "uses",
        "the",
        "circuit",
        "'s",
        "number",
        "of",
        "inputs",
        "to",
        "determine",
        "a",
        "subset",
        "of",
        "the",
        "states",
        "in",
        "the",
        "learned",
        "abstraction",
        "."
      ]
    },
    {
      "sentence": "Also, identification in the limit is not considered in [29] .",
      "tokens": [
        "Also",
        ",",
        "identification",
        "in",
        "the",
        "limit",
        "is",
        "not",
        "considered",
        "in",
        "[",
        "29",
        "]",
        "."
      ]
    },
    {
      "sentence": "Learning from \"inexperienced teachers\", i.e.",
      "tokens": [
        "Learning",
        "from",
        "``",
        "inexperienced",
        "teachers",
        "''",
        ",",
        "i.e",
        "."
      ]
    },
    {
      "sentence": "by using either (1) only equivalence queries or (2) equivalence plus membership queries that may be answered inconclusively, has been studied in [20, 34] .",
      "tokens": [
        "by",
        "using",
        "either",
        "(",
        "1",
        ")",
        "only",
        "equivalence",
        "queries",
        "or",
        "(",
        "2",
        ")",
        "equivalence",
        "plus",
        "membership",
        "queries",
        "that",
        "may",
        "be",
        "answered",
        "inconclusively",
        ",",
        "has",
        "been",
        "studied",
        "in",
        "[",
        "20",
        ",",
        "34",
        "]",
        "."
      ]
    },
    {
      "sentence": "Related but different from our work are approaches which synthesize state machines from scenarios and requirements.",
      "tokens": [
        "Related",
        "but",
        "different",
        "from",
        "our",
        "work",
        "are",
        "approaches",
        "which",
        "synthesize",
        "state",
        "machines",
        "from",
        "scenarios",
        "and",
        "requirements",
        "."
      ]
    },
    {
      "sentence": "Scenarios can be provided in various forms, e.g.",
      "tokens": [
        "Scenarios",
        "can",
        "be",
        "provided",
        "in",
        "various",
        "forms",
        ",",
        "e.g",
        "."
      ]
    },
    {
      "sentence": "message sequence charts [5] , event sequence charts [24] , or simply, input-output examples [47] .",
      "tokens": [
        "message",
        "sequence",
        "charts",
        "[",
        "5",
        "]",
        ",",
        "event",
        "sequence",
        "charts",
        "[",
        "24",
        "]",
        ",",
        "or",
        "simply",
        ",",
        "input-output",
        "examples",
        "[",
        "47",
        "]",
        "."
      ]
    },
    {
      "sentence": "Requirements can be temporal logic formulas as in [5, 47] , or other types of constraints such as the scenario constraints used in [24] .",
      "tokens": [
        "Requirements",
        "can",
        "be",
        "temporal",
        "logic",
        "formulas",
        "as",
        "in",
        "[",
        "5",
        ",",
        "47",
        "]",
        ",",
        "or",
        "other",
        "types",
        "of",
        "constraints",
        "such",
        "as",
        "the",
        "scenario",
        "constraints",
        "used",
        "in",
        "[",
        "24",
        "]",
        "."
      ]
    },
    {
      "sentence": "In this paper we have examples, but no requirements.",
      "tokens": [
        "In",
        "this",
        "paper",
        "we",
        "have",
        "examples",
        ",",
        "but",
        "no",
        "requirements",
        "."
      ]
    },
    {
      "sentence": "Also related but different from ours is work in the areas of invariant generation and specification mining, which extract properties of a program or system model, such as invariants [22, 13, 23] , temporal logic formulas [27, 33] or non-deterministic finite automata [6] .",
      "tokens": [
        "Also",
        "related",
        "but",
        "different",
        "from",
        "ours",
        "is",
        "work",
        "in",
        "the",
        "areas",
        "of",
        "invariant",
        "generation",
        "and",
        "specification",
        "mining",
        ",",
        "which",
        "extract",
        "properties",
        "of",
        "a",
        "program",
        "or",
        "system",
        "model",
        ",",
        "such",
        "as",
        "invariants",
        "[",
        "22",
        ",",
        "13",
        ",",
        "23",
        "]",
        ",",
        "temporal",
        "logic",
        "formulas",
        "[",
        "27",
        ",",
        "33",
        "]",
        "or",
        "non-deterministic",
        "finite",
        "automata",
        "[",
        "6",
        "]",
        "."
      ]
    },
    {
      "sentence": "FSM learning is related to FSM testing [32] .",
      "tokens": [
        "FSM",
        "learning",
        "is",
        "related",
        "to",
        "FSM",
        "testing",
        "[",
        "32",
        "]",
        "."
      ]
    },
    {
      "sentence": "In particular, notions similar to the nucleus of an FSM and to distinguishing suffixes of states, which are used to define characteristic samples, are also used in [12, 16] .",
      "tokens": [
        "In",
        "particular",
        ",",
        "notions",
        "similar",
        "to",
        "the",
        "nucleus",
        "of",
        "an",
        "FSM",
        "and",
        "to",
        "distinguishing",
        "suffixes",
        "of",
        "states",
        ",",
        "which",
        "are",
        "used",
        "to",
        "define",
        "characteristic",
        "samples",
        ",",
        "are",
        "also",
        "used",
        "in",
        "[",
        "12",
        ",",
        "16",
        "]",
        "."
      ]
    },
    {
      "sentence": "The connection between conformance testing and regular inference is made explicit in [8] and [32] describes how an active learning algorithm can be used for fault detection.",
      "tokens": [
        "The",
        "connection",
        "between",
        "conformance",
        "testing",
        "and",
        "regular",
        "inference",
        "is",
        "made",
        "explicit",
        "in",
        "[",
        "8",
        "]",
        "and",
        "[",
        "32",
        "]",
        "describes",
        "how",
        "an",
        "active",
        "learning",
        "algorithm",
        "can",
        "be",
        "used",
        "for",
        "fault",
        "detection",
        "."
      ]
    },
    {
      "sentence": "Reviewers of an earlier version of this paper pointed out the similarity of Moore and Mealy machines: a Moore machine is a special case of a Mealy machine where the output depends only on the state but not on the input; and a Mealy machine can be transformed into a Moore machine by delaying the output by one step.",
      "tokens": [
        "Reviewers",
        "of",
        "an",
        "earlier",
        "version",
        "of",
        "this",
        "paper",
        "pointed",
        "out",
        "the",
        "similarity",
        "of",
        "Moore",
        "and",
        "Mealy",
        "machines",
        ":",
        "a",
        "Moore",
        "machine",
        "is",
        "a",
        "special",
        "case",
        "of",
        "a",
        "Mealy",
        "machine",
        "where",
        "the",
        "output",
        "depends",
        "only",
        "on",
        "the",
        "state",
        "but",
        "not",
        "on",
        "the",
        "input",
        ";",
        "and",
        "a",
        "Mealy",
        "machine",
        "can",
        "be",
        "transformed",
        "into",
        "a",
        "Moore",
        "machine",
        "by",
        "delaying",
        "the",
        "output",
        "by",
        "one",
        "step",
        "."
      ]
    },
    {
      "sentence": "This similarity naturally raises the question to what extent methods to learn Mealy machines can be used to learn Moore machines (and vice versa).",
      "tokens": [
        "This",
        "similarity",
        "naturally",
        "raises",
        "the",
        "question",
        "to",
        "what",
        "extent",
        "methods",
        "to",
        "learn",
        "Mealy",
        "machines",
        "can",
        "be",
        "used",
        "to",
        "learn",
        "Moore",
        "machines",
        "(",
        "and",
        "vice",
        "versa",
        ")",
        "."
      ]
    },
    {
      "sentence": "Answering this question is beyond the scope of the current paper.",
      "tokens": [
        "Answering",
        "this",
        "question",
        "is",
        "beyond",
        "the",
        "scope",
        "of",
        "the",
        "current",
        "paper",
        "."
      ]
    },
    {
      "sentence": "However, note that an algorithm that learns a Mealy machine cannot be used as a black box to learn Moore machines, for two reasons: first, the input-output traces for a Moore machine are not directly compatible with Mealy machines, and therefore need to be transformed somehow; second, the learned Mealy machine must also be transformed into a Moore machine.",
      "tokens": [
        "However",
        ",",
        "note",
        "that",
        "an",
        "algorithm",
        "that",
        "learns",
        "a",
        "Mealy",
        "machine",
        "can",
        "not",
        "be",
        "used",
        "as",
        "a",
        "black",
        "box",
        "to",
        "learn",
        "Moore",
        "machines",
        ",",
        "for",
        "two",
        "reasons",
        ":",
        "first",
        ",",
        "the",
        "input-output",
        "traces",
        "for",
        "a",
        "Moore",
        "machine",
        "are",
        "not",
        "directly",
        "compatible",
        "with",
        "Mealy",
        "machines",
        ",",
        "and",
        "therefore",
        "need",
        "to",
        "be",
        "transformed",
        "somehow",
        ";",
        "second",
        ",",
        "the",
        "learned",
        "Mealy",
        "machine",
        "must",
        "also",
        "be",
        "transformed",
        "into",
        "a",
        "Moore",
        "machine",
        "."
      ]
    },
    {
      "sentence": "The exact form of such transformations and their correctness remain to be demonstrated.",
      "tokens": [
        "The",
        "exact",
        "form",
        "of",
        "such",
        "transformations",
        "and",
        "their",
        "correctness",
        "remain",
        "to",
        "be",
        "demonstrated",
        "."
      ]
    },
    {
      "sentence": "Such transformations may also incur performance penalties which make a learning method especially designed for Moore machines more attractive in practice.",
      "tokens": [
        "Such",
        "transformations",
        "may",
        "also",
        "incur",
        "performance",
        "penalties",
        "which",
        "make",
        "a",
        "learning",
        "method",
        "especially",
        "designed",
        "for",
        "Moore",
        "machines",
        "more",
        "attractive",
        "in",
        "practice",
        "."
      ]
    }
  ]
}