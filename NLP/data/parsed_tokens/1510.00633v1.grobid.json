{
  "title": [
    {
      "sentence": "Distributed Multitask Learning",
      "tokens": [
        "Distributed",
        "Multitask",
        "Learning"
      ]
    }
  ],
  "abstract": [
    {
      "sentence": "We consider the problem of distributed multi-task learning, where each machine learns a separate, but related, task.",
      "tokens": [
        "We",
        "consider",
        "the",
        "problem",
        "of",
        "distributed",
        "multi-task",
        "learning",
        ",",
        "where",
        "each",
        "machine",
        "learns",
        "a",
        "separate",
        ",",
        "but",
        "related",
        ",",
        "task",
        "."
      ]
    },
    {
      "sentence": "Specifically, each machine learns a linear predictor in high-dimensional space, where all tasks share the same small support.",
      "tokens": [
        "Specifically",
        ",",
        "each",
        "machine",
        "learns",
        "a",
        "linear",
        "predictor",
        "in",
        "high-dimensional",
        "space",
        ",",
        "where",
        "all",
        "tasks",
        "share",
        "the",
        "same",
        "small",
        "support",
        "."
      ]
    },
    {
      "sentence": "We present a communication-efficient estimator based on the debiased lasso and show that it is comparable with the optimal centralized method.",
      "tokens": [
        "We",
        "present",
        "a",
        "communication-efficient",
        "estimator",
        "based",
        "on",
        "the",
        "debiased",
        "lasso",
        "and",
        "show",
        "that",
        "it",
        "is",
        "comparable",
        "with",
        "the",
        "optimal",
        "centralized",
        "method",
        "."
      ]
    }
  ],
  "introduction": [
    {
      "sentence": "Introduction Learning multiple tasks simultaneously allows transferring information between related tasks and for improved performance compared to learning each tasks separately [Caruana, 1997] .",
      "tokens": [
        "Introduction",
        "Learning",
        "multiple",
        "tasks",
        "simultaneously",
        "allows",
        "transferring",
        "information",
        "between",
        "related",
        "tasks",
        "and",
        "for",
        "improved",
        "performance",
        "compared",
        "to",
        "learning",
        "each",
        "tasks",
        "separately",
        "[",
        "Caruana",
        ",",
        "1997",
        "]",
        "."
      ]
    },
    {
      "sentence": "It has been successfully exploited in, e.g., spam filtering [Weinberger et al., 2009] , web search [Chapelle et al., 2010] , disease prediction [Zhou et al., 2013] and eQTL mapping [Kim and Xing, 2010] .",
      "tokens": [
        "It",
        "has",
        "been",
        "successfully",
        "exploited",
        "in",
        ",",
        "e.g.",
        ",",
        "spam",
        "filtering",
        "[",
        "Weinberger",
        "et",
        "al.",
        ",",
        "2009",
        "]",
        ",",
        "web",
        "search",
        "[",
        "Chapelle",
        "et",
        "al.",
        ",",
        "2010",
        "]",
        ",",
        "disease",
        "prediction",
        "[",
        "Zhou",
        "et",
        "al.",
        ",",
        "2013",
        "]",
        "and",
        "eQTL",
        "mapping",
        "[",
        "Kim",
        "and",
        "Xing",
        ",",
        "2010",
        "]",
        "."
      ]
    },
    {
      "sentence": "Tasks could be related to each other in a number of ways.",
      "tokens": [
        "Tasks",
        "could",
        "be",
        "related",
        "to",
        "each",
        "other",
        "in",
        "a",
        "number",
        "of",
        "ways",
        "."
      ]
    },
    {
      "sentence": "In this paper, we focus on the high-dimensional multi-task setting with joint support where a few variables are related to all tasks, while others are not predictive [Turlach et al., 2005; Obozinski et al., 2011; Lounici et al., 2011] .",
      "tokens": [
        "In",
        "this",
        "paper",
        ",",
        "we",
        "focus",
        "on",
        "the",
        "high-dimensional",
        "multi-task",
        "setting",
        "with",
        "joint",
        "support",
        "where",
        "a",
        "few",
        "variables",
        "are",
        "related",
        "to",
        "all",
        "tasks",
        ",",
        "while",
        "others",
        "are",
        "not",
        "predictive",
        "[",
        "Turlach",
        "et",
        "al.",
        ",",
        "2005",
        ";",
        "Obozinski",
        "et",
        "al.",
        ",",
        "2011",
        ";",
        "Lounici",
        "et",
        "al.",
        ",",
        "2011",
        "]",
        "."
      ]
    },
    {
      "sentence": "The standard approach is to use the mixed ℓ 1 /ℓ 2 or ℓ 1 /ℓ ∞ penalty, as such penalties encourage selection of variables that affect all tasks.",
      "tokens": [
        "The",
        "standard",
        "approach",
        "is",
        "to",
        "use",
        "the",
        "mixed",
        "ℓ",
        "1",
        "/ℓ",
        "2",
        "or",
        "ℓ",
        "1",
        "/ℓ",
        "∞",
        "penalty",
        ",",
        "as",
        "such",
        "penalties",
        "encourage",
        "selection",
        "of",
        "variables",
        "that",
        "affect",
        "all",
        "tasks",
        "."
      ]
    },
    {
      "sentence": "Using a mixed norm penalty leads to better performance in terms of prediction, estimation and model selection compared to using the ℓ 1 norm penalty, which is equivalent to considering each task separately.",
      "tokens": [
        "Using",
        "a",
        "mixed",
        "norm",
        "penalty",
        "leads",
        "to",
        "better",
        "performance",
        "in",
        "terms",
        "of",
        "prediction",
        ",",
        "estimation",
        "and",
        "model",
        "selection",
        "compared",
        "to",
        "using",
        "the",
        "ℓ",
        "1",
        "norm",
        "penalty",
        ",",
        "which",
        "is",
        "equivalent",
        "to",
        "considering",
        "each",
        "task",
        "separately",
        "."
      ]
    },
    {
      "sentence": "Shared support multi-task learning is generally considered in a centralized setting where data from all tasks is available on a single machine, and the estimator is computed using a standard single-thread algorithm.",
      "tokens": [
        "Shared",
        "support",
        "multi-task",
        "learning",
        "is",
        "generally",
        "considered",
        "in",
        "a",
        "centralized",
        "setting",
        "where",
        "data",
        "from",
        "all",
        "tasks",
        "is",
        "available",
        "on",
        "a",
        "single",
        "machine",
        ",",
        "and",
        "the",
        "estimator",
        "is",
        "computed",
        "using",
        "a",
        "standard",
        "single-thread",
        "algorithm",
        "."
      ]
    },
    {
      "sentence": "With the growth of modern massive data sets, there is a need to revisit multi-task learning in a distributed setting, where tasks and data are distributed across machines and communication is expensive.",
      "tokens": [
        "With",
        "the",
        "growth",
        "of",
        "modern",
        "massive",
        "data",
        "sets",
        ",",
        "there",
        "is",
        "a",
        "need",
        "to",
        "revisit",
        "multi-task",
        "learning",
        "in",
        "a",
        "distributed",
        "setting",
        ",",
        "where",
        "tasks",
        "and",
        "data",
        "are",
        "distributed",
        "across",
        "machines",
        "and",
        "communication",
        "is",
        "expensive",
        "."
      ]
    },
    {
      "sentence": "In particular, we consider a setting where each machine holds one \"task\" and its related data.",
      "tokens": [
        "In",
        "particular",
        ",",
        "we",
        "consider",
        "a",
        "setting",
        "where",
        "each",
        "machine",
        "holds",
        "one",
        "``",
        "task",
        "''",
        "and",
        "its",
        "related",
        "data",
        "."
      ]
    },
    {
      "sentence": "We develop an efficient distributed algorithm for multi-task learning that exploits shared sparsity between tasks.",
      "tokens": [
        "We",
        "develop",
        "an",
        "efficient",
        "distributed",
        "algorithm",
        "for",
        "multi-task",
        "learning",
        "that",
        "exploits",
        "shared",
        "sparsity",
        "between",
        "tasks",
        "."
      ]
    },
    {
      "sentence": "Our algorithm (DSML) requires only one round of communication between the workers and the central node, involving each machine sending a vector to the central node and receiving back a support set.",
      "tokens": [
        "Our",
        "algorithm",
        "(",
        "DSML",
        ")",
        "requires",
        "only",
        "one",
        "round",
        "of",
        "communication",
        "between",
        "the",
        "workers",
        "and",
        "the",
        "central",
        "node",
        ",",
        "involving",
        "each",
        "machine",
        "sending",
        "a",
        "vector",
        "to",
        "the",
        "central",
        "node",
        "and",
        "receiving",
        "back",
        "a",
        "support",
        "set",
        "."
      ]
    },
    {
      "sentence": "Despite the limited communication, our algorithm enjoys the same theoretical guarantees, in terms of the leading term in reasonable regimes and mild conditions, as the centralized approach.",
      "tokens": [
        "Despite",
        "the",
        "limited",
        "communication",
        ",",
        "our",
        "algorithm",
        "enjoys",
        "the",
        "same",
        "theoretical",
        "guarantees",
        ",",
        "in",
        "terms",
        "of",
        "the",
        "leading",
        "term",
        "in",
        "reasonable",
        "regimes",
        "and",
        "mild",
        "conditions",
        ",",
        "as",
        "the",
        "centralized",
        "approach",
        "."
      ]
    },
    {
      "sentence": "Table 1 summarizes our support recovery guarantees compared to the centralized (group lasso) and local (lasso) approaches, while",
      "tokens": [
        "Table",
        "1",
        "summarizes",
        "our",
        "support",
        "recovery",
        "guarantees",
        "compared",
        "to",
        "the",
        "centralized",
        "(",
        "group",
        "lasso",
        ")",
        "and",
        "local",
        "(",
        "lasso",
        ")",
        "approaches",
        ",",
        "while"
      ]
    }
  ]
}