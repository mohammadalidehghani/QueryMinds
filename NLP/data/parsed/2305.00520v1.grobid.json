{
  "title": "The ART of Transfer Learning: An Adaptive and Robust Pipeline",
  "abstract": "Transfer learning is an essential tool for improving the performance of primary tasks by leveraging information from auxiliary data resources. In this work, we propose Adaptive Robust Transfer Learning (ART), a flexible pipeline of performing transfer learning with generic machine learning algorithms. We establish the non-asymptotic learning theory of ART, providing a provable theoretical guarantee for achieving adaptive transfer while preventing negative transfer. Additionally, we introduce an ART-integrated-aggregating machine that produces a single final model when multiple candidate algorithms are considered. We demonstrate the promising performance of ART through extensive empirical studies on regression, classification, and sparse learning. We further present a real-data analysis for a mortality study.",
  "introduction": "INTRODUCTION The age of rapid technological change is unfolding in real time, empowering the collection of massive amounts of data in a variety of fields. Despite this, many fields still struggle with data acquisition with limited sample sizes, particularly in experiments that involve human or animal subjects and can be prohibitively expensive. To improve the performance of the primary task on those occasions, transfer learning has been widely advocated as a means of leveraging knowledge from available auxiliary data that are different while related to the primary data. Successful applications of transfer learning in data-scarce fields include drug development (Turki, Wei, & Wang 2017) , clinical trials (Bellot & van der Schaar 2019) , and material sciences (Hutchinson et al. 2017 ), among others. For an overview of transfer learning methodologies and applications, interested readers may refer to survey papers by Pan and Yang (2009) , Weiss, Khoshgoftaar, and Wang (2016) , Niu, Liu, Wang, and Song (2020) , and Zhuang et al. (2020) . Although transfer learning has achieved pervasive success and shows great promise, there is no guarantee that it will always improve performance -there is no free lunch for transfer learning. When a large discrepancy exists between the primary and auxiliary data, the performance of the primary estimator is likely to be negatively affected by auxiliary data. This phenomenon is referred to as \"negative transfer\" (Rosenstein, Marx, Kaelbling, & Dietterich 2005 ; Z. Wang, Dai, Póczos, & Carbonell 2019) . Therefore, the success of a transfer learning method largely depends on its ability to be robust against negative transfer. As quoted from the survey paper Zhuang et al. (2020) , \"The negative transfer still needs further systematic analyses.\" In recent literature, the study of negative transfer has been embraced from the perspective of statistical guarantees for transfer learning. Bastani (2021) studied estimation and prediction in high-dimensional linear models with one informative auxiliary data, where the sample size of the auxiliary data is required to be larger than its dimension. Li, Cai, and Li (2021) proposed trans-lasso under a more general setting allowing for multiple auxiliary data, which can be even high-dimensional, i.e., the size can be smaller than the dimension. Trans-lasso has been shown to improve the learning efficiency with known informative auxiliary data and can be robust to non-informative auxiliary data. The idea of trans-lasso was further extended to generalized linear models in Tian and Feng (2022) . Cai and Wei (2021) proposed an estimation algorithm with a faster convergence arXiv:2305.00520v1 [stat.ML] 30 Apr 2023 Algorithm 1 ART: Adaptive and Robust Transfer Learning Pipeline Input: Primary data T (0) = {(x (0) i , y (0) i )} n 0 i=1 and M auxiliary data T (m) = {(x (m) i , y (m) i )} nm i=1 , for m = 1, 2, . . . , M . 1: Split the primary data into two parts: T (0) train = {(x (0) i , y (0) i )} n 0,train i=1 and T (0) test = {(x (0) i , y (0) i )} n 0 i=n 0,train +1 . 2: Fit the model ĝ(0) by A(T (0) train ). 3: for m = 1 to M do 4: Stack T (m) with T (0) train to have T (m) , and obtain the model ĝ(m) by A( T (m) ).",
  "body": "INTRODUCTION The age of rapid technological change is unfolding in real time, empowering the collection of massive amounts of data in a variety of fields. Despite this, many fields still struggle with data acquisition with limited sample sizes, particularly in experiments that involve human or animal subjects and can be prohibitively expensive. To improve the performance of the primary task on those occasions, transfer learning has been widely advocated as a means of leveraging knowledge from available auxiliary data that are different while related to the primary data. Successful applications of transfer learning in data-scarce fields include drug development (Turki, Wei, & Wang 2017) , clinical trials (Bellot & van der Schaar 2019) , and material sciences (Hutchinson et al. 2017 ), among others. For an overview of transfer learning methodologies and applications, interested readers may refer to survey papers by Pan and Yang (2009) , Weiss, Khoshgoftaar, and Wang (2016) , Niu, Liu, Wang, and Song (2020) , and Zhuang et al. (2020) . Although transfer learning has achieved pervasive success and shows great promise, there is no guarantee that it will always improve performance -there is no free lunch for transfer learning. When a large discrepancy exists between the primary and auxiliary data, the performance of the primary estimator is likely to be negatively affected by auxiliary data. This phenomenon is referred to as \"negative transfer\" (Rosenstein, Marx, Kaelbling, & Dietterich 2005 ; Z. Wang, Dai, Póczos, & Carbonell 2019) . Therefore, the success of a transfer learning method largely depends on its ability to be robust against negative transfer. As quoted from the survey paper Zhuang et al. (2020) , \"The negative transfer still needs further systematic analyses.\" In recent literature, the study of negative transfer has been embraced from the perspective of statistical guarantees for transfer learning. Bastani (2021) studied estimation and prediction in high-dimensional linear models with one informative auxiliary data, where the sample size of the auxiliary data is required to be larger than its dimension. Li, Cai, and Li (2021) proposed trans-lasso under a more general setting allowing for multiple auxiliary data, which can be even high-dimensional, i.e., the size can be smaller than the dimension. Trans-lasso has been shown to improve the learning efficiency with known informative auxiliary data and can be robust to non-informative auxiliary data. The idea of trans-lasso was further extended to generalized linear models in Tian and Feng (2022) . Cai and Wei (2021) proposed an estimation algorithm with a faster convergence arXiv:2305.00520v1 [stat.ML] 30 Apr 2023 Algorithm 1 ART: Adaptive and Robust Transfer Learning Pipeline Input: Primary data T (0) = {(x (0) i , y (0) i )} n 0 i=1 and M auxiliary data T (m) = {(x (m) i , y (m) i )} nm i=1 , for m = 1, 2, . . . , M . 1: Split the primary data into two parts: T (0) train = {(x (0) i , y (0) i )} n 0,train i=1 and T (0) test = {(x (0) i , y (0) i )} n 0 i=n 0,train +1 . 2: Fit the model ĝ(0) by A(T (0) train ). 3: for m = 1 to M do 4: Stack T (m) with T (0) train to have T (m) , and obtain the model ĝ(m) by A( T (m) ). 5: Set w m,n 0,train +1 = πm such that πm ≥ 0 and M m=0 πm = 1. 6: For each m ≥ 0 and n 0,train + 2 ≤ i ≤ n 0 , calculate the weights w m,i = πm exp -λ i-1 j=n 0,train +1 L y (0) j , ĝ(m) (x (0) j ) M m =0 π m exp -λ i-1 j=n 0,train +1 L y (0) j , ĝ(m ) (x (0) j ) . (1) 7: end for 8: Output the final model: gART (x) = M m=0   n 0 i=n 0,train +1 w m,i n 0 -n 0,train   ĝ(m) (x). (2) rate than the minimax rate in the single study setting for high-dimensional Gaussian graphical models. For general function classes, Tripuraneni, Jin, and Jordan (2021) proposed meta-learning algorithms with theoretical underpinnings to estimate multiple linear regression models which share a common, low-dimensional linear representation. Hanneke and Kpotufe (2022) demonstrated that without access to distributional information, no algorithm could guarantee to improve the convergence rate with enlarging auxiliary data and primary data being fixed. The aforementioned theoretical studies mainly focused on certain methods under the framework of transfer learning. In this work, we consider a more general transfer learning framework called the Adaptive and Robust Transfer learning (ART) pipeline. ART is flexible and applicable to generic regression and classification methods rather than focusing on specific methods. The way that ART utilizes auxiliary data to supply information for the primary data is inspired by adaptive regression by mixing proposed in Yang (2001) . With some random data splittings, primary and auxiliary data are aggregated through an exponential weighting scheme. We shall show a theoretical guarantee of robustness against the negative transfer for ART. The ART predictor has a prediction risk smaller than the best candidate's prediction risk plus a small penalty term, and the penalty term is the price to pay to achieve adaptivity without knowing which candidate is the best. In addition, when transfer learning is performed with multiple candidate algorithms, we propose a new method called ART-Integrated-Aggregating Machine (ART-I-AM) that aggregates those candidate algorithms under the framework of ART, automatically outputting a single model for the final prediction. Thus ARM-I-AM does not need the effort of selecting an algorithm, say by cross-validation, as is typically done in the standard practice. Further, when ART is applied for a sparse learning method that outputs sparse representations of the coefficient, e.g., lasso Tibshirani (1996) , we present an ART variable importance measure that describes each predictor's contribution in the final predictions. The rest of this paper is organized as follows. Section 2 presents the methodological details of ART. Section 3 establishes the theoretical properties of our proposed methods. Section 4 contains simulation results, and Section 5 performs a real-data analysis for predicting the survival rate of ICU patients. Technical proofs and additional simulation results are presented in the supplemental file. METHODOLOGY Consider using a certain algorithm A to train a model ĝ on primary data T (0) = {(x (0) i , y (0) i )} n 0 i=1 , where each x i ∈ R p and y i ∈ R for regression and y i ∈ {0, 1} for classification. The performance of ĝ is assessed by its generalization error EL(y, ĝ(x)) with a loss function L, where the expectation is taken over the same data generating distribution of the data in T (0) . Despite the focus on binary labels for classification, the proposed method in this work can be naturally extended to multi-class classification. In this work, the ultimate goal is to enhance the performance of ĝ with possible help from external data resources. Suppose M auxiliary data, namely, T (m) = {(x (m) i , y (m) i )} nm i=1 , m = 1, 2, . . . , M , are available and they may potentially provide useful information for building ĝ. For simplicity, each T (m) is assumed to have the same predictors as T (0) and thus can be stacked upon T (0) . A new pipeline called ART is introduced for transfer learning and presented as in Algorithm 1. It is sketched as follows. We random split the primary data into two parts T train to have T (m) . We fit each ĝ(m) , m = 0, 1, 2, . . . , M , by running the algorithm A on T (0) train and each T (m) , respectively. The models ĝ(m) are then aggregated according to an exponential-weighting scheme with the weights given in (1), yielding the final ART estimate gART . For the sake of exposition, in Algorithm 1, only a single random split Algorithm 2 ART-I-AM: ART-Integrated-Aggregating Machines Input: Primary data T (0) = {(x (0) i , y (0) i )} n 0 i=1 and M auxiliary data T (m) = {(x (m) i , y (m) i )} nm i=1 , for m = 1, 2, . . . , M . Candidate algorithms: A 1 , A 2 , . . . , A R . 1: Random split the primary data into two parts: T (0) train = {(x (0) i , y (0) i )} n 0,train i=1 and T (0) test = {(x (0) i , y (0) i )} n 0 i=n 0,train +1 . 2: for r = 1 to R do 3: Fit the model ĝ(0,r) by A r (T (0) train ). 4: end for 5: for m = 1 to M do 6: Stack T (m) with T (0) train to have T (m) 7: for r = 1 to R do 8: Otain the model ĝ(m,r) by A r ( T (m) ). 9: Set w m,r,n 0,train +1 = πm,r such that πm,r ≥ 0 and M m=0 R r=1 πm,r = 1. 10: For each n 0,train + 2 ≤ i ≤ n 0 , calculate the weights w m,r,i = πm,r exp -λ i-1 j=n 0,train +1 L y (0) j , ĝ(m,r) (x (0) j ) M m =0 R r =1 π m r exp -λ i-1 j=n 0,train +1 L y (0) j , ĝ(m ,r ) (x (0) j ) . 11: end for 12: end for 13: Output the final model: gART (x) = M m=0 R r=1   n 0 i=n 0,train +1 w m,r,i n 0 -n 0,train   ĝ(m,r) (x). on the primary data is presented, while the algorithm can be repeated to perform multiple random splits until the weights converge, making the output gART more stable at the end. The ART pipeline is generically applicable under both regression and classification settings, which differ in Algorithm 1 only in the choice of the loss function L when assessing the accuracy and determining the weights. For regression problems, a common choice is L(y, ŷ) = (y -ŷ) 2 . For classification problems, with y ∈ {0, 1}, the cross entropy, L(y, ĝ(x)) = -y log ĝ(x)-(1-y) log(1-ĝ(x)), is employed, where ĝ(x) is an estimate of the conditional probability P (y = 1|x) being yielded by A. The conditional probabilities can be intrinsically estimated by some algorithms such as logistic regression, random forest, AdaBoost, etc; otherwise, we recommend using the classification calibration approach as a post-hoc manner: for example, Platt scaling (Platt et al. 1999) , which transfers the support vector machine (SVM, Cortes & Vapnik 1995) outputs into probabilities. Other examples of classification calibration methods include beta calibration (Kull, Silva Filho, & Flach 2017) , isotonic regression (Zadrozny & Elkan 2002) , and confidence calibration (Guo, Pleiss, Sun, & Weinberger 2017) , among many others. Remark 1. Algorithm 1 can be simplified. The weights w m,i calculated in (1) are attributed to the cumulative performance of ĝ(m) on {(x (0) t , y (0) t )} i t=n 0,train +1 from T (0) test . To reduce the computational cost, we suggest the use of g(x) = M m=0 wmĝ (m) (x) and wm = πme -λ n 0 j=n 0,train +1 L y (0) j ,ĝ (m) (x (0) j ) M m =0 π m e -λ n 0 j=n 0,train +1 L y (0) j ,ĝ (m ) (x (0) j ) , in place of equations ( 1 ) and ( 2 ) in Algorithm 1. Remark 2. Regarding the initial weighting choice πm for each auxiliary data, larger weights are typically recommended for more sizeable and trustful auxiliary data. Nevertheless, the equal weights πm ≡ 1/(M + 1) usually work well in practice. As will be seen in Theorem 1, the upper bound of the generalization error of the final estimator gART establishes a trade-off between the model complexity and accuracy. In addition, we recommend n 0,train = n 0 /2 , and shall discuss the choice of λ in Remark 3. Machine learning practitioners often need to choose from a wide variety of applicable algorithms to solve a certain problem. Given the flexibility of ART, we propose an ART-integrated-aggregating machine (ART-I-AM) in the context of transfer learning. ART-I-AM integrates multiple algorithms, e.g., the SVM, random forest, and boosting, in the ART pipeline, automatically producing a single output without extra tuning efforts. More details about ART-I-AM are summarized in Algorithm 2. ART also provides a natural way of calculating variable importance as long as the algorithm A outputs a set of variables that are important for prediction. Lasso is utilized to demonstrate the idea in this work, while other sparse penalties like elastic-net (Zou & Hastie 2005) , SCAD (Fan & Li 2001) , and MCP (Zhang 2010 ) can be imposed in the algorithm A to produce sparse coefficients as well. With slight abuse of notation, we denote X j ∈ ĝ(m) if the j-th predictor X j is selected by the model ĝ(m) trained by A( T (m) ). For example, variable selection methods (usually enjoy variable selection consistency) like Lasso selects a sparse set of variables. Another example is the random forest, which outputs the variable importance for each feature. In that case, users can determine their own cutoff to select the variables (e.g., top 10 variables or the set of variables with importance greater than 3). Note that if the method A does not carry out variable selection, the ART variable importance is not well-defined. Definition 1. The ART variable importance for the jth predictor is defined as VI j = M m=0 wmI(X j ∈ ĝ(m) ), where I(•) is the indicator function and wm is given in Algorithm 1. The ART variable importance cannot lay down a dichotomy rule about whether a predictor is important, while it is a relative importance measure for each predictor's contribution to the final model gART , bearing a resemblance to the variable importance that arises in random forest and boosting. THEORY In this section, we establish the non-asymptotic statistical learning theory of ART. We first introduce some notations. The generalization error of an estimated function ĝ is assessed based on a given loss EL(y, ĝ(x)), where the expectation E is taken over (x, y) that is drawn from (X, Y ) and all pairs of data that used to generate ĝ. For example, ĝ( 1 ) is trained based on the data {(x (0) i , y (0) i )} and T (1) , and then the expectation in EL(y, ĝ(1) (x)) is taken over all (x, y) that is drawn from (X, Y ), and T (0) train ∪ T (1) . Let | • | denote the Euclidean norm. For a function g, let ||g|| 2 := E|g(X)| 2 = |g(X)| 2 P X (dX) denote the L 2 norm of g with respect to the distribution of X. When no confusion arises, we write the final model of Algorithm 1, gART , as g, for the sake of exposition. ART for regression Assume the primary data T (0) = {x (0) i , y (0) i } n 0 i=1 are i.i.d. realizations of the random vector (X, Y ), where X = (X 1 , ..., Xp) ∈ R p and Y ∈ R. Denote the conditional mean function as g(X) = E(Y |X) and the conditional variable function as σ 2 (X) = Var(Y |X). We consider the data-generating model Y = g(X) + σ(X) , (3) where, without loss of generality, the error term ∈ R has E( |X) = 0 and Var( |X) = 1. Assumption 1 (Boundedness). Assume that the mean function, the estimated mean functions, and the variance function are upper bounded, i.e., there exists a positive constant A such that |g(X)| ≤ A, sup m |ĝ (m) (X)| ≤ A, and σ(X) ≤ A almost surely. The above boundedness assumption about mean and variance functions are mild and common in the model averaging/aggregation literature. Assumption 2. The loss function L(a, b) is convex in b and can be written in the form ρ(a -b) for some function ρ(•). In addition, there exists two positive constants c 1 and c 2 such that 2c 1 |t 1 -t 2 | ≤ |ρ (t 1 )-ρ (t 2 )| ≤ 2c 2 |t 1 -t 2 | and c 1 (t 1 -t 2 ) 2 ≤ ρ(t 1 )-ρ(t 2 )-ρ (t 2 )(t 1 -t 2 ) ≤ c 2 (t 1 -t 2 ) 2 for t 1 , t 2 ∈ R. Assumption 2 requires that the function ρ has a Lipschitz continuous first-order derivative, and its second-order derivative is bounded. Many loss functions satisfy this general assumption, for example, the squared error loss L(a, b) = (a -b) 2 and the asymmetric error loss Lτ (a, b) = |τ -I(a -b < 0)| • (a -b) 2 with τ ∈ (0, 1). Assumption 3. Given X, the noise is sub-exponential. A random variable Z ∈ R is called a sub-exponential variable (Vershynin 2010) if its sub-exponential norm is bounded, i.e., sup k≥1 k -1 (E|Z| k ) 1/k < ∞. If the noise term is independent of X, then the assumption reduces to require a sub-exponential noise. The sub-exponential family contains random variables whose moment generating functions exist in a neighborhood of 0. This is a large and general class. Theorem 1. Recall that ĝ(0) is the estimate without transfer learning. Under Assumptions 1, 2, and 3, the excess risk of the final estimate g in Algorithm 1 is upper bounded as EL(Y, gART (X)) -EL(Y, ĝ(0) (X)) ≤ log M λñ , (4) where ñ = n 0 -n 0,train , if the tuning parameter λ satisfies λ -1 ≥ [16 √ 2d 2 1 exp(e 2 d 2 1 /2) + 32c 2 2 A 2 exp(1/(16e 2 d 1 ))] • exp(2λc 2 A 2 )/2c 1 } and λ -1 ≥ 8e • d 1 A, where d 1 = 2c 2 A sup k≥1 k -1 (E| | k ) 1/k . As indicated by Theorem 1, the excess prediction risk of the proposed estimator g is upper bounded by a small penalty term 1/{λ(n 0 -n 0,train )}• log M . The penalty term is the price to pay to achieve the best performance without knowing which auxiliary data set is the best. Hence, our method still has good performance in the case where all auxiliary data give terrible transferred predictions, i.e., the negative transfer occurs, because the non-transferred model ĝ(0) (obtained by training the primary data T (0) without any auxiliary data) is included in the candidate pool. In other words, our method does not require the strong assumption that the auxiliary data should be transferable. Note that the upper bound is generally loose. We can further improve the transferred estimate g in line 2 of Algorithm 1. Currently, for each auxiliary data, we simply stack it with the primary data and obtain a transferred estimate A(T (0) train ). Different transfer learning algorithms have their own way of utilizing the auxiliary data. If we know a transfer learning method that has a much smaller excess risk, we can obtain A(T (0) train ) following that transfer learning method. In that case, the excess risk of our final transferred estimate will also improve. We want to emphasize that our algorithm applies to any machine learning method, at the cost of a loose bound in the theorem. Remark 3. The tuning parameter λ should not be too small; otherwise, the penalty term will be much larger than EL(Y, ĝ(0) (X)) and the upper bound becomes meaningless. In terms of the convergence rate, one only needs to make the penalty term 1/{λ(n 0 -n 0,train )} • log M = O(1/(n 0,train + nm)) since the term EL(Y, ĝ(0) (X)) converges to EL(Y, g(X)) at a rate no faster than 1/(n 0,train + nm). Thus the penalty term will not affect the convergence rate. In practice, we recommend the value λ = (n 0,train + nm)/(n 0 -n 0,train ) when at least one of the auxiliary data sizes is much larger than the primary data size; otherwise, we recommend λ = 1. In our simulations and real-data analysis, the choice λ = 1 works very well. Indeed, the proposed method is stable against the choice of λ in a wide range. ART for classification Suppose the primary data T (0) = {x (0) i , y (0) i } n 0 i=1 are i.i.d. realizations of the random vector (X, Y ), where X = (X 1 , ..., Xp) ∈ R p and Y ∈ 0, 1. Let g(X) = P (Y = 1|X) be the conditional probability of Y being 1 given the features X. Let the mth trained model ĝ(m) be an estimated function of f . Then the classifier for each new data point xnew is taken as I(ĝ (m) (xnew) > 0.5). Assumption 4. For each auxiliary data T (m) , there exists a positive constant 0 < Am < 0.5 such that ĝ(m) (x) ∈ (Am, 1 -Am) for any x. The constant sequence Am is allowed to converge to 0 as m → ∞. Assumption 4 is mild since the case g(x) = 0 or 1 is trivial for classification. Theorem 2. Under Assumption 4, the excess risk of the final estimate gART is upper bounded as E||g ART -g|| 2 2 - 2 A 2 m E||ĝ (0) -g|| 2 2 ≤ 2 log M n 0 -n 0,train . (5) Unlike the regression setting, we present the bound for the squared error loss. This is because when evaluating a classifier ĝ(X) ∈ 0, 1, the mean error probability EP (Y = ĝ(X)) is commonly considered. If the underlying conditional probability g(X) = P (Y = 1|X = X) is known, the mean error probability is minimized by the Bayes classifier g * (X) := I(g(X) > 0.5). It is then natural to consider the following measure for evaluating g: EP (Y = ĝ(X)) -P (Y = g * (X)). Let ĝ be an estimator of f . It is known that for any plug-in classifier I(ĝ(x) > 0.5), it satisfies EP (Y = ĝ(X)) -P (Y = g * (X)) ≤ 2(E||f -ĝ|| 2 2 ) 1/2 . The plug-in classifier I(g(X) > 0.5) in our method also satisfies this inequality. ART variable importance Theoretical properties of ART variable importance that is proposed in Definition 1 are derived in this section. Theorem 3. Define S to be the unknown set that contains all the important features in the conditional mean function g(•). If there exists some m ∈ {0, 1, ..., M } such that P (X j ∈ A(ĝ (m) )) → 1 (6) as n → ∞ for any X j ∈ S, we have min j:X j ∈S VI j P -→ 1 and max j:X j / ∈S VI j P -→ 0. The ART variable importance depends on A. As Theorem 3 stated, ART will retain the variable selection property of the original algorithm. The theorem does not hold if A does not provide variable importance measure (e.g., SVM) or the nice property (6) (e.g., random forest). SIMULATION STUDIES ART for regression With p = 10 and n = 50, we construct the primary data T (0) by independently sampling each x (0) i from Np(0, Σ), where i = 1, 2, . . . , n and Σ possesses the auto-regression correlation structure, i.e., Σ = (0.5 |i-j| ) p×p . Generate each response as y (0) i = β x (0) i + , where is from the standard normal distribution and independent of the predictors. The true coefficient of interest, β, is drawn from Np(1, Ip). To simulate the auxiliary data T (m) , each x (m) i is produced in the same way as x (0) i , and y (m) i = β (m) x (m) i + , where β (m) = β + ξ and ξ indicates the noise level. We consider three methods of handling the auxiliary data: (1) fit the least squares regression only on the primary data, giving rise to βLS , (2) grow a pooled data by stacking the primary data and all the M auxiliary data together, and fit the least squares regression on the pooled data, yielding βpool-LS , and (3) apply ART to obtain βART-LS . To assess the performance, we independently generate another 5,000 observations as test data following the same distribution of the primary data T (0) and evaluate the prediction error 5000 i=1 (ŷ i -y i ) 2 /5000 according to the test data. Example 4.1.1 We study the prediction errors of the three methods by varying M from 1 to 10, and the noise level ξ is fixed to be 0.5. As shown in the panel (a) of Figure A1 , the prediction error of βART-LS stays lower than that of βLS starting at M = 1, and declines quickly as M increases. This observation indicates that ART can effectively gain useful information from the auxiliary data. In contrast, the prediction error of βART-LS grows with M , hence directly treating the primary and auxiliary data equally brings more noise and exacerbates the accuracy of βpool-LS . The performance with different noise levels of the auxiliary data is further investigated. With M = 10 and ξ ranging from 0.1 to 1, the panel (b) of Figure A1 exhibits the prediction errors: the error curve of βART-LS is quite flat when the noise level ξ is small, indicating that ART consistently improves the original estimator with relatively low-level noise emerging in the auxiliary data; the prediction error approaches, but does not exceed, the error of the βLS when ξ rises. Nevertheless, the prediction accuracy of βpool-LS drops rapidly as ξ increases. Hence, when the auxiliary data are noisy, ART automatically switches the focus on the primary data and prevents the negative transfer, rather than naïvely trust the auxiliary data as does βpool-LS . Example 4.1.2 To further illustrate the robustness of ART against noisy data, we generate ten additional adversarial data, Ť (m) , which are of the same size as the primary data T (0) . For each m = 1, 2, . . . , 10 and i = 1, 2, . . . , n, the predictors m) are generated in the same way as the primary data T (0) . The response is obtained from x(m) i in Ť ( y(m) i = β(m) x(m) i + where β(m) = -β (0) -ξ, that is, the coefficients in the auxiliary data T (m) and the adversarial data Ť (m) are the opposite. The panel (c) of Figure A1 displays the prediction errors against M , the number of auxiliary data. Remarkably, the prediction errors of βART-LS are almost identical to the case when the adversarial data are absent. This observation demonstrates the robustness of the ART framework against noisy or even adversarial data. On the other hand, the prediction errors βpool-LS are extremely high. Even when M is as high as 10, the prediction error is 42.26, and it further rises to 162.41 when M = 1. The pooled estimator βpool-LS breaks down when the external data resources are excessively noisy. ART for classification Example 4.2.1 We first consider a commonly used linear classifier -logistic regression. Similar to Section 4.1, with p = 10, we independently generate each predictor x i from the same distribution Np(0, Σ) for one primary data, M auxiliary data, and 10 adversarial data, all of which are of the size n = 50. For the primary data, each binary response is drawn from the Bernoulli distribution with the probability P (y i = 1) = 1/(1+exp(-π i )), where π i = β x i and β is generated from Np(1, Ip). The binary responses in the auxiliary and adversarial data are generated in the same way as the primary data, except the coefficients are different: for the mth auxiliary data, β (m) = β + ξ, and the mth adversarial data, β(m) = -β -ξ, where ξ is the noise level. We independently generate 5000 data points forming the test data to evaluate the prediction accuracy. We fit logistic regression, ĝlogit , ĝpool-logit , ĝART-logit , on the primary data, on the pooled data, and with ART, respectively. The panel (a) of Figure A2 plots the prediction error over M with ξ = 0.5. We see ĝpool-logit is greatly affected by the noise in external data resource, and ĝART-logit outperforms ĝlogit when M > 2. The panel (b) of Figure A2 plots the prediction error over ξ with M = 5, and it reveals the robustness of ART against the noise level, while ĝpool-logit incurs higher error as ξ increases. Example 4.2.2 To illustrate the wide applicability of ART, we consider more general classifiers. The primary data are generated from a Gaussian mixture distribution. The positive class is assemble by 5 j=1 0.2N(µ j+ , Σ) with each µ j+ drawn from N(µ + , 1), where µ + = µ(1, . . . , 1, 0, . . . , 0), and the negative class is generated according to 5 j=1 0.2N(µ j-, Σ) with each µ j-drawn from N(µ -, 1), where µ + = -µ(1, . . . , 1, 0, . . . , 0). We set µ = 1. The auxiliary and adversarial data are generated in the same way, except the auxiliary data have µ (m) = µ + ξ while the adversarial data have μ(m) = -µ -ξ. We fit random forest, kernel SVM, AdaBoost, and neural nets, using the R packages randomForest Liaw and Wiener (2002) , magicsvm (B. Wang & Zou 2022) , gbm (Greenwell, Boehmke, Cunningham, & Developers 2022) , and nnet (Venables & Ripley 2002) , respectively, with tuning parameters selected based on cross-validation or out-of-bag errors. We see that ART enhances the four classifiers fitted on the primary data as soon as M > 1 as shown in the left panel, and it is robust against the adversarial data as observed in the right panel. Among the four classifiers, neural nets perform better than the rest, and ART advances the accuracy on top of them. In addition, ART-I-AM also outperforms the SVM and AdaBoost, and performs similarly to the neural nets, which deliver the best accuracy among the four classifiers. ART sparse learning ART can naturally account for high-dimensional data analysis when it is coupled with sparse penalized methods such as lasso. We compare ART with lasso which is fitted with the R package glmnet (Friedman, Hastie, & Tibshirani 2010 ) and the trans-lasso method proposed in Li et al. (2021) . Example 4.3.1 Following simulation settings in Li et al. (2021) , we set the dimension p = 200, the sample size for the primary and each auxiliary data, n 0 = 150 and nm = 100, respectively. All x i are drawn from N(0, 1). To generate the sparse coefficients, for the primary data, the first 16 coordinates of β are 0.3 and all the others are zeros. For the mth auxiliary data, m = 1, 2, . . . , M , define a set H (m) including the first 16 coordinates and 12 other randomly selected coordinates, and let β (m) = β + v, where v j = 2ξ if j ∈ H (m) or 0 otherwise, for each j = 1, 2, . . . , 200. Plotted in the panel (a) of Figure A4 are the prediction errors of βlasso , βtrans-lasso , and βART-lasso over M , and plotted in the panel (b) are the prediction errors over the noise level ξ. It is observed that βART-lasso consistently improves βlasso in all the examples, and βlasso outperforms βtrans-lasso when more auxiliary data are available. ART is more robust over high noise levels than the trans-lasso approach. With M fixed to be 5, Figure A5 depicts a relative importance spectrum obtained from ART, where the noise level ξ = 0.1, 0.4, 0.7, 1 are used to exemplify the results. ART sets a clear cut-off in the importance of the first 16 active coefficients, and the growing noise level brings only little increase in the relative importance of the inactive coefficients. A REAL APPLICATION ON INTENSIVE CARE UNIT MORTALITY Intensive care units (ICU) are lifesaving for urgent and life-threatening patients, thanks to advanced therapeutic and monitoring technologies, as well as large provider-to-patient ratios. On the other hand, the lifesaver comes with a high cost. Since back in 2005, the total cost of ICU has been around 30% of the healthcare budget and been over 0.66% of the gross domestic product (Halpern & Pastores 2010 2015) , making ICU a highly limited healthcare resource. It is of critical importance to triage patients with a reasonable estimate of the post-ICU survival rate. The outcome can help patients and their families better prepare the possible long-term ICU care that may have poor outcomes despite high expenses, or help providers decide on an alternative of ICU, e.g., progressive care (Stacy 2011) . In this work, we apply ART to study the mortality rate of the ICU. We collected data from a multi-center database, eICU Collaborative Research Database (Pollard et al. 2018) , comprising de-identified health data across the United States between 2014 and 2015. To predict the survival status of the individuals, we only used their information when they were at the ICU admission and excluded all the discharge information. We grouped the patient ages into six categories: infants & children (0-12), teens (13-19), early adults (20-39), middle-aged adults (40-59), senior adults (60-89), and extremely senior adults (>89). To reduce the admission diagnosis categories, we merged the categories with low mortality rates as \"others\". Our goal is to predict the post-ICU survival status of the teaching hospitals in the data. By grouping the hospitals by their region (Midwest, Northeast, South, and West) and capacity (Large if over 500 beds and Small otherwise) and using the undersampling method to have the same number of survived and decreased patients, we generated four sub-data, Midwest-Small (n = 72, mortality rate p = 9.47%), Northeast-Large (n = 1230, p = 8.84%), South-Large (n = 644, p = 6.93%), South-Small (n = 210, p = 4.29%), and West-Large (n = 372, p = 6.59%). The estimation of the survival status of the Midwest-Small sub-data is of particular interest due to its relatively high mortality rate, while the problem is challenging because of the relatively small sample size. Consequently, we treat Midwest-Small as the primary data and appoint the other three subdata as the auxiliary data in the ART framework. To assess the performance, we randomly split the primary data by having 50 patients for training and the rest for evaluating the classification error. ART is applied on random forest, AdaBoost, and neural nets, while SVM is not included due to its high computational cost. With 50 random splits, the averaged classification error is exhibited in Table A1 , where we see AdaBoost delivers lower classification error than random forest and neural nets when these classifiers are fitted on only the primary data. The errors of random forest and neural nets decrease when the classifiers are fitted on the pooled data stacking the primary and the three auxiliary data, whereas the pooling strategy increases the error of AdaBoost. This observation reflects the potential risk of the negative transfer. For all three classifiers, ART outperforms both the original and pooled algorithms. Last, we observe that ART-I-AM delivers the same classification accuracy as the best classifier. CONCLUSION In this work, we propose ART, an adaptive and robust pipeline designed for applying transfer learning to general statistical and machine learning methods. Through examples of regression, classification, and sparse learning methods, we demonstrate that ART can effectively enhance estimation by extracting and digesting useful information from auxiliary data, while remaining resilient to noisy data sources. As ART is a general pipeline that is not specifically tailored to any particular methods, it would be intriguing to explore its performance on large-scale image and text data with deep learning algorithms in future research. APPENDIX A TECHINICAL PROOFS A.1 Proof of Theorem 1. Denote q n 0 n 0,train = M m=0 πm exp    -λ n 0 i=n 0,train +1 L y i , ĝ(m) (x (0) i )    . ( A1 ) We can decompose q n 0 n 0,train as q n 0 n 0,train = M m=0 πm exp -λL yn 0,train , ĝ(m) (x (0) n 0,train +1 ) × M m=0 πm exp -λ n 0,train +2 i=n 0,train +1 L y i , ĝ(m) (x (0) i ) M m=0 πm exp -λL y n 0,train +1 , ĝ(m) (x (0) n 0,train +1 ) × • • • × M m=0 πm exp -λ n 0 i=n 0,train +1 L y i , ĝ(m) (x (0) i ) M m=0 πm exp -λ n 0 -1 i=n 0,train +1 L y i , ĝ(m) (x (0) i ) = n 0 i=n 0,train +1 M m=0 w m,i exp -λL y i , ĝ(m) (x (0) i ) . ( A2 ) Let J be a discrete random variable with P (J = m) = w m,i , m ≥ 0, where i ∈ {n 0,train + 1, ..., n 0 } is fixed. Let ν be the discrete measure induced by J on Z + such that ν(m) = P (J = m). Denote h(J) = -L(y (0) i , ĝ(J) (x (0) i )). We have that M m=0 w m,i exp -λL y (0) i , ĝ(m) (x (0) i ) = Eν exp(λh(J)). By Lemma 3.6.1 of Catoni and Picard (2004) , we have log Eν exp(λh(J)) ≤ λEν h(J) + λ 2 2 Varν (h(J)) exp λ max 0, sup γ∈[0,λ] M 3 νγ (h(J)) Varν γ (h(J)) , where the discrete measure νγ (m) = w m,i exp(γh(m)) M m=1 w m,i exp(γh(m)) for m ≥ 0 and M 3 νγ (h(J)) = Eν γ (h(J) -Eν γ (h(J))) 3 . Then sup γ∈[0,λ] M 3 νγ (h(J)) Varν γ (h(J)) ≤ sup γ∈[0,λ] sup m≥0 |h(m) -Eν γ h(J)| ≤2 sup m≥0 L y (0) i , ĝ(m) (x (0) i ) -L y (0) i , g(x (0) i ) ≤2|ρ (y (0) i -g(x (0) i ))| • sup m≥0 |ĝ (m) (x (0) i ) -g(x (0) i )| + 2c 2 sup m≥0 (ĝ (m) (x (0) i ) -g(x (0) i )) 2 ≤2|ρ (σ(x (0) i ) i )| • A + 2c 2 A 2 and Varν (h(J)) ≤ Eν L y (0) i , ĝ(J) (x (0) i ) -L y (0) i , Eν ĝ(J) (x (0) i ) 2 ≤ sup j≥0 ρ (y (0) i , ĝ(j) (x (0) i )) + c 2 |ĝ (j) (x (0) i ) -Eν ĝ(J) (x (0) i )| 2 Ev ĝ(J) (x (0) i ) -Eν ĝ(J) (x (0) i ) 2 ≤ sup j≥0 ρ (y (0) i , g(x (0) i )) + 4c 2 sup j≥0 |ĝ (j) (x (0) i ) -g(x (0) i )| 2 • Ev ĝ(J) (x (0) i ) -Eν ĝ(J) (x (0) i ) 2 ≤ ρ (σ(x (0) i ) i ) + 4c 2 A 2 Ev ĝ(J) (x (0) i ) -Eν ĝ(J) (x (0) i ) 2 , where the first two inequalities hold by Assumption 3. Furthermore, by Assumption 3, Ev L y (0) i , ĝ(J) (x (0) i ) -L y (0) i , Eν ĝ(J) (x (0) i ) ≥Ev ρ y (0) i -Eν ĝ(J) (x (0) i ) Eν ĝ(J) (x (0) i ) -ĝ(J) (x (0) i ) + c 1 Ev Eν ĝ(J) (x (0) i ) -ĝ(J) (x (0) i ) 2 =c 1 Ev Eν ĝ(J) (x (0) i ) -ĝ(J) (x (0) i ) 2 which leads to Ev(Eν ĝ(J) (x (0) i ) -ĝ(J) (x (0) i )) 2 ≤ 1 c 1 Ev L y (0) i , ĝ(J) (x (0) i ) -L y (0) i , Eν ĝ(J) (x (0) i ) . We have log Ev exp{λh(J)} ≤ -λEν L(y (0) i , ĝ(J) (x (0) i )) + λ 2 2 (ρ (σ(x (0) i ) i ) 2 + 16c 2 2 A 2 ) • exp 2λ|ρ (σ(x (0) i ) i )| • A • 1 c 1 Ev L y (0) i , ĝ(J) (x (0) i ) -L y i , Eν ĝ(J) (x (0) i ) • exp{2λc 2 A 2 }. (A3) Since any sub-exponential variable Z satisfies E exp (t|Z|) ≤ 2 exp(2e 2 d 2 1 t 2 ) and E Z 2 exp {t|Z|} ≤ d 4 exp(d 3 t 2 ) for any |t| ≤ d 2 /d 1 , where d 1 = sup k≥1 k -1 (E|Z| k ) 1/k , d 2 = 1/(4e), d 3 = 8e 4 d 2 1 , d 4 = 16 √ 2d 2 1 . Here, redefine d 1 = sup k≥1 k -1 (E |X |ρ (σ(X)) • | k ) 1/k ≤ 2c 2 A sup k≥1 k -1 (E| | k ) 1/k . By Assumption 3, the above inequalities hold for Z := given X. Taking expectation E y i |x (0) i ,(x (0) k ,y (0) k ) i-1 k=1 ,T (J) (denoted as E i for convenience) of both sides of the inequality (A3), for 2λA ≤ d 2 /d 1 we have E i log Ev exp{λh(J)} ≤ -λE i Eν L(y (0) i , ĝ(J) (x (0) i )) + λ 2 2 E i (d 2 exp(d 3 (2λA) 2 ) + 32c 2 2 A 2 exp(d 1 (2λA) 2 )) • 1 c 1 Ev L y (0) i , ĝ(J) (x (0) i ) -L y (0) i , Eν ĝ(J) (x (0) i ) • exp{2λc 2 A 2 }. By choosing a small enough λ such that λ 2 2 exp{2λc 2 A 2 } c 1 E i (d 2 exp(d 3 (2λA) 2 ) + 32c 2 2 A 2 exp(d 1 (2λA) 2 ))≤ λ, which gives E i log Eve λh(J) ≤ -λE i Eν L(y (0) i , ĝ(J) (x (0) i )) + λE i Ev L y (0) i , ĝ(J) (x (0) i ) -L y (0) i , Eν ĝ(J) (x (0) i ) = -λE i L y (0) i , Eν ĝ(J) (x (0) i ) . We have E log(1/q n 0 n 0,train ) = - n 0 i=n 0,train +1 E log M m=0 w m,i exp -λL y (0) i , ĝ(m) (x (0) i ) = - n 0 i=n 0,train +1 EE i log Ev exp -λL y (0) i , ĝ(J) (x (0) i ) ≥λ n 0 i=n 0,train +1 EL y (0) i , Ev ĝ(J) (x (0) i ) . We also have for each m ≥ 0, E log(1/q n 0 n 0,train ) ≤ log(1/πm) + λ n 0 i=n 0,train +1 EL y (0) i , ĝ(m) (x (0) i ) = log(1/πm) + λ(n 0 -n 0,train )EL Y, ĝ(m) (X) . Thus, by convexity, we have EL y (0) i , g(x (0) i ) ≤ 1 (n 0 -n 0,train ) n 0 i=n 0,train +1 EL y (0) i , Ev ĝ(J) (x (0) i ) log(1/πm) λ(n 0 -n 0,train ) + EL Y, ĝ(m) (X) , where the desired result follows. A.2 Proof of Theorem 2. Denote Kg(x, y) = g(x) y (1 -g(x)) 1-y as the joint density function of (X, Y ) with respect to the product measure µ × ν, where ν is the counting measure on {0, 1}. Denote gi (x) = m w m,i ĝ(m) (x), then K gi (x, y) = m w m,i K ĝ(m) (x, y). Take λ = 1 and the loss function in (A1) to be L y (0) i , ĝ(m) (x (0) i ) := -y (0) i log(ĝ (m) (x (0) i )) -(1 -y (0) i ) log(1 -ĝ(m) (x (0) i )), we then have q n 0 n 0,train = n 0 i=n 0,train +1 K gi (x i , y i ). Hence, n 0 i=n 0,train +1 E Kg(x, y) log Kg(x, y) K gi (x, y) µ × ν(dxdy) = n 0 i=n 0,train +1 E Kg(x (0) i , y (0) i ) log Kg(x (0) i , y (0) i ) K gi (x (0) i , y (0) i ) µ × ν(dx (0) i dy (0) i ) = n 0 i=n 0,train +1 E [Π n 0 i=n 0,train +1 Kg(x (0) i , y (0) i )] • log Kg(x (0) i , y (0) i ) K gi (x (0) i , y (0) i ) µ × ν(dx (0) n 0,train +1 dy (0) n 0,train +1 ) • • • µ × ν(dx (0) n 0 dy (0) n 0 ) =E [Π n 0 i=n 0,train +1 Kg(x (0) i , y (0) i )] • log Π n 0 i=n 0,train +1 Kg(x (0) i , y (0) i ) q n 0 n 0,train µ × ν(dx where we use change of variable for the first equality, the fact that Kg is a probability density function for the second equality, and the fact that the logarithm is an increasing function in the first inequality. We have Kg(x, y) log Kg(x, y) K ĝ(m) (x, y) µ × ν(dxdy) = g(x) log g(x) ĝ(m) (x) + (1 -g(x)) log 1 -g(x) 1 -ĝ(m) (x) µ(dx) ≤ 1 A 2 m ||g -ĝ(m) || 2 2 , where the first inequality follows from the fact that the K-L divergence is upper bounded by Chi-squared distance (D KL (g 1 ||g 2 ) := g 1 (x) log(g 1 (x)/g 2 (x))dx ≤ (g 1 -g 2 ) 2 /g 2 (x)dx for any probability densities g 1 and g 2 ), and the second inequality is due to the boundedness assumption. Next, we denote the squared Hellinger distance between g 1 and g 2 as d 2 H (g 1 , g 2 ) := ( √ g 1 -√ g 2 ) 2 dx. Then we have 1 2 n 0 i=n 0,train +1 E||g -gi || 2 2 ≤ n 0 i=n 0,train +1 Ed 2 H (Kg, K gi ) ≤ n 0 i=n 0,train +1 ED KL (Kg||K gi ) ≤ log(1/πm) + 1 A 2 m n 0 i=n 0,train +1 E||g -ĝ(m) || 2 2 , where the first inequality holds due to Ed 2 H (Kg 1 , Kg 2 ) = ( √ g 1 - √ g 2 ) 2 + ( 1 -g 1 -1 -g 2 ) 2 µ(dx) ≥ 1 4 (g 1 -g 2 ) 2 + (1 -g 1 -(1 -g 2 )) 2 µ(dx) = 1 2 (g 1 -g 2 ) 2 µ(dx) for any two bounded functions 0 ≤ g 1 , g 2 ≤ 1, and the second inequality holds because the K-L divergence is lower bounded by the squared Hellinger distance. Thus, by convexity of the squared error loss, we have E||g -g|| 2 2 ≤ 1 n 0 -n 0,train n 0 i=n 0,train +1 E||g -gi || 2 2 ≤ 2 inf m log(1/πm) n 0 -n 0,train + 1 A 2 m E||g -ĝ(m) || 2 2 . A.3 Proof of Theorem 3 Suppose that m 0 is such that P (X j ∈ ĝ(m 0 ) ) → 1 as n → ∞, we have E j:X j ∈S VI j = E j:X j ∈S M m=0 wmI(X j ∈ ĝ(m) ) = M m=0 wm j:X j ∈S P (X j ∈ ĝ(m) ). By Yang (2007) , when the data splitting ratio n 0,train /n 0 is chosen properly (such as n 0,train /n 0 = 1/2 in our case), the exponential-type weighting wm is consistent in the sense that wm 0 → 1 and wm → 0 for m = m 0 . Hence we have E j:X j ∈S VI j → |S|. Since 0 ≤ VI j ≤ 1 for any j, we have min j:X j ∈S VI j P -→1. The proof of max j:X j / ∈S VI j P Table A1 Classification error (in percentage) for the real data analysis. Compared are the three transfer learning methods, fitting classifiers on the primary data ĝprimary , on the pooled data, ĝpool , and using the ART framework, gART , applied on random forest, AdaBoost, and neural nets. The lowest classification errors are boldfaced. All the errors are averaged from 50 random splits of the primary data and the standard errors are given. method ĝprimary ĝpool gART RF 44.00± 0.01 41.36± 0.01 39.91± 0.01 AdaBoost 41.55± 0.01 41.73± 0.01 38.55± 0.01 nnet 48.72± 0.01 40.73± 0.01 38.64± 0.01 ART-I-AM --38.55± 0.01 test , and stack each of the auxiliary data with T (0) ≤E log(1/πm) + E [Π n 0 i=n 0,train +1 Kg(x train +1 ) • • • µ × ν(dx Kg(x, y) log Kg(x, y) K ĝ(m) (x, y) µ × ν(dxdy),"
}