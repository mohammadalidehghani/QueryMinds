{
  "title": "Matched Machine Learning: A Generalized Framework for Treatment Effect Inference With Learned Metrics",
  "abstract": "We introduce Matched Machine Learning, a framework that combines the flexibility of machine learning black boxes with the interpretability of matching, a longstanding tool in observational causal inference. Interpretability is paramount in many highstakes application of causal inference. Current tools for nonparametric estimation of both average and individualized treatment effects are black-boxes that do not allow for human auditing of estimates. Our framework uses machine learning to learn an optimal metric for matching units and estimating outcomes, thus achieving the performance of machine learning black-boxes, while being interpretable. Our general framework encompasses several published works as special cases. We provide asymptotic inference theory for our proposed framework, enabling users to construct approximate confidence intervals around estimates of both individualized and average treatment effects. We show empirically that instances of Matched Machine Learning perform on par with black-box machine learning methods and better than existing matching methods for similar problems. Finally, in our application we show how Matched Machine Learning can be used to perform causal inference even when covariate data are highly complex: we study an image dataset, and produce high quality matches and estimates of treatment effects.",
  "introduction": "Introduction Matching methods have a long history in observational causal inference. Their simplicity makes them interpretable even by non-technical audiences, as well as guarantees fast execution of causal analyses with known statistical properties, all while requiring no parametric assumptions on either outcome or treatment distributions (Rosenbaum and Rubin, 1983) . Recently, black-box machine learning (ML) tools for nonparametric estimation have come to supplant matching as the default for treatment effect estimation with contextual covariates (e.g., Hill, 2011; Wager and Athey, 2018; Chernozhukov et al., 2018; Hahn et al., 2020) . There are good reasons for this: the complexity of ML black boxes allows them to predict treatment effects with an unprecedented degree of accuracy, which is sometimes not achieved by matching methods. However, the use of black box ML comes at a cost of interpretability in the results. Our main concern is that models that are not interpretable are difficult to audit, i.e., it is difficult to assess the robustness and credibility of results from an uninterpretable model using contextual information about the data, problem, or population under study. This in turn is problematic since most causal inference datasets can have myriad forms of hidden noise, as well as unmeasured confounding. In this paper, we propose to bridge the gap between the accuracy of ML and the auditability of matching by using the first to inform the second. We propose a general framework that first uses flexible ML to learn a distance metric for matching units, and then employs a matching algorithm that uses the learned metric to construct high-quality matches. These matches are designed to approximate the predictions of the black-box ML while still being auditable; after the matches are made, the black box is thrown out and the analysis proceeds with the matches only. Analysts can then audit quality of the matched estimate by simply examining the matches themselves. Methods from our framework output estimates for the Conditional Average Treatment Effect (CATE), i.e., the expected effect on any individual unit (also known as individualized treatment effect), the Average Treatment Effect (ATE), and Average Treatment Effect on the Treated (ATT), which are average treatment effects on respectively all or only the treated units. Our paper makes several key contributions to the literature on matching and treatment effect estimation in general: (i) We introduce a framework for the production of interpretable treatment effect estimates that are still black-box accurate for the CATE. (ii) We derive the asymptotic distributions and error bounds for CATE estimates made with any matching method falling under our framework. (iii) We expand our framework into a general, doubly-robust matching framework for valid √ n-asymptotic inference for the ATE/ATT. We also show empirically that the finite-sample performance of our tools does indeed match that of black box ML, and theoretically, that our matched estimates are asymptotically normal and with known and estimable variance for conditional treatment effects. In addition, we leverage Double Machine Learning (DML) (Chernozhukov et al., 2018) methodologies to combine CATEs from matching into a doubly-robust estimator to obtain estimates for average treatment effects that are asymptotically normal at a rate of √ n. Importantly, this last method allows us to sidestep the issue of the slow-vanishing asymptotic bias of many common matching methods brought up by Abadie and Imbens (2006) . Our framework generalizes many known and widely-employed matching methods, some of which are summarized in Table 1 . Importantly, the theoretical guarantees that we establish for our framework can be applied to any of the matching methods it generalizes. We expand on how our framework generalizes the matching methods in Table 1 in Section 6. We will demonstrate the power and flexibility of our method by matching on images, where we learn a low-dimensional representation of image covariates with a convolutional neural network. We will show that our method produces interpretable matched groups even when input covariates are complex and high-dimensional, like images. While the representation we match on is uninterpretable, the results are visually auditable: humans will be able to visually inspect the matched groups of images and easily assess their quality and trustworthiness. This will enable us to study whether brand responsiveness to consumers on social media is associated with an increase Table 1 : Some existing matching methods that are special cases of M-ML. Method Choice of φ Choice of q Nearest Neighbor φ(x) = x, 2 Propensity Score Matching φ(x) = h(x), h ∈ arg min h∈H E X [(h(X) -Pr(T i = t|X)) 2 ] 1 (Rosenbaum and Rubin, 1983) Prognostic Score Matching φ(x) = h(x), h ∈ arg min h∈H E X,Y i (t) [(h(X) -Y i (t)) 2 ] 1 (Hansen, 2008) Adaptive Hyper-Boxes * φ(x) = [h t (x), h t (x)] ( Morucci et al., 2020) h t ∈ arg min h∈H E X,Y i (t) [(h(X) et al., 2012) Γ ∈ R p×p diag is a matrix of dimension-wise calipers Genetic φ(x) = Mx 2 (Diamond and Sekhon, 2013) M ∈ arg min M∈R p×p diag i,j∈Tr Maha(x i , x j , M) MALTS φ(x) = Mx, 2 (Parikh et al., 2022) M ∈ arg min M∈R p×p diag i,j∈Tr (y i -y j ) exp(-Maha(x i ,x j ,M)I(T i =T j )) -Y i (t)) 2 ] 1 h t ∈ arg min h∈H E X,Y i (t ) [(h(X) -Y i (t )) 2 ] Coarsened Exact Matching φ(x) = Γx ∞ (Iacus k∈T r exp(-Maha(x i ,x k ,M)I(t i =t k )) Fine Balance * φ(x) = h(x), h ∈ arg min h∈H E X [(h(X) -Pr(T i = t|X)) 2 ] 1 (Rosenbaum et al., 2007) Note: * Requires additional constraints on the matching problem. The parameters φ and q are M-ML hyperparameters that will be defined later; setting them to the values in the table give us the methods in the left column. φ is a mapping from the original space to a useful feature space. It is estimated using a machine learning model. That machine learning model minimizes the loss function shown in the table. q defines a distance metric in the learned feature space. See Section 6 for an in-depth explanation of this table. Treatment represented by the random variable T , a specific treatment level is t, covariates are X (or x if not random), potential outcomes are Y (t), Tr is a training set, Maha(x i , x j , M) is the Mahalanobis distance of the covariate vectors of units i and j weighted by the positive, real-valued diagonal matrix M. in consumer interaction with the brand. This is an important problem in marketing and consumer behavior (e.g., Laroche et al., 2013) , but so far it has not been studied at the level of granularity that our method enables. Our paper will proceed as follows: In Section 2, we introduce matching methods in general. In Section 3, we outline the Matched Machine Learning framework for estimation of Conditional Average Treatment Effects by matching units on learned distance metrics. In Section 4, we present large-sample theoretical properties of our methodology. In Section 5, we propose an algorithm for asymptotically efficient matched estimation of the Average Treatment Effect. Section 7 presents empirical evidence of the performance of our methods on simulated datasets. Finally, in Section 8, we apply our methods to the problem of studying the impact of brand responsiveness on social media on the amount of consumer interaction with the brand.",
  "body": "Introduction Matching methods have a long history in observational causal inference. Their simplicity makes them interpretable even by non-technical audiences, as well as guarantees fast execution of causal analyses with known statistical properties, all while requiring no parametric assumptions on either outcome or treatment distributions (Rosenbaum and Rubin, 1983) . Recently, black-box machine learning (ML) tools for nonparametric estimation have come to supplant matching as the default for treatment effect estimation with contextual covariates (e.g., Hill, 2011; Wager and Athey, 2018; Chernozhukov et al., 2018; Hahn et al., 2020) . There are good reasons for this: the complexity of ML black boxes allows them to predict treatment effects with an unprecedented degree of accuracy, which is sometimes not achieved by matching methods. However, the use of black box ML comes at a cost of interpretability in the results. Our main concern is that models that are not interpretable are difficult to audit, i.e., it is difficult to assess the robustness and credibility of results from an uninterpretable model using contextual information about the data, problem, or population under study. This in turn is problematic since most causal inference datasets can have myriad forms of hidden noise, as well as unmeasured confounding. In this paper, we propose to bridge the gap between the accuracy of ML and the auditability of matching by using the first to inform the second. We propose a general framework that first uses flexible ML to learn a distance metric for matching units, and then employs a matching algorithm that uses the learned metric to construct high-quality matches. These matches are designed to approximate the predictions of the black-box ML while still being auditable; after the matches are made, the black box is thrown out and the analysis proceeds with the matches only. Analysts can then audit quality of the matched estimate by simply examining the matches themselves. Methods from our framework output estimates for the Conditional Average Treatment Effect (CATE), i.e., the expected effect on any individual unit (also known as individualized treatment effect), the Average Treatment Effect (ATE), and Average Treatment Effect on the Treated (ATT), which are average treatment effects on respectively all or only the treated units. Our paper makes several key contributions to the literature on matching and treatment effect estimation in general: (i) We introduce a framework for the production of interpretable treatment effect estimates that are still black-box accurate for the CATE. (ii) We derive the asymptotic distributions and error bounds for CATE estimates made with any matching method falling under our framework. (iii) We expand our framework into a general, doubly-robust matching framework for valid √ n-asymptotic inference for the ATE/ATT. We also show empirically that the finite-sample performance of our tools does indeed match that of black box ML, and theoretically, that our matched estimates are asymptotically normal and with known and estimable variance for conditional treatment effects. In addition, we leverage Double Machine Learning (DML) (Chernozhukov et al., 2018) methodologies to combine CATEs from matching into a doubly-robust estimator to obtain estimates for average treatment effects that are asymptotically normal at a rate of √ n. Importantly, this last method allows us to sidestep the issue of the slow-vanishing asymptotic bias of many common matching methods brought up by Abadie and Imbens (2006) . Our framework generalizes many known and widely-employed matching methods, some of which are summarized in Table 1 . Importantly, the theoretical guarantees that we establish for our framework can be applied to any of the matching methods it generalizes. We expand on how our framework generalizes the matching methods in Table 1 in Section 6. We will demonstrate the power and flexibility of our method by matching on images, where we learn a low-dimensional representation of image covariates with a convolutional neural network. We will show that our method produces interpretable matched groups even when input covariates are complex and high-dimensional, like images. While the representation we match on is uninterpretable, the results are visually auditable: humans will be able to visually inspect the matched groups of images and easily assess their quality and trustworthiness. This will enable us to study whether brand responsiveness to consumers on social media is associated with an increase Table 1 : Some existing matching methods that are special cases of M-ML. Method Choice of φ Choice of q Nearest Neighbor φ(x) = x, 2 Propensity Score Matching φ(x) = h(x), h ∈ arg min h∈H E X [(h(X) -Pr(T i = t|X)) 2 ] 1 (Rosenbaum and Rubin, 1983) Prognostic Score Matching φ(x) = h(x), h ∈ arg min h∈H E X,Y i (t) [(h(X) -Y i (t)) 2 ] 1 (Hansen, 2008) Adaptive Hyper-Boxes * φ(x) = [h t (x), h t (x)] ( Morucci et al., 2020) h t ∈ arg min h∈H E X,Y i (t) [(h(X) et al., 2012) Γ ∈ R p×p diag is a matrix of dimension-wise calipers Genetic φ(x) = Mx 2 (Diamond and Sekhon, 2013) M ∈ arg min M∈R p×p diag i,j∈Tr Maha(x i , x j , M) MALTS φ(x) = Mx, 2 (Parikh et al., 2022) M ∈ arg min M∈R p×p diag i,j∈Tr (y i -y j ) exp(-Maha(x i ,x j ,M)I(T i =T j )) -Y i (t)) 2 ] 1 h t ∈ arg min h∈H E X,Y i (t ) [(h(X) -Y i (t )) 2 ] Coarsened Exact Matching φ(x) = Γx ∞ (Iacus k∈T r exp(-Maha(x i ,x k ,M)I(t i =t k )) Fine Balance * φ(x) = h(x), h ∈ arg min h∈H E X [(h(X) -Pr(T i = t|X)) 2 ] 1 (Rosenbaum et al., 2007) Note: * Requires additional constraints on the matching problem. The parameters φ and q are M-ML hyperparameters that will be defined later; setting them to the values in the table give us the methods in the left column. φ is a mapping from the original space to a useful feature space. It is estimated using a machine learning model. That machine learning model minimizes the loss function shown in the table. q defines a distance metric in the learned feature space. See Section 6 for an in-depth explanation of this table. Treatment represented by the random variable T , a specific treatment level is t, covariates are X (or x if not random), potential outcomes are Y (t), Tr is a training set, Maha(x i , x j , M) is the Mahalanobis distance of the covariate vectors of units i and j weighted by the positive, real-valued diagonal matrix M. in consumer interaction with the brand. This is an important problem in marketing and consumer behavior (e.g., Laroche et al., 2013) , but so far it has not been studied at the level of granularity that our method enables. Our paper will proceed as follows: In Section 2, we introduce matching methods in general. In Section 3, we outline the Matched Machine Learning framework for estimation of Conditional Average Treatment Effects by matching units on learned distance metrics. In Section 4, we present large-sample theoretical properties of our methodology. In Section 5, we propose an algorithm for asymptotically efficient matched estimation of the Average Treatment Effect. Section 7 presents empirical evidence of the performance of our methods on simulated datasets. Finally, in Section 8, we apply our methods to the problem of studying the impact of brand responsiveness on social media on the amount of consumer interaction with the brand. Matching and Observational Causal Inference We first introduce notation. We have a sample of n units, i = 1, . . . , n, having potential outcomes Y i (1), . . . , Y i (M ) ∈ R for a treatment that can take M possible values, t ∈ {1, . . . , M }. Assigned treatments are denoted by the random variable T i ∈ {1, . . . , M }. We never observe the full vector of potential outcomes for each unit, but instead we observe the outcome vari- able Y i = n i=1 Y i (t)I[T i = t], where I[E] is the indicator function for event E. Each unit has is assigned a p-dimensional random vector of covariates X i taking values in X, where X ⊂ R p is a compact set; observed covariate vectors are x i ∈ X. For an arbitrary random variable A, will use the notation f A to denote the Probability Mass Function (PMF) or Probability Distribution Function (PDF) of A, and use F A to denote the Cumulative Distribution Function (CDF) of A, and we will also use f A to denote the distribution of A. We use the notation E A [A] and V A [A] to denote expectation and variance of A with respect to the distribution of A. When we use this notation without subscripts we mean that the expectation operator is with respect to all the random quantities inside of the square brackets. We make the following classical assumptions, for all i: A1 (Data Distribution): (a) The data O n = {O i } n i=1 = {Y i , X i , T i } n i=1 is a set of n i.i.d. copies of O. (b) The domain of the covariate distribution, X is a compact subset of R p . (c) The covariates have marginal distribution with differentiable CDF (w.r.t. the lebesgue measure) F X (x), and constants c f X , C f X , such that 0 < c f X < f X (x) < C f X < ∞ everywhere over X. A2 (Overlap): For all x ∈ X and t = 1, . . . , M we have 0 < Pr(T = t|X = x) < 1. A3 (Conditional Ignorability ): T ⊥ ⊥ (Y (1), . . . , Y (M ))|X. A4 (Bounded Higher Moments): For all t, t ∈ {1, . . . , M }, all x ∈ X and for some δ > 0 and a constant C δ we have: E[|Y (t)| 2+δ |X = x, T = t ] ≤ C δ . This paper is largely focused on estimating the Conditional Response Function (CRF) and Conditional Average Treatment Effect for a given covariate vector, x. These are denoted, respectively, by: µ(x, t) = E[Y (t)|X = x], and τ (x) = µ(x, t) -µ(x, t ), for two treatments t, t . Note that Assumption 3 allows us to write: E[Y |X = x, T = t] = E[Y (t)|X = x], and, therefore, implies that our quantities of interest can be consistently estimated from our observed data. We will also use the notation σ 2 (x, t) = V[Y (t)|X = x] to denote the conditional variance of the potential outcomes. Later in this paper, we will be concerned with estimating averaged versions of the CRF and the CATE, which are defined as follows: Average Response Function (ARF) µ(t) = E[Y (t)], Average Treatment Effect (ATE): τ (t, t ) = E[Y (t)] -E[Y (t )], and Average Treatment Effect on the Treated (ATT): δ(t, t ) = E[Y (t)|T = t] -E[Y (t )|T = t]. We will see how consistent estimation of the CRF allows for consistent estimation of all the other quantities. The main idea of matching is to create a Matched Group, i.e., a subset of units: MG( φ, x, t) ⊂ {1, . . . , n} that contains units whose observed outcomes will be used to estimate the quantities of interest defined above for the desired value x. It follows that the main problem of a matching procedure is to select which units we should include in MG( φ, x, t). In the following section we outline our strategy to do so. Matched Machine Learning: A General Procedure The key idea of this paper is to take advantage of powerful black-box machine learning models to inform how we should make matched groups, and, consequently, estimate CRFs and CATEs. To do this, we propose using machine learning to construct a d-dimensional representation of the covariates, and to subsequently match on these representations instead of the raw covariate values: ML will flexibly learn representations that are informative about the relationship between X, T , and Y , leading to higher-quality matches. To accomplish the goal just described, we introduce the function φ : X → R d , which is a representation function for the observed covariates. We assume that φ(x) exists for all x in their respective domains and is continuous. It is also possible for φ to depend on the treatment level, meaning that one separate φ will be estimated per treatment group. We omit this from the notation for ease of readership. We then propose that φ is learned with a ML method on a separate training set. The idea behind this representation is to map the covariates to a space where units are close if their potential outcomes are close, which is ultimately the goal of matching. For example, if we considered similarity between three units i, j, k based on X alone, we might might match i to k even though i is more similar to j in terms of (unobserved) potential outcomes. Instead, if we considered some transformation φ(X) that is informative as to the relationship between X and Y (t), we might be able to correctly conclude that i should be matched to j instead of k. Specifying a useful map φ can lead to great improvement in match quality over simple matches on raw covariate values. This idea has already been explored in the existing literature on matching, and popular examples of φ that have been used previously include the propensity score for covariates x and a desired treatment level, t, x: and Rubin, 1983) , the prognostic score, or expected potential outcome under control: φ(x) = Pr(T = t|X = x) (Rosenbaum φ(x) = E[Y (0)|X = x] (Hansen, 2008) (assuming that t = 0 represents the control condition), and the Mahalanobis distance: φ(x) = Mx, with M being a diagonal p×p matrix of positive weights (Rubin, 1980; Diamond and Sekhon, 2013; Parikh et al., 2022) . Once we have formulated a representation of the covariates that we wish to use for matching, we will need a distance metric that encodes similarity of units on the transformed covariates. We employ a general L q norm for this purpose. For any (u, v) ∈ X × X, let: D q φ (u, v) = d j=1 |φ(u) j -φ(v) j | q 1 q , be the q-norm distance between u and v. q can be any integer or infinity, which we define as usual as D ∞ φ (u, v) = max j=1,...,d |φ(u) j -φ(v) j |. In practice, the most popular choices of norm are q = 2 (e.g., Rubin, 1980; Abadie and Imbens, 2011; Diamond and Sekhon, 2013) , for matching on the covariates themselves on the L 2 distance, absolute value distance (which is any L q in 1D) (e.g., Rosenbaum and Rubin, 1983) , for matching on 1-dimensional representations of the covariates, such as the propensity score, and q = ∞ (e.g., Rosenbaum and Rubin, 1984; Iacus et al., 2012) , for coarsening-based matching methods. Our main algorithm is as follows: Algorithm: Matched Machine Learning (M-ML) Input: A dataset of n observations D = {x i , y i , t i } n i=1 split into a training set and a matching set. A desired covariate value x, desired treatment level t, a matching set of units, and a separate training set, a positive, real-valued caliper, Γ n > 0. Output: Estimator of conditional response function for covariate value x and treatment level t. Stage 1: Using the separate training set, construct an estimator of the representation φ(•), denoted φ(•). Calculate φ(x i ) for all units i in the matching set as well as the input values: φ(x). Stage 2: Form the Matched Group by choosing units in the matching set that have the desired treatment level and are at a distance less than Γ n from x: MG( φ, x, t) = i = 1, . . . , n : D q φ (x, x i ) ≤ Γ n , T i = t . (1) Stage 3: Construct the estimator: μ(x, t) = 1 |MG( φ, x, t)| i∈MG( φ,x,t) y i . (2) In Stage 1, we split the data into a training and matching set, and learn an estimator the function φ on the training set, and use it to estimate φ(x i ) for every unit in the matching set. In Stage 2, we construct our matches by maximizing the weighted sum of units with distance less than some generalized caliper, Γ n . In Stage 3, we use the matched group constructed at Stage 2 to estimate the CRF for x. We choose to control the size of the matched group and who gets included with a constraint on the representation distance defined in (3): units with a distance from our target value less than Γ n are included in the matched group. The way in which Γ n is defined results in two variants of the M-ML algorithm: Caliper M-ML: In this case, Γ n is defined to be some positive, real value chosen by the analyst. This is the technique known as caliper matching (e.g., Rosenbaum and Rubin, 1985b) . This technique guarantees that the distance between units within a matched group will never be less than a known value. Note that in Caliper M-ML, it could happen that there are no units in MG( φ, x, t): in this case, the estimator cannot be constructed; we should use a larger value of Γ n so that matches can be constructed. KNN M-ML: In this case, Γ n = D q φ (x, x (kn) ), where (k n ) is the k th n order statistic of the vector (D q φ (x, x 1 ), . . . , D q φ (x, x n )). This technique is known as K-Nearest-Neighbor matching (e.g., Rubin, 1976) . This method guarantees that each matched group will contain exactly k n units (assuming no ties), however, in this case the caliper Γ n will be a function of x, and of the data, which implies that users will not be able to directly control its value. We will show in the next section that these two variants of the M-ML algorithm are essentially equivalent asymptotically, under appropriate choices of Γ n and k n . In Stage 3, a canonical matching estimators for µ(x, t) is constructed with matches made at the prior step. An estimator for the CATE, τ (x, t, t ) can be intuitively constructed by running the M-ML algorithm twice: once with x and t as inputs, obtaining μ(x, t) as output, and once with x, t as inputs, obtaining μ(x, t ) as output; and finally by taking the difference between the two: τ (x, t, t ) = μ(x, t) -μ(x, t ). We will see in an upcoming section that this estimator shares the desirable asymptotic properties of μ(x, t) constructed with M-ML. Matched Machine Learning: Asymptotic Properties We now study the statistical behavior of our M-ML estimator. This is important because doing so will allow us not only to give bounds on estimation error as n grows, but also because it will allow us to construct approximate confidence intervals for our CATE and ATE/ATT estimates. Quantifying uncertainty in this way is paramount in virtually all scientific application of matching, and is necessary to improve the trustworthiness of matched estimates. Since M-ML is nonparametric, we focus on establishing results concerning its asymptotic properties, and study finite-sample behavior empirically via simulations. We will show in this section that CRF and CATE estimates for any x in the domain of the distribution of our data can be estimated consistently and efficiently at the nonparametrically optimal rate in the sense of Stone (1982) . We will see in Section 5 that achieving this rate allows us to use Double Machine Learning methods with M-ML estimates as inputs to obtain root-n asymptotically normal estimates of ARF, ATE and ATT. It follows from these results that conventional sample variance estimators applied to MG( φ, x, t) are consistent for V[Y (t)|X = x], and that, therefore, approximate confidence intervals can be constructed for M-ML CRF and CATE estimates. We will see that letting either the caliper Γ n shrink or the number of matches k n grow as n grows is fundamental to achieve consistency for M-ML estimates. Additionally, one key intuition behind our results is that the first-stage estimates do not affect the asymptotic behavior of the matching estimators, only its convergence rate, and the matching estimator can be understood asymptotically as if matches were made on the true value of φ, as we will show. All proofs for the results below are available in the supplement. They key assumption is that the following condition holds with respect to D q φ : A5 (Lipschitz Condition): For all x, z ∈ X and t ∈ {1, . . . , M } there exists a constant C L such that: (a) |µ(x, t) -µ(z, t)| ≤ C L D q φ (x, z), and (b) |σ 2 (x, t) -σ 2 (z, t)| ≤ C L D q φ (x, z). This (or a similar) smoothness condition on the outcome function is a common assumption in virtually all nonparametric estimation frameworks similar to matching (e.g., Kallus, 2020; Farrell et al., 2021; Wager and Athey, 2018) , but the key difference here is that we would like it to hold for our transformed covariates, but not necessarily on the raw covariates. Assuming smoothness on the raw covariates, as is commonly done in matching and nonparametric methods, is a much stronger assumption: it would directly imply that the condition is also respected for the transformed covariates, as long as φ is Lipschitz-continuous in the covariate values, which is a simple and widely-satisfied requirement for many choices of φ. The final component of our framework is a flexible ML method to estimate φ from the data. To this end, we introduce a separate training set, of size ρn, for some fraction ρ ∈ (0, 1). This training set can be obtained by randomly subsetting the whole data into two sets: a training set, and a matching set. For notational simplicity, we will assume that the total number of units is n + ρn. We then assume that a ML method will be applied to the training data, to construct an estimator of φ denoted by φ. In practice φ can be modeled as the minimizer of some population loss function over a space of functions, and φ as its empirical counterpart, but this need not always be the case. The requirement that we will need on φ for our theoretical results to hold is that φ is a consistent estimator of φ, as well as both being differentiable functions. In order to establish the asymptotic properties of M-ML estimates, we need to make one additional but reasonable assumption for the first-stage distance metric estimates: A6 (Representation function): There exists a function φ(x, O n ) : X × Ω → R d such that, for real-valued r M L > 0: (a) The functions φ(x, O n ) and φ(x) are f O -almost surely continuous with respect to x at all x ∈ X, (b) φ(x, O n ) -φ(x) P,q = o(n -r M L ) almost surely over f X , (c) φ(X, O n ) -φ(X) P,q = o(n -r M L ). Part a) of this assumption limits potential representation to continuously differentiable functions of x, which is a common property of most ML algorithms. Part b) of this assumption states that the process used for learning φ must lead to a quantity with a proper distribution for all possible inputs. Part c) is satisfied as long as φ is learned from an independent training sample. Finally, part d) of this assumption states that first-stage ML estimates of φ must converge to the true value of φ both point-wise and in mean square. This assumption is relatively standard in nonparametric two-stage estimation settings (Chernozhukov et al., 2018) , and has been verified for a number of different ML methods such as LASSO (Belloni et al., 2014) , Random Forests (Wager and Athey, 2018) , Support Vector Machines (Devroye et al., 2013) , and Deep Neural Networks (Farrell et al., 2021) , which are all also shown to converge at a rate r ≥ 1/4 under relatively mild assumptions. Consider a unit outside of the data, which has observed covariates x. The probability that any of the units in our data are a match for x is given in the following lemma. Lemma 1. Let A1-A6 hold. For x ∈ X, let matches be made with Caliper M-ML for a fixed Γ n ≥ 0, i.e.: MG( φ, x, t) = {i = 1, . . . , n : D q φ (X i , x) ≤ Γ n , T i = t}. Then, if Γ n → 0 as n → ∞ we have, for arbitrary i ∈ 1, . . . , n: 1. Γ -d n Pr On,X i ,T i (i ∈ MG( φ, x, t)) → V d e(t)f φ(X)|T =t (φ(x)) for all x ∈ X, 2. Γ -d n Pr X,On,X i ,T i (i ∈ MG( φ, X, t)) → V d e(t)E X [f φ(X)|T =t (φ(X))], where e(t) = Pr( T = t), V d = 2Ga( 2 q +1) d Ga( d q +1 ) , where Ga is the Gamma function, and f φ(X)|T =t (φ(x)) is the pdf of φ(X) conditional on T = t. Note that the first statement concerns almost sure convergence over f X , while the second concerns convergence in expectation over the same distribution. The above result is both intuitive and interesting: its proof does not rely on the ML convergence rate r at all, but instead takes advantage of continuity of φ, together with a generalized change of variables to establish the result. The theorem shows that Pr(i ∈ MG( φ, x, t)) is asyptotically proportional to Γ d n : this has the important consequence that, asymptotically, the rate at which our caliper Γ n contracts is the only relevant one for the probability of matching any unit i, and that the dimensionality of φ, d, will influence this rate regardless of the original number of covariates. After this result is established, it can be used to prove the main theoretical result for CRF estimates obtained with M-ML, using the constants defined in the assumptions A4 and A5: Theorem 1. (Asymptotic Behavior of Caliper M-ML CRF Estimates) Let A1-A6 hold, with A5 holding for some δ > 0. Let e(t), V d , and f φ(X)|T =t (φ(x)) be defined as in Lemma 1. Let r = min 1 2+d , r M L . For matches made with Caliper M-ML we have: (i) For caliper Γ n = Kn 2r-1 d : n r (μ(x, t) -µ(x, t)) d → N 0, σ 2 (x,t) K d V d e(t)f φ(X)|T =t (φ(x)) . (ii) For caliper Γ n = n -1 2+d and s = 2 + δ: μ(X, t) -µ(X, t) P,s = O(n -1 2+d ) + o(n -r M L ), and this bound is minimal over all possible values of Γ n . The same result holds for KNN M-ML: the following theorem establishes that, under suitable conditions on k n , M-ML CRF estimates made with this methodology are asymptotically equivalent to estimates made by controlling Γ n directly. Theorem 2. (Asymptotic Behavior of KNN M-ML CRF estimates) Let A1-A6 hold. Let MG( φ, x, t) = {i = 1, . . . , n : D q φ ≤ Γ n , T i = t}, with Γ n equal to the k th n order statistic of the vector (D q φ (x, X i ), . . . , D q φ (x, X n )) (note that in this case Γ n is a function of x and X 1 , • • • X n ) with k n being a positive integer. Let r = min 1 2+d , r M L . We have: (i) For k n = Kn 2r , for a positive constant K > 0: n r (μ(x, t) -µ(x, t)) d → N 0, σ 2 (x,t) K . (ii) For k n = n 2 2+d and integer s > 2: μ(x, t) -µ(x, t) P,s = O(n -1 2+d ) + o(n -r M L ), and this bound is minimal over all possible values of k n . Lemma 1, which gives us a way to establish the asymptotic order of the size of the matched group, |MG( φ, x, t)|, in Theorem 1 and of Γ n in Theorem 2, is of fundamental importance in the proof of both theorems. An important implication of both theorems is that the choice of Γ n and k n directly impacts the convergence rate and asymptotic variance of M-ML estimates. In the case of Caliper M-ML, using the same reasoning as in the proof of Theorem 1, the asymptotic variance can be made equal to 1 by setting Γ n = n r-1 K d V d e(t)f φ(X)|T =t (φ(x)) σ 2 (x,t) 1 p , and it can be made arbitrarily small by multiplying the above by a positive constant. Obviously, this decrease in variance is paid for by an increase in bias due to the larger matched group, making it impractical to achieve an asymptotic variance lower than 1 in most cases. An analogous relationship is true for KNN M-ML: here one option to choose k n is to set it to the integer closest to n r K. In this case, when we choose K = 1, the asymptotic variance is exactly σ 2 (x, t), however, depending on the data, there might not be n r high quality matches for x, and K < 1 might have to be chosen, leading to larger asymptotic variance. We note that our results on asymptotic normality of KNN regression generalize those of Stute et al. (1984) by incorporating a distance metric learning step. The bounds given in Theorems 1 and 2 have two important consequences. First, that the optimal convergence rates of KNN matching and caliper matching are the same, determining the asymptotic equivalence of these two long-standing matching procedures. Second, our bounds are directly related to the results on the convergence rates for KNN classification and regression on matches made on the L q distance of the raw covariates established in various works and summarized by Györfi (1981) ; Györfi et al. (2002) . Notably, the main difference between our bound and other bounds on non-transformed matching have a difference of a factor of o(n -r M L ), which is due to the covariate transformation having to be learned in our case. This fact has an important consequence for our setting: gains in performance due to learning a distance metric, rather than matching on raw values of the covariates, can only be made in finite samples, rather than asymptotically. This conclusion is supported by recent work of Rimanic et al. (2020) , who derive a similar bound for KNN regression but under different assumptions on the representation function φ. We will show in our simulations section that these finite-sample gains are substantial. Even more importantly, the bound implies that greatly improving the predictive accuracy of matching by adding a distance-learning step via ML comes at almost no cost in terms of convergence rate, since the matching portion of the error bound decreases at its nonparametric rate. Let us move on to discuss the asymptotic variance of the potential outcomes, σ 2 (x, t), which is of importance for asymptotic inference. This quantity can also be estimated via M-ML by applying the traditional variance estimator to the matched groups constructed with M-ML. This is stated formally in the following theorem: Theorem 3. (Consistency of Sample Variance Estimator) Let the sample variance estimator for σ 2 (x, t) be defined as: σ2 (x, t) = 1 N ( φ,x,t) i∈MG( φ,x,t) (Y i -μ(x, t)) 2 . Let A1-A6 hold, and let MG( φ, x, t) be constructed either with Caliper M-ML or KNN M-ML. Then we have: σ2 (x, t) p → σ 2 (x, t) for all t as n → ∞. Note that the result holds independently of whether the number of units to match to x is chosen or whether Γ n is chosen to control the radius of MG( φ, x, t). Finally, the theorems just introduced have the following direct consequence as a corollary, which permits us to construct asymptotic confidence intervals for the CATE. : n r (τ (x, t, t ) -τ (x, t, t )) d → N 0, σ 2 (x,t) K d V d e(t)f φ(X)|T =t (φ(x)) + σ 2 (x,t ) K d V d e(t )f φ(X)|T =t (φ(x)) . (ii) If matches are made with KNN M-ML and k n = n 2r K : n r (τ (x, t, t ) -τ (x, t, t )) d → N 0, σ 2 (x,t) K + σ 2 (x,t ) K . This corollary is possible because only units with observed treatment T i = t are used to construct μ(x, t), and only units with T i = t are used to construct μ(x, t ): this renders the two estimators independent of each other. With the two estimators independent of one another, the continuous mapping theorem applied to the vector (μ(x, t), μ(x, t )) allows the conclusion in the corollary to be reached. The result in the corollary implies that an approximate 1 -α confidence interval can be constructed for a fixed x with:CI (x, t, t ) = τ (x, t, t ) ± Φ -1 (1 -α/2) σ2 (x,t) c(x,t) + σ2 (x,t ) c(x,t ) , where c(x, t) = n r K d V d e(t)f φ(X)|T =t (φ(x) ) for caliper matches (Thm. 1), or c(x, t) = k n for KNN matches (Thm. 2). This will permit analysts to quantify the uncertainty around their CATE estimates in a way that is widely accepted, and has known guarantees. Matched Double Machine Learning For Average Estimands The M-ML framework can naturally be extended to nonparametric estimation of ATE and ATT in a way that maintains the auditability of matching, as well as the ability to construct asymptotically valid confidence intervals. This is possible because M-ML estimates can be used as input for first-stage estimates in Augmented Inverted Propensity Weighted (AIPW) estimators (Robins et al., 1994) . These estimators have been found to behave normally asymptotically and with known variance, provided that first-stage estimates of CRF and propensity converge sufficiently fast (Chernozhukov et al., 2018; Van Der Laan and Rubin, 2006) , which is a property that our methods have, as shown in the analysis above. Thanks to this property, we can formulate a version of the M-ML algorithm for ATE and ATT estimation modeled after the DML algorithm of Chernozhukov et al. (2018) . The algorithm we propose is called Matched Double Machine Learning (M-DML), and is defined as follows: ATE or ATT Estimation: Matched Double Machine Learning (M-DML) Stage 1: Randomly split the data {x i , y i , t i } n i=1 into L folds each of size n/L. Let S ℓ denote all the indices of units in fold ℓ, and S \\ℓ all the indices of units not in that fold. The units in fold ℓ are used for estimating the ATE and ATT. Repeat the following steps for ℓ = 1, . . . , L. Stage 2: Further split the units in S \\ℓ into a training set, denoted by T S ℓ and a matching set, denoted by MS ℓ . Using only the units in T S ℓ , learn the representation function φ(x). Using all units in S \\ℓ , construct a consistent estimator of the propensity for each treatment level t, denoted by ê(x, t), and of the marginal propensity for receiving treatment t: Pr(T = t), the latter denoted by ê(t). Stage 3: For each unit i ∈ S ℓ , and for treatment levels t, t , run the M-ML algorithm for each treatment level, with all the units in MS ℓ as candidates for matching to obtain μ(x i , t), μ(x i , t ). Additionally predict the propensity score of i for each treatment level, ê(x i , t), using the propensity models learned in Stage 2. Stage 3: For each unit i ∈ S ℓ , using the outputs of the previous stage, construct the doubly robust score function: ψ(x i , t) = μ(x i , t) + I[t i =t](y i -μ(x i ,t)) ê(x i ,t) , and compute ψ(x i , t ) analogously, then compute: ψ(x i , t, t ) = I[t i =t](y i -μ(x i ,t )) ê(t) -I[t i =t ]ê(x i ,t)(y i -μ(x i ,t )) ê(t)ê(x i ,t ) . Stage 4: Construct the estimators: μDR ℓ (t) = L n i∈S ℓ ψ(x i , t), for both t,t', τ DR AT E (t, t ) ℓ = μDR ℓ (t) -μDR ℓ (t ), τ DR AT T (t, t ) ℓ = L n i∈S ℓ ψ(x i , t, t ). Stage 5: Average across folds: μDR (t) = 1 L ℓ μDR ℓ (t), τ DR ATE (t, t ) = 1 L ℓ τ DR AT E (t, t ) ℓ , and τ DR ATT (t, t ) = 1 L ℓ τ DR AT T (t, t ) ℓ . These three quantities are the output of M-DML. The algorithm works by splitting the data into L folds (Stage 1), which are then further split into training and matching set. Note that this is a 3-way data split, which is intuitively required by the matching step added on top of the ML prediction step, a similar splitting procedure is also used in (Wang et al., 2021) . The M-ML algorithm is then fit separately to each fold (Stage 2) and results are averaged to obtain a final estimate of the parameter of interest (Stage 5). Note that if one has enough data, then one could use only a single held out training split and eliminate the need to further split units outside fold ℓ into training and matching sets. This avoids increasing the complexity of cross-fitting, which could be computationally expensive for large datasets. Given two treatment levels of interest to the user, t and t , the M-ML algorithm is run twice on each fold, once for treatment level t and once for t . The estimators constructed using μ(x, t) output by M-ML are given in Equations ( 5 ) and ( 5 ) and they are the doubly robust score functions, used in the AIPW estimators of Robins et al. (1994) . The idea of these estimators is to use the observed data to correct the first-stage predictions, and thus ensure asymptotic normality of estimates. As shown in the algorithm, one needs a consistent estimate of the propensity score, e(x i , t) for all units, i, and treatment levels of interest. Many good estimators exist for this quantity, and the use of any estimator based on a ML method that satisfies the requirements on convergence rates given in Theorem 4 will result in the asymptotic guarantees on M-DML given in the theorem. The M-DML algorithm is a special case of the DML2 algorithm given in Definition 3.2 of Chernozhukov et al. (2018) . To match M-DML to that definition, M-ML is taken to be the first stage estimator in the definition. The properties of the AIPW estimators, together with the convergence rates of M-ML give us guarantees on the asymptotic normality and convergence rate of M-DML. This is stated in the following theorem. further that the user has chosen a propensity score estimator that satisfies, for a positive, real r e : (i) ê(X, t) -e(X, t) P,2 = O(n -re ), (ii) ê(X, t) -1/2 P,∞ ≤ 1/2 -, for some > 0, (iii) 0 < ê(x, t) < 1 for all x and t. Let r = min 1 2+d , r M L and assume that r + r e ≥ 1/2. Let MG( φ, X, t) be constructed either with Caliper M-ML or with KNN M-ML with either Γ n = Kn 2r-1 d , or k n = Kn 2r , for a fixed integer K > 0. Then the following holds for M-DML estimates: 1) Asymptotic Normality: √ n(μ DR (t) -µ(t)) d → N (0, σ 2 (t)), with σ 2 (t) = E X [ψ(X, t) 2 ], √ n(τ DR AT E (t, t ) -τ (t, t )) d → N (0, σ 2 AT E (t, t )), with σ 2 AT E (t, t ) = E X [(ψ(X, t) -ψ(X, t )) 2 ], and √ n(τ DR AT T (t, t ) -τ (t, t )) d → N (0, σ 2 AT T (t, t )), with σ 2 AT T (t, t ) = E X [ψ(X, t, t ) 2 ]. 2) Consistency of the sample variance estimators applied to the second-stage estimators, i.e.: σ2 (t) = 1 n n i=1 ( ψ(X i , t) -μDR (t)) 2 p → σ 2 (t), σ2 AT E (t, t ) = 1 n n i=1 ( ψ(X i , t) -ψ(X i , t ) - τ DR AT E (t, t )) 2 p → σ 2 AT E (t, t ), and, σ2 AT T (t, t ) = 1 n n i=1 ( ψ(X i , t, t ) -τ DR AT T (t, t )) 2 p → σ 2 AT T (t, t ). 3) Approximate confidence intervals: Let ∆ be a M-DML estimator from Stage 5 of the M-DML algorithm, ∆ its corresponding estimand, and σ2 its respective asymptotic variance. An approximate 1-α confidence interval for the parameter of interest is: CI(δ) = ∆ ± Φ -1 1 -α 2 σ2 n , where Φ -1 (a) is the a th quantile of the standard normal distribution. The statement follows almost directly from our Theorems 1, 2 and Theorem 5.1 in Chernozhukov et al. (2018) . This result establishes asymptotic normality at a √ n rate for ATE and ATT estimates obtained with M-DML. This is of primary importance because it enables us to approximate confidence intervals on our average parameters of interest with the asymptotic distribution of our estimators, thus providing the uncertainty quantification that is needed for causal inference. Note that, if the same ML estimator is used for both φ and ê, then the requirement on its rate becomes: r M L ≥ 1 4 , which is the same rough requirement given in Chernozhukov et al. (2018) . Note that this rate can be achieved by M-ML and first stage methods under the condition that β ≥ p 2 , i.e., if outcomes are smooth enough as a function of the covariates, which is a common requirement in nonparametric estimation frameworks. In order to achieve the rate needed it is also important to choose the dimensionality of the representation φ in such a way that the condition 1 2+d + r e ≥ 1 2 holds. This can be achieved by choosing d ≤ 2re 1 2 -re . If r e is the optimal nonparametric convergence rate with a β-smooth propensity score and p covariates (Stone, 1982) , then the condition reduces to d ≤ 4β p . M-ML and M-DML: Examples and Extensions In this section, we present some practical examples of how M-ML and M-DML might be used, and give some case-specific considerations that apply to the algorithms in these settings. In addition, we present an extension to the M-ML algorithm that allows the user to add arbitrary constraints to the matching optimization problem at Stage 2 of the M-ML algorithm. Matching to explain ML predictions The most straightforward application of M-ML is to match on the estimated potential outcomes from a black-box ML model in order to audit the model's predictions with case-based reasoning. In the causal inference literature, matching on an estimate of µ(x, t) is known as prognostic score matching (Hansen, 2008) , which displays many of the properties of propensity score matching. In this case, we would define φ as min h E[ℓ(Y (t), X, h)], where ℓ is a loss function. For regression problems, for example, one could use the loss ℓ(Y (t), X, h) = (Y (t) -h(X)) 2 . It is easy to show that in this case φ(x) = E[Y (t)|X = x] = µ(x, t). Conven- tional ML methods will estimate φ by minimizing the empirical risk 1 n n i=1 ℓ(Y i (t), X i , h ) over a space of hypothesis functions, H, which is potentially very large, complex, uninterpretable, and therefore almost impossible to audit. As argued before, matching will remedy this lack of interpretability by replacing the output of black box h(x, t) with the average of the observed outcomes of nearby units; if we construct the distance metric well, those units will have similar predicted Y (t) values. Importantly, in this case d = 1, implying that the convergence rate for M-ML will be min(n 1 3 , n r M L ), which will almost always equal r M L , since it is very unlikely that any ML method may achieve a convergence rate greater than 1/3, especially when p > 1. This consequently implies that adding matching on top of ML for auditability comes at virtually no cost in terms of convergence rate of the ML predictions. Notably, in this case the dimensionality of φ will be exactly d = 1. This implies that the rate of convergence for the matching portion of our estimators will be exactly equal to the nonparametrically optimal one (see Stone (1982) as well as Sec. 6.3 of Györfi et al. (2002) ). This implies that, in this case, the rate of convergence of the CATE M-ML estimator will be r = r M L , i.e., the M-ML estimator will converge as fast as any backend ML estimator of φ can. This has the important implication that adding a layer of interpretability on top of ML predictions with matching comes at no cost in terms of convergence rates. Matching on the Mahalanobis distance with learned weights One potential use of M-ML is to construct covariate weights that describe the importance of each feature for outcome generation, and to then match on a weighted L 2 distance with those weights. This is already accomplished by several existing matching methods (Wang et al., 2021; Parikh et al., 2022; Diamond and Sekhon, 2013) , each targeting a different set of weights that ensures different desirable properties of the matches. This setting can be expressed in the M-ML framework by setting φ(x) = Mx, where M is a p × p diagonal matrix of weights that are either known or learned from the data. In this case, φ(x) is invertible, and the asymptotic probability of a match, n r K d V d e(t)f φ(X)|T =t (φ(x)), used in our framework to estimate the asymptotic variance of caliper matches, becomes: n r K d V d e(t)f X|T =t (x) p j=1 m j , where m j is the true value of the weight on covariate j. M-ML as a General Matching Framework As the previous examples suggest, the M-ML algorithm can also be seen as a generalization of several other popular matching methods when matching is done with replacement, either with a caliper on the pair-wise distance of units to be matched, or with a fixed number of matches. We give a description of methods that are special cases of M-ML here, and a summary in Table 1 . Specifically, the following methods are special cases of the M-ML framework: Nearest Neighbors, Propensity Score Matching, Prognostic Score Matching, Prognostic Score Matching, Adaptive Hyperboxes, Coarsened Exact Matching, Genetic Matching, Genetic Matching, Matching After Learning to Stretch (MALTS), and Fine Balance. Let us describe in more detail how these are special cases of M-ML, starting with Mahalanobis distance matching, which includes MALTS and Genetic Matching. Mahalanobis distance matching (Rubin, 1980) matches units that are close in terms of Mahalanobis distance, which is defined for two vectors u, v ∈ R p and a square matrix M ∈ R p×p as: Maha(u, v, M) = (u -v) T M(u -v). M is usually chosen to be diagonal, and we will use diagonal M. Mahalanobis matching can be implemented as M-ML by choosing φ(x) = Mx and then matching on the L 2 distance. Setting M = I, where I is the identity matrix in the same scenario will result in simple Nearest-Neighbor Matching, used, for example, by Abadie and Imbens (2006) . Methods like Genetic Matching (Diamond and Sekhon, 2013) and MALTS (Parikh et al., 2022) perform Mahalanobis matching just as described, but they add a first step for learning an optimal M, thus also taking advantage of the learning component of M-ML. For a version of Genetic Matching that learns its distance on a separate training set, this first step can be expressed as finding M that solves: M ∈ arg min M∈R p×p diag i,j∈Tr Maha(x i , x j , M), where Tr is a set of indices indicating which of the units belong to the training set. In the case of MALTS, M is found by optimizing: M ∈ arg min M∈R p×p diag i,j∈Tr (y i -y j )I(t i =t j ) exp(-Maha(x i ,x j ,M)) k∈Tr I(t i =t k ) exp(-Maha(x i ,x k ,M)) . Methods that use predictors of treatment and outcomes and match on those can also be implemented as special cases of M-ML. For propensity score matching (Rosenbaum and Rubin, 1985a), φ(x) = h(x) and h is chosen to be the best predictor of treatment assignment within a class of functions, H, i.e: h ∈ arg min h∈H E X [(h(X)-Pr(T i = t|X)) 2 ]. For prognostic score matching (Hansen, 2008) , the same is done, but with h being the best predictor of the control outcome, denoted here by t : h ∈ arg min h∈H E X,Y (t ) [(h(X) -Y (t )) 2 ]. A pre- trained version of the Adaptive Hyperboxes (AHB) matching algorithm (Morucci et al., 2020) can also be cast as a version of M-ML, by adopting the same form for h as in prognostic score matching, but for both treatment levels of interest, t, t , and constructing the vector: φ(x) = (h t (x), h t (x)), where h t ∈ arg min h∈H E X,Y (t) [(h(X) -Y (t)) 2 ] , and h t is defined in an analogous manner. In addition to this, AHB matches units in a hyperrectangular region of the covariate space that is learned from the data: while this is not directly achievable within M-ML, it is possible to pre-specify a rectangular region of the covariate space, H(x), and to add a constraint to the M-ML matched group that requires matched units to be within that region: MG( φ, x, t) = {i = 1, . . . , n : t i = t, D q φ (x i , x) ≤ Γ n , x i ∈ H(x)}. After estimating φ, all of these matching methods match using the L 1 distance, which could be chosen for M-ML as well. Coarsened Exact Matching (Iacus et al., 2012) can be implemented as M-ML by creating a diagonal matrix of dimension-wise calipers, Γ, where the diagonal is given by the vector 1 γ 1 , . . . , 1 γp , and each value of γ j is the maximum allowed distance for two units on the j th dimension. To fully emulate CEM, matches should then be made on the sup norm, i.e., by setting q = ∞. In a similar vein, matching with near-fine balance on the j th covariate (Rosenbaum et al., 2007) can be implemented as M-ML by adding a constraint to the matched group that takes the form |x ij -x j | ≤ γ j , where γ j is a small caliper on the j th dimension; fine balance can be achieved by setting γ j = 0. Fine balance matches can be made with any choice of φ and q, but to emulate the implementation of Rosenbaum et al. (2007), one would choose φ to be the propensity score, and set q = 1. Finally, analysts could be interested in creating optimal matched groups by solving a weighted version of an optimization problem, where the number of units to include in MG( φ, x, t) is chosen as the optimum of a weighted combination of cumulative distance and number of units. This is a type of bias-variance trade-off, as larger groups have lower variance, but higher bias since they include points that are farther away. The following lemma establishes that the matched group formulation defined in Eq. ( 1 ) is also an optimal solution to such a weighted problem: Lemma 2. (M-ML is a solution to the weighted matching problem.) Let W i ( φ, x, t) = I[i ∈ MG( φ, x, t)] represent whether unit i is included in MG( φ, x, t), then the matched group MG( φ, x, t), defined in (1), is also a solution to the problem: min W 1 (x,t),..., Wn(x,t) :∈{0,1} n n i=1 D q φ (x, X i )- Γ n n i=1 W i ( φ, x, t). The above formulation is used, for example, in Morucci et al. (2020) , or in some of the optimization problems of Zubizarreta ( 2012 ), together with additional constraints on the matching problem. This lemma importantly shows that the M-ML framework incorporates matching algorithms that target combined optimization problems, implying that the asymptotic and empirical results we obtain for M-ML can also be extended to such methods. In conclusion, we have shown that our methodology and theoretical results apply generally to many existing matching algorithms, and this in turn enables easy computation of asymptotic confidence intervals for these algorithms. Related Work The idea of matching on a learned function of the covariates has been previously explored in the literature on matching in various specialized and restricted settings. Of these settings, the first to emerge and to be extensively studied was Propensity Score Matching (PSM) (Rosenbaum and Rubin, 1983) . Of the various analyses of propensity score matching, the two closest to our setting are that of Rubin and Thomas (1992) , and that of Abadie and Imbens (2016) . The former shows that theoretical guarantees on finite-sample bias and variance can be derived for matching methods when covariate transformations are affine, and outcomes have ellipsoidal distributions. The latter shows that propensity score matching does indeed exhibit efficient asymptotic behavior when propensity scores are linear and for average effects only. Other recent work that considers matching on a transformation of the covariates includes Luo and Zhu (2020) , who consider matching on linear transformations of the covariates, and Kallus (2020), who proposes a method for estimation of the ATT that is √ n-consistent without requiring additional nonparametric adjustments, and relying on a kernel mapping of the covariates. Our paper is more general in that our matching framework works with any transformation of the covariates and require minimal distributional assumptions on the outcome data, as well as encompassing estimation of both ATE/ATT and CATE. Aside from tools for statistical inference, the literature on matching for treatment effect estimation has seen a proliferation of methods to make matches on the raw, untransformed values of the covariates (e.g., Iacus et al., 2012; Diamond and Sekhon, 2013; Zubizarreta, 2012) , but most of these methods focus on matching to optimize some aggregate metric of quality across units, and therefore perform poorly when estimating CATEs, unlike our proposed approach, and for the ATE/ATT they are prone to the issues of convergence outlined by Abadie and Imbens (2006) . That work shows that nearest-neighbor matching methods fail to attain the nominal, √ n, convergence rate for the ATE/ATT, a problem important for our setting. Recent work by Sävje (2022) shows that matching methods that match without replacement fail to attain this rate as well. We introduce a methodology based on recent results for efficient two-stage estimation (Chernozhukov et al., 2018; Van Der Laan and Rubin, 2006 ) that allows our average estimates to be consistent at the nominal rate. Other methods to address this issue include work by Abadie and Imbens (2011) and Otsu and Rai (2017) , but both of those methods require combining matching with independent nonparametric estimates of outcome and propensity functions that do not involve matching and therefore render final estimates hard to audit. Another existing method that addresses this issue is that of Wang and Zubizarreta (Forthcoming) , who show that matching methods that target average balance, rather than nearest-neighbor balance per unit, can achieve the nominal rate. Our results and proposed framework differ in that it uses nearest-neighbor matches, which is both computationally faster than optimizing the full set of matches simultaneously (which is done by mixed-integer program), and enables direct estimation of unit-level treatment effects, unlike their method. There also exists a literature on matching methods for individualized treatment effect estimation that combines machine learning of distance functions with matching (Dieng et al., 2019; Parikh et al., 2022; Morucci et al., 2020; Wang et al., 2021) : our paper aims to generalize all these methods under a single framework, and to provide users of these methods with a way to perform inference for their output estimates. Finally, the literature on nonparametric CATE estimation is related to our work. This literature has mainly focused on powerful black-box methods (Chipman et al., 2010; Wager and Athey, 2018; Farrell et al., 2021) whose predictions are not auditable by analysts and decision-makers, leading to substantially less trustworthy and potentially wrong results in many settings. Our method explicitly addresses this problem with matching. Simulations We present results from an empirical evaluation of the performance of M-ML for CATE and ATE estimation on several simulated datasets for which we know ground truth causal effects. As a setting, we focus on the application of M-ML as an auditing tool for ML by matching on outcome predictions made by black-box algorithms, as this is one of the most natural uses of M-ML. We show that, on average, M-ML performs comparably to blackbox methods that it is based on, and in some settings even improves on their performance. Global to all simulations, we generate data for n = 20000 units and p = 20 covariates, where 5000 units are used for training and the remaining for matching/estimation. For i = 1, . . . , n, we generate: X i ∼ N p (1, 1), σ i ∼ Uniform(1, 2), λ ∼ Uniform p (-4, 4), β lin = λ, β qua ∼ Uniform p (0, 1) + λ, β cos ∼ Uniform p (0, 1) + λ, δ ∼ Uniform p (-1, 1), δ int ∼ Uniform p×p (-0.5, 0.5), τ = 5, α = 5, i ∼ N (0, σ i where, for some vector u ∈ R p , u ∼ f p denotes a vector made up of p draws from the same distribution, f . We then generate outcomes according to the following DGP, for two treatment levels t = 0, 1: Nonlinear: Y i (t) = α+tτ +X i β lin +X 2 i β qua +cos(X i )β cos +tX i δ+t p j=1 p k=1 X ij X ik δ int jk + i Piecewise: Y i (t) = α + tτ + p j=1 I(X ij > 0)β lin j + t p j=1 I(X ij > 0)δ j + i Selection: Y i (t) = α + tτ + 10 j=1 X j β lin j + t 10 j=1 X j δ j + i . We choose the DGPs above because they simulate three settings that are complicated to deal with nonparametrically, but that may occur in applied scenarios. The nonlinear setting is one in which the outcome is a complex function of the covariates that may vary in unexpected ways, the piecewise setting is simpler, but each covariate is considered as a simple threshold, which adds a stepwise component to the function. Finally, the selection setting is also linear, but involves a variable selection component, as only 10 of the 20 simulated covariates are used to generate outcomes, and estimation methods need to be flexible enough to exclude or downweight the unused covariates to attain optimal results. Finally, we also generate propensity scores and treatment indicators with: u i ∼ Uniform(0.1, 1), e(X i , 1) = exp(u i (Y i (1) + Y i (0))/2 -i ) 1 + exp(u i (Y i (1) + Y i (0))/2 -i ) , T i ∼ Bernoulli(e(X i , 1)), note that the correlation between potential outcomes and treatment assignment is controlled by the random variable u i , which we introduce to avoid fully correlated treatment and outcomes and potential overlap violations. Our simulations will include BART, Gaussian Process, SVM as baseline predictors for M-ML as well as several other comparison methods including Causal Forests. A complete list of methods used can be found in Table 2 of the Appendix.For all the M-ML methods employed in our simulations, we match on the unweighted L2 distance, where φ is either the propensity score or the difference in potential outcomes estimated with one of three ML methods. We use KNN M-ML matching with fixed k n and k n set to n 1/2 , so that √ k n is a lower bound on the first stage convergence rates of most ML methods, under sufficient regularity assumptions on the data (Chernozhukov et al., 2018) . We first present results for CATE estimation in the top row of Figure 1 . CATEs in this setting are estimated as simple differences of predicted potential outcomes fitted by each method under consideration. Our results for this setting show that, while M-ML does not generally outperform the non-parametric black box methods that we compare it to, it also does not generally underperform them. This lends evidence to the idea that adding matching on top of ML methods can boost interpretability, auditability and enable uncertainty quantification, while leading to minimal or no loss in performance. Results also show that the DGP does have an influence on performance: specifically, M-ML seems to perform better under the Nonlinear and Selection DGPs, and outperforms nonparametric causal methods such as causal forests and X-learner in these settings. The bottom row of Note: Top Row: CATE, Bottom Row: ATE. Different methods compared are on the horizontal axis, and the vertical axis is the mean absolute estimation error at each each iteration. Acronyms are described in Table 2 . Figure 1 presents results for a similar set of simulations, but for ATE estimation. We use the M-DML algorithm with the KNN M-ML algorithm to construct first-stage predictions of conditional response functions. Causal forests, and bias-corrected matching methods, are used with the estimators provided in the original papers and packages that implement them. We compare to matching methods intended for ATE estimation, such as GenMatch, as well as the other nonparametric ML methods. Results are presented for 500 simulation rounds, at each of which a dataset of n = 5000 units was generated with the same DGP as before, and 3000 units were separated as a training set. Parameters other than , X,, and Y were generated first and kept the same for all 500 rounds, while other variables were generated at each round. Again we see that M-ML performs comparably with other ML methods, and can outperform some of them in certain settings. Again, choice of baseline algorithm and DGP seem to have an influence on performance. Finally, we conduct a set of simulations to study the coverage of 95% asymptotic confidence intervals obtained with M-ML and a BART ML backend. We choose to compare the coverage of M-ML against Causal Forests (Wager and Athey, 2018) , as this is the only other method we know of that produces asymptotically valid confidence intervals for CATE estimation. We run the same set of simulations as before, but vary the size of the training set each time. At each train set size, we randomly draw 250 CATEs to estimate from the distribution of X, and compute the proportion covered by their respective estimated CI. This procedure is repeated and averaged over 1000 simulations for each setting. Results are reported in the bottom row of Figure 2 . We see that M-ML performs much better than Causal Forests in Figure 2 , having larger coverage in all our simulation settings. Additionally we can see that M-ML still does not reach the nominal coverage level: this is expected as existing methods for CATE estimation also rarely do (Künzel et al., 2019) , given the hardness of the problem. Turning to the ATE, we compare coverage of M-DML to coverage obtained by causal forests with the same 8 Application: Matching with Image Data We apply our method to the study of the returns of brand responsiveness to social media followers. This is a well-studied issue in online marketing and consumer behavior: there is a cyclical relationship between brand relationships and engagement on social media. Engaging with a brand on social media can strengthen the consumer-brand relationship (Laroche et al., 2013; Labrecque, 2014) . Social media engagement strengthens the consumer-brand relationship when the consumer feels like the brand is responsive to them (Labrecque, 2014) . However, considerable evidence also shows that consumers who already have strong relationships with a brand are more likely to engage with that brand on social media (John et al., 2017; Simon and Tossan, 2018) . Because of this, understanding the effect of brand responsiveness to consumers on social media presents a clear causal inference challenge that we try to address here. Specifically, in order to control for potential confounders of the relationship in question, we match posts on metadata, such as date/time and number of comments, but also on the image that was posted. Matching on images is important because the content of an image in a post likely has an influence on the likelihood of interaction with that post. This application also demonstrates how M-ML allows matching of units on complex covariates such as images, and how one can audit results by simple inspection of the matches. Data and Methodology We trained the model on 70% of the post data and used the remaining 30% for inference. This left us with n = 1677 posts that we matched and estimated CATEs for. We chose the size of the matched groups as follows: for t = 0, 1 we set k nt set to the integer closest to n 1/2 t , where n t is the size of the group with treatment t in the matching set, using this procedure for both the treated and control group, we obtained k 1 = 7 to estimate µ(x, 1) and k 0 = 6 units to estimate µ(x, 0). Results The ATE of having at least one brand interaction during the same day a post was made on the number of comments received by that post in the following days was 0.36 with a 95% asymptotic confidence interval between 0.27 and 0.63. Since the outcome variable is the natural logarithm of a count, the result can be interpreted as saying that adding a brand interaction within the day of posting produces approximately a 44% increase in the number of comments received by that post in the following days. Additional results are presented in Figure 3 , which shows individual ATE estimates for each brand. These estimates were obtained by aggregating CATEs for individual posts for each brand with the M-DML estimator. Notably, most brands seem to exhibit a similar positive treatment effect, while only RightRice has a negative and statistically significant treatment effect. This suggests the presence of heterogeneities in the treatment effect that could motivate further investigation. Finally, we present some sample images from the matched groups created by M-ML with the VAE back-end. This is important because it allows us to better audit our estimates by looking at the cases that were used to generate them, i.e., the matched groups: if matched groups do not make intuitive sense, then there is reason to doubt their usefulness and overall trustworthiness for treatment effect estimation. The sample groups shown in Figure 4 highlight how images with similar elements are matched together: most of the groups contain posts from the same brand and contain visual representations of similar foods. Additional sample matched groups displaying a similar pattern are available in the supplement. This shows that our results are interpretable on a human level, and based on clear visual cues present in the matching covariates. Conclusion Interpretability is paramount in the high-stakes decision making settings in which causal inference is used because it enables estimates to be audited based on analysts' contextual knowledge. In this paper we have introduced Matched Machine Learning, a method that aims to combine the predictive capabilities of black-box ML methods with the auditability and user-friendliness of matching. We have presented M-ML algorithms for both CATE and ATE estimation in a general framework. Many different choices of matching metrics, representation functions, and additional constraints can be formulated as M-ML. We have theoretically shown that, under reasonable conditions, M-ML for CATE estimation achieves asymptotic normality and consistency at a rate close to the nonparametrically optimal one. We have also shown that, by using M-ML estimates as inputs to AIPW estimators, ATE and ATT can be estimated consistently at a √ n rate. Empirically, we have shown that M-ML does not compromise accuracy for auditability. In our application, we have shown how M-ML can be used to analyze causally non-standard data such as images. Overall, M-ML expands the boundary of research in interpretable but accurate causal inference. Potential extensions of M-ML include matching with continuous treatments that are transformed via ML methods, as well as developing milder theoretical conditions on first-stage ML estimates than those introduced in the present paper. Supplement A Preliminaries A.1 Assumptions and Main Notation Here we restate the main notation and assumptions of the paper. Let (Ω, F, P) be a probability space, with Ω = R × X × {1, . . . , M }, and let O = (Y, X, T ) be a set of random variables on this space, with Y = M j=1 Y (j)I[T = j]. Note that Y (t) has domain in R, X in X and T in {1, . . . , M }. Denote the joint distribution of O by P. For a random variable A, we use F A to denote its CDF and f A to denote its PDF, as well as E A and V A to denote expectation and variance wrt A. When the notation E[•] or V[•] is used without any indices it is taken to be with respect to all the random variates within the brackets. For a function g : R p → R d , define the distance function: D q g (u, v) := g(u) -g(v) q , where • q is the standard q-norm. Let A be a random variable over R p , and let f (A) : R p → R d . We will use the notation f (A) P,q = q max j=1,...,d |f (a) j | q dP(a) to denote the L q norm wrt measure P. We use the notation: µ(x, t) := E[Y |X = x, T = t], σ 2 (x, t) = V[Y |X = x, T = t], and τ (x, t, t ) = µ(x, t) -µ(x, t ) to refer to quantities of interest. We assume the following: A1 (Data Distribution): (a) The data O n = {O i } n i=1 = {Y i , X i , T i } n i=1 is a set of n i.i.d. copies of O. (b) The domain of the covariate distribution, X is a compact subset of R p . (c) The covariates have marginal distribution with differentiable CDF (w.r.t. the lebesgue measure) F X (x), and constants c f X , C f X , such that 0 < c f X < f X (x) < C f X < ∞ everywhere over X. A2 (Overlap): For all x ∈ X and t = 1, . . . , M we have 0 < Pr(T = t|X = x) < 1. A3 (Conditional Ignorability ): T ⊥ ⊥ (Y (1), . . . , Y (M ))|X. A4 (Bounded Higher Moments): For all t, t ∈ {1, . . . , M }, all x ∈ X and for some δ > 0 and a constant C δ we have: E[|Y (t)| 2+δ |X = x, T = t ] ≤ C δ . A5 (Lipschitz Condition): For all x, z ∈ X and t ∈ {1, . . . , M } there exists a constant C L such that: (a) |µ(x, t) -µ(z, t)| ≤ C L D q φ (x, z) (b) |σ 2 (x, t) -σ 2 (z, t)| ≤ C L D q φ (x, z) A6 (Representation function): There exists a function φ(x, O n ) : X × Ω → R d such that, for real-valued r M L > 0, and q > 0: (a) The functions φ(x, O n ) and φ(x) are f O -almost surely continuous with respect to x at all x ∈ X. (b) φ(x, O n ) -φ(x) P,q = o(n -r M L ) almost surely over f X . (c) φ(X, O n ) -φ(X) P,q = o(n -r M L ). Throughout this appendix we will also make use of some specialized notation to refer to matching operations. We will use MG( φ, x, t) ⊂ {1, . . . , n} to denote the matched group made around covariate value x, treatment value t, and with representation function φ. Note that the definition of MG( φ, x, t) will vary depending on whether Caliper M-ML or KNN-M-ML is used, and what definition is used will be specified in each theorem. We will also use the notation W i ( φ, x, t) = I[i ∈ MG( φ, x, t)] to denote membership of units i in MG( φ, x, t), and N ( φ, x, t) = n i=1 W i ( φ, x, t) to count the number of units in MG( φ, x, t). B Proofs B.1 Proof of Lemma 1 Proof. Before proving the result we establish some important facts. Consider the quantity φ(x, O n ) =: φ(x), where we remove the explicit dependence of φ on O n for notational simplicity. By A6 (b) and (c), we know that it must be a random variable (i.e., measurable function) over some subset A ⊂ R d . Denote the CDF of this random variable by F φ(x) . By A6 (b), we have that, for any u ∈ A: lim n→∞ F φ(x) (u) = F φ(x) (u) = 1 if u j ≥ φ(x) j , j = 1, . . . , d 0 otherwise. , due to the fact that φ(x) is a constant with respect to u. This also implies that dF φ(x) (u) = δ(φ(x)-u)du, where δ(u) is Dirac's delta function that puts density 1 at 0 and 0 everywhere else. By the above, we can also conclude that the joint CDF of the pair ( φ(x), φ(z)), denoted by F ( φ(x), φ(z)) (u, v) will converge to F φ(x) (u)F φ(z) (v). For arbitrary x, z ∈ X and Γ n ≥ 0, we can write the quantity: Pr On ( φ(x)-φ(z) q ≤ Γ n ) (where the randomness is over the training data) as a function of the quantities just studied: Pr On ( φ(x) -φ(z) q ≤ Γ n ) = R d R d I[ u -v q ≤ Γ n ]dF ( φ(x), φ(z)) (u, v). Let us change variables from u, v to u, r, where r = u-v Γn with Jacobian determinant equal to Γ d n . We have: Pr On ( φ(x) -φ(z) q ≤ Γ n ) = Γ d n R d R d I[ r q ≤ 1]dF ( φ(x), φ(z)) (u, u -Γ n r). Consider now the limiting behavior of Γ -d n Pr On ( φ(x) -φ(z) q ≤ Γ n ), we have: lim n→∞ Γ -d n Pr On ( φ(x) -φ(z) q ≤ Γ n ) = lim n→∞ R d R d I[ r q ≤ 1]dF ( φ(x), φ(z)) (u, u -Γ n r) = R d R d I[ r q ≤ 1] lim n→∞ dF ( φ(x), φ(z)) (u, u -Γ n r) = R d R d I[ r q ≤ 1]dF φ(x) (u)F φ(z) (u) = R d R d I[ r q ≤ 1]δ(φ(x) -u)δ(φ(z) -u)dudr = R d I[ r q ≤ 1]dr R d δ(φ(x) -u)δ(φ(z) -u)du = 2Ga( 2 q + 1) d Ga( d q + 1) δ(φ(x) -φ(z)) = V d δ(φ(x) -φ(z)). where the second equality follows from the dominated convergence theorem (DCT), which we can apply because the indicator function is upper bounded by 1. The fourth equality follows from the fact that F φ(x) is absolutely continuous wrt. the Lebesgue measure, and therefore has density equal to δ(φ(x)). The final equality follows from the definition of the volume under the d-dimensional unit ball around 0 defined by the q-norm, i.e., V d = R d I[ r q ≤ 1]dr = 2Ga( 2 q +1) d Ga( d namely that: 1) R φ ( φ, x, t) = o p (n -r ), 2) n 2r N ( φ,x,t) (N ( φ,x,t)+1) 2 p → 1 K for some constant, K, and 3) E n 2r N ( φ,x,t)+1 2 = O(1). Starting from the first condition, let X max = X i * , s.t: i * ∈ arg max i∈MG( φ,x,t) D q φ (X i , x), and recall that, by definition: R φ ( φ, x, t) = D q φ (X max , x). By assumption that matches are made with Caliper M-ML, we have D q φ (X max , x) ≤ Γ n , and by assumption that Γ n n 2r-1 d it follows that: n r D q φ (X max , x) ≤ n r Γ n = O(n r n 2r-1 d ) (3) = O(n r(1+ 2 d )-1 d ) → 0, for any r < 1 2+d . Using this fact, along with A6c, we can show n r R φ ( φ, x, t) p → 0 and verify Condition 1 as follows: n r R φ ( φ, x, t) = n r D q φ (X max , x) = n r φ(X max ) -φ(x) + φ(X max ) -φ(X max ) + φ(x) -φ(x) q ≤ n r φ(X max ) -φ(X max ) q + n r φ(x) -φ(x) q + n r φ(X max ) -φ(x) q = o p (1) + o p (1) + n r D q φ (X max , x) = o p (1). The inequality follows from the triangle inequality, and the last line follows by Assumption A6 and Eq. ( 3 ). Second, we will show that Condition 2 holds by showing that n 2r N ( φ,x,t) t) , where: ν φ (x, t) = V d e(t)f φ(X)|T =t (φ(x)) as defined in Lemma 1. Note that N ( φ, x, t) is a binomial random variable with size n and probability Pr(i ∈ MG( φ, x, t)). We know by Lemma 1 that: (N ( φ,x,t)+1) 2 p → 1 ν φ (x, E N ( φ,x,t) N ( φ, x, t) n 2r = n 1-2r Pr(i ∈ MG( φ, x, t)) p → ν φ (x, t) (4) whenever Γ n n 2r-1 d as we have assumed in this theorem. By Markov's inequality, this implies that N ( φ,x,t) n 2r p → ν φ (x, t). Consider now the quantity: (N ( φ, x, t) + 1) 2 : we know by Eq. ( 4 ) that: N ( φ, x, t) = O p (n 2r ), which implies that N ( φ, x, t) 2 = O p (n 4r ) and therefore: n -2r (N ( φ, x, t) + 1) 2 ≥ n -2r N ( φ, x, t) 2 = n -2r O p (n 4r ) p → ∞. Then we can apply the continuous mapping theorem to g(N ( φ, x, t) + 1), where: g(a) = 1 n -2r a -1 n -2r a 2 , because a = N ( φ, x, t)+1 > 0 in our context, and g(a) as defined is continuous over that domain. Then Condition 2 is verified as follows: n 2r N ( φ, x, t) (N ( φ, x, t) + 1) 2 = N ( φ, x, t) + 1 -1 n -2r (N ( φ, x, t) + 1) 2 = 1 n -2r (N ( φ, x, t) + 1) - 1 n -2r (N ( φ, x, t) + 1) 2 p → ν φ (x, t) -1 . To verify the last condition needed for Lemma 3 we first examine two related quantities. First, we know that N ( φ, x, t) is binomial with size n and probability Pr(i ∈ MG( φ, x, t)), and, therefore, its second moment is E[N ( φ, x, t) 2 ] = n(n -1)γ 2 + nγ, where γ = Pr(i ∈ MG( φ, x, t)) = O(Γ d n ) = O(n 2r-1 ), and (n 1-2r γ) 2 → ν φ (x, t) 2 , by Lemma 1 and the Continuous Mapping Theorem. Therefore we have: E   N ( φ, x, t) n 2r 2   = n(n -1) n 4r γ 2 + n n 4r γ = n 2-4r γ 2 -n 1-4r γ 2 + n 1-4r γ = (n 1-2r γ) 2 -n 1-4r O(n 4r-2 ) + n 1-4r O(n 2r-1 ) = (n 1-2r γ) 2 -O(n -1 ) + O(n -2r ) → ν φ (x, t) 2 . Another application of the results just stated gives us the following: E   N ( φ, x, t) + 1 n 2r 2   = E N ( φ, x, t) 2 + 2N ( φ, x, t) + 1 n 4r = E   N ( φ, x, t) n 2r 2   + 2 n 4r E[N ( φ, x, t)] + n -4r = E   N ( φ, x, t) n 2r 2   + o(1) + o(1) = O(1) → ν φ (x, t) 2 . The above display implies, by Markov's inequality, that N ( φ,x,t)+1 n 2r 2 p → ν φ (x, t) 2 . Additionally, since the function g(a) = 1/a is continuous over the positive reals, and N ( φ, x, t) + 1 is within this domain, we can apply the continuous mapping theorem to conclude that: n 2r N ( φ,x,t)+1 2 p → ν φ (x, t) -2 . Since g(a) is also bounded above by 1 over the same domain, the dominated convergence theorem can be applied to conclude that E n 2r N ( φ,x,t)+1 2 p → ν φ (x, t) -2 as well, which directly implies the condition we needed to verify. Since all three conditions are verified, result (i) in the theorem follows from applying Lemma 3. Claim (ii) Let μ(x, t) = 1 N ( φ,x,t)+1 n i=1 W i ( φ, x, t)µ(X i , t): we apply the triangle inequality to break up the error into two components featuring this term: μ(x, t) -µ(x, t) P,s = (E[|μ(x, t) -μ(x, t) + μ(x, t) -µ(x, t)| s ]) 1/s ≤ 2 1-1/s   (E[|μ(x, t) -μ(x, t)| s ] I 1 ) 1/s + (E[|μ(x, t) -µ(x, t)| s ] I 2 ) 1/s   . (5) We proceed by upper bounding I 1 and I 2 separately. Starting with component I 2 , recall that N ( φ, x, t) = n i=1 W i ( φ, x, t) and that N ( φ, x, t) follows a binomial distribution. Now by Lemma 1 and continuous mapping, we have (nΓ d n ) -s N ( φ, x, t) s p → ν φ (x, t) s , therefore: (nΓ d n ) s (N ( φ,x,t)+1) s p → ν φ (x, t) -s also by continuous mapping theorem. Finally, by dominated convergence we have: E 1 (N ( φ, x, t) + 1) s = O((nΓ d n ) -s ). ( 6 ) I 2 = E[|μ(x, t) -µ(x, t)| s ] = E 1 N ( φ, x, t) + 1 n i=1 W i ( φ, x, t)µ(X i , t) -µ(x, t) s = E 1 N ( φ, x, t) + 1 n i=1 W i ( φ, x, t)µ(X i , t) -µ(x, t) + µ(x, t) N ( φ, x, t) + 1 s ≤ 2 s-1 E 1 N ( φ, x, t) + 1 n i=1 W i ( φ, x, t)µ(X i , t) -µ(x, t) s + µ(x, t) N ( φ, x, t) + 1 s ≤ 2 s-1 E 1 N ( φ, x, t) + 1 n i=1 W i ( φ, x, t)C L D q φ (X i , x) s + µ(x, t) N ( φ, x, t) + 1 s ≤ 2 s-1 E C L N ( φ, x, t) + 1 n i=1 W i ( φ, x, t)R φ ( φ, x, t) s + 2 s-1 E µ(x, t) N ( φ, x, t) + 1 s = 2 s-1 C s L E N ( φ, x, t) N ( φ, x, t) + 1 s R φ ( φ, x, t) s + 2 s-1 |µ(x, t)| s E 1 (N ( φ, x, t) + 1) s ≤ 2 s-1 C s L E φ(X max ) -φ(X max ) + φ(X max ) -φ(x) + φ(x) -φ(x) s q + O((nΓ d n ) -s ) ≤ 2 s-1 C s L E[ φ(X max ) -φ(X max ) s q ] + 2 s-1 C s L E[ φ(x) -φ(x) s q ] + 2 s-1 C s L E[ φ(X max ) -φ(x) s q ] + O((nΓ d n ) -s ) = o(n -sr M L ) + o(n -sr M L ) + O(Γ s n ) + O((nΓ d n ) -s ). (7) The first inequality follows from A5, the second by definition of R φ ( φ, x, t), and the fourth from the triangle inequality. Note also that the fraction at the fourth line is always less than 1. The statement in the last line follows from A6, and from the fact that φ(X max )-φ(x) s q ≤ Γ n under caliper M-ML. We use Lemma 4 in order to upper bound I 1 . Letting Ỹ = (Y 1 , . . . Y n ), X = (X 1 , . . . , X n ), and T = (T 1 , . . . , T n ), we have: I 1 = E 1 N ( φ, X, t) + 1 n i=1 (Y i -µ(X, t))W i ( φ, X, t) s = E 1 N ( φ, X, t) + 1 s E Ỹ | X, T n i=1 (Y i -µ(X, t))W i ( φ, X, t) s (By Lemma 4) ≤ E B s C s N ( φ, x, t) s/2 (N ( φ, X, t) + 1) s ≤ B s C s E N ( φ, x, t) s/2 (N ( φ, X, t)) s = B s C s E 1 (N ( φ, X, t)) s/2 . ( 8 ) Therefore we have: I 1 ≤ B s C s E 1 (N ( φ, X, t)) s/2 = O((nΓ d n ) -s/2 ). (9) Putting together ( 5 ), ( 9 ), and ( 7 ), and applying Jensen's inequality, we obtain: μ(x, t) -µ(x, t) P,s ≤ 2 1-1/s (I 1 + I 2 ) 1/s = O((nΓ d n ) -1/2 ) + O(Γ n ) + o(n -r M L ). ( 10 ) The bound in the theorem can be obtained by setting Γ n = n 2r-1 d and r = 1 2+d and plugging into (10): μ(x, t) -µ(x, t) P,s = O(n -1 2+d ) + o(n -r M L ). (11) Since the domain of X is bounded, we can apply the DCT to μ(X, t) -µ(X, t) P,s = E X [ μ(X, t) -µ(X, t) s P ] 1/s to see that the bound holds in expectation over X as well. This concludes the proof. B.3 Proof of Theorem 2 Proof. Claim (ii) We will start by bounding the error: μ(x, t) -µ(x, t) P,s for arbitrary x ∈ X, as many of the steps of the proof of Claim (i) become simple after introducing this result. The result in Claim (ii) will follow by application of the DCT to this first result. Recall that we have defined μ(x, t) = 1 kn n i=1 W i ( φ, x, t)µ(X i , t), we apply the triangle inequality to break up the error into two components featuring this term: μ(x, t) -µ(x, t) P,s = E[ μ(x, t) -μ(x, t) + μ(x, t) -µ(x, t) s ] 1/s ≤ 2 1-1/s   (E[ μ(x, t) -μ(x, t) s ] I 1 ) 1/s + (E[ μ(x, t) -µ(x, t) s ] I 2 ) 1/s   . We use Lemma 4 in order to upper bound I 1 . Letting Ỹ = (Y 1 , . . . Y n ), X = (X 1 , . . . , X n ), and T = (T 1 , . . . , T n ), we have: I 1 = E 1 k n n i=1 (Y i -µ(X, t))W i ( φ, X, t) s = E 1 k n s E Ỹ | X, T n i=1 (Y i -µ(X, t))W i ( φ, X, t) s (By Lemma 4) ≤ E B s C s k s/2 n k s n = B s C s 1 k s/2 n . Before directly upper-bounding bias term I 2 , we establish a bound on the quantity: E[ φ(X (kn) ) -φ(x) s q ] = D q φ (X (kn) , x) s . Note that the transformed covariates, φ(X), have continuous and bounded density by continuity and boundedness of f X (the density function of the original covariates), and continuity of φ(x) at all x ∈ X. With these facts, we can apply Lemma 5 to φ(X 1 ), . . . , φ(X n ) as inputs, and with λ = -s and γ = 0 (λ and γ are defined in Lemma 5). From this we obtain: E[D q φ (X (kn) , x) s ] = O k n n s/d . ( 12 ) Using this result we can now switch to upper-bounding the bias term I 2 . Recall that R φ ( φ, x, t) = max i=1,...,n W i ( φ, x, t)D q φ (x, X i ), and note that in this case R φ ( φ, x, t) is the φ-distance between x and its k th n nearest neighbor within the matching sample. We have: I 2 = E[|μ(x, t) -µ(x, t)| s ] = E 1 k n n i=1 W i ( φ, x, t)µ(X i , t) -µ(x, t) s = E 1 k n n i=1 W i ( φ, x, t)(µ(X i , t) -µ(x, t)) s ≤ E 1 k n n i=1 W i ( φ, x, t)C L D q φ (X i , x) s ≤ E C L k n n i=1 W i ( φ, x, t)R φ ( φ, x, t) s = C L E[R φ ( φ, x, t) s ] where the first inequality follows from Assumption 5 and the second from the definition of R φ ( φ, x, t). Let X (kn) be the covariates of x's k th n nearest neighbor in terms of D q φ , and note that, using (12), we have: E[R φ ( φ, x, t) s ] = E[ φ(X (kn) ) -φ(x) s q ] ≤ 2 s-1 (E[ φ(X (kn) ) -φ(X (kn) ) s q ] + E φ(x) -φ(x) s q ] + E[ φ(X (kn) ) -φ(x) s q ]) = o(n -r M L s ) + o(n -r M L s ) + 2 s-1 E[D q φ (X (kn) , x) s ] = o(n -r M L s ) + O k n n s/d (13) where the fact that terms like E[ φ(x) -φ(x) q ] are o(n -r M L ) follows from Assumption 6. Finally, we can put together the bounds obtained so far to establish the result in the theorem: μ(x, t) -µ(x, t) P,s ≤ 2 1-1/s (I 1 + I 2 ) 1/s ≤ 2 1-1/s   (B s C s k -s/2 n ) 1 s + O k n n s/d + (o(n -sr M L )) 1 s   ≤ 2 1-1/s C s B 1/s s k -1/2 n + O k n n 1/d + o(n -r M L ) = O(k -1/2 n ) + O k n n 1/d + o(n -r M L ). This result can be easily extended to μ(X, t) -µ(X, t) P,s by application of the DCT to μ(X, t) -µ(X, t) P,s = (E x∼f X [ μ(x, t) -µ(x, t) s P,s ]) 1/s . The final lower bound in the Theorem can be obtained by plugging k n = n 2 2+d into the bound above and simplifying. Claim (i) We finish by proving the asymptotic normality result given in (i). We will appeal to Lemma 3 to verify this claim, and therefore need to verify that the three conditions required in the lemma hold in this case. Condition 1 holds since by ( 13 ) and Markov's inequality we have: R φ ( φ, x, t) = o p (n -r ) almost surely over f X whenever we set k n = Kn 2r , where r = min( 1 2+d , r M L ). Second, for Conditions 2 and 3, we know that N ( φ, x, t) = k n , and therefore: n 2r N ( φ,x,t) = n 2r kn → 1 K by assumption. This also implies that E n 2r N ( φ,x,t) 2 → 1 K 2 = O(1) . Therefore Conditions 2 and 3 of Lemma 3 are verified, and the lemma directly implies the result. B.4 Proof of Theorem 3 Proof. We will essentially use all the same arguments employed before to show this fact. Let η(x, t) = E[Y (t) 2 |X = x], and recall that we have previously defined µ(x, t) = E[Y (t)|X = x], and W i ( φ, x, t) to be a binary variable denoting membership in MG( φ, x, t). We will first concentrate on showing that: 1 N ( φ,x,t) n i=1 W i ( φ, x, t)Y 2 i p → η(x, t). To see that this is indeed the case, notice that: 1 N ( φ, x, t) n i=1 W i ( φ, x, t)Y 2 i -η(x, t) = 1 N ( φ, x, t) n i=1 W i ( φ, x, t)(Y 2 i -η(X i , t)) + 1 N ( φ, x, t) n i=1 W i ( φ, x, t)(η(X i , t) -η(x, t)). Starting with the first term, we have, for any i: E[Y 2 i -η(X i , t)|T i , X i ] = 0 by definition of η(X i , t), which implies that E[W i ( φ, x, t)(Y 2 i -η(X i , t))] = E T i ,X i [W i ( φ, x, t)E Y i |X i ,T i [(Y 2 i - η(X i , t))]] = 0, and therefore, by the weak law of large numbers: 1 N ( φ,x,t) n i=1 W i ( φ, x, t)(Y 2 i - η(X i , t)) p → 0. Moving on to the second term, note first that Assumption A5 implies, for all u, v ∈ X : |µ(u, t) 2 -µ(v, t) 2 | = |(µ(u, t) -µ(v, t))(µ(u, t) + µ(v, t))| ≤ |(µ(u, t) -µ(v, t))||(µ(u, t) + µ(v, t))| ≤ C L D q φ (u, v)|(µ(u, t) + µ(v, t))| ≤ C L D q φ (u, v)2C δ , where the first inequality follows by the Cauchy-Schwartz inequality, the second by the Lipschitz condition of Assumption A5, and the third by Assumption A4, which implies that |µ(u, t)| is bounded by some constant C δ . Applying the above to the second term of the previous expression we see that: 1 N ( φ, x, t) n i=1 W i ( φ, x, t)(η(X i , t) -η(x, t)) = 1 N ( φ, x, t) i∈MG( φ,x,t) (σ 2 (X i , t) + µ(X i , t) 2 -σ 2 (x, t) -µ(x, t) 2 ) = 1 N ( φ, x, t) i∈MG( φ,x,t) (σ 2 (X i , t) -σ 2 (x, t)) + (µ(X i , t) 2 -µ(x, t) 2 ) ≤ 1 N ( φ, x, t) i∈MG( φ,x,t) C L D q φ (X i , x) + 2C δ C L D q φ (X i , x) ≤ (C L + 2C δ C L ) max i∈MG( φ,x,t) D q φ (X i , x) = O p (R φ ( φ, x, t)), where the first equality follows by definition of variance, the first inequality by Assumption A5, and the second inequality by the definition of max. By the same argument as the proofs of Thms 1 and 2, we know that R φ ( φ, x, t) p → 0, both when matches are made with a caliper (by Eq. ( 7 )), and with fixed k n (by Eq. ( 12 )). Therefore, 1 N ( φ,x,t) n i=1 W i ( φ, x, t)(η(X i , t) - η(x, t)) p → 0. This establishes convergence of 1 N ( φ,x,t) i∈MG( φ,x,t) Y 2 i to η(x, t). Using this result, we can show that the simple variance estimator is indeed consistent for the CATE variance: 1 N ( φ, x, t) i∈MG( φ,x,t) (Y i -μ(x, t)) 2 = 1 N ( φ, x, t) i∈MG( φ,x,t) (Y 2 i -2Y i μ(x, t) + μ(x, t) 2 ) =   1 N ( φ, x, t) i∈MG( φ,x,t) Y 2 i   -   μ(x, t) 2 N ( φ, x, t) i∈MG( φ,x,t) Y i   + μ(x, t) 2 = 1 N ( φ, x, t) i∈MG( φ,x,t) Y 2 i -μ(x, t) 2 p → η(x, t) -µ(x, t) 2 = σ 2 (x, t), where converge of μ(x, t) 2 to µ(x, t) 2 follows from the continuous mapping theorem applied to μ(x, t) p → µ(x, t). B.5 Proof of Theorem 4 Proof. The proof of this statement follows from applying Theorem 5.1 in (Chernozhukov et al., 2018) to the estimators ψ(X i , t). The theorem can be applied because M-DML is a case of the DML2 algorithm in Definition 3.2 of the same paper, which is covered by Theorem 5.1. This theorem requires us to check that our estimators satisfy Assumption 5.1 in the same paper, which is comprised of several conditions. We first examine the primitive conditions of Assumption 5.1 of Chernozhukov et al. (2018) . All of these conditions are satisfied by our main assumptions, specifically: Condition (i) is satisfied by assumption in the theorem, Condition (ii) is satisfied by A4, Condition (iii) is satisfied by A2, Condition (iv) is satisfied by A1, Condition (v) is satisfied by A4. We now need to verify three conditions on the estimators of μ and ê. First, let η(x) = (µ(x, 1), µ(x, 0), e(x, 1), e(x, 0)), where we use η(x) j to refer to the j th component of this vector, for j = 1, . . . , 4. Additionally, let the respective estimator for this quantity be ηO \\ℓ (x) = (μ(x, 1), µ(x, 0), ê(x, 1), ê(x, 0)), where we use the notation O \\ℓ to emphasize that the estimator ηO \\ℓ (x) depends on data not in fold ℓ: O \\ℓ = {X i , T i , Y i } i∈S \\ℓ . For s > 2, define: ηO \\ℓ -η P,s = max j∈1,...,4 O \\ℓ ,X ηD (x) j -η(x) j q f O \\ℓ (D)f X (x)dDx. In order to show that Assumption 5.1 of Chernozhukov et al. (2018) is satisfied in our setting, we nee to show that ηO \\ℓ -η P,s ≤ C for some strictly positive C. Note first that ê(x, t) -e(x, t) P,s < 1, since 0 < ê(x, t) < 1, and 0 < e(x, t) < 1 for all datasets D, x and t by construction. It remains to show that μ -µ P,s ≤ C. This follows from our A4 by setting δ = s -2 therein. Then, for any unit, i, t, and x: E Y i [ Y i -µ(x, t) s |X i = x i , T i = t] ≤ E Y [ Y i s |X i = x i , T i = t] + µ(x, t) s = E Y i [ s |Y i | s |X i = x i , T i = t] + E Y [ s |Y | s |X = x, T = t] ≤ E Y i [ Y i s |X i = x i , T i = t] + E Y [ Y s |X = x, T = t] ≤ C s + C s , therefore: μ -µ P,s = E[E Y \\ℓ [ μ(x, t) -µ(x, t) q |X = x, X \\ℓ , T \\ℓ ]] = E   E Y \\ℓ   1 N ( φ, x, t) i∈MG( φ,x,t) Y i -µ(x, t) q X = x, X \\ℓ , T \\ℓ     ≤ E E Y \\ℓ max i∈MG( φ,x,t) Y i -µ(x, t) q X = x, X \\ℓ , T \\ℓ ≤ 2C s . Second, we must show that ηO \\ℓ -η P,2 = o(1). This is true for ê -e P,2 by assumption, and it holds true for μ -µ P,2 by Theorems 1, for Caliper M-ML, and 2 for KNN-MML. Finally, the last requirement for Assumption 5.1 of Chernozhukov et al. (2018) is that: μ -µ P,2 × ê -e P,2 = O(n -1 2 ), by Theorems 1, and 2, we know that μ -µ P,2 = O(n -r ), and by assumption that êe P,2 = O(n -re ), since we have assumed that r + r e = 1/2, we have: μ -µ P,2 × ê -e P,2 = O(n -r ) × O(n -re ) ≤ O(n -1/2 ). The same exact argument can be used to show that the same is true for the case of the ATT. B.6 Proof of Lemma 2 Proof. Let MG * = {i : D q φ (X i , x) ≤ Γ n }, and define the associated membership indicators: W * i = 1 if D q φ (X i , x) ≤ Γ n 0 otherwise. D( φ, x, t) + B( φ, x, t), as follows: μ(x, t) -µ(x, t) = 1 N ( φ, x, t) + c i∈MG( φ,x,t) Y i -µ(x, t) + 1 N ( φ, x, t) + c i∈MG( φ,x,t) µ(X i , t) -1 N ( φ, x, t) + c i∈MG( φ,x,t) µ(X i , t) = 1 N ( φ, x, t) + c i∈MG( φ,x,t) Y i -µ(X i , t) D( φ,x,t) + 1 N ( φ, x, t) + c i∈MG( φ,x,t) µ(X i , t) -µ(x, t) B( φ,x,t) . ( ) 14 We will, for now, disregard the B( φ, x, t) term, and come back to it later, as we will see that the conditions needed for asymptotic normality of μ(x, t) imply vanishing of this term. Because of this intuition, it will suffice to show asymptotic normality of n r D( φ, x, t) as Slutzky's theorem will imply that the asymptotic distribution of this term is the same as that of n r (μ(x, t) -µ(x, t)). To study the asymptotic distribution of D( φ, x, t), we wish to write it as a martingale, which will then enable us to employ central limit theorems for martingale arrays in order to establish its asymptotic normality. We can show that D( φ, x, t) does indeed constitute a martingale w.r.t. a certain filtration by rewriting it as a sum of martingale differences. Recall that the binary variable W i ( φ, x, t) = I[i ∈ MG( φ, x, t)] denotes membership of matching set unit i in MG( φ, x, t). Note that, W i ( φ, x, t) = 1 only if T i = t, and define, for any i ∈ 1, . . . , n: ξ n,i (x) = n r N ( φ, x, t) + c W i ( φ, x, t)(Y i -µ(X i , t)) These quantities will be the martingale differences in the representation we will construct, and by definition: n r D( φ, x, t) = n i=1 ξ n,i (x). Finally, define the following σ-field: F n,i (x) = σ{X 1 , . . . , X n , T 1 , . . . , T n , Y 1 , . . . , Y i , φ}. Note that we include the representation φ directly in the filtration defined, but if the representation is learned from a separate training set, then this dataset can be included in the filtration instead of it to obtain the same results. Since the ξ n,i (x) have zero mean, and are adapted to the filtration F n,i (x), then the array: i j=1 ξ n,j (x), F n,i (x), 1 ≤ i ≤ n (16) is a martingale for each n > 2 by the same arguments in Abadie and Imbens (2012) . We can now apply Lindeberg's central limit theorem for triangular martingale arrays to the martingale array defined in ( 16 ). The CLT in question states that if: → N (0, σ 2 ). We will now show that all three conditions hold. Starting with Condition 1, this condition is easily verified because E[ξ n,i (x)|F n,i-1 (x)] = 0, since ξ n,i (x) is a martingale difference term, and that, therefore, E[ξ n,i (x)] = E[E[ξ n,i (x)|F n,i-1 (x)]] = E[0] = 0. Second, Condition 3, commonly known as Lindeberg's condition, is implied by Lyapunov's condition, which is much easier to check. Lyapunov's condition statest that, for some δ > 0: lim n→∞ N i=1 E[|ξ n,i (x)| 2+δ ] = 0. Lyapunov's condition can be seen to hold in our case by the following: fix a s > 0, then, E[|ξ n,i (x)| 2+δ ] = E      n r N ( φ, x, t) + c ≥0 W i ( φ, x, t) ∈{0,1} (Y i -µ(X i , t)) 2+δ      = E n 2r+rδ (N ( φ, x, t) + c) 2+δ W i ( φ, x, t)|Y i -µ(X i , t)| 2+δ , Recall now that, by Assumption A5, E[|Y i | 2+δ |X i , T i ] ≤ C δ for some constant C δ < ∞. Additionally, since Y i ⊥ ⊥ φ by A6.b, it follows that: E[|Y i | 2+δ | φ, X i , T i ] ≤ C s . Since conditionally on φ, X i , and T i , all of µ(X i , t), N ( φ, x, t), W i ( φ, x, t) are constants, it follows that: E W i ( φ, x, t) n 2r+rδ (N ( φ, x, t) + c) 2+δ |Y i -µ(X i , t)| 2+δ = E W i ( φ, x, t) n 2r+rδ (N ( φ, x, t) + c) 2+δ E[|Y i -µ(X i , t)| 2+δ | φ, X i , T i ] ≤ E W i ( φ, x, t) n 2r+rδ (N ( φ, x, t) + c) 2+δ C δ . Note that Requirement (3) of this lemma implies that n r cµ(x,t) N ( φ,x,t)+c = o p (1) by Markov's inequality. This concludes the proof. Lemma 4. (Bound on moments of matched outcomes) Let MG( φ, x, t) be a collection of units with treatment t matched to x and let N ( φ, x, t) denote the size of this collection. Let A1-A4 hold and let all other queantities be defined as in the rest of the paper. We have, for s ≥ 2: E n i=1 W i ( φ, x, t)(Y i -µ(X i , t)) s ≤ B s C s N ( φ, x, t) s/2 , ( 20 ) for a constant B s depending only on s, and C s defined in Assumption 4. Proof. This is a well-known results that holds generally for mean-0 random variables. Here we simply adapt its proof to our setting. Let Ỹ = (Y 1 , . . . , Y n ), X = (X 1 , . . . , X n ), and T = (T 1 , . . . , T n ). Since the random variables Y i -µ(X i , t) have mean 0, conditional on X i , then by the Marcinkiewicz-Zygmund inequality, there exists a constant B s such that: E Ỹ | X, T n i=1 W i ( φ, x, t)(Y i -µ(X i , t)) s ≤ B s E Ỹ | X, T   n i=1 |W i ( φ, x, t)(Y i -µ(X i , t))| 2 s/2   = B s N ( φ, x, t) s/2 E Ỹ | X, T   1 N ( φ, x, t) n i=1 |W i ( φ, x, t)(Y i -µ(X i , t))| 2 s/2   then by Jensen's inequality we have: ≤ B s N ( φ, x, t) s/2 E Ỹ | X, T 1 N ( φ, x, t) n i=1 |W i ( φ, x, t)(Y i -µ(X i , t))| s = B s N ( φ, x, t) s/2 1 N ( φ, x, t) n i=1 W i ( φ, x, t)E Y i |X i ,T i [|(Y i -µ(X i , t))| s ] and since This lemma is a restatement of Lemma 14.1 of Li and Racine (2007) and is proven therein. E Y i |X i ,T i [|(Y i -µ(X i , t))| s C Methods used in the simulation Corollary 1 . 1 (Asymptotic Normality of CATE estimates) Let A1-A6 hold, and let let r = min 1 2+d , r M L . For two treatment levels t, t ∈ {1, . . . , M } and a real K > 0: as n → ∞: (i) If matches are made with Caliper M-ML and Γ n = Kn 2r-1 p Theorem 4 . 4 Let the observed outcome and treatment be defined as follows: Y = µ(X, D) + U, E[U |X, D] = 0, and D = e(X, D) + V, E[V |X] = 0. Let A1-A6 hold, and assume Figure 1 : 1 Figure 1: Estimation error Figure 2 : 2 Figure 2: 95% Asymptotic Confidence Interval Coverage use a dataset of Instagram image posts made by 31 food brands between May 15th 2020 and May 15th 2021. The treatment is 1 if the post had any responses from the brand itself to comments left by the viewers in the same day it was posted, and the outcome variable is the number of comments received by a post a day or more after it was posted. The control covariates are hour, month and weekday that the original post was made, and total number of comments left by users on the post on the day it was posted, as well as the image of the post itself. The latter allows us to control directly for the content of the post. For this application, we first constructed our ML representation function by training a variational autoencoder (Kingma and Welling, 2013) on the training set. We used the representation function to construct a 100-dimensional representation of each image within the matching set. Our encoder-decoder architecture consists of two identical CNNs with 4 layers. We Figure 3 : 3 Figure 3: CATE by brand Figure 4 : 4 Figure 4: Sample matched groups 1. (Condition 1) E[ξ n,i (x)] = 0 2. (Condition 2) n i=1 E[ξ n,i (x) 2 |F n,i-1 (x)] p → σ 2 , for some constant, σ 2 , as n → ∞ 3. (Condition 3) ∀ > 0 : N i=1 E[ξ n,i (x) 2 I [|ξ n,i (x)|> ] ] → 0, as n → ∞,then n r D( φ, x, t) d ] ≤ C s by Assumption 4 with δ = s -2:≤ B s N ( φ, x, t) s/2 1 N ( φ, x, t) n i=1 W i ( φ, x, t)C s = B s C s N ( φ, x, t) s/2 .Lemma 5. (Bound on KN N distances, Lemma 14.1 in Li and Racine 2007) Let Z 1 , . . . , Z n be i.i.d. observations with bounded continuous density f Z supported over a subset of R d . For a point z in the support of f Z , let B(z, r) be a ball of radius r centered at z, and define G(r) = Pr Z (Z ∈ B(z, r)). Additionally let R k (z) be the Euclidean distance between z and its k th nearest neighbor among the Z 1 , . . . , Z n . Finally, let λ and γ be integers such that the function Φ(R k (z)) := 1 R k (z) λ G(R k (z)) γ exists. Then: E Z 1 ,...,Zn [Φ(R k (z)) Figure 5 : 5 Figure 5: 95% Asymptotic Confidence Interval Size for the CATE Table 2 : 2 Methods used in simulated experiments Acronym Method q +1) , where Ga is the Gamma function (see e.g., Wang, 2005) , and from known properties of Dirac's δ function.We can now study the limiting behavior of Pr On (Z ∈ MG( φ, x, t)), for (Z, T ) ∼ f X,T , using the result just obtained and applying the DCT once again. Define first the density function f φ(X) (u) = X f X (z)δ(φ(z) -u)dz. Fix now an arbitrary unit i in the matching data with"
}