{
  "title": "Machine Learning with a Reject Option: A survey",
  "abstract": "Machine learning models always make a prediction, even when it is likely to be inaccurate. This behavior should be avoided in many decision support applications, where mistakes can have severe consequences. Albeit already studied in 1970, machine learning with rejection recently gained interest. This machine learning subfield enables machine learning models to abstain from making a prediction when likely to make a mistake. This survey aims to provide an overview on machine learning with rejection. We introduce the conditions leading to two types of rejection, ambiguity and novelty rejection, which we carefully formalize. Moreover, we review and categorize strategies to evaluate a model's predictive and rejective quality. Additionally, we define the existing architectures for models with rejection and describe the standard techniques for learning such models. Finally, we provide examples of relevant",
  "introduction": "Introduction The canonical task in machine learning is to learn a predictive model that captures the relationship between a set of input variables and a target variable on the basis of training data. Machine-learned models are powerful because, after training, they offer the ability to make accurate predictions about future examples. Since this enables automating a number of tasks that are difficult and/or time-consuming, such models are ubiquitously deployed. However, their key functionality of always returning a prediction for a given novel input is also a drawback. While the model may produce accurate predictions in general, in certain circumstances this may not be the case. For instance, there could be certain regions of the feature space where the model struggles to differentiate among the different classes. Or the current test example could be highly dissimilar to the data used to train the model. In certain application domains, such as medical diagnostics (Kotropoulos and Arce 2009) and engineering (Zou et al. 2011) , mispredictions can have serious consequences. Therefore, it would be beneficial for a model to be cautious in situations where it is uncertain about its predictions. The prediction task could be deferred to a human expert in these situations. One way to accomplish this is to use machine learning models with rejection. Such models assess their confidence in each prediction and have the option to abstain from making a prediction when they are likely to make a mistake. This ability to abstain from making a prediction has several benefits. First, by only making predictions when it is confident, it can result in improved performance for the retained examples (Pudil et al. 1992) . Second, avoiding mispredictions can increase a user's trust in the system (El-Yaniv and Wiener 2010). Third, it can still result in time savings by only requiring human interventions to make decisions in a small number of cases. Fourth, avoiding strongly biased predictions helps build a more fair model (Lee et al. 2021; Ruggieri et al. 2023) . This machine learning subfield was already studied in 1970 by Chow (1970) and Hellman (1970) . However, the proliferation of applications has resulted in renewed interest in this area. This survey aims to provide an overview of the subfield of machine learning with rejection, which we structure around eight key research questions. Q1. How can we formalize the conditions for which a model should abstain from making a prediction? Q2. How can we evaluate the performance of a model with rejection? Q3. What architectures are possible for operationalizing (i.e., putting this into practice) the ability to abstain from making a prediction? Q4. How do we learn models with rejection? Q5. What are the main pros and cons of using a specific architecture? Q6. How can we combine multiple rejectors? Q7. Where does the need for machine learning with rejection methods arise in real-world applications? Q8. How does machine learning with rejection relate to other research areas? In addition to the individual contributions of addressing each of these research questions, our major contribution is that we identify the main characteristics of machine learning models with rejection, allowing us to structure the methods in this research field. By providing an overview of the research field as well as deeper insights into the various techniques, we aid in further advance this research area, as well as its adaptation to real-world applications. The remainder of this paper is structured as follows. In Section 2, we formalize the setting in which machine learning with rejection operates and identify the two main motivations to abstain from making a prediction (Q1). Section 3 introduces the means to evaluate the performance of models with rejection (Q2). Sections 4, 5, and 6 provide a structured overview of the actionable techniques to reject based on the relevant literature. In these sections, we focus on describing the architecture (Q3), the rejector's learning (Q4), and the key pros and cons (Q5). In Section 7 we explore how to combine multiple rejectors to allow different types of rejection (Q6) Section 8 discusses the main application fields (Q7), while Section 9 explores the relation of machine learning with rejection with other research areas (Q8). Finally, Section 10 summarizes our conclusions and lists the main open research questions. 2 The learning with reject problem setting In the standard supervised setting, a learner has access to a training set D = {(x 1 , y 1 ), . . . , (xn, yn)}, where each x i is a d dimensional vector and y i is the target. The training data is assumed to be independent and identically distributed (i.i.d.) according to some unknown probability measure P (with density p(X, Y )). More generally, we denote the feature space as X and the target space as Y, which could be discrete Y = {1, 2, . . . , K}, continuous Y = R, or even probabilistic Y = [0, 1]. The assumption is that there is an unknown, non-deterministic function f : X → Y that maps the examples to their target value. Given a hypothesis space H of functions h : X → Y, the goal of a learner is to find a good approximation to f . Typically, this can be done by finding a model h ∈ H with a small expected risk R which is usually approximated using the training data R(h) := X ×Y L(h(x), y)dP (x, y) ≈ n i=1 L(h(x i ), y i ) n , (1) where L is a suitable loss function such as the squared or zero-one loss.",
  "body": "application domains and show how machine learning with rejection relates to other machine learning research areas. Introduction The canonical task in machine learning is to learn a predictive model that captures the relationship between a set of input variables and a target variable on the basis of training data. Machine-learned models are powerful because, after training, they offer the ability to make accurate predictions about future examples. Since this enables automating a number of tasks that are difficult and/or time-consuming, such models are ubiquitously deployed. However, their key functionality of always returning a prediction for a given novel input is also a drawback. While the model may produce accurate predictions in general, in certain circumstances this may not be the case. For instance, there could be certain regions of the feature space where the model struggles to differentiate among the different classes. Or the current test example could be highly dissimilar to the data used to train the model. In certain application domains, such as medical diagnostics (Kotropoulos and Arce 2009) and engineering (Zou et al. 2011) , mispredictions can have serious consequences. Therefore, it would be beneficial for a model to be cautious in situations where it is uncertain about its predictions. The prediction task could be deferred to a human expert in these situations. One way to accomplish this is to use machine learning models with rejection. Such models assess their confidence in each prediction and have the option to abstain from making a prediction when they are likely to make a mistake. This ability to abstain from making a prediction has several benefits. First, by only making predictions when it is confident, it can result in improved performance for the retained examples (Pudil et al. 1992) . Second, avoiding mispredictions can increase a user's trust in the system (El-Yaniv and Wiener 2010). Third, it can still result in time savings by only requiring human interventions to make decisions in a small number of cases. Fourth, avoiding strongly biased predictions helps build a more fair model (Lee et al. 2021; Ruggieri et al. 2023) . This machine learning subfield was already studied in 1970 by Chow (1970) and Hellman (1970) . However, the proliferation of applications has resulted in renewed interest in this area. This survey aims to provide an overview of the subfield of machine learning with rejection, which we structure around eight key research questions. Q1. How can we formalize the conditions for which a model should abstain from making a prediction? Q2. How can we evaluate the performance of a model with rejection? Q3. What architectures are possible for operationalizing (i.e., putting this into practice) the ability to abstain from making a prediction? Q4. How do we learn models with rejection? Q5. What are the main pros and cons of using a specific architecture? Q6. How can we combine multiple rejectors? Q7. Where does the need for machine learning with rejection methods arise in real-world applications? Q8. How does machine learning with rejection relate to other research areas? In addition to the individual contributions of addressing each of these research questions, our major contribution is that we identify the main characteristics of machine learning models with rejection, allowing us to structure the methods in this research field. By providing an overview of the research field as well as deeper insights into the various techniques, we aid in further advance this research area, as well as its adaptation to real-world applications. The remainder of this paper is structured as follows. In Section 2, we formalize the setting in which machine learning with rejection operates and identify the two main motivations to abstain from making a prediction (Q1). Section 3 introduces the means to evaluate the performance of models with rejection (Q2). Sections 4, 5, and 6 provide a structured overview of the actionable techniques to reject based on the relevant literature. In these sections, we focus on describing the architecture (Q3), the rejector's learning (Q4), and the key pros and cons (Q5). In Section 7 we explore how to combine multiple rejectors to allow different types of rejection (Q6) Section 8 discusses the main application fields (Q7), while Section 9 explores the relation of machine learning with rejection with other research areas (Q8). Finally, Section 10 summarizes our conclusions and lists the main open research questions. 2 The learning with reject problem setting In the standard supervised setting, a learner has access to a training set D = {(x 1 , y 1 ), . . . , (xn, yn)}, where each x i is a d dimensional vector and y i is the target. The training data is assumed to be independent and identically distributed (i.i.d.) according to some unknown probability measure P (with density p(X, Y )). More generally, we denote the feature space as X and the target space as Y, which could be discrete Y = {1, 2, . . . , K}, continuous Y = R, or even probabilistic Y = [0, 1]. The assumption is that there is an unknown, non-deterministic function f : X → Y that maps the examples to their target value. Given a hypothesis space H of functions h : X → Y, the goal of a learner is to find a good approximation to f . Typically, this can be done by finding a model h ∈ H with a small expected risk R which is usually approximated using the training data R(h) := X ×Y L(h(x), y)dP (x, y) ≈ n i=1 L(h(x i ), y i ) n , (1) where L is a suitable loss function such as the squared or zero-one loss. Models with a reject option In learning with rejection, the output space of the model is extended to include a new value ® (Cortes et al. 2016a (Cortes et al. , 2018;; Gamelas Sousa et al. 2014a) . This new symbol means that the model abstains from making a prediction. When performing classification with rejection, which is also called cautious classification, this new output ® can be seen as an additional class (Ferri and Hernández-Orallo 2004) . Conceptually, since h only approximates the true underlying model, there are likely regions of X where h systematically differs from f . Specifically, discrepancies between h and f can be due to inconsistent data (e.g., classes overlapping), insufficient data (e.g., unexplored regions), or even incorrect model assumptions (e.g., h must be linear while f is not). Therefore, the goal of rejection is to determine such regions in order to abstain from making likely inaccurate predictions. Formally, a model with rejection m : X → Y ∪ {®} is represented by a pair (h, r), where h : X → Y is the predictor and r : R → R is the rejector. Note that the rejector may use a variety of different inputs such as examples (R = X ), confidence or probability values (R = [0, 1]), or even both (R = X × [0, 1]). At prediction time, m outputs the symbol ® and abstains from making predictions when the rejector r determines that the predictor is at a heightened risk of making a misprediction and otherwise returns the predictor's output: m(x) = ® if the prediction is rejected ; h(x) if the prediction is accepted . (2) At prediction time, the key design decision for a model with rejection is how to structure the relationship between the predictor and rejector. Based on our analysis of the literature, we have identified three common architectural principles. Separated rejector architecture. The rejector operates independently from the predictor. The most typical operationalization of this architecture lets the rejector serve as a filter that decides whether to pass a test example to the predictor. Figure 1 shows the test time data flow of a separated rejector. Dependent rejector architecture. Here, the rejector bases its decision on the output of the predictor. For instance, the dependent rejector can look at how close a prediction is to the predictor's decision boundary and abstain if it is too close. Figure 2 shows the data flow for the dependent rejector. Integrated rejector architecture. This principle involves integrating the rejector and predictor into a single model m by treating rejection as an additional class that can be returned by the model m. Thus, it is impossible to distinguish between the role of the predictor h and the rejector r. Figure 3 illustrates this scenario. Fig. 1 : Data flow in a separated rejector, in which both the predictor and the rejector are stand-alone models. The rejector is a filter and only passes accepted examples to the predictor. Types of rejection At a high-level, a learned predictor can exhibit (high) uncertainty in its predictions for four reasons: R1. There can be cases where a vector x i ∈ X is associated with multiple values from the target space Y. This can arise in situations such as when classes overlap in classification tasks.  R2. Some instances in the training data are incorrect (e.g., the values of certain features were recorded incorrectly, labeling errors). R3. P (X, Y ) might differ between the training phase and deployment (e.g., concept drift). Consequently, the training data is no longer representative. R4. Some examples x could simply not be acquired due to their inherent rarity (anomalies, out-of-distribution). Based on this intuition, two types of rejections can be performed: Ambiguity Rejection: occurs if x falls in a region where the target y is ambiguous (R1 and R2). This often occurs in regions that are close to the decision boundary in classification tasks; Novelty Rejection: occurs if x falls in a region where there was little (or no) training data. Hence, the predictor may struggle to make accurate predictions because it did not see enough data to accurately model the relationship between X and Y (R3 and R4). Ambiguity Rejection Ambiguity rejection allows a model to abstain from making a prediction for an example x in regions where, despite having access to some training examples, the model h fails to capture the correct relationship f between X and Y (Flores 1958; Hellman 1970; Fukunaga and Kessell 1972) . This can happen for two reasons. First, the observed relationship between X and Y is not deterministic. This can arise due to the intrinsic probabilistic nature of Y |X, which a deterministic predictor h cannot handle (e.g., coin toss), or the training data containing too many errors (e.g., incorrectly labeled examples), which would make it difficult for h to approximate f . In classification, this can arise due to classes overlapping in certain regions of the instance-space (Figure 4a ), while in regression, it leads to high variance in the target variable in certain regions (Figure 5a ). One way to interpret this issue is that the chosen feature space does not allow for accurately determining the target value (e.g., missing features might cause examples with different predictions to be projected onto the same example (Van Craenendonck et al. 2018 , Figure 2 )). Second, a poor choice of the predictor's hypothesis space makes it impossible to learn the relationship between X and Y . This occurs when the chosen hypothesis space H does not include f . Figure 4b illustrates this error in binary classification, where only linear models (e.g., perceptron) are considered for H while the true target concept f is non-linear. Similarly, Figure 5b shows a regression problem with H as the family of quadratic models, while f is non-quadratic. In both cases, the expected prediction error is large for certain examples because f ̸ ∈ H. Novelty Rejection Many machine learning models struggle when forced to extrapolate to regions of the feature space that were not (sufficiently) present in the training data (Cordella et al. 1995a; Sambu Seo et al. 2000; Vailaya and Jain 2000) . Novelty rejection allows a model to abstain from making predictions for examples that are sufficiently different from the training data (Dubuisson and Masson 1993) . For such examples, the predictor h is likely to make mistakes because the absence of training data similar to x prevents h from learning the correct target y. In practice, this arises when one of the following assumptions of the training procedure is violated. First, the sampling distribution differs from the true distribution. Thus, parts of the feature space are not represented in the data (e.g., the data does not contain any examples of patients suffering from a particular rare disease) ( Van der Plas et al. 2021) or one cannot generate data for all imaginable situations (e.g., a sensor can break in many different ways) (Hendrickx et al. 2022; Urahama and Furukawa 1995; Hsu et al. 2020) . Second, the skew in the class distribution is too large that the model ignores parts of the feature space. Thus, the predictor may choose to ignore these examples in its objective to optimize the accuracy model-complexity trade-off. Third, a new distribution appears after training and these new examples are out-of-distribution. For instance, this can arise due to drift that leads to new classes (Landgrebe et al. 2004 ) or an adversarial agent that deliberately tries to mislead (Wang and Yiu 2020; Corbière et al. 2022) . Figures 4c and 5c illustrate this rejection type for a classification and a regression problem. In both cases, the three black stars represent test examples that are far away from the training examples. The learned model h may be inaccurate in these regions due to the lack of training data, which increases the chance of making a misprediction for these test examples. The importance of novelty rejection often becomes particularly apparent in medical applications since in many of these applications, it is challenging or expensive to get an exhaustive training set. Therefore, the training set might only include patients from specific age groups or with particular medical conditions. For instance, Van Accept Ambiguity Reject Novelty Reject Rejector Fig. 5: Illustration of a regression scenario where rejection can be applied. The dash-dotted line represents the predictor h, while the solid line indicates the true function f . In a), examples in between the dotted lines are rejected (cross mark) due to the high variance of Y . In b), examples indicated with the cross mark are rejected due to the incorrect model bias. In c), star-marked examples are rejected because they differ from the training data (novelties). encountered during training such as children or people suffering from extremely rare disorders. However, this information and the assumptions made during data collection might not be available to the user of the model. Therefore, adding a novelty rejector is crucial to avoid poor prediction performance on these patients. In this case, a rejector based on a LOF outlier detector can reject the predictions from children as they have a different morphology than the adults in the training set (Figure 6 ). This mitigates the risk of incorrect predictions. The predictor is trained only on adults. The accuracy on children (66.8%) is much lower than the accuracy on adults (77.7%). Introducing the reject option mitigates the risk of making incorrect predictions as it ends up rejecting the predictions for most children. 3 Evaluating models with rejection Rejection Prediction No Yes Correct True accept (TA) False reject (FR) Incorrect False accept (FA) True reject (TR) Table 1 : Confusion matrix for learning-to-reject models. The columns show whether an example is rejected, the rows show whether h's prediction is correct. Conceptually, a model with a reject option involves evaluating the outputs of both the predictor and the rejector. Thus, its performance can be viewed through the prism of the confusion matrix shown in Table 1 , where the columns represent the rejector's decision and the rows whether the predictor's output is correct or not. Intuitively, the learning-to-reject model is \"correct\" if a correct prediction is returned to the user (a true accept) or an example is rejected when the model's prediction was wrong (a true reject). It is considered to have made a \"mistake\" if the model provides the user with an incorrect prediction (false accept) or rejects an example for which the model's prediction was correct. Viewed through this lens, a model with rejection has two goals. On the one hand, it wants to have high accuracy A on examples for which it makes a prediction: A = T A T A + F A . This makes the model reliable as practitioners can trust its outputs. On the other hand, it wants to have high coverage: ϕ = T A + F A T A + F A + F R + T R . That is, it should make a prediction for as many test examples as possible (De Stefano et al. 2000; El-Yaniv and Wiener 2010; Lei 2014) . This can alternatively be viewed as having a low rejection rate, defined as 1-ϕ. This makes the model useful in practice as its predictions can be utilized for decision-making. Unfortunately, these two goals are competing as the accuracy can be increased by limiting the predictions to the most confident cases, i.e., reducing the coverage (Hansen et al. 1997; Homenda et al. 2016 ). As a result, metrics specifically tailored to learning to reject must capture this trade-off (Cordelia et al. 1998) . Broadly speaking, three categories of metrics exist that evaluate different aspects of a model with rejection: Evaluating models for a given rejection rate: This entails having a fixed rejection rate provided by the user. In this case, one only needs to evaluate performance on the non-rejected examples and it is possible to use the standard evaluations (e.g., accuracy (Golfarelli et al. 1997 )); Evaluating the overall model performance/rejection trade-off : One can plot the rejection rate on the x-axis and the predictor's performance obtained on a representative test set on the y-axis, similar to Receiver Operating Characteristic (ROC) analysis; Evaluating models through a cost function: This case only requires knowing the model's output and the costs for (mis)predictions and rejections. 3.1 Evaluating models with a fixed rejection rate. Given a dataset and a fixed rejection rate, Condessa et al. (2017) argue that a good evaluation metric should meet four main criteria: given a fixed predictor, such metric should: (p1) depend on the model's rejection rate; (p2) be able to compare two models with different rejectors for a given rejection rate (and for the same predictor); (p3) be able to compare two models with different rejectors with different rejection rates when one clearly outperforms the other; (p4) reach its maximum value for a perfect rejector (i.e., a rejector that rejects all misclassified examples) and its minimum value for a rejector that rejects all accurate predictions. In addition, Condessa et al. (2017) propose three types of evaluation metrics that meet the required conditions: a) Prediction quality. The model's prediction quality (PQ) measures the predictor's performance on the non-rejected examples. For instance, one can use classical evaluation metrics on the accepted examples such as the accuracy P Qacc = T A T A + F A , the F-scores (Pillai et al. 2011; Mesquita et al. 2016) or any other evaluation metric, including fairness metrics (Madras et al. 2018) . While this allows comparing models with different rejectors, looking only at the prediction quality will tend to favor the model with the highest rejection rate. By being more conservative (i.e., having a lower coverage), the model tends only to offer predictions for the subset of examples for which it is most confident. b) Rejection quality. The rejection quality (RQ) indicates the rejector's ability to reject misclassified examples. One way to do this is by comparing the ratio of misclassified examples on the rejected subset ( T R F R ) to the ratio on the complete dataset ( F A+T R T A+F R ), i.e. RQratio = T R F R F A + T R T A + F R . Looking only at the rejection quality will favor models with the lowest rejection rate. The lower the rejection rate is, the more likely the rejector is to abstain only on those few examples for which it is most confident that the predictor will make a mistake. c) Combined quality. The combined quality (CQ) evaluates the model with a reject option as a whole. One way to accomplish this is by combining the predictor's performance on the non-rejected examples (prediction quality) with the rejector's performance on the misclassified examples (rejection quality). For instance, using P Qacc and RQratio yields to CQacc-ratio = T A + T R T A + F A + F R + T R . Overall, the combined quality offers a more holistic assessment of the model's overall performance as it measures both the predictor's and the rejector's quality (Lin et al. 2018 ). The downside is that aggregating the two metrics yields a less fine-grained characterization of the model performance. Specifically, in case a model has low CQ, it is hard to ascertain which component, the predictor or rejector, is contributing the most to the model's poor performance. Pros and Cons. The main advantage of this category is that the metrics clearly measure the fine-grained model performance in the given setting. However, using one of these types of metrics may be limiting in some cases. For instance, theoretical research may not care about evaluating the model with rejection for a specific rejection rate, as it is usually specified based on domain knowledge. Moreover, given a rejection rate, not all performance metrics can be always used, as some may suffer from task-related issues. For instance, rejecting a whole class would not allow utilizing metrics like F1-score and AUC for the prediction quality as they need both classes' labels. Evaluating the model performance/rejection trade-off. To assess the performance-rejection trade-off, a common approach is to evaluate the prediction quality (for non-rejected examples) by varying the rejection rate from 0% to 100%, which is known as the Accuracy-Reject Curve (ARC) (Nadeem et al. 2010) . This involves plotting the rejection rate on the x-axis and the prediction quality (e.g., accuracy) on the y-axis (Hanczar and Sebag 2014) . Higher curves indicate better performance. Alternatively, risk-based metrics like mean squared error can be plotted, with lower curves indicating better performance (Sambu Seo et al. 2000) . Sometimes the predictor's performance on the rejected examples is also shown with the intuition that it should be worse on this subset of the data than on the accepted ones (Zou et al. 2011; Condessa et al. 2015c,b) . 2023 ) compare two of their proposed models with a novelty reject option (blue) with two models that were used as baseline (black). The proposed models outperform the baselines but the light blue model only does for rejection rates lower than 0.01. When comparing two models using the ARC method, two scenarios arise. First, one model clearly outperforms the other in terms of prediction quality for all rejection rates. Second, the models show varying prediction quality across different rejection rates. To illustrate this, consider Figure 7 where the light blue curve only outperforms the black curves if the rejection rate is lower than 0.01. When it is not clear which model performs best, the overall performance can be assessed using the Area Under the ARC Curve (AURC), similar to the AUC in standard machine learning (Vanderlooy et al. 2006a,b; Landgrebe et al. 2006) . In this example, the AURC of the light blue curve will be higher than the AURC of the black curves, indicating that it performs better overall than the black curves. Pros and Cons. The main advantage of this category is that any prediction quality metric can be used on the y-axis. Moreover, they provide a high-level overview of how the model works for different rejection rates. However, generating these curves can be challenging for two reasons. First, some rejectors do not allow directly setting the rejection rate (Wu et al. 2007; Homenda et al. 2014) , but they might have other hyperparameters (e.g., rejection threshold). Mapping these to rejection rates may be challenging and may not be possible to achieve all possible rejection rates. Second, altering the rejection rate of a model with rejection can require completely retraining the whole model. This may be too computationally demanding to perform a fine-grained analysis (Condessa et al. 2017) . Evaluating models through a cost function. For classification tasks, one can ask the user to specify the costs for (mis)predictions as well as for rejection and evaluate a model by its (expected) total cost at test time. Although the costs can be designed as a continuous function of the examples (Mozannar and Sontag 2020; De et al. 2021) , the cost function typically accounts only for three constant costs: the cost of correct prediction Cc, the cost of a prediction error Ce, and the cost of rejection Cr such that Cc < Cr < Ce (De Stefano et al. 2000; Balsubramani 2016; Condessa et al. 2013) . Without loss of generality, usually one assumes normalized costs, i.e., Cc = 0, Ce = 1 and Cr ∈ [0, 1] in which the normalized value for Cr can be obtained from the initial values as Cr-Cc Ce-Cc . Although the costs need to be set based on some domain knowledge, there are two constraints for setting the rejection cost properly. First, it must be lower than a random predictor's average cost for a classification task with K classes, i.e. Cr ≤ 1 K (Cordella et al. 1995b; Herbei and Wegkamp 2006) . Otherwise, the expected cost of always making a random prediction would be lower than the rejection cost, which nullifies the task of rejection. Second, one should account for possible imbalance classes by setting Cr ≤ 1 -max k≤K P (Y = k), where P (Y = k) is the class frequency (Perini et al. 2023 ). In fact, for higher Cr, a naive model that always predicts the most frequent class k would obtain a cost equal to 1-P (Y = k) and rejecting examples would not be worth it for higher rejection costs. Pros and Cons. The main benefit of this category is its high interpretability: given a final cost, we can easily go back to the causes that yield such a cost. Moreover, one can use the same cost function to optimize the model parameters during the learning phase. This ensures coherence between learning the optimal model at training time and measuring its performance at test time. However, this category has the key drawback that the user must set the cost function based on domain knowledge, which is not always easy to obtain. Setting different costs changes the quality of the models, which may end up ranking several compared models differently. A way to alleviate this would be to make the Cost-Reject plot (Hanczar 2019) , where, similar to the ARC, the x-axis and y-axis represent respectively the normalized rejection cost and the normalized prediction cost (Friedel et al. 2006; Abbas et al. 2019) . Separated rejector Separated rejectors operate by filtering out unlikely examples. They are typically used for novelty rejection though there are some examples of using them for ambiguity rejection (Asif and Minhas 2020) . Because the rejector does not use the predictor's output in any way, it is typically a function of the examples: r : X → R. Formally, the separated architecture yields the following model: m(x) = ® if r(x) < τ h(x) otherwise. (3) If the rejector r outputs a value less than τ , then the model m rejects the example (®). Otherwise, m uses the predictor h to make a prediction. The separation between predictor and rejector means that the rejector is learned independently of the predictor. The learning task involves learning the rejector itself as well as setting the threshold τ . To align with its goal of identifying unlikely or unexpected examples, a common choice is to use anomaly/outlier, out-ofdistribution, or novelty detection algorithms. Three categories of methods can be used for this goal: models that 1) estimate p(X), 2) are one-class classifiers, and 3) quantify the degree of novelty using a data-driven score function. Learning a separated rejector. A first option to learn a separated rejector is to use a probabilistic model that estimates the marginal density p(X) and to reject a test example x if p(x) < τ . These probabilistic models often make assumptions about the distribution of the examples and are trained to maximize the likelihood of the training dataset (Vasconcelos et al. 1993) . For instance, Landgrebe et al. (2004) proposes a locally normal distribution assumption and uses a Gaussian Mixture Model (GMM) to estimate p(X) with a specified number of components whereas others have considered Variational Autoencoders (Wang and Yiu 2020) and Normalizing Flows (Nalisnick et al. 2019) . Another option to learn a separated rejector is by employing a one-class classification model. Generally, they enclose the dataset into a specific surface and flag any example that falls outside such region as novelty. For instance, a typical approach is to use a One-Class Support Vector Machine (OCSVM) to encapsulate the training data through a hypersphere (Coenen et al. 2020; Homenda et al. 2014) . By adjusting the size of the hypersphere, the proportion of non-rejected examples can be increased (Wu et al. 2007) . Alternatively, some models assign scores that represent the degree of novelty of each example (i.e., the higher the more novel), such as LOF (Van der Plas et al. 2023) or Neural Networks (Hsu et al. 2020 ). When dealing with these methods, one often initially transforms the scores into novelty probabilities using heuristic functions, such as sigmoid and squashing (Vercruyssen et al. 2018) , or Gaussian Processes (Martens et al. 2023) . Then, the rejection threshold can be set to reject examples with high novelty probability. Learning the rejection threshold τ . The rejection threshold τ is a crucial parameter that determines whether an example is rejected or not. In many cases, the threshold is set based on domain knowledge. For instance, one can introduce adversarial examples and set a threshold to reject them all (Hosseini et al. 2017) . In case the number of novelties is unknown, one can use existing methods to estimate the contamination factor, i.e. the proportion of novelties, and set the threshold accordingly (Perini et al. 2022b,a) . Otherwise, heuristics can be employed, such as rejecting examples falling within the first or second percentiles of correctly classified training examples (Wang and Yiu 2020) . Benefits and drawbacks of a separated rejector. Using a separated rejector has several benefits. First, the rejector is predictor agnostic. Hence, it can be combined with any type of predictor. Second, because the rejector can be trained independently of the predictor, it is possible to augment an existing predictor with a reject option using this architecture. Third, by serving as a filter, the predictor makes fewer predictions. This is particularly advantageous when there is a high computational cost associated with using the predictor. Finally, this architecture is generally simpler to operationalize compared to rejectors that interact with the predictor. However, there are two evident drawbacks. First, not sharing information between the predictor and the rejector results often in sub-optimal rejection performance (Homenda et al. 2014 ). Second, this architecture is typically only used for novelty rejection because it is naturally related to assessing whether x is rare or not while ambiguity rejection requires information on p(Y |X), which is often estimated through the predictor's output. Dependent rejector Dependent rejectors analyze the predictor's output to identify examples that the predictor is likely to mispredict. The rejector is typically represented as a confidence function c h : X → [0, 1] that measures how likely the predictor is to make a correct prediction. Formally, the model for a dependent architecture has the form: m(x) = ® if r(x; h) < τ ; h(x) otherwise. ( 4 ) where r may depend on the feature vector x, and on the predictor h through the confidence function c h . Similar to the separated rejector, the model rejects the example (®) only if the rejector outputs a value lower than τ . Without loss of generality, we assume the confidence values c h (x) ∈ [0, 1], as one can always transform a score function into this range. The learning task for a dependent rejector usually entails (1) selecting a confidence function that measures how confident the predictor is in its predictions, and (2) setting the rejection threshold τ . Learning a dependent rejector: types of confidence function c h . The form of the confidence function depends on the desired rejection type. For ambiguity rejection, the metric should indicate the variability of the target variable or the potential predictor bias. For novelty rejection, the confidence should capture the example's similarity to the training data. We distinguish among four ways to derive the confidence scores: i) estimating the conditional probability P (Y |X), ii) estimating the class conditional density p(X|Y ), iii) performing a sensitivity analysis, and iv) exploiting the predictor's properties. The conditional probability approaches allow for ambiguity rejections by using the maximum of the class conditional probability as confidence function (Pazzani et al. 1994; Fumera et al. 2004 ; Lam and Suen 1995) c h (x) = max k∈Y P (Y = k|X = x) ( 5 ) where k is either the true target value or the predictor's output. Low P (Y |X) values for two or more targets k 1 , k 2 ∈ Y indicate high randomness of the data or proximity to the decision boundary (Arlandis et al. 2002) . Deriving the conditional probabilities from the predictor's outputs can be done by post-processing the predictor's output using techniques such as sigmoid calibration for binary classification tasks (Cordella et al. 2014; Brinkrolf and Hammer 2017 ) P (Y = 1|X = x) ≈ 1 1 + exp(Ah(x) + B) , with parameters A and B learned during the training (Brinkrolf and Hammer 2018) , softmax transformation for multi-class classification tasks (Kwok 1999 ) P (Y = k|X = x) ≈ exp (h k (x)) j∈Y exp (h j (x)) , where h j (x) is the predictor's output for x related to class j, or by fitting Gaussian Processes for regression tasks (Sambu Seo et al. 2000) . In case of multiple predictors h 1 , . . . , h V , one can also measure the ensemble agreement as the conditional probability (Glodek et al. 2012; Zhang 2013 ) P (Y = k|X = x) ≈ V v=1 1[hv(x) = k] V . On the other hand, the class conditional density approaches perform novelty rejection putting (Dubuisson and Masson 1993; Dübuisson et al. 1985 ) c h (x) = max k∈Y p(X = x|Y = k). (6) Intuitively, a low density p(X|Y ) expresses that a sample is rare (Condessa et al. 2015b) . Common methods to estimate the confidence in Eq. 6 employ generative predictors that directly measure the data density such as Gaussian Mixture Models (GMMs) (Vailaya and Jain 2000) . It is also possible to employ heuristic approaches such as normalizing the class distance between the example x and its v-th nearest neighbor x ′ (Conte et al. 2012; Villmann et al. 2015; Fischer et al. 2014b) , i.e. p(X = x|Y = k) ≈ d(x, x ′ ) {(x * ,y * )∈D : y * =k} d(x * , x ′ * ) and computing the proportion of neighbors within a specified radius R (Berlemont et al. 2015) as p(X = x|Y = k) ≈ |{x ′ : d(x, x ′ ) ≤ R, (x ′ , y ′ ) ∈ D, y ′ = k}| (x ′ ,y ′ )∈D |{x * : d(x ′ , x * ) ≤ R, (x * , y * ) ∈ D, y * = k}| . The sensitivity analysis line allows only ambiguity rejection, as it measures the robustness of the predictor under perturbation of either (a) its parameters or (b) the examples (Lewicke et al. 2008; Hellman 1970) . Intuitively, slightly perturbing the predictor's parameters has major effects on the predictions only for examples that fall in the proximity of the decision boundary: slight variations of the parameters yield slight changes in the decision boundary, which, in turn, may end up flipping the predictions for some examples. Examples of employed perturbations involve adding some noise to the model's parameter values (e.g., adding a random sample from a normal distribution with null mean and small variance to the weights of a neural network), employing neural networks with a dropout layer (Geifman and El-Yaniv 2017), or using a Bayesian simulation (Perini et al. 2020b ). In the case of constructing multiple predictors, a common and simple confidence metric is c {h1,...,h M } (x) = 1 -Var{h 1 (x), . . . , h M (x)} where h 1 , . . . , h M are the M predictors constructed by perturbing the parameters, and the variance is scaled to be in [0, 1]. In some cases, one can directly employ an ensemble of M similar predictors and measure the variance of their predictions (Fumera and Roli 2004; Jiang et al. 2020 ). Alternatively, one can perturb the test example x to be x + ε, where ε is a random noise such that ∥ε∥ is small. Intuitively, we want a predictor's output to remain the same when the example is only slightly perturbed. Thus, the confidence metric should reflect the robustness of h (Mena et al. 2020; Denis and Hebiri 2020; Kühne et al. 2021) , such as c h (x) = P (h(x + ε) = h(x)), which measures how likely it is that the prediction does not change when the example is perturbed. More generally, we can apply transformations such as rotations and symmetries to the examples (Chen et al. 2018) . Finally, because choosing a specific value for ε is hard, one can use existing approaches to find each example's minimum ε that will alter its predicted label (Devos et al. 2021 ) and derive a confidence metric as a function of the training ε. The property-based methods consist of learning the confidence based on some of the predictor's properties, such as using the leaf configurations of a tree ensemble or the neural network's weight of specific neurons. This line allows both ambiguity and novelty rejection, depending on the utilized property. These methods tend to exploit heuristic and data-driven intuitions and there are no overarching themes that connect these intuitions. For instance, Devos et al. (2023) present a method to detect evasion attacks in tree ensembles. By enumerating the leaves of each tree as o i , they map each example x to the configuration o = (o 1 , . . . , o V ) ∈ N V of the V activated leaves (one per tree) when passing x as input to the ensemble. In such output configuration space, they quantify the proximity to the decision boundary by measuring the Hamming distance between the configuration o of a test example with ensemble's prediction y and the closest training example's configuration o ′ with flipped prediction ŷ ̸ = y: OC-score(x) = min o ′ ∈Rŷ V v=1 1 ov ̸ = o ′ v where R ŷ is the set of training configurations with flipped predictions. One can derive a confidence metric c h by, for instance, min-max normalizing the OC-score. On the other hand, confidence values can also be derived from the weight vectors of a Self-Organizing Map (SOM) (Gamelas Sousa et al. 2014b Sousa et al. , 2015)) . Because SOM's can approximate the input data density, they approximate p(X = x|Y = k) with p(w|Y = k, X = x), where w are the weights of the neural network, using standard statistical techniques, such as the Parzen Windows (Alhoniemi et al. 1999 ). Moreover, El-Yaniv and Wiener (2011) propose a disbelief principle, which computes the confidence function by measuring how much the predictor h deteriorates if retrained with the constraint to predict a specific example x differently (i.e., hx) c h (x) = 1 R(hx) -R(h) , where R(hx) > R(h) > 0. Finally, the literature presents additional ad-hoc confidence metrics for k-NN and Random Forest (Göpfert et al. 2018; Dalitz 2009) . Learning the rejection threshold τ . Setting an appropriate rejection threshold τ is crucial for having an accurate dependent rejector. At a high level, the threshold is set in three main ways: using domain knowledge, adhering to user-provided constraints, or tuning it empirically based on some objective function. In some situations, users possess domain knowledge that enables setting τ to achieve a desired rejection rate ρ (Le Capitaine and Frélicot 2012; Pang et al. 2021) . Setting τ in this situation entails (1) ranking training examples based on their confidence level, and (2) setting τ such that the desired percentage of predictions are rejected (Sotgiu et al. 2020) , that is, at P X (c h (x) < τ ) = ρ. Note that this approach is also used when evaluating the model performance/rejection trade-off, which needs to measure the model performance for a fixed rejection rate (see Sec. 3.2) (Ma et al. 2001; Heo et al. 2018; Fumera et al. 2003) . In other cases, users provide knowledge as specific constraints that should be satisfied (Pietraszek 2005 ). On the one hand, the user may provide an upper bound R for the rejection rate and aim to limit the number of rejections. This results in learning the appropriate τ by minimizing the model misclassification risk while adhering to the rejection rate constraint (Zhou et al. 2022; Pugnana and Ruggieri 2022, 2023) τ = arg min t∈[0,1] P XY (h(x) ̸ = y, c h (x) ≥ t) subject to P X (c h (x) < t) ≤ R. On the other hand, the user may provide an upper bound M for the proportion of mispredictions, and aim to control the allowable error (Varshney 2011; Sayedi et al. 2010 ). Thus, one needs to learn τ by setting up the complementary problem as before, namely by minimizing the model rejection rate while satisfying the constraints on error (Li and Sethi 2006; Franc and Prusa 2019; Franc et al. 2021 ) τ = arg min t∈[0,1] P X (c h (x) < t) subject to P XY (h(x) ̸ = y, c h (x) ≥ t) ≤ M. Moreover, one can generalize this problem by finding the threshold τ such that the predictor's misclassification risk at test time is guaranteed to be bounded with high probability (Geifman and El-Yaniv 2017) . Finally, it is possible to set τ empirically according to some objective function. The most common approach is to set a single global threshold τ , which makes the rejection both simple and transparent, yet usually effective (Fukunaga and Kessell 1972) . This is the case for Chow's rule (Chow 1970 ) which involves learning the optimal τ by minimizing the risk function that includes the expected error rate and the rejection rate τ = arg min t∈[0,1]      {x∈X : c h (x)≥t} (1 -c h (x)) p(x) dx Error rate + t {x∈X : c h (x)<t} p(x) dx Rejection rate      . (7) However, in real-world scenarios, obtaining complete knowledge of class distributions is challenging, limiting the applicability of Chow's rule (Shekhar et al. 2019) . Thus, in a binary classification case, Tortorella (2000) proposes to use two rejection thresholds τ 1 and τ 2 such that h(x) =      0 if c h (x) < τ 1 ; 1 if c h (x) > τ 2 ; ® if τ 1 ≤ c h (x) ≤ τ 2 (8) with c h (x) = P (Y = 1|X = x). He proposes to learn τ 1 , τ 2 by optimizing a cost function that is identical to finding the intersection between the cost function and the convex hull of the ROC curve (10) where C f n , C f p , C tn , and C tp are the costs for false negatives, false positives, true negatives, and true positives, while F N R(t), T N R(t), T P R(t) and F P R(t) are the false negative, false positive, true negative and true positive rates obtained by evaluating the models with the thresholds set to t. This approach is theoretically equivalent to Chow's rule under the Bayesian optimality assumption (Santos-Pereira and Pires 2005; Du et al. 2010 ). However, when estimating posterior probabilities, Chow's rule is not suitable, and τ should be learned using a cost-based approach (Marrocco et al. 2007; Kotropoulos and Arce 2009) . Different approaches have extended Tortorella's method to address other scenarios (Sansone et al. 2001) , such as stable formulations of ROC curves for small datasets (Jigang et al. 2006) , robust and fast-to-retrain rejections for cost-sensitive situations (Dubos et al. 2016; Fischer et al. 2015b) , and tailored solutions for learning metaclassifiers or handling multiple classes (Pietraszek 2007; Cecotti and Vajda 2013) . τ 1 = arg min t∈[0,1] P (Y = 1)(C f n -Cr)F N R(t) + P (Y = 0)(C tn -Cr)T N R(t) (9) τ 2 = arg min t∈[0,1] P (Y = 1)(C tp -Cr)T P R(t) + P (Y = 0)(C f p -Cr)F P R(t) For tasks requiring a more fine-grained rejection capability, considering multiple local thresholds τ 1 , τ 2 , . . . (up to a finite number) may be beneficial (Muzzolini et al. 1998; Kummert et al. 2016; Krawczyk and Cano 2018) . Normally, setting local thresholds requires dividing the feature space into J regions J i and setting a (local) threshold in each region. For instance, one can design regions and thresholds by constructing one region for each class, i.e. J i = {x * | y * = i}, which means that the number of regions J equals the number of classes K (Fumera et al. 2000) ; then, one often finds the local threshold by using for each J i the same approach as for global thresholds; -using the Voronoi-cell decomposition, which requires J prototypes w i to have present a greedy optimization method to adaptively determine local thresholds using a heuristic principle; -setting up an optimization problem that finds the optimal thresholds by assigning different class rejection costs; for instance, in binary classification, Zheng et al. (2011) proposes to find τ 1 , τ 2 = arg min 0≤t1,t2≤1 P XY (c h (x) < t 1 |y = 0)C r,0 + P XY (c h (x) < t 2 |y = 1)C r,1 + P XY (m(x) ̸ = y)Ce where C r,0 and C r,1 are the costs for rejecting examples from the negative and positive classes; -optimizing an objective function that accounts for different user-specified class misclassification risks M 1 , . . . , M K ; Lin et al. (2022) treat each class indepen-dently, setting L(t k ) = Â(t k ) + K j λ j ( Mj -M j ) 2 where Â(t k ) is any ambiguity metric, λ j is a penalization term that needs to be set to high values to penalize high differences between the model's misclassification risk M and the user-specified target. Although multiple thresholds give more fine-grained control over a rejector's performance (Laroui et al. 2021; Gangrade et al. 2021a) , this is usually more computationally expensive. However, Fischer et al. (2016) propose efficient schemes for optimizing local thresholds and show that the computation time can be reduced to polynomial (Boulegane et al. 2019) . Benefits and drawbacks of a dependent rejector. Designing a dependent rejector has several benefits. First, the interaction between the predictor and rejector enables both types of rejection, because the rejector learns from the predictor's output the regions of the feature space where examples are mispredicted or unlikely to fall. Second, a dependent rejector can extend an existing predictor (including black-box) by simply setting a proper threshold on a confidence measure. Third, it allows the reuse of previously learned models, eliminating the need for costly retraining (Zou et al. 2011; Tang and Sazonov 2014) . Fourth, a confidence-based rejection could be improved by considering multiple confidence metrics where each one captures different aspects of the underlying uncertainty (Tax and Duin 2008) . However, this architecture has potential drawbacks as well. First, the quality of the dependent rejector is highly influenced by the quality of the confidence metric, which is usually hard to evaluate. Second, typically a dependent rejector does not affect the predictor's learning phase. This results in possible sub-optimal predictions of the model with a reject option. Integrated rejector The integrated rejector combines the rejector and predictor into a single model where it is impossible to distinguish between the role of the h and the r. Formally, the model with integrated reject option acts as m(x) ∈ Y ∪ {®}. (11) Conceptually, this model simply includes ® as an additional output. This architecture usually needs a unique algorithm for learning predictor and rejector in tandem (Cortes et al. 2016a,b) . There are two distinct approaches to learning an integrated rejector. The first approach is model-agnostic and involves designing an objective function that penalizes (mis)predictions as well as rejections. The second approach is model-specific and entails integrating a rejector into an existing predictor, where rejection becomes part of the decision-making process. Learning a model-agnostic integrated rejector. Typically, learning a model that simultaneously makes accurate predictions and rejects the examples that will be otherwise mispredicted can be done by simply designing a specialized objective function (Mozannar and Sontag 2020) . Then, such a function can be minimized using potentially any existing optimizer, which makes it model-agnostic. For instance, for classification, a simple cost-based objective for any hypothesis m can be expressed as L = E p(X,Y ) Cr1 m(x)=® (x) + 1 m(x)̸ ∈{y,®} (x) with Cr ∈ (0, 1/2]. For tasks other than classification, ad-hoc loss functions are used, such as those for multilabel classification (Pillai et al. 2013; Nguyen and Hüllermeier 2020, 2021) , regression (Asif and Minhas 2020; Kalai and Kanade 2021) , online learning (Cortes et al. 2018; Kocak et al. 2020) , and multi-instance learning (Zhang and Metaxas 2006) . However, in many cases, surrogate losses are employed to enable efficient optimization, as learning from discrete losses is computationally impractical (Wegkamp 2007; Grandvalet et al. 2009; Cao et al. 2022) . Consequently, the original loss L is converted into a convex loss by utilizing surrogate functions ψ : R → R, such as the logistic and hinge functions (Ramaswamy et al. 2018; Zhang et al. 2018; Bartlett and Wegkamp 2008) : Logistic: ψ(L) = 1 1 + exp(L) , Hinge: ψ(L) =      1 -1-Cr Cr L if L < 0 1 -L if 0 ≤ L < 1 0 otherwise For the hinge loss to be convex, it is required that Cr ≤ 1/2 which is the case for classification as otherwise the cost of rejection would be higher than the cost of random guessing. Numerous studies in the literature have explored the properties of surrogate loss functions (Yuan and Wegkamp 2010) , including calibration effects (Ni et al. 2019; Charoenphakdee et al. 2021) , estimates of bounds for misclassification risk (Shekhar et al. 2019; Kato et al. 2020) , penalization effects in high-dimensional spaces (Wegkamp and Yuan 2012) , proximity to the optimal Bayes solution (Bounsiar et al. 2008; Shen et al. 2020a) , and convergence rate analysis (Denis and Hebiri 2020) . Lastly, one can allocate an extra class K + 1 (commonly known as the reject class) for rejection and assign a specific penalization cost Cr for predicting such a class. With this setting, there are two main alternatives. In the first case, there are no actual examples belonging to this class. Thus, these approaches design loss functions to enable the classifier to assign on its own a positive score to ambiguous examples (Huang et al. 2020; Feng et al. 2022) . For instance, Ziyin et al. (2019) propose to measure the expected loss as L = E p(X,Y ) log(s k (x) + 1 Cr s K+1 (x)) , where s k (x) and s K+1 (x) are probabilities, respectively, for the class y = k and K + 1 (rejection). At a high level, decreasing the rejection cost Cr results in higher chances of rejection. In the second case, one artificially generates examples x n+1 , . . . , x N (e.g., adversarial examples) and assigns them to the rejection class K + 1. By training a predictor with K + 1 classes, the reject option is naturally incorporated as output, and any (multi-class) predictor can be used for novelty (Vasconcelos et al. 1995; Singh and Markou 2004; Urahama and Furukawa 1995) or ambiguity rejection (Thulasidasan et al. 2019; Pang et al. 2022 ). Learning a model-specific integrated rejector. In many practical use cases, one may already know that a specific class of models works well within the given context, such as SVM models in medical applications (Hanczar and Dougherty 2008; Hamid et al. 2017) . Given a specific predictor, its learning algorithm can be slightly adapted to include the reject option. For instance, integrated SVMs set two (or more) hyperplanes on the feature space and reject all the examples located in between them (Pillai et al. 2011; Lin et al. 2018; Zidelmal et al. 2012) . Figure 8 shows two common cases to learn the hyperplanes. First, one can parametrize the hyperplane as w • x + b ± ε = 0, with ε ≥ 0, which results in parallel and equidistant hyperplanes from the decision boundary, where ε indicates the distance (Fumera and Roli 2002) . Learning such hyperplanes requires minimizing the empirical loss L = 1 2 w • w + C n i=1 l(ξ i , ε) - n i=1 α i [y i (w • x i + b) -1 + ξ i ] where w is the weight vector, b is the intercept of the hyperplane, C is a (large) hyperparameter that regulates the importance of the performance/rejection tradeoff expressed inside the function l(ξ i , ε), and α i are the Lagrangian multipliers. Second, the two hyperplanes can be parametrized as w ′ • x + b ′ = 0 and w ′′ • x + b ′′ = 0. By formulating two distinct optimization problems, one can learn the parameters of these hyperplanes. In this approach, one hyperplane is highly penalized for mispredicting the positive class, while the other one is for the negative class. Essentially, this technique yields two SVMs that have few mispredictions on either class, and examples falling in between the hyperplanes can be naturally rejected (Varshney 2006) . With the same approach, one can also learn a OCSVM for each class to reject test examples that lie outside any learned hypersphere (novelty) or within two overlapping hyperspheres (ambiguity) (Lotte et al. 2008; Loeffel et al. 2015; Wu et al. 2007 ). Finally, Gamelas Sousa et al. (2014a) shows that limiting the number of support vectors reduces the computational cost, while still ensuring high performance in most cases. However, in several cases, more than two SVMs are used. For instance, in multi-label classification one can exploit as many SVMs as the number of labels and fit each hyperplane to discriminate between one class and all the others (Pillai et al. 2011) . This raises the issue of defining rejection in the regions of intersection between some, but not all, of the hyperplanes. To address this, a natural solution is to utilize a data-replication method (Gamelas Sousa et al. 2009 ). This approach involves replicating the complete dataset for each class k ∈ Y, adding a new dimension z with the class number, changing the target variable of each replica to a discrete one-vs-all label, and discriminating class k from the other classes (Cardoso and Pinto Da Costa 2007; da Rocha Neto et al. 2011) . Finally, Neural Network models allow integrating the rejector and predictor into the same structure by modifying their output layers (Gangrade et al. 2021b; Ziyin et al. 2019) . Geifman and El-Yaniv (2019) propose to introduce an additional head mr into the network that is dedicated to rejection. Specifically, mr is set as a sigmoid function and used such that m(x) = ® if mr(x) < 0.5. Similar to the SVM case, Gasca A. et al. (2011) and Mesquita et al. (2016) measure the disagreement of two Neural Networks trained to prioritize the classes differently. Specifically, they assume a binary classification task and use the output of two neural networks h 1 , h 2 to predict the positive class if h 1 (x), h 2 (x) ≥ 0, the negative class if h 1 (x), h 2 (x) < 0 and rejection if they disagree on the sign. For this task, they use two weighted Extreme Learning Machines (wELM) (Zong et al. 2013) , namely two neural networks with Q hidden neurons that output h * (x) = Q q=1 wyβqg(aq • x + bq) where wy is the cost related to the example x that belongs to the class y, aq is the weight vector connecting the q-th hidden node and the input nodes, bq is the bias of the q-th hidden node and g is the activation function. By setting the class misprediction costs, learning the parameters β = (β 1 , . . . , β Q ) requires using the traditional weighted least square formulation min ∥Hβ -Y ∥ 2 so that β = (H T W H) -1 H T W Y where H is the n × Q matrix of activation functions h iq = g(aq • x i + bq), W is the n×1 matrix of class costs (one per example) and Y is the target vector. Thus, each network limits one class mispredictions and the region of disagreement is designed to be the rejection region. Benefits and drawbacks of an integrated rejector. This architecture has two key benefits. First, integrating the predictor and rejector means that both aspects of the model are optimized toward the task at hand. This can improve the performance of the model with rejection when compared to using other architectures because the predictor's and the rejector's components can affect each other. Second, because it is a unique model, the bias introduced by the model with rejection is potentially less than in the scenario where the predictor and rejector are two different models. However, this architecture has potential drawbacks, as designing such a rejector might not be trivial. First, it requires extensive knowledge about the predictor in order to integrate the reject option. Second, it may require developing a novel algorithm to learn the model with a reject option from data. Finally, it is computationally more expensive than the other architectures, as any changes to the rejector require retraining the entire model, which can be timeconsuming (Clertant et al. 2020; Shpakova and Sokolovska 2021) . Combining multiple rejectors Most rejectors are tailored towards a single rejection type. However, by combining multiple rejectors one can enable multiple rejections, such as performing both ambiguity and novelty rejection. We distinguish between two types of combinations of rejectors based on whether the rejectors' rejection regions overlap or not because examples in overlapping regions require deeper analysis (e.g., to specify the underlying rejection type). First, when rejectors do not overlap (or when we are not interested in the example's rejection type), one can simply combine the rejection sets by a logical or-rule: reject the example if any of the rejectors rejects it and assign such rejection type (Frélicot 1997; Suutala et al. 2004 ). For instance, given Z rejectors r 1 , r 2 , . . . , r Z with thresholds τ 1 , τ 2 , . . . , τ Z , one can combine them into m as m(x) = ® if ∃ i ≤ Z : r i (x; h) < τ i h(x) otherwise Second, when rejectors overlap in some regions a simple or-rule can be insufficient to determine the reason for rejection because each rejector may decide to abstain for a different reason. Typically, existing works carefully select the order to evaluate the rejectors. This is usually done in a multi-step architecture: either by stacking only the rejectors (Frélicot 1998; Frélicot and Mascarilla 2002) , or even using multiple models with rejection (Pudil et al. 1992; Barandas et al. 2022) . For instance, given Z rejectors r 1 , r 2 , . . . , r Z with thresholds τ 1 , τ 2 , . . . , τ Z , one can order rejectors by importance and combine them as m(x) =            ® 1 if r 1 (x; h) < τ 1 ; ® 2 if r 1 (x; h) ≥ τ 1 and r 2 (x; h) < τ 2 ; . . . h(x) if r i (x; h) ≥ τ i ∀ i ≤ Z; where ® i indicates the rejector r i 's type of rejection. Applications of machine learning models with rejection In safety-sensitive domains, making the wrong decision can have serious consequences such as fatal accidents with self-driving cars, major breakdowns in industrial settings or incorrect diagnoses in medical applications. In these domains, rejection can be used to make cautious predictions. However, the number of papers discussing machine learning with rejection in practical applications is still limited. In this section, an overview of these papers is given. Biomedical applications. Machine learning with rejection is primarily explored in medical applications due to the potential consequences of incorrect decisions (Liu et al. 2022) . The main focus is on ambiguity rejection for medical diagnosing, specifically the detection and classification of diseases. If the model is confident enough, the detection results are automatically translated into a diagnosis. Otherwise, a medical expert verifies the detection (Kompa et al. 2021) . For instance, vocal pathologies are detected using voice recording data, where a linear classifier is trained and uncertain predictions are rejected based on a threshold of the derived posterior probability (Kotropoulos and Arce 2009) . Spine disease diagnosis employs the data-replication method, which predicts only when two biased classifiers agree (Gamelas Sousa et al. 2009) . Cancer detection, particularly breast tumor detection, benefits from a reject option implemented with an SVM classifier using confidence-based rejection (Guan et al. 2020) . The rejection thresholds are chosen to limit the rejection rate and reduce manual effort. Other biomedical applications have also adopted the use of a reject option. Lotte et al. (2008) conduct an experiment on distinguishing hand movements using brain activity. They employ a separate novelty rejector trained in a supervised manner to discard brain activity associated with other activities. Lewicke et al. (2008) explore sleep stage scoring with both types of rejection, utilizing confidence metrics derived from a Neural Network classifier's neural activities. Another sleep stage scoring application utilizes a separate rejector based on Local Outlier Factor (LOF) anomaly scores for novelty rejection, identifying patients who deviate from the training data (Van der Plas et al. 2021) . Some papers compare the performance of multiple models with rejection to determine the optimal approach for specific biomedical applications. For instance, Kang et al. (2017) predict the effectiveness of a diabetes drug for individual patients, while Tang and Sazonov (2014) investigate the classification of body positions using sensors placed in patients' shoes. Lastly, a medical application focuses on the analysis of tissue examples, aiming to classify each pixel of tissue images into categories such as bone, fat, or muscle (Condessa et al. 2013 (Condessa et al. , 2015a)) . Engineering applications. Applications in engineering can also benefit from a reject option. For instance, in the chemical identification of gases, time-series data is processed by two classifiers to classify the observed gas. Classification occurs only when there is agreement between the classifiers, and ambiguous predictions are rejected until consensus is reached (Hatami and Chira 2013) . A similar ambiguity rejection technique, rejecting when two classifiers disagree, is employed in defect detection in software applications (Mesquita et al. 2016) . Fault detection in steam generators utilizes a set of one against all SVM classifiers, and rejection is based on the distance to the decision boundary of these classifiers, allowing for both rejection types (Zou et al. 2011 ). Finally, Hendrickx et al. (2022) employs a separated novelty rejector for vehicle usage profiling. Economics applications. In the domain of economics, two applications of machine learning with rejection have been proposed, both focused on ambiguity rejection and novelty rejection. The first application uses a Learning Vector Quantization (LVQ) to classify dollar bills by value (Ahmadi et al. 2004 ). Confidence metrics are obtained from the classifier for both types of rejection. The second application investigates a few rejection techniques on top of a predictor to decide whether to grant a loan (Coenen et al. 2020) Image recognition applications. Reject options are usually available for analyzing text styles and reading handwritten numbers (Fumera and Roli 2004) , used for both ambiguity rejection (Xu et al. 1992; Huang and Suen 1995; Rahman and Fairhurst 1998) and novelty rejection (Lou et al. 1999; Arlandis et al. 2002) . These methods employ a confidence-based dependent rejector. Additionally, there is a paper focused on identifying walkers based on their footprints (Suutala et al. 2004 ). Initially, each footprint is individually predicted or rejected, and then the information from three consecutive footprints is combined for the final decision. 9 Link to other research areas This section briefly discusses the fields related to learning with rejection. Uncertainty quantification The field of uncertainty quantification (UQ) aims to measure how uncertain a learned model's predictions are (Gal et al. 2017) . It distinguishes between two types of uncertainties: aleatoric uncertainty, which is the randomness in the data, and epistemic uncertainty, which is the lack of knowledge. Aleatoric uncertainty arises from non-deterministic relations between features and the target, while epistemic uncertainty can be caused by a small training set or incorrect model bias. For instance, when predicting the outcome of tossing an unfair coin, initially we lack historical data, resulting in high data-epistemic uncertainty. As we observe more coin tosses, data-epistemic uncertainty decreases, but aleatoric uncertainty remains due to the stochastic nature of the coin flip (Senge et al. 2014) . These uncertainties are inherently related to rejection. Rejecting examples due to high aleatoric uncertainty falls into the ambiguity rejection scenario. On the other hand, high epistemic uncertainty due to the lack of data may cause either ambiguity or novelty rejection. That is, if an example is similar to the training set but its prediction strongly depends on the choice of the dataset (e.g., close to the predictor's decision boundary for classification tasks), then this gives rise to an ambiguity rejection. Alternatively, if an example is dissimilar to any of the training examples, this leads to a novelty rejection. Methods for UQ can be applied within learning with rejection. UQ focuses on obtaining (calibrated) estimates that meaningfully convey the level of uncertainty (Kotelevskii et al. 2022) , which learning with rejection can leverage to allow the model to abstain when the uncertainty is high (Perello-Nieto et al. 2017; Kompa et al. 2021) . While calibrated uncertainty estimates are not always necessary for learning with rejection, they can be important. For instance, calibrated uncertainty estimates enable setting an optimal threshold that minimizes the empirical risks (Chow 1970) . Anomaly detection Anomaly detection (Prasad et al. 2009 ) is a Data Mining task aimed at identifying examples that deviate from expected behavior in a dataset. It is closely linked to novelty rejection because anomalies, being rare and substantially different from the training data, fall under the category of novelties (Ulmer and Cinà 2020; Pimentel et al. 2014; Markou and Singh 2003) . Anomaly detectors are often utilized for novelty rejection within a separate rejector architecture. Adding a reject option to anomaly detectors allows them to abstain from processing examples when a clear decision cannot be made (Perini et al. 2020b (Perini et al. , 2023)) . However, enabling this option in unsupervised anomaly detection poses two challenges. First, most confidence metrics assume a supervised setting, relying on measuring the distance to a decision surface. However, in anomaly detection, a hard decision surface may not always exist, necessitating specialized metrics that consider the model bias of the detector (Perini et al. 2020b) . Second, the lack of labeled data makes it difficult to train a rejector using standard performance metrics. Instead, unsupervised techniques are employed, leveraging performance metrics that measure the stability of the anomaly detector itself (Perini et al. 2020a ). Active learning Active learning (Settles 2009; Fu et al. 2013; Zhang and Chaudhuri 2014; Nguyen et al. 2019) involves the interaction between a learning algorithm and an oracle who provides feedback to guide the learner. Its purpose is to reduce the need for labeling large amounts of data while still achieving high predictive performance. The algorithms focus on identifying the examples that would be most beneficial for the learner to label, thus minimizing the associated labeling costs. Active learning and learning with rejection share the focus on uncertain examples (Amin et al. 2021 ). However, they differ in their motivations for addressing uncertainty. In active learning, uncertainty is crucial during training to improve efficiency by minimizing the amount of labeled data required for an accurate model. In contrast, learning with rejection aims to capture uncertainty at test time to prevent mispredictions. Its focus is on avoiding unreliable predictions based on uncertain examples. Another difference is that outliers are not always considered. For instance, methods based on discriminative learning cannot express low-density regions. Sharma and Bilgic (2017) determine uncertain examples based on evidence measures that support the positive (E +1 ) or negative class (E -1 ) in binary classification. An example x has an uncertain class if E +1 (x) ≈ E -1 (x). Two cases are distinguished based on the magnitude of the evidence: if both E +1 and E -1 are large, the model is uncertain because of strong, but conflicting evidence for both classes, while if both E +1 and E -1 are small, the model is uncertain because of insufficient evidence for either class. Because both cases assume that a model is uncertain if P (Y |X) ≈ 0.5 when using a uniform prior, they both correspond to our ambiguity rejection scenario. Combining active learning with machine learning with rejection could be of great use (Korycki et al. 2019; Puchkin and Zhivotovskiy 2022; Shekhar et al. 2020) . When the interaction with an oracle is possible, it may be of interest to query the rejected test examples. New data types could be identified by novelty rejection, while ambiguity rejection may fine-tune the decision boundary. 9.4 Class-incremental / incomplete learning Typically, learned models assume knowledge of all possible classes during training. However, class-incremental learning focuses on models that adapt during deployment to detect and predict novel classes that were not seen during training. Novelty rejection and class-incremental learning both operate under an openworld assumption and aim to detect novel examples compared to the training set. However, there are two key differences. First, class-incremental learning specifically targets examples belonging to novel classes, distinguishing them from outliers. In contrast, novelty rejection techniques do not prioritize this distinction. Second, class-incremental learning involves detecting novel class examples and retraining the model to recognize them. Novelty rejection techniques can be considered in class-incremental learning. Moreover, both techniques can be combined into a single pipeline, by adapting incremental models with novelty rejected examples. For instance, such examples can be used as prototypes in a k-Nearest Neighbors (k-NN) model. Delegating classifiers Similar to learning with rejection, the approach of delegation involves the use of a classifier, which only classifies examples with high confidence and delegates the prediction for the remaining examples (Temanni and Nadeem 2007; Khodra 2016) . The delegated examples are given to another, more specialized, classifier which makes a prediction (Ferri et al. 2004; Prasad and Sowmya 2008) . In contrast, learning with rejection usually assumes that the user will inspect any rejected examples. Furthermore, delegation can be developed as a chain, where the next classifier makes a prediction for the examples for which the previous model was too uncertain (Giraud-Carrier 2022). Meta-learning Meta-learning, also known as \"learning to learn\", explores methods and techniques for automatically learning the characteristics, behaviors, and performance of machine learning models (Bock 1988; Vanschoren 2018 ). It aims to develop higher-level knowledge that guides the learning process itself (Brazdil et al. 2009; Gridin 2022) . Despite having different goals and levels of abstraction, meta-learning can provide valuable insights and approaches for the context of learning with rejection. For instance, meta-learning algorithms analyze the behavior and performance of classifiers on different datasets to derive general knowledge about their strengths, weaknesses, and limitations (Abbasi et al. 2012; Tremmel et al. 2022; Cohen et al. 2022) . This knowledge can then be used to make informed decisions about when to reject predictions. Moreover, meta-learning algorithms can identify relevant features or attributes that are informative for determining when to reject predictions (Filchenkov and Pendryak 2016; Shen et al. 2020b) . By focusing on important features, rejectors can make more accurate decisions. Conclusions and perspectives We have studied the subfield of machine learning with rejection and provided a higher-level overview of existing research. To conclude, we revisit our key research questions and point to new directions that future research might take. Research questions revisited This survey paper is built around eight key research questions, introduced in the introduction. In this section, we revisit each of these questions and briefly summarize our findings. How can we formalize the conditions for which a model should abstain from making a prediction? In Section 2, we identify two types of rejections: ambiguity rejection and novelty rejection. Ambiguity rejection abstains from making a prediction an example falls in a region where the target value is ambiguous (e.g., close to the decision boundary in classification tasks). This could be due to a non-deterministic true relation between the features and target variable, or due to a hypothesis space that is not able to capture the true relation. Novelty rejection abstains from making a prediction on examples that are rare with respect to the given training set. For such an example, there is no guarantee that the model correctly extrapolates to this untrained region, making it likely that the model mispredicts the example. How can we evaluate the performance of a model with rejection? Standard machine learning evaluation is focused on a model's predictive quality. However, in machine learning with rejection, there exists a trade-off between the predictive quality and the proportion of rejected examples. In Section 3, we provide an overview of techniques evaluating both the prediction and rejection quality of models with rejection. We identify three categories: metrics evaluating models with a given rejection rate, metrics evaluating the overall model performance/rejection trade-off, and metrics evaluating models through a cost function. What architectures are possible for operationalizing (i.e., putting this into practice) the ability to abstain from making a prediction? We categorize machine learning methodologies with rejection in three different architectures, depending on the relationship between the predictor and the rejector: separated, dependent and integrated rejector. These categories are introduced and mapped to the existing literature in Sections 4, 5 and 6. How do we learn models with rejection? For each architecture, we discuss the main techniques to learn a model with rejection and related these to the existing literature in Sections 4, 5 and 6. First, the separated rejector is usually learned independently of the predictor. Second, learning the dependent rejector entails learning for which examples the predictor is likely to mispredict using a confidence function. Both architectures need setting a rejection threshold. Third, integrated rejector needs a unique algorithm for learning predictor and rejector in tandem. Usually, this architecture relies on designing an objective function. What are the main pros and cons of using a specific architecture? Each architecture, discussed in Sections 4,5, and 6, offers distinct benefits and drawbacks. Separated rejectors show broad applicability, as they can be combined with any predictor. However, they often yield sub-optimal rejection performance since they do not learn from the predictor's mispredictions. On the other hand, dependent rejectors have reduced, yet still high, applicability, relying on a specific confidence function learned from the predictor's output, but they can enhance the rejection quality by leveraging the predictor's mispredictions. Finally, integrated rejectors necessitate joint design with the predictor, but learning a single model for prediction and rejection improves the overall performance for both prediction and rejection tasks. How can we combine multiple rejectors? We discuss the combination of multiple rejectors for enabling various types of rejections within a unique model. There are two approaches for combining rejectors. First, when rejectors do not overlap, a logical \"or\" rule is applied, rejecting an example if any of the rejectors rejects it. Second, when rejectors overlap in some regions and disagree on the type of rejection, a multi-step architecture is used, ordering rejectors by importance to make decisions based on the most relevant rejector. Where does the need for machine learning with rejection methods arise in real-world applications? On a high level, machine learning with rejection is typically used in applications where incorrect decisions can have severe consequences, both financially and safety-related. These consequences motivate the need for robust and trustworthy machine learning. In Section 8, we provide an overview of application areas in which machine learning with rejection is already used. How does machine learning with rejection relate to other research areas? Section 9 shows that machine learning with rejection is closely related to several other subfields of machine learning. This relation sometimes leads to terminology and techniques overlapping or inspired by these other domains. In contrast, other cases show machine learning with rejection from a broader perspective. In this survey, we related machine learning with rejection to uncertainty quantification, anomaly detection, active learning, class-incremental learning, delegating classifiers, and meta-learning. Future directions Given its significance for the usage of machine learning in real-world problems and the growing attention for trustworthy AI, we expect machine learning with rejection to remain an active research field. In this section, we briefly discuss three key research directions for which we see a strong need. Standard settings to compare different models with rejection. A large number of machine learning models with rejection already exist. However, these are typically evaluated on custom or even proprietary data. This makes it difficult to benchmark and compare the different approaches. While some papers use publicly available datasets, there is no standard benchmark set for machine learning with rejection. Additionally, applying multiple strategies to evaluate the rejector offers a better view of an algorithm's performance and improves comparability. Partial rejection for machine learning models. A promising avenue for further exploration is the concept of partial abstention. Nowadays, machine learning problems often involve seeking elaborated predictions rather than simple scalar or class values as in classification and regression tasks. For instance, in multi-label classification, a prediction for an instance is a subset of possible class labels. In such cases, the idea of abstaining from a complete prediction can be extended to partial abstention, where the learner delivers predictions on some but not necessarily all class labels, according to its level of certainty (Nguyen and Hüllermeier 2020) . This has the key benefit of providing a middle ground between making predictions for the entire structure and completely abstaining from making any predictions. Algorithms enabling models with rejection in domains other than classification. Most papers on machine learning with rejection study supervised classification problems. Modern machine learning tackles numerous other tasks such as regression, forecasting, and clustering, or even semi-supervised and self-supervised feedback loops. We believe that the rejection can also be of use in such areas. However, since only a handful of relevant studies exist, this requires more attention from the research community. Future research can also focus on integrating rejectionrelated variables into statistical frameworks utilized in educational measurement, such as Item Response Theory (IRT). This integration has the potential to improve the precision of item calibration, trait estimation, and the interpretation of test scores. Furthermore, it can provide valuable insights into the psychological aspects of learning, enabling the development of more precise instructional strategies and interventions. Declarations Fig. 2 : 2 Fig. 2: Data flow in a dependent rejector. First, the predictor processes the example at hand. Next, the rejector assesses the confidence in the prediction based on the predictor's representation of the example. Fig. 3 : 3 Fig. 3: Data flow in an integrated rejector, in which the predictor and rejector are one model. This model embeds the reject and predict functions and directly outputs a prediction or a rejection. Fig. 4 :Fig. 5 : 45 Fig. 4: Illustration of a classification scenario where the two classes overlap in a region. The dotted lines represent the rejector, the dash-dotted line the fitted predictor h, and the solid line the ground truth relation f . a) shows ambiguity rejection due to a non-deterministic relation between X and Y , b) introduces ambiguity rejection due to the model bias, and c) illustrates an example of novelty rejection. While in the first two plots the rejection region is inside the two dotted lines (examples with cross marks are rejected), in the third figure the rejected novel examples (stars) are outside the dotted line. a) b) c) Fig. 6 : 6 Fig. 6: Results of a novelty reject option in a sleep stage scoring application (Van der Plas et al. 2021).The predictor is trained only on adults. The accuracy on children (66.8%) is much lower than the accuracy on adults (77.7%). Introducing the reject option mitigates the risk of making incorrect predictions as it ends up rejecting the predictions for most children. Fig. 7 : 7 Fig. 7: Example of an accuracy-reject curve in which Van der Plas et al. (2023) compare two of their proposed models with a novelty reject option (blue) with two models that were used as baseline (black). The proposed models outperform the baselines but the light blue model only does for rejection rates lower than 0.01. J i = {x * | d(x * , w j ) ≤ d(x * , w k ) ∀k ̸ = i}, for i ≤ J (Villmann et al. 2015; Fischer et al. 2015a,b; Fischer and Villmann 2016); then, Fischer et al. (2014a) Fig. 8 : 8 Fig. 8: Two cases of Integrated SVMs: (a) on the left side, the two hyperplanes are parallel and equidistant to the decision boundary (dashed line); (b) on the right side, each SVM gives higher priority to one class by limiting mispredictions. FundingKilian Hendrickx and Dries Van der Plas received funding from VLAIO (Flemish Innovation & Entrepreneurship) through the Baekeland PhD mandates [HBC.2017.0226] (KH) and [HBC.2019.2615] (DV). Lorenzo Perini received funding from FWO-Vlaanderen, aspirant grant 1166222N. Jesse Davis is partially supported by the KU Leuven research funds [C14/17/070]. Lorenzo Perini, Jesse Davis and Wannes Meert received funding from the Flemish Government under the \"Onderzoeksprogramma Artificiële Intelligentie (AI) Vlaanderen\" programme."
}