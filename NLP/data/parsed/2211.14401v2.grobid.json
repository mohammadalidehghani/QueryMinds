{
  "title": "Elements of effective machine learning datasets in astronomy",
  "abstract": "In this work, we identify elements of effective machine learning datasets in astronomy and present suggestions for their design and creation. Machine learning has become an increasingly important tool for analyzing and understanding the large-scale flood of data in astronomy. To take advantage of these tools, datasets are required for training and testing. However, building machine learning datasets for astronomy can be challenging. Astronomical data is collected from instruments built to explore science questions in a traditional fashion rather than to conduct machine learning. Thus, it is often the case that raw data, or even downstream processed data is not in a form amenable to machine learning. We explore the construction of machine learning datasets and we ask: what elements define effective machine learning datasets? We define effective machine learning datasets in astronomy to be formed with well-defined data points, structure, and metadata. We discuss why these elements are important for astronomical applications and ways to put them in practice. We posit that these qualities not only make the data suitable for machine learning, they also help to foster usable, reusable, and replicable science practices.",
  "introduction": "Introduction In recent years astronomy has seen a wide application of machine learning (ML) in numerous subfields, from exoplanets and stellar astrophysics to extragalactic and cosmology applications [5] [22] . In particular, the imminent start of the largest sky surveys ever conducted have motivated astronomers to adopt machine learning methods to filter, analyze, and extract information from these surveys. A large number of astronomy publications cite the Legacy Survey of Space and Time (LSST) and the Euclid space mission as the main drivers for implementing machine learning processes [9] Machine Learning and the Physical Sciences workshop, NeurIPS 2022. arXiv:2211.14401v2 [astro-ph.IM] 29 Nov 2022 [17] . The sheer volume of data to be generated by those telescopes is far more than any other survey or mission to date [1] [24] [18] [12] [14] . Astronomy as a field has famously and painstakingly made numerous datasets freely available in the forms of mission archives and survey repositories, but there has been less work in general on defining and building common practices for creating machine learning datasets [6] . We claim traditional mission and survey catalogs are effective astronomy datasets: they comprise careful calibrations, calculations, meticulously detailed descriptions and imagery, typically in a format enabling SQL queries [21] . They are queryable, available, interpretable for humans and readable by astronomers' tools. To employ machine learning techniques, these datasets are commonly transformed for tools developed in industry like PyTorch and TensorFlow [13][15] . This laborious transformation process to an ML-ready dataset requires choices about what content, structure, and metadata to include. However, little work has been done on understanding this process and identifying what constitutes an effective machine learning dataset for astronomy [16] . In this paper, we outline three elements in effective machine learning datasets for astronomy and suggest adopting them in practice. In our view, effective datasets are useful, usable, and reusable for all researchers. We propose that effective ML datasets have three characteristics: well-defined data points, well-defined structure, and well-defined metadata. In the sections below, we explore these three characteristics through the lens of astronomy datasets for machine learning. We use the term well defined to describe datasets conceptually, structurally, and holistically. The datasets should possess the necessary characteristics for being effective, useful, usable, and reusable [23] . Figure 1 : Diagram of a typical data flow for astronomical data. From the left, observations from a telescope, resulting data products are fed into scientific analysis tools. Divergences in the data flow often occur when data intended for machine learning applications take one form and data used by more traditional astronomy tools take another. Divergence occurs because 1) science goals affect the selection and quantity of data and, 2) data requirements for tools may differ.",
  "body": "Introduction In recent years astronomy has seen a wide application of machine learning (ML) in numerous subfields, from exoplanets and stellar astrophysics to extragalactic and cosmology applications [5] [22] . In particular, the imminent start of the largest sky surveys ever conducted have motivated astronomers to adopt machine learning methods to filter, analyze, and extract information from these surveys. A large number of astronomy publications cite the Legacy Survey of Space and Time (LSST) and the Euclid space mission as the main drivers for implementing machine learning processes [9] Machine Learning and the Physical Sciences workshop, NeurIPS 2022. arXiv:2211.14401v2 [astro-ph.IM] 29 Nov 2022 [17] . The sheer volume of data to be generated by those telescopes is far more than any other survey or mission to date [1] [24] [18] [12] [14] . Astronomy as a field has famously and painstakingly made numerous datasets freely available in the forms of mission archives and survey repositories, but there has been less work in general on defining and building common practices for creating machine learning datasets [6] . We claim traditional mission and survey catalogs are effective astronomy datasets: they comprise careful calibrations, calculations, meticulously detailed descriptions and imagery, typically in a format enabling SQL queries [21] . They are queryable, available, interpretable for humans and readable by astronomers' tools. To employ machine learning techniques, these datasets are commonly transformed for tools developed in industry like PyTorch and TensorFlow [13][15] . This laborious transformation process to an ML-ready dataset requires choices about what content, structure, and metadata to include. However, little work has been done on understanding this process and identifying what constitutes an effective machine learning dataset for astronomy [16] . In this paper, we outline three elements in effective machine learning datasets for astronomy and suggest adopting them in practice. In our view, effective datasets are useful, usable, and reusable for all researchers. We propose that effective ML datasets have three characteristics: well-defined data points, well-defined structure, and well-defined metadata. In the sections below, we explore these three characteristics through the lens of astronomy datasets for machine learning. We use the term well defined to describe datasets conceptually, structurally, and holistically. The datasets should possess the necessary characteristics for being effective, useful, usable, and reusable [23] . Figure 1 : Diagram of a typical data flow for astronomical data. From the left, observations from a telescope, resulting data products are fed into scientific analysis tools. Divergences in the data flow often occur when data intended for machine learning applications take one form and data used by more traditional astronomy tools take another. Divergence occurs because 1) science goals affect the selection and quantity of data and, 2) data requirements for tools may differ. Well-defined data points Astronomical data in an upstream state often consists of unstructured raw images and spectra from telescopes that require further processing into data products for use in scientific analysis. Additionally, further processing is required to transform these data products into structured data points (tabular, time series, etc.) or image formats for machine learning. Some areas of research do not use image data, while others use combinations of both image and measurement data. In this paper we provide best practices using both; but image data can be eliminated and the data flows would remain similar. Well-defined data points are outcomes of processing raw data, and have clear boundaries delineating what information is and is not contained in the dataset. Some boundaries stem from choices made by the people previously or presently involved in the dataset creation process, while other boundaries come from structural limitations such as instrument configurations and the size and construction of the mirrors. These boundaries may be mutable or immutable, depending on the context; our focus is on documenting these decision-making processes as an integral part of ML datasets, as associated metadata. Structural boundaries describe 'fixed' data collected and stored from instruments, wavelengths, time durations, and regions of sky, to name a few. Boundaries resulting from human choice, such the selection of objects, are malleable; and can be reworked to create different datasets. Datasets are blended results of iterations of decisions. For example, a machine learning dataset might include galaxies over a particular region of the sky. The selection of galaxies is a choice while the region of the sky may be limited by the original survey parameters. Documenting details for why a particular dataset's attributes were chosen are helpful for others to understand and potentially reuse data. In this sense, the boundaries can define a limited ground truth. Well-defined data attributes formed from careful documentation and decision-making processes should be documented and consistent. This allows astronomers to have confidence in the use and reuse of the data and in understanding potential biases in the data. When selecting and organizing data points, astronomers must make decisions about: 1) quantifying the quality of data points, 2) establishing criteria for included data points, 3) establishing outlier criteria, and 4) identifying and potentially removing missing or low-quality data. Data quality measures are a way to signify how much trust the data curators have on the resulting data points. For example, some data points have higher uncertainties or have an increased chance of being artifacts due to limits of the instruments used to make the measurements. By including attributes such as data quality flags [2] , data curators can help users filter data according to quality that might be necessary for different ML models. For example, some machine learning models are much more sensitive to noisy data than others. Outliers are important to identify and potentially remove. Two main types of outliers are: (1) data points outside of the typical sample distribution and (2) data points that are erroneous measurements. In machine learning, training data that contains outliers can strongly bias the predictions of models. Outliers that are confirmed to be artifacts or errors that make them 'mistakes' should likely be discarded, as machine learning algorithms will 'learn' these errors and skew results. A different approach must be taken with outliers that are likely to have been measured correctly but have values that are very far away from the rest of the data distribution. This type of outlier should be kept in the data but considerations must be taken about how to deal with it. Identification of these outliers require characterizing the statistical distribution of the existing data points. Documenting these outliers will alert users to their potential effects during ML training. When dealing with outliers, one approach users can take is to bin them as a category, thereby reducing their effect or otherwise diminishing their power with other statistical techniques. Missing data points are also important to consider. Missing data might be in the form of a single attribute of a data point, or, it might mean a large sector of data points is not available. This might happen because of instrumentation limitations. For example, some astronomical datasets may contain both imaging and spectroscopic observations of many objects. However, because spectroscopy is much more difficult to obtain than images, some objects may be missing spectroscopic data. One way to mitigate problematic missing data is to use simulated data [3] . In machine learning, interpolation and extrapolation techniques can mitigate these issues, with varying degrees of success. Sampling techniques such as these may shape a better representation of a possible ground truth for a particular study. Astronomers should interpret results sensitive to missing data as a way of handling known limitations. Well-defined dataset structure The form and structure of datasets are important for both machine learning and astronomy, but additional work must be taken to translate astronomical data points into ML-ready datasets. Structural considerations such as the data format, tabular shape, and image sizes and dimensions can have major impacts on the type of machine learning models able to be used. In astronomy, data is often stored in the FITS file format, which is a broad data format that can store metadata, imaging, spectra, and tabular data [7] [20] . While FITS files are highly compatible with, and designed for astronomical software, the files are not standardized enough to use directly in machine learning models. Machine learning tools expect inputs of certain data types, and are not flexible enough to handle aberrations in data structures. While there are API libraries available such as AstroPy [4] to convert FITS files into machine learning amenable data formats, this transformation is not trivial, and can be problematic. PNG files are the most common image format used in mainstream machine learning, with lower resolution and smaller dimensional images comprising many datasets such as ImageNet or MNIST. PNG and JPG file formats use at the smallest 8 bits per channel, up to three channels (RGB). FITS image files, on the other hand, may contain many channels of various wavelengths at once, for example the COSMOS survey [19][11] contains thirty different bands of wavelengths for its image data. Reducing image resolution, number of channels, and image dimensions can greatly affect the amount of information contained in each image. For example, astronomers use multiple units for brightness, but in transformations to PNG these values would be reduced to a scale of integers from 0-255, greatly reducing each measurement's precision. Therefore, it is not recommended in many cases to transform astronomy images stored in FITS files to PNGs or JPGs. Also, FITS holds metadata about each image in its header section which also needs to be retained, and would be lost in a format transformation. Instead of PNG files, a more flexible format that works well with machine learning algorithms like HDF5 [8] is a wiser choice. HDF5 provides a better compromise between preserving all the information in FITS and ease of use in ML models. HDF5 is a library and associated file format that can store most types of multi-dimensional array data. This means it is able to preserve all wavelength channels in an astronomical image. The HDF5 data format is capable of storing metadata, tabular data, and image data, and works well to enable data to be ingested into TensorFlow or PyTorch. One major downside to HDF5 for astronomers is that its flexibility of storing metadata and data varies widely in terms of structure and labeling. Therefore, the FITS structure astronomers are familiar with is absent in HDF5, and conversions between the two formats are not one-to-one mappings. Because of this issue, datasets for machine learning in astronomy must retain critical information spanning two file formats. Best practices include providing code to produce the HDF5 file in addition to descriptions of the storage of metadata alongside the data itself. There is no elegant solution; perhaps in the future a more seamless system could be developed to ingest FITS images into machine learning, but image sizes and the number of channels could be too large for model training. Issues of computing power, training time, and file size are of serious importance when constructing ML datasets. Restrictions imposed on data formats originate from tool design outside of astronomy, so the structure of machine learning datasets must be made to align the science goals with requirements from the tools. For instance, computer vision for recognizing galaxy morphologies may need to work for galaxies of many different scale sizes, but ML tools require images to be a specific dimension. In most cases, the images from telescopes are much larger than the sizes that are accepted by ML tools. Structuring astronomical data for current ML tools can limit the amount of information that was originally available, for example in mainstream ML tools, to decrease training time image dimensions and resolutions are routinely resized and downscaled. Astronomers building ML datasets should consider and articulate potential information loss from transforming the data. Well-defined metadata Well-defined metadata includes: 1) all contextual information relevant to the creation of the dataset, 2) the features and form of the dataset, 3) motivations for creating the dataset with respect to the initial scientific goal. To document contextual information, an astronomer should document the creation of the dataset starting from how the original data was obtained from the archives or instruments to the dataset's final form. For example, users of most astronomy archives use SQL queries to extract subsets of data; queries used to form ML datasets should be preserved. Filtering and processing steps should also be documented and explained. Often, ML datasets in astronomy end up being different versions of similar data; specific versioning schemas should be enacted to ensure consistency in subsequent use of each dataset. With respect to feature and form preservation, well-defined tabular metadata should include metadata for each column and should include details such as units, descriptions, and how features were obtained. For images from FITS files, relevant data from the FITS headers should be preserved outside of FITS, if possible, and made available with the final machine learning dataset. The file format version (if any) and tools that can read the dataset should be documented in an archival file format. Metadata detailing the motivation for the creation of the dataset enables users to better understand ways it contextually could be used. Often, ML datasets for astronomy are created with specific science goals in mind (e.g. photometric redshifts [10] ). Decisions about the boundaries of the initial dataset are easier to understand if the original goals are known. By documenting the goals and the requirements of the initial scientific investigations, users can situate the dataset with respect to their own science goals. Conclusion Datasets with well-defined data points, structure, and metadata invite reusability, which makes scientific studies more reliable and efficient. Because of the intensive labor that necessarily goes into creating machine learning-ready datasets, reusing these datasets makes enormous sense to researchers. Machine learning datasets possessing the elements we outlined in this work are a way forward to effectively use massive datasets that are unable to be manually explored. We recommend that astronomers create effective datasets with an eye toward machine learning-ready characteristics, for the benefit of all data-intensive science. Broader Impacts We believe that our paper may have a positive impact in the field of astronomy, because we suggest best practices that can be incorporated into workflows to improve research practices surrounding the creation, curation, and preservation of datasets for machine learning in astronomy. We feel that potential ethical issues stemming from our work are minimal."
}