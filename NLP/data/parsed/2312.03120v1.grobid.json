{
  "title": "The Landscape of Modern Machine Learning: A Review of Machine, Distributed and Federated Learning",
  "abstract": "With the advance of the powerful heterogeneous, parallel and distributed computing systems and ever increasing immense amount of data, machine learning has become an indispensable part of cuttingedge technology, scientific research and consumer products. In this study, we present a review of modern machine and deep learning. We provide a high-level overview for the latest advanced machine learning algorithms, applications, and frameworks. Our discussion encompasses parallel distributed learning, deep learning as well as federated learning. As a result, our work serves as an introductory text to the vast field of modern machine learning.",
  "introduction": "Introduction Over the last decade, Machine Learning (ML) has been applied to ever increasing immense amount of data that is becoming available as more people become daily users of internet, mobile and wireless networks. Coupled with the significant advances in deep learning (DL), ML has found more complex applications: from medical to machine translation and speech recognition, to intelligent object recognition, and to smart cities [1, 2] . Modern parallel and heterogeneous computing systems [3, 4, 5] have enabled such applications by supporting highly parallel training. These large-scale and distributed systems therefore have become the backbone of modern ML [6, 7, 8] . Federated Learning (FL), as a sub-field of DL, has emerged as a distributed learning solution to provide data privacy [9] . Ever since its inception [9] , FL has been studied extensively and adapted widely [10, 11, 12, 13] . In this study, we review the current landscape of modern ML systems and applications, and offer an overview as a self-contained text. While there are many surveys on large-scale [6, 8] , distributed ML [7] , DL [1, 2, 14] , and FL [10, 11, 12, 13] , we instead provide a high-level joint view of modern parallel and distributed ML and FL. In this way, our work differentiates itself from the existing literature. In brief, our study • presents the concepts and methods of ML and DL. • discusses the parallelism and scaling approaches of large-scale distributed ML. Moreover, it explores the communication aspects, such as costs, topologies, and networking, of parallel and distributed training and inference. • introduces FL, its applications and aggregation methods. It then elaborates on the security and privacy aspects as well as the existing platforms and datasets. • summarizes open research questions in the modern landscape of parallel and distributed ML, DL and FL. Figure 1 outlines and summarizes our study. Our study is organized as follows: Section 2 overviews the related work on large-scale and distributed ML. Section 3 provides the background on ML. Section 4 discusses distributed ML. Section 5 presents FL. Section 6 summarizes the existing open challenges. Finally, Section 7 concludes our review.",
  "body": "Introduction Over the last decade, Machine Learning (ML) has been applied to ever increasing immense amount of data that is becoming available as more people become daily users of internet, mobile and wireless networks. Coupled with the significant advances in deep learning (DL), ML has found more complex applications: from medical to machine translation and speech recognition, to intelligent object recognition, and to smart cities [1, 2] . Modern parallel and heterogeneous computing systems [3, 4, 5] have enabled such applications by supporting highly parallel training. These large-scale and distributed systems therefore have become the backbone of modern ML [6, 7, 8] . Federated Learning (FL), as a sub-field of DL, has emerged as a distributed learning solution to provide data privacy [9] . Ever since its inception [9] , FL has been studied extensively and adapted widely [10, 11, 12, 13] . In this study, we review the current landscape of modern ML systems and applications, and offer an overview as a self-contained text. While there are many surveys on large-scale [6, 8] , distributed ML [7] , DL [1, 2, 14] , and FL [10, 11, 12, 13] , we instead provide a high-level joint view of modern parallel and distributed ML and FL. In this way, our work differentiates itself from the existing literature. In brief, our study • presents the concepts and methods of ML and DL. • discusses the parallelism and scaling approaches of large-scale distributed ML. Moreover, it explores the communication aspects, such as costs, topologies, and networking, of parallel and distributed training and inference. • introduces FL, its applications and aggregation methods. It then elaborates on the security and privacy aspects as well as the existing platforms and datasets. • summarizes open research questions in the modern landscape of parallel and distributed ML, DL and FL. Figure 1 outlines and summarizes our study. Our study is organized as follows: Section 2 overviews the related work on large-scale and distributed ML. Section 3 provides the background on ML. Section 4 discusses distributed ML. Section 5 presents FL. Section 6 summarizes the existing open challenges. Finally, Section 7 concludes our review. Related Work Surveys pertaining to parallel, distributed and large scale ML have been very numerous in the literature [6, 7, 8] . Our work is different and unique because it provides an introductory review of the latest joint landscape of ML, DL and FL. Different than the general surveys such as [15, 6, 7, 8] , some surveys offer in depth cost and comparisons of algorithms and methods both theoretically and empirically [16, 17] . Many studies focus on distributed DL. Some of them are [1, 2, 18, 19, 14, 20] . Moreover, there exists a significant number of surveys that focus on specific types of models such as [21] for graph neural networks (GNNs), [22] for Internet-of-Things (IoTs), [23] for wireless networks, [24] for mobile and 5G networks or for specific target environments such as [25] for unmanned aerial vehicles (UAV). FL literature unsurprisingly offers many surveys. Some of the latest surveys are [10, 11, 12] . Among studies having specific topics, [26] surveys privacy and security methods for FL, [27] discusses block chain-based FL. [28] presents differential privacy for FL. [13] offers a survey of FL for IoT. Introduction to ML ML is the process of learning from data to perform complex tasks for which there is no known deterministic and algorithmic solution, or building such a solution is not practical. For instance, developing a deterministic algorithm based on rules to detect spam emails is highly impractical. It is not possible to know the exact list of the detection rules. In addition, these rules most often change over time. Since the list of the rules may be ever-increasing and even contradictory, the maintenance of such algorithms would require constant labor. The ML process is mainly two-fold: Training and prediction (inference). In the training phase, the parameters of a learning model are optimized based on data. In the prediction phase, the trained model is deployed to perform predictions on new data. While in most cases the training and prediction phases are mutually exclusive, in incremental learning cases, they are coupled together. The models in these cases are continuously trained and make predictions. Figure 2 visualizes the training and prediction phases. The main goal of ML is to generalize such that it performs well with unseen data. However, this goal contradicts its optimization goal in which ML tries to minimize the training loss with the training data. As a result, the well-known bias-variance problem emerges. If an ML model over-fits the training data, that is, having high variance, it performs poorly with the unseen data. On the other hand, if the model under-fits, that is, having high bias, it does not learn important patterns or regularities in the data. Over-fitting typically happens when a model is too complex for the underlying problem. In contrast, under-fitting happens when the model is too simple. Figure 3 depicts the bias-variance trade-off. In the following, we present different types of ML tasks. After that, we look into different problems that ML can solve. Then, we review widely used ML algorithms and methods. Finally, we survey the existing ML platforms that are not supported with specialized hardware and not suited for DL or FL. §3: Machine Learning • §3.B: Algorithms • Feedback based • Target problem based • Algo. approach based • §3.C: Frameworks • Scikit-Learn • Weka • XGBoost • Shogun • LibSVM • Cloud based • §4.B: Parallelism Types • Data • Model • Pipeline • §4.C: Vertical Optimization • Model Simplification • Optimization Approximation • Communication Optimization • §4.D: Comm. Topologies • Centralized • Hierarchical • Fully Distributed §5: Federated Learning §6: Open Questions & Challenges • §6.A: Parallel & Distributed ML • §6.B: Federated Learning Our Review • §4.E: Sync Models • Bulk Synchronous • Stale Synchronous • Approximate Synchronous • Asynchronous • §4.F: Distro. ML Frameworks • Tensorflow • PyTorch • … §4: Distributed Learning • §5.B: Aggregation Algorithms ML Algorithm Trained Model Prediction Training Phase Prediction Phase (Inference) Training data New data Hyperparameters Fig. 2: ML phases: Training and prediction (inference). • FedAvg • FedProx, • SCAFFOLD • FedSGD, • FedOpt • … • §5.C: Security & Privacy • Attacks • Defenses • §5.D: Frameworks • Tensorflow Federated • IBM Federated • NVIDIA FLARE • FedML • FATE • PySyft • OpenFL • §5.E: Datasets ML Algorithms ML algorithms can be categorized by the format and requirements of data (external feedback), by the type of problems they are designed for (target problem), and by the techniques they use (algorithmic approaches). It is worth noting that there is another way of categorizing ML: online and offline. In offline learning, the entire training data is available prior to training. This is the most common application of ML. In online learning [29] , either the entire data is not available beforehand or it is computationally infeasible to perform training over the entire data at once. An example of the former is sequential training such as time series analysis in financial markets. An example of the latter is learning with a very large dataset which does not fit into the memory and consequently, training becomes prohibitive. Model Complexity Loss Fig. 3 : Bias-variance trade-off. Model complexity with respect to bias and variance. External feedback ML algorithms can be classified based on the external feedback as follows: Supervised Learning: Learning is performed by feeding labeled input data so that a model's parameters are optimized. Labeled data can be desired classes, categories, or numerical outputs corresponding to the training instances. During training, the optimization is achieved by minimizing a predetermined cost function. After training, the trained model is deployed to predict the outputs of new instances. An example supervised learning is to classify newly seen handwritten digits by training with the labeled digits. Unsupervised Learning: The goal of unsupervised learning is to find structures and patterns Fig. 4 : An artificial neural network example. in unlabeled data. This means that in unsupervised learning, the data does not possess desired outputs. As an example of unsupervised learning, clustering aims to find similar groups (clusters) in given data. Dimensionality reduction is another example of unsupervised learning where the goal is to find a subset of key features that describes the data well. Semi-supervised Learning: In semi-supervised learning, the amount of labeled data is small while the amount of unlabeled data is large. Clustering algorithms are typically used to propagate existing labels to the unlabeled data. An assumption of semi-supervised learning is that similar data shares the same label. Reinforcement Learning: Reinforcement learning is applied when an agent interacts with an environment. Based on the observations it makes, the agent takes actions. The actions are rewarded or penalized according to a reward function. Applications of reinforcement learning lie in the fields such as game theory, robotics and industrial automation. Target Problem Under this categorization, ML algorithms are grouped according to the kind of problems they are designed to solve. In classification problems, the aim is to correctly categorize data instances into the known classes. In regression problems, the goal is to estimate the value of a variable based on other variables (features). Clustering finds the distinct groups of similar data instances based on a selected similarity metric. Anomaly and novelty detection is used to find data instances that are significantly different than others. These instances are called outliers. In anomaly detection, training data consists of both outliers and regular (expected) data instances. In novelty detection, on the other hand, the goal is used to detect unseen data where training data is free of outliers. Dimensionality reduction is used to reduce the number features of the training data. In dimensionality reduction, if a subset of the original set of the features is selected, it is called feature selection. In contrast, if features are combined into new ones, it is called feature extraction. Dimensionality reduction can also be used to decrease computational costs of training. Furthermore, it can also be used to prevent over-fitting. The problem of over-fitting with high-dimensional data is famously known as the curse of dimensionality. The curse of dimensionality arises due to data sparsity in high dimensional spaces. Algorithmic Approaches ML algorithms can be categorized based on algorithmic approaches that they employ. Stochastic Gradient Decent (SGD) based algorithms are optimized based on a loss function of the outputs of the model parameters in the opposite direction of the gradient. Because at each training step a random subset of data is used, this optimization method is called stochastic. Many common ML algorithms are optimized with SGD such as artificial neural networks. Support Vector Machines (SVMs) [30] are typically used when the input data is not linearly separable in its original space. They map the input data to high dimensional spaces where it becomes linearly separable. SVMs can be used for classification, regression, and novelty detection. Artificial Neural Networks (ANNs) are constructed by multiple layers of nodes (neurons) that have inputs, outputs, corresponding feature weights, and an activation function. Layers can be input, hidden, and output layers. ANNs have recently been very successful in tasks such as image classification, object detection, and natural language processing. Figure 4 depicts an example of an ANN. Some well-known types of ANNs include: • Convolutional Neural Networks (CNNs) [31] are deep neural networks that incorporate convolutions and pooling. While convolutions help with learning local data, pooling help with learning abstract features. CNNs have been extremely successful in tasks such as image classification, object detection, and image segmentation. • Recurrent Neural Networks (RNNs) [32] maintains a temporal state of sequence data. The temporal state may hold short-term or longterm memory. RNNs are used in tasks such as time series forecasting, natural language processing, and anomaly detection. • Autoencoders [33] are ANNs that learn latent representations of input data with no supervision. They are used for dimensionality reduction and visualization of high dimensional data. • Generative Adversarial Networks (GANs) [34] are (originally unsupervised) neural networks used to generate data based on a game between a generator and discriminator network. They have been successfully applied in supervised and semi-supervised learning. • Graph Neural Networks (GNNs) [35] are a type of ANNs designed to perform learning and prediction on data described by graphs. GNNs provide an easy way to do node, edge, and graph level ML tasks. • Self-Organizing Maps (SOMs) [36] are neural networks which produce a low dimensional representation of high dimensional data. SOMs are used for visualization, clustering, and classification. The training is unsupervised where after random initialization, neurons compete against each other. • Boltzmann Machines [37, 38] are fully connected ANNs which, unlike other ANNs, have probabilistic activation functions. Neurons output 1 or 0 based on Boltzmann distribution. Boltzmann Machines can be used for classifying, denoising, or completing images. • Deep Belief Networks [39] are stacked Boltzmann Machines designed to tackle larger and more complex learning challenges. They are used for semi-supervised learning. • Hopfield Networks [40, 41] are fully connected networks that are used for tasks such as character recognition. Transformers [42] are a class of DL models that has shown extraordinary success in many ML fields including natural language processing and computer vision. Transformers were first introduced by a landmark paper from Google [43] which were based on a novel mechanism called Attention. At its core, a transformer is an encoderdecoder model. The success of Transformers has become a regular news-headliner such as the release of GPT-4 [44] and ChatGPT [45] . Rule-based algorithms [46] use a set of rules to learn patterns from the input data. They are typically easier to interpret than other ML algorithms. Decision trees are the most well-known rule-based algorithms. Evolutionary algorithms [47] use ideas from biological evolution. In evolutionary algorithms, the target problem is represented by a set of properties. The performance metric is called fitness function. Based on fitness scores, the set of properties is mutated and crossed over. These algorithms iterate until accurate estimates are obtained. Evolutionary algorithms can also be used to create other algorithms such as neural networks. Semantic and Topic algorithms [48, 49] are used to learn specific semantic patterns and distinct relationships in the input data. An example application of these algorithms is to find the topics and relate them to each other in a given set of documents. Ensemble algorithms combine other algorithms to obtain a solution that performs better than the individual algorithms. Different ways to build ensembles are: • Bagging combines multiple classifiers and uses voting to determine the final output. • Boosting is a technique that trains the subsequent models with the data instances misclassified by the preceding models in the chain. • Stacking is the process where a model trains with the outputs of the preceding models in a chain of several models. Stacking typically reduces the classification variance. • Random Forests combine multiple decision trees and output an (weighted) average of the outputs of the individual trees. Existing ML Frameworks In this section, we present the existing ML platforms that are not supported with specialized hardware and typically not suited for DL or FL. We then briefly mention the popular ML services in the cloud. Scikit-Learn [50] is the most popular opensource Python library that offers an extensive suite of ML algorithms. The library is very well maintained and provides a comprehensive set of algorithms, methods, pre-processing, pipelining, model selection and hyper-parameter search capabilities. It provides interfaces to work with NumPy and SciPy packages. Weka [51] is a general-purpose and popular Java ML library. It provides a large collection of algorithms and visualization tools. Weka supports numerous tasks such as pre-processing, classification, regression, clustering and visualization. XGBoost [52] is a scalable and distributed gradient boosting library based on decision trees. It implements parallel ML algorithms for classification, regression and ranking tasks. Shogun [53] is a research-oriented open-source ML library. It offers a large number of ML algorithms and cross-platform support by providing bindings with other languages and environments such as Python, Octave, R, Java. Shogun's core library is implemented in C++. LibSVM [54] is a specialized C/C++ library for SVMs. It provides interfaces for Python, R, MATLAB and many others. Many companies offer standard ML and distributed ML services. Moreover, these services often include the support for GPUs and other ML specific hardware. Popular cloud ML services are Google's Cloud [55] , Microsoft Azure [56] , Amazon's SageMaker [57] and the IBM Watson Cloud [58] . Distributed Machine Learning In this section, we introduce large-scale distributed ML. We then explore different types of parallelisms used in distributed training. Next, we dive into vertical scaling techniques. After that, we present the optimizations for communications in distributed ML. Then we continue with the communication topologies and synchronization models. Finally, we conclude this section by the discussion of the existing distributed ML frameworks. As a side note, we use client and participant interchangeably in the rest of the paper. Introduction to Distributed ML Distributed ML is proposed to utilize distributed and heterogeneous computing systems to solve large and complex problems where a solution cannot be obtained by a single standalone homogeneous computing device. Distributed ML offers two different approaches. The first is to use heterogeneous resources available in a single computing system such as Graphical Processing Units (GPUs). This is called vertical scaling. The second is to use multiple machines to solve larger problems and to support fault-tolerance. This is called horizontal scaling. GPUs have been the most common mean of vertical scaling. Given sufficient parallelism, it has been shown that GPUs significantly accelerate training [59, 60] . For instance, NVIDIA GPUs have been popular in accelerating ML [59, 61] . Vendors such as Google have implemented their own specific hardware accelerators. Tensor Processing Units (TPUs) [60] are designed specifically for this purpose. Others such as Graphcore [62] and SambaNova [63] have followed this trend with sophisticated dataflow-based hardware designs and powerful system software tool-chains. In contrast to vertical scaling, horizontal scaling corresponds to distributed training and inference across multiple machines. Horizontal scaling enables ML solutions to handle applications and data that do not fit in the resources of a single machine. Additionally, the usage of multiple machines typically accelerate training and inference. Parallelisms in Distributed Training and Inference There are three types of parallelisms used in distributed training. These are data, model and pipeline parallelism. Data Parallelism In data parallelism, the same ML model is trained with different subsets of the data in parallel at different computing resources. Once all computing resources finish the assigned training, the models are accumulated and an average model is obtained. Then, this average model is distributed back to each computing resource for the subsequent rounds of training. Figure 5 depicts data parallelism with two parallel resources. The main advantage of data parallelism is that it is applicable to any distributed ML model without requiring expert/domain knowledge. It is also very scalable for compute-intensive models, such as CNNs. One disadvantage of data parallelism is that model synchronization may become a bottleneck. Another disadvantage occurs when the model does not fit in the memory of a single device. Model Parallelism In model parallelism, the model is partitioned and distributed to different computing resources. The data is distributed as well according to the model distribution. When there is a dependency among the computing resources, synchronization is needed for the parameters (weights) to be shared consistently. Figure 6 shows model parallelism where two resources are used. An important note is that in the figure, every time that a dashed line crosses a resource boundary, at least one synchronization event must take place to ensure data consistency. The main advantage of model parallelism is that models take less memory in each single resource (device). Its main disadvantage is that the model partitioning is often nontrivial. Another disadvantage is the potential intensive communications among the resources. Pipeline Parallelism Pipeline parallelism combines model and data parallelisms. It distributes the model and data in a such a way that there is a pipeline among the computing resources in which each resource has a different part of the model. Pipeline parallelism maintains the advantages of model parallelism while increasing the resource utilization. Figure 7 illustrates pipeline parallelism. Vertical Optimization Approaches We have discussed the types of parallelisms used in distributed ML above. Now, we explore three vertical optimization approaches. They are model simplification, optimization approximation, and communication optimization approaches. Model Simplification Model simplification refers to the reformulation of a target model to decrease its computational complexity as a way of achieving efficiency. Model simplification can be further divided into categories based on the type of the ML models. These models can be based on kernels, trees, graphs and deep neural networks. Table 1 summarizes the model simplification techniques. Simplifications for kernel-based models are made by sampling-based or projection-based approximations. While sampling-based methods [64, 65] approximate kernel matrices by random samples, projection-based methods [66, 67] use Gaussian or sparse random projections to map the data features to low dimensional sub-spaces. Performance and scalability improvements for tree-based models, such as decision trees and random forests, are commonly based on rule [68] or feature sampling [52] [69] . Graph-based simplifications are developed for graph-based models where nodes represent the data instances and edges represent the similarity between the instances. In these models, the cost of training comes from two main sources: graph construction and the label matrix inversion. For sparse graphs, graph construction constitutes the main cost of training. This is because when label  propagation is used, it lowers the cost of the inversion of the label matrix and it becomes less costly than graph construction. As a result, graph construction dominates the main computational cost. To construct sparse graphs [70] , hashing methods [71] [72] are often used. Different than sparse graph models, there are also graph models that are built by anchor graphs [73] . An anchor graph is a hierarchical representation of a target graph. It is built with a small subset of the instances. This small subset is used to retain the similarities between all instances. In such a representation, the label matrix inversion is the main cost of training. To reduce the cost of the matrix inversion, the pruning of anchors' adjacency [74] is a common technique. Performance improvements for deep neural networks can be achieved in two different ways. First, activation functions, such as Rectified Linear Unit (ReLU) [75] and its variants [76] [77], can be employed instead of the expensive functions, such as sigmoid and tanh, which use the exponential function. Other techniques, specifically for CNNs, involve depth-wise filter factorization [78] and group-wise convolutions [79] . Optimization Approximation Optimization approximation is a family of techniques that are used to reduce the cost of the optimization related computations, i.e., gradient computations, for training. It is generally realized by computing the gradients with a small number  of instances or parameters instead of all instances or parameters. Care has to be taken since such approximations can lead to longer convergence times, local extrema, or even non-convergence. Optimization approximation can be categorized based on the specific optimization algorithm that is being used: Mini-batch gradient descent, coordinate descent, and numerical integration based on Markov chain Monte Carlo. Table 2 shows the existing techniques. Techniques that are used for mini-batch gradient descent approximations are adaptive sampling of mini-batches, adaptive learning rates, and the improvements in gradient approximations. Adaptive sampling [80] [81] for mini-batches takes the data distribution and gradient contributions into account rather than just using random batches of samples or making a gradual increase in the batch size [82] . Learning rates are also crucial in terms of achieving fast convergence [83] . Adaptive learning rates can boost the speed and quality of convergence [84] . Further adaptive adjustments are shown to be effective [85] [86] . Complementary to adaptive sampling or adaptive learning rates, reducing the variance of gradients and computing more accurate gradients are shown to be effective and efficient in achieving fast convergence. Such methods use average gradients or look-ahead corrections of gradients [87] [88] . In addition to the accurate first-order gradients, higher-order gradients may be needed due to ill-conditioning [89] [90] . Hessian matrices are estimated by the high-order gradients to make convergence possible [89] . Coordinate gradient descent are targeted at the problems where the instances are high dimensional, such as recommender systems [91] and natural language processing [92] Table 2: Optimization approximation based techniques. optimizations performed by coordinate gradient descent, a small number of parameters can be selected at each iteration. Random selection of parameters has shown to be effective [93] [94] . Parameter selection can also be based on the first and/or second-order gradients information [95] [96] . Another approach for speedup is to use extrapolation steps during the optimization phase [94] . If the optimization problem is non-convex, then studies such as [97] [98] present specific solutions. For instance, Li and Lin [97] propose an extended variant of accelerated proximal gradient method. Finally, Bayesian optimization methods are commonly based on Markov chain Monte Carlo [99] [100] . Such methods employ stochastic minibatches due to the high cost of the acceptance tests [101] . Communication Optimization Approaches Optimizations to reduce communication costs constitute another option to those for computation. In these optimizations, compression of gradients is one of the two main ideas. Some studies compress each gradient component to just 1 bit [102] . Others map gradients to a discrete set of values [103] or sketch gradients into buckets and then encode them [104] . Some proposals only communicate gradients that are bigger than a certain threshold [105] . A combination of gradient compression and low-precision learning has been shown to further reduce the communication costs [106] . The other main idea for the optimization of communication is gradient delaying [107] Communication Topology In a distributed ML system, the computing resources (clusters) can be structured in different ways. The types of topologies that the resources use can be categorized into three: centralized, hierarchical, and fully distributed (decentralized). Figure 8 depicts these topologies. Table 4 summarizes our discussion. Centralized Topology In this topology, the computation of the global model parameters, gradient averaging and communications with the distributed nodes/clients are performed at a central server. Every distributed client directly communicates with the central server and works with its local data only. A major disadvantage of a centralized topology is that the central server constitutes a single point of failure and a computational bottleneck. Advantages of a centralized topology are the ease of its implementation and inspection. Figure 8 (a) presents an example of this topology. Hierarchical Topology The computations and aggregation of the global model parameters are performed in a stage-wise and hierarchical way. Each child node only communicates with its parent. These topologies offer higher scalability than the centralized counterparts and easier manageability than the distributed counterparts. Figure 8 (b) depicts a hierarchical topology. Fully Distributed Topology Every participant maintains a local copy of the global model in a fully distributed topology. Participants directly communicate with each other. Compared to the centralized and hierarchical topologies, scalability is much higher and the single points of failure are eliminated. However, the implementation of these topologies is relatively more complex. Figure 8 (c) shows this topology. Synchronization Models Synchronization models are techniques to guide and perform synchronization between parallel computations and communications. These models seek to establish the best trade-off between fast updates and accurate models. To do fast updates, lower levels of synchronization are required. In comparison, to obtain accurate models, higher levels of synchronization are needed. As far as ML is concerned, stochastic gradient descent is one of the most popular algorithms for the optimization during the training phase. As discussed below, variants of stochastic gradient descent have been implemented in accordance with the underlying synchronization model. Therefore, those variants constitute practical examples for the corresponding synchronization model. Bulk Synchronous Parallel It is a synchronization model [111] where synchronization happens between each computation and communication phase. Since this model is serializable by construction, the final output is guaranteed to be correct. However, when there are discrepancy between the progress of parallel workers, the faster workers have to wait for the slower ones. This can result in significant synchronization overhead. Stale Synchronous Parallel This synchronization model [107] allows the faster workers continue with their version of data for an additional but limited number of iterations to reduce the synchronization overheads due to the wait on the slower workers. While this can help reduce the overheads, data consistency and model convergence may become difficult to establish. Approximate Synchronous Parallel In this model, synchronization is sometimes omitted or delayed to reduce the overheads. However, the accuracy and consistency of a model may deteriorate if care is not taken. An advantage of approximate synchronicity is that when a parameter update is insignificant, the server can delay synchronization as much as possible. A disadvantage is that selecting which updates are significant or not is typically difficult to do. As an example of the application of this model, Gaia [112] is an approximate synchronous parallel ML system. Asynchronous Parallel This synchronization model omits all synchronizations among the workers. While these omissions may significantly reduce the computation time and communication overhead, asynchronous communications may cause ML models to produce incorrect outputs. To give an example application, HOGWILD algorithms [113] are developed based on asynchronous communications. Existing Distributed Learning Frameworks There are many ML frameworks that provide distributed ML algorithms and utilities. The most popular distributed implementations are Tensorflow [114, 115, 116] , PyTorch [117, 118] , MXNet [119, 120] , Horovod [121] , Baidu [122] , Dianne [123] , CNTK [124] and Theano [125] . Table 5 summarizes these frameworks. Other than the ML frameworks above, some general-purpose distributed computing libraries, such as Apache Spark [126] and Hadoop [127], also support distributed ML. Tensorflow [114] is a free and open-source software library developed for ML and DL by Google. In fact, Tensorflow is the most popular library among the DL libraries. It supports distributed learning with several distribution strategies, such as mirrored, multi-worker and parameter server, that are either data or model parallel [115, 116] . The library provides efficient and scalable ML implementations for CPUs, multi-GPUs and mobile devices. PyTorch [117] is another free and open-source framework based on the Torch Library developed by Meta. It is a popular framework for scientific research and provides automatic differentiation and dynamic computation graphs. It supports distributed learning mainly in two ways with torch.distributed package [118] . First, same as the Tensorflow mirrored strategy, PyTorch offers distributed data-parallel training which is based on the single-program and multiple-data paradigm. Second, for the cases that do not fit into data parallelism, PyTorch provides Remote Procedure Call (RPC) based distributed training. Examples of these types of distributed training are parameter server, pipeline parallelism, and reinforcement learning with multiple agents and observers. MXNet [119] is an open-source DL framework for research prototyping and production. It offers data-parallel distributed learning with parameter servers. MXNet allows mixing both symbolic and imperative programming for computational efficiency and scalability. MXNet supports many programming languages such as C++, Python, R and Julia. Horovod [121] is a distributed wrapper DL framework for TensorFlow, Keras, PyTorch, and Apache MXNet. Horovod is often easy to use because it only requires an addition of a small number of library calls to the source code. Horovod supports data, model and pipeline parallelisms. Baidu [122] was started as an easy-to-use, efficient distributed DL platform. It supports largescale ML and can train hundreds of machines in parallel with GPUs. Baidu offers various commercial solutions, such as machine translation, recommender systems, image classification and segmentation. Dianne [123] is a distributed and ANNsfocused software framework based on OSGi which is a dynamic module system for Java. Dianne supports both model and data parallelisms and offers UI-based functionality. Theano [125] was a popular open-source Python library to define, optimize and evaluate mathematical expressions. It has support for efficient multi-dimensional arrays. Developed by Universite de Montreal, it is no longer used widely. Theano supports data-parallel distributed learning by both synchronous and asynchronous training. It also supports multi-GPU multi-machine distributed training. General-purpose distributed frameworks that are based on MapReduce programming model [128] , such as Apache Spark [126] and Apache Hadoop [127], supports distributed ML algorithms, applications and utilities. Apache Spark is one of the most popular implementations of MapReduce. It includes MLlib [129] which is an open-source scalable distributed ML library. MLlib consists of widely-used ML algorithms and utilities for classification, regression, clustering, and dimensionality reduction tasks. Federated Learning (FL) In this section, we first introduce FL. We then present the existing aggregation algorithms in detail. After that, we discuss the security and privacy aspects of FL. We conclude this section by the available FL platforms and datasets. Introduction to FL W 1 W 2 W n W 1 , W 2 , …, W n -> W Fig. 9 : Federated Learning Overview. FL can be categorized based on how data partitioning is done. Horizontal FL [130] refers to the case where the clients share the same feature space but have different sample spaces. This is similar to data parallelism. An example of horizontal FL is wake-up voice recognition on smartphones. Users with different types of voices (different sample spaces) speak the same wake-up command (same feature space). Vertical FL [130] takes place where the clients share the same sample space but have different feature spaces. As an example, the common customers (same sample space) of a bank and an e-commerce company (different feature spaces) join the training of an FL model for optimizing personal loans. Finally, Federated Transfer Learning Distributed machine learning and FL have some fundamental differences. These are: • While distributed machine learning's main goal is to minimize the computational costs and achieve high scalability, FL's main goal is to provide privacy and security for the user/client data. As a result, FL is designed such that user/client data is never shared. • Distributed learning assumes that the user data is independent and identically distributed (i. for epochs e from 1 to E do the following is done in parallel 20: w k t+1 ← U pdateClientW eight(k, w k t ) 21: end for 22: w t+1 ← K k=1 w k t+1 K 23: end function 24: end if We now discuss the very first FL algorithm, FedAvg, proposed by McMahan et. al. [9] . Algorithm 1 describes FedAvg. It shows the action taken by the server and clients during a round of FL. The clients train the model with their data. Once trained, the weights are sent to the server as described by the U pdateClientW eight function on line 7. Once the server receives the weights from the clients, which is done in parallel, it averages out all the weights and sends the average weights back to each clients, as seen in the ServerU pdateW eight function on line 16. Training is repeated if the data changes. This is to keep the weights updated. FL Applications FL has a wide range of applications across different domains and settings. Some of them are: • Smartphones: FL has been used to develop ML applications for smartphones such as next-word prediction, and face and voice recognition. • Healthcare: FL has been applied successfully for research problems in medical studies such as drug discovery and brain tumor segmentation. • The internet of things (IoT): IoT is a network of digital or mechanical computing objects that have sensors, software, and other computing technologies. IoT exchanges data with other devices and systems over the internet to perform specific learning tasks. Applications of FL in IoT include autonomous driving and intrusion and anomaly detection. • Finance: FL has been adopted to detect/identify financial crimes such as fraudulent loans and money laundering. FL Aggregation Algorithms In FL, due to data parallelism and horizontal FL, aggregation algorithms are needed to aggregate the models or gradients between the participants. As stated above, the very first aggregation algorithm, called Federated Averaging (FedAvg), was introduced by McMahan et. al. [9] who essentially kick-started FL itself. FedAvg computes the global model parameters by averaging the parameter updates of the participants. Once the global parameters are computed and updated, these parameters are communicated back to the participants. FedAvg is a straightforward algorithm however, it is biased toward the participants who have favorable network conditions. Aggregation algorithms have been studied extensively for centralized topologies [132, 133] . To decrease the communication overheads, Liu et. al. propose the Federated Stochastic Block Coordinate Descent (FedBCD) algorithm [132] in which each participant makes multiple local updates before synchronizing with other participants. Differently, FedOpt [133] uses gradient compression to reduce communication overhead while sacrificing accuracy. Furthermore, for edge devices where computational resources are limited, algorithms such as FedGKT [134] are developed. A significant objective in FL is to provide fairness. Fairness means that the clients equally contribute to the global model with respect to certain metrics. Researchers have proposed algorithms such as Stochastic Agnostic Federated Learning (SAFL) [135] and FedMGDA+ [136] to achieve fairness. Adaptive FL and its impact on convergence and accuracy have been explored in various recent works. ADAGRAD [137] offers an adaptive approach to ML optimization compared to FedAvg. ADAGRAD and its variants dynamically choose server and client learning rates and momentum parameters during training. Mime Lite [138] is a closely related study where adaptive learning rates and momenta are reported to improve accuracy. Some recent aggregation algorithms support heterogeneity of participant data. FedProx [139] is such an algorithm used for FL over heterogeneous data and resources. SCAFFOLD [140] is another algorithm that accounts for heterogeneous data while reducing the number of rounds to converge. FedAtt [141] accounts for the client contributions by attending to the importance of their model updates. The attention is quantified by the similarity between the server model and the client model in a layer-wise manner. FedNova [142] proposes a normalized averaging method as a way to avoid objective inconsistencies and to achieve fast convergence for highly heterogeneous clients. Personalization is another important consideration in FL. There has been extensive research on personalized FL [143] [144] . Tan et. al. [145] offer a survey of the latest personalization techniques. When the topology of the clients in FL is hierarchical, an aggregation algorithm needs to take the hierarchy into account. Numerous hierarchical aggregation algorithms have been proposed for such settings [146, 147] . Among hierarchical solutions, SPAHM [146] and PFNM [147] are Bayesian FL methods. Similarly, for decentralized topologies, decentralized algorithms have been developed [148, 149] . Considering fault-tolerance in FL, Krum [150] is an aggregation scheme that is reportedly resilient to Byzantine failures [151] where computing processes fail arbitrarily and failure symptoms are different for different observers. For these types of failures, more fault-tolerant FL studies are needed. Security and Privacy in FL The security of FL entails ensuring the triad of confidentiality, integrity and availability of its data and models, and particularly, data privacy. Privacy is defined as the protection of the raw data against the information leakage. In this section, we first summarize the attack types and then the defensive actions and methods existing in the FL literature [26] . Attacks There are numerous attack types in FL. Poisoning attacks aim to tamper with and/or alter the data or the model. Data poisoning [156, 157, 158] refers to altering the features in the training data or generating false data to degrade the performance of a model on the unseen data. Model poisoning [159, 160, 161] refers to the modification of the model parameters and/or the fabrication of false weights that are communicated between the participants and the servers. Backdoor attacks [177, 178] inject malicious instructions into the models while not impacting their expected performance. These attacks are non-transparent and notoriously difficult to detect. Inference attacks [26, 162, 163] involve gaining knowledge of the sensitive information of the participants, the training data or the model through the communications occurring during training or inference. Membership inference attacks aim to learn if a sample has been used as a training instance. Property inference attacks aim to learn the meta-characteristics of the training data. Class representative inference attacks aim to learn representative samples of a target class. Generative Adversarial Networks (GANs) based attacks [166, 167, 168] are used to launch poisoning attacks where GANs generate the altered or false data and/or model parameters. There are many other attack types [179, 180] , such free-riders [26, 163] and Eavesdropping [26, 163] . Defenses The most commonly used attack defense mechanisms can be categorized by the usage of trusted execution environments [169, 170] , homomorphic encryption [164, 165] , differential privacy [28, 154, 155] , and possibly some combinations of them. There are many other techniques which are based on GANs [181] , anomaly detection [176] , secure multi-party computation [171] , data anonymization [175] , and blockchains [27, 172] . A trusted execution environment [169, 170] is an (hardware/software) architecture where the program execution is secured and information leakage is not possible. Such architectures use specialized designs to prevent unauthorized accesses as well as privacy violations in FL [169, 170] . Homomorphic encryption [182] is a certain type of encryption in which the decryption of the results of the computations performed on the encrypted data is the same as the result of the same computations performed on the unencrypted data. Homomorphic encryption has various levels depending on the whether addition and/or multiplication is supported. It has been adapted for data privacy in FL [164, 165] . Differential privacy [152, 153] is a technique for achieving data privacy by adding noise to raw data. It is commonly used in FL [28, 154, 155] . Table 6 reviews attacks and defenses in FL. In addition, Table 7 compares the defense mechanisms in terms of the strength of the protection, the computational and communication efficiency, robustness, scalability, and generalizability of a mechanism. Existing FL Frameworks The most widely used FL frameworks are Ten-sorFlow Federated [183, 184] , IBM Federated Learning [185] , NVIDIA FLARE [186] NVIDIA FLARE (Federated Learning Application Runtime Environment) [186] is a modular open-source software development kit (SDK) for FL which offers secure and privacy-preserving distributed learning. FLARE provides FL algorithms such as FedAvg, FedProx and SCAFFOLD. It offers differential privacy and homomorphic encryption. FLARE SDK has several components, such as a simulator for prototyping, secure management tools for provisioning and deployment and an API for extensions. FedML [187] framework offers a wide-range of cross-platform FL capabilities including natural language processing, computer vision, and GNNs. FedAvg, FedOpt, FedNova and FedGKT are the supported FL algorithms. FedML offers defense mechanisms such as differential privacy, cryptography routines, and several coding methods. It supports data and model parallel distributed learning. FedML models can be trained and deployed at the edge or on the cloud. FATE [188] is an open-source platform initiated by WeBank, a bank based in Shenzhen, China. It provides a diverse set of FL algorithms, such as tree-based algorithms, DL, and transfer learning. It offers a set of modules consisting of an ML algorithms library, a high-performance serving system, an end-to-end pipeline system, a multi-party communication network system, and a module for cloud technologies. FATE provides homomorphic encryption and RSA for secure and privacy preserving training. FATE supports data and pipeline parallelisms. PySyft [189] is an open-source multi-language library that provides secure and private DL and FL in Python for frameworks such as PyTorch, Tensorflow and Keras. It supports differential privacy and homomorphic encryption. FedAvg, FedProx and FedSGD are among the available aggregation algorithms. Training can be data or model parallel. OpenFL [190] is an open-source Python framework originally developed by Intel Labs. It provides a set of workflows for the researchers to experiment with FL. FedAvg and ADAGRAD algorithms are built-in. OpenFL's capabilities include trusted execution environments, RSA, differential privacy. FL Datasets As FL research progresses, new datasets are being built. One of the most well-known datasets for FL is the LEAF [191] . It is a suite of open-source federated datasets. There are a total of six different datasets. One of the datasets, called FEMNIST, is built for image classification. Sentiment140, which consists of Tweets, is a dataset for sentiment analysis. Shakespeare is a text dataset of Shakespeare Dialogues which is used for next character prediction. Celeba is an image classification dataset of celebrity images. There is a synthetic classification dataset which is generated for the FL models that are device-dependant. Lastly, the Reddit comments dataset is used for next word prediction. TensorFlow Federated [192] offers several datasets to support FL simulations. While some of its datasets are the same as those of LEAF, there are also different datasets, such as the federated CIFAR-100 dataset, the FLAIR dataset, and the federated Google Landmark v2 dataset. Street Dataset [193] is a real-world image dataset. It contains images generated from street cameras. A total of seven object categories annotated with bounding boxes. This dataset is built for object detection tasks. CC-19 [194] is a new dataset related to the latest family of coronavirus (COVID-19). It contains the Computed Tomography (CT) scan of subjects and is built for image classification. FedTADBench [195] offers three different datasets to evaluate time series anomaly detection algorithms. Open Questions and Challenges In this section, we summarize the challenges that ML and FL face. We only present major problems. This is because there is a large number of open problems, and we choose to keep our presentation concise and focused. Challenges for Parallel and Distributed ML The major challenges with parallel and distributed ML are related to performance, fault-tolerance, security and privacy [7, 196, 197] . Typically, in distributed and parallel training, additional resources are used to decrease wallclock time [198] . Such additional resources can be multiple machines, multiple GPUs and highend communication networks. As a result, the decrease in wall-clock time may not compensate for the additional resources or their energy consumption. Therefore, research studies, such as [16] , are needed to investigate this trade-off with different applications and system architectures. Distributed and parallel ML platforms, especially those executed on high-performance computing systems, often consider fault-tolerance as a second-class concern. However, given the sizes of the latest large-scale computing systems, failures are common; not rare [199] . As a result, efficient checkpointing and/or replication solutions [199] are needed to recover from errors and to limit the amount of lost computation due to a failure. Ensuring security and privacy for distributed and parallel ML has consistently been a serious concern [196] . While FL was devised for the privacy of user data, there have been many novel types of attacks [179, 180] . These attacks include adversarial [168] , poisoning, evasion, backdoor, and integrity attacks [180, 197] . As such attacks get sophisticated, so must their defenses. Moreover, the systematic deployment of the defenses to the physical systems as well as the evaluation of these deployments have not studied well [197] . Furthermore, there is a lack of the rigorous efficiency and efficacy studies of attack defense mechanisms. As a result of these issues, security and privacy for ML remain an open problem. Challenges for FL The main challenges in FL are two-fold [200] : explainability and interpretability, and federated GNNs. Explainability and interpretability refer to the understanding of the contributions of the clients or the data features. For instance, Shapley values are proposed [201] to quantify the impact of the features on the model output. Zheng et. al. propose a quantified ranking of features [202] . Similarly, there are studies [203] targeting vertical FL. Several works introduce tailored measures of interpretability such as [204] defining a measure based on the gradients. However, in general, the problem of explainability and interpretability remains open because i) ensuring privacy while building explainable models is not trivial, ii) the aggregation of the local parameters obscures interpretability, iii) there is a lack of datasets that are not composed of images or text, and iv) there is a lack of a general framework for explainable federated models. Research for FL with GNNs [205, 206, 207] has recently started. For instance, FedGraphNN [205] provides an FL benchmark system to evaluate various graph models, algorithms and datasets. Another example is GraphFL [207] which is designed to classify nodes on graphs. However, many questions are still waiting to be solved, such as the protection against malicious attacks, interpretability, lack of modern graph neural frameworks for FL [208] . Conclusions In this work, we provided a review of modern large-scale, parallel and distributed ML: the state-of-the-art algorithms, optimization methods, types of parallelisms, communication topologies, synchronization models, and the existing frameworks. Moreover, we reviewed FL. We discussed various aggregation algorithms in FL. In addition, we reviewed the security and privacy aspects including various types of attacks and defense mechanisms. Moreover, we explored the existing FL frameworks and datasets. We concluded our study with the open research problems and challenges in large-scale distributed ML and FL. The major challenges are typically related to performance, security, privacy, explainability, portability, and fault-tolerance. Fig. 1 :Fig. 2 : 12 Fig. 1: The outline of our review. Fig. 5 : 5 Fig. 5: Data parallelism for a deep neural network. Fig. 6 : 6 Fig. 6: Model parallelism for a deep neural network. Fig. 7 : 7 Fig. 7: Pipeline parallelism for a deep neural network. Fig. 8 : 8 Fig. 8: Different topologies of distributed ML. FL [ 9 ] 9 is a variant of ML where training a model is done by distributed clients that individually train local models. Once local models are trained, all local model parameters are sent to a central server which then calculates the average of the parameters (weights) to compute an average model. This average model is then communicated back to the clients for subsequent local training. FL performs distributed training without sharing private client data. 3 - 3 Global model aggregation and update 2-Local model training and W i upload [131] refers to the case where both the sample and the feature spaces are different. Federated transfer learning transfers features from different feature spaces to the same representation to train a model with the data of different clients. An example is disease diagnosis by many different collaborating countries with multiple hospitals which have different patients (different sample spaces) with different medication tests (different feature spaces). Algorithm 1 7 : 17 i.d). On the other hand, FL assumes noni.i.d because users typically have different data distributions and types. • Distributed learning is performed based on aggregating client data, which is then distributed to different clients for training and inference. Contrarily, FL utilizes decentralized data. The client data is never shared and is never aggregated on a central server. Federated learning: client and server functions 1: i ← isClient or isServer 2: E ← totalEpochs 3: B ← totalN umBatches 4: η ← learningRate 5: w ← initialW eights 6: if i = isClient then function UpdateClientWeight(w,k) 8: 9 : 18 : 918 for batchs b from 1 to B do 10: w ← w -η∇l(w, b) for k in sub batch of K clients do 19: Table 1 : 1 . To speed up the Model simplifications for different ML models. Model Type Techniques Existing Work Kernel-based Models Sampling-based Projection-based [64, 65, 66, 67] Tree-based Models Rule sampling Feature sampling [68, 69, 52] Graph-based Models Sparse graph construction Anchor graph based optimization [70, 71, 72, 73, 74] Deep Neural Network Models Efficient activation functions Filter factorization and grouping [75, 76, 77, 78, 79] Categories Techniques Existing Work [80], [81], [82] Adaptive sampling [83] [84] Mini-batch gradient descent Adaptive learning rates [85] [86] Gradient corrections [87], [88] [89], [90] Coordinate gradient descent Rule sampling Feature sampling [91] [92] [93] [94] [95] [96] [94] [97] [98] Bayesian optimization Sparse graph construction Anchor graph based optimization [99], [100], [101] Table 3 : 3 . Ho et. al. explore the usage of gradient delays for stale synchronous parallel communications. Zheng et. al. [108] on the other hand compute approximate second-order gradients and overlap these computations with the delays to enhance the communication efficiency.Communication optimization approaches. Zhang, Choromanska, and LeCun [109] define an elastic relationship between the local and global model to avoid local minima as gradient transfers are delayed. Different than these studies, McMa- han and Streeter [110] introduce communication optimizations for online learning. Table 3 summarizes these techniques. Table 4 : 4 Comparison of different communication topologies. Topology Complexity Scalability Manageability Single Point Failures Latency Centralized Low Low High Yes Low Hierarchical Medium Medium Medium Yes Medium Fully Distributed High High Low No High Table 5 : 5 Existing distributed learning platforms. Frameworks Pros Cons Parallelism Most popular. Strong support by Google. Efficient and scalable CPU, Tensorflow multi-GPU, Difficult to use API Data, Model mobile implementations. Various training strategies: Multi-worker, Parameter server... PyTorch Dynamic computation graph Automatic differentiation Support of remote procedure calls No support for mobile Data, Model, Pipeline High scalability Support of many languages: MXNet C++, Python, Julia, R Difficult to use API Data Usage of symbolic and imperative programming Horovod Easy to use Supports Tensorflow, Keras, PyTorch, and MXNet Lacks fault tolerance Data Model Pipeline Baidu Commercial ML and DL solutions Limited scalability No support for fault-tolerance Data, Pipeline Dianne Java based development platform No other languages Data, Model CNTK Open-source Efficient and high-performing No longer actively developed Limited mobile support Data, Model Theano Open-source and cross-platform Powerful numerical library Discontinued Data The Microsoft Cognitive Toolkit (CNTK) [124] is open-source software for commercial-grade DL. However, it is no longer actively developed. It supports distributed learning through parallel Stochastic Gradient Descent (SGD) algorithms. CNTK implements the following four parallel SGD algorithms: Data-parallel, block momentum, model averaging, and asynchronous data-parallel SGD. Table 8 : 8 Existing FL platforms. , FedML Machine Learning (ML)In this section, we first overview ML in terms of concepts and goals. Then we review various ML algorithms. Finally, we discuss the existing modern ML frameworks."
}