{
  "title": "A METHOD TO BENCHMARK HIGH-DIMENSIONAL PROCESS DRIFT DETECTION",
  "abstract": "Process curves are multivariate finite time series data coming from manufacturing processes. This paper studies machine learning that detect drifts in process curve datasets. A theoretic framework to synthetically generate process curves in a controlled way is introduced in order to benchmark machine learning algorithms for process drift detection. An evaluation score, called the temporal area under the curve, is introduced, which allows to quantify how well machine learning models unveil curves belonging to drift segments. Finally, a benchmark study comparing popular machine learning approaches on synthetic data generated with the introduced framework is presented that shows that existing algorithms often struggle with datasets containing multiple drift segments.",
  "introduction": "Introduction Manufacturing lines typically consist of processes arranged sequentially, each using techniques like casting, forming, or joining to shape components to their final specifications. Advanced sensor technology enables precise monitoring of key performance indicators, like force, pressure, or temperature, over time. IoT-enabled systems now commonly store the data obtained, called process curves, facilitating analysis across both single components and entire production sequences [1] . Issues like anomalous batches, tool wear, or miscalibrations can degrade performance, often subtly, by causing gradual shifts in process curves. Thus, detecting process drifts is key to keep unplanned downtimes and scrap parts at bay. In high-volume production, this is particularly challenging due to the rapid data generation and complexity of multi-variable curves and hence these settings have been an ideal application for machine learning methods [2, 3, 4, 5, 6, 7, 8] . Although process curves are multivariate time-series, process drift detection should not be confused with drift detection in time series [9] or drifts in profile data [10] (see also Figure 1 )). Typically, statistical drift detection methods from time series analysis are not direct applicable, not alone because process curves are highdimensional objects, but also because of high autocorrelation among their sample axis. As a consequence, deep learning techniques, most prominently dimensionality reduction methods like autoencoders [11, 12, 13, 14, 15] , have become increasingly popular [16] as they allow to first learn a low-dimensional representation of the high-dimensional input and then analyse the learned latent variables with classic statistical tools, like sliding Kolmogorov-Smirnov tests [17] , Hellinger-distance based techniques [18] , or by facilitating the Maximum Mean Discrepancy [19] . For many machine learning applications relevant for manufacturing, estab- lished ways and datasets to benchmark the performance of algorithms exist, like for causal discovery in quality data [20] , anomaly detection in images from optical inspections [21] , or reinforcement learning in continuous control tasks [22] . However, for process drift detection, such a framework is yet missing to the best of our knowledge. This may be due to the following two reasons: The lack of both, publicly available datasets and a suitable evaluation metric. Beside a few publicly released datasets [23, 24, 25] , most of the existing work does not release any data to the public, making it impossible to test other detectors on the same dataset. Often, this is due to privacy issues and fear of leaking information to competitors. In addition, as datasets for process drifts are inherently non identically and identically distributed (iid), any sort of test and train splits introduced significant biases making evaluation of algorithms hard if only one variant of a dataset is available Finally, process drift detection is by definition an unsupervised learning task, but to benchmark detectors, a ground truth is required, labeling precisely when a drift starts and when it ends. This seamlessly leads to the second challenge, namely the missing evaluation metric. As in any machine learning task, the metric depends on the precise application and a trustworthy ground truth. A commonly used metric used in research and practice to measure the statistical performance of a binary classifier, often independent of the application, is the area under the ROC curve [26] -short AUC. However, the usage of the AUC is typically only applicable in settings where data is assumed to be iid, unlike in drift detection. In our work, we want to exactly address these issues by introducing a benchmarking framework for researchers, allowing them to reliably validate their process drift detection algorithms. At a high level, our main contributions are: • We present a simple, yet flexible and effective theoretic framework to generate synthetic process curve datasets including drifts with a validated ground truth (Section 2 and Section 3) which also allows feeding of curves from real processes. • We introduce an evaluation metric called temporal area under the curve (TAUC) in Section 4, which aims to take the temporal context of a detection into account. • We conduct a short benchmark study in Section 5 as a proof of concept for the effectiveness of both, our TAUC metric and our proposed data generation method to measure the predictive power of drift detectors. Our work is based on preliminary results of the first author [27] . In this work, we provide additionally insights into the introduced metric, introduce a variant called soft TAUC and compare it in depth with existing metrics. Moreover, we substantially generalize the data synthetization framework, for instance by allowing higher-order derivatives, and we generate more sophisticated datasets for the benchmark study. We also release the code that helps to generate process curves to benchmark drift detectors, which is freely available under https://  github.com/edgarWolf/driftbench . Its optimization back-end is implemented in Jax [28] allowing a fast GPU-based generation of process curves.",
  "body": "Introduction Manufacturing lines typically consist of processes arranged sequentially, each using techniques like casting, forming, or joining to shape components to their final specifications. Advanced sensor technology enables precise monitoring of key performance indicators, like force, pressure, or temperature, over time. IoT-enabled systems now commonly store the data obtained, called process curves, facilitating analysis across both single components and entire production sequences [1] . Issues like anomalous batches, tool wear, or miscalibrations can degrade performance, often subtly, by causing gradual shifts in process curves. Thus, detecting process drifts is key to keep unplanned downtimes and scrap parts at bay. In high-volume production, this is particularly challenging due to the rapid data generation and complexity of multi-variable curves and hence these settings have been an ideal application for machine learning methods [2, 3, 4, 5, 6, 7, 8] . Although process curves are multivariate time-series, process drift detection should not be confused with drift detection in time series [9] or drifts in profile data [10] (see also Figure 1 )). Typically, statistical drift detection methods from time series analysis are not direct applicable, not alone because process curves are highdimensional objects, but also because of high autocorrelation among their sample axis. As a consequence, deep learning techniques, most prominently dimensionality reduction methods like autoencoders [11, 12, 13, 14, 15] , have become increasingly popular [16] as they allow to first learn a low-dimensional representation of the high-dimensional input and then analyse the learned latent variables with classic statistical tools, like sliding Kolmogorov-Smirnov tests [17] , Hellinger-distance based techniques [18] , or by facilitating the Maximum Mean Discrepancy [19] . For many machine learning applications relevant for manufacturing, estab- lished ways and datasets to benchmark the performance of algorithms exist, like for causal discovery in quality data [20] , anomaly detection in images from optical inspections [21] , or reinforcement learning in continuous control tasks [22] . However, for process drift detection, such a framework is yet missing to the best of our knowledge. This may be due to the following two reasons: The lack of both, publicly available datasets and a suitable evaluation metric. Beside a few publicly released datasets [23, 24, 25] , most of the existing work does not release any data to the public, making it impossible to test other detectors on the same dataset. Often, this is due to privacy issues and fear of leaking information to competitors. In addition, as datasets for process drifts are inherently non identically and identically distributed (iid), any sort of test and train splits introduced significant biases making evaluation of algorithms hard if only one variant of a dataset is available Finally, process drift detection is by definition an unsupervised learning task, but to benchmark detectors, a ground truth is required, labeling precisely when a drift starts and when it ends. This seamlessly leads to the second challenge, namely the missing evaluation metric. As in any machine learning task, the metric depends on the precise application and a trustworthy ground truth. A commonly used metric used in research and practice to measure the statistical performance of a binary classifier, often independent of the application, is the area under the ROC curve [26] -short AUC. However, the usage of the AUC is typically only applicable in settings where data is assumed to be iid, unlike in drift detection. In our work, we want to exactly address these issues by introducing a benchmarking framework for researchers, allowing them to reliably validate their process drift detection algorithms. At a high level, our main contributions are: • We present a simple, yet flexible and effective theoretic framework to generate synthetic process curve datasets including drifts with a validated ground truth (Section 2 and Section 3) which also allows feeding of curves from real processes. • We introduce an evaluation metric called temporal area under the curve (TAUC) in Section 4, which aims to take the temporal context of a detection into account. • We conduct a short benchmark study in Section 5 as a proof of concept for the effectiveness of both, our TAUC metric and our proposed data generation method to measure the predictive power of drift detectors. Our work is based on preliminary results of the first author [27] . In this work, we provide additionally insights into the introduced metric, introduce a variant called soft TAUC and compare it in depth with existing metrics. Moreover, we substantially generalize the data synthetization framework, for instance by allowing higher-order derivatives, and we generate more sophisticated datasets for the benchmark study. We also release the code that helps to generate process curves to benchmark drift detectors, which is freely available under https://  github.com/edgarWolf/driftbench . Its optimization back-end is implemented in Jax [28] allowing a fast GPU-based generation of process curves. Statistical framework to model process drifts In this section, we formalize what we consider as process curves and drifts within. Generally speaking, process curve datasets are datasets consisting of finitely many multivariate time series each having finitely many steps. We formally model a process curve as a finite time-series (Y (x)) x∈I with Y (x) ∈ R c , I ⊂ R a finite set, and where Y : R → R c represent physical properties of the process to be measured and x an independent variable, often the time. In staking processes, for instance, Y is the measured force and x the walked path of the press (compare also [20, Figure 9] ). Another example are pneumatic test stations, where Y might be a pressure measured over time x. In bolt fastening processes, Y represents the torque measured over the angle x [8] . We call the number of variables c ∈ N in the curve the dimension of the process curve and write [T ] for the set {1, . . . , T } and often refer to it as temporal axis. Whenever a manufacturing process finishes its work on a component, a process curve is yielded. Thus, when the same process is executed on multiple times sequentially, a long sequence C 1 , C 2 , . . . , C t , . . . , C T with T ∈ N of process curves is obtained where each C t arises under slightly different physical conditions Y 1 , . . . , Y T , i.e., C t = (Y t (x + ϵ x ) + ϵ y ) x∈It , where ϵ x and ϵ y represents measurement noise or inaccuracies. In theory, also the sets I t can vary for each t ∈ [T ], for instance due to different offsets. Wearout or tool degradation affects the process curves gradually and to model their deformation along the execution axis, we assume that there exists functions f : R k × R → R c and w : [T ] → R k such that for all t ∈ [T ] and x ∈ I t : (2.1) f (w(t), x) = Y t (x) where the function f is a proxy for the physics underneath the process. The vector w(t) ∈ R k represents environmental properties of the t-th execution, and some of its coordinates correspond to component properties, some to properties of the machine. Without restricting generality and to keep notation simple, we will assume for the remainder that c = 1, as the multivariate case is a straight-forward application of our approach by modeling each variable in Y individually (see also Remark 3.1). Assuming only component variance and no tool degradation, we could assume that w(t) is sampled in each process execution from a fixed but unknown distribution on R k , like w(t) ∼ N µ,σ with fixed µ ∈ R k and σ ∈ R k×k for all t ∈ [T ]. As mentioned, tool degradation, in contrast, affects the process from execution to execution, i.e., the parameters of the distribution shift over time leading to a deformation of the observed process curve. Such process drifts should not be confused with concept drifts, where the goal is typically to analyse the declining performance of a trained machine learning model when new data starts to differ from the train data [29] . Moreover, detecting drifts in process curves is different to detecting drift in profile data [10] , where one typically is interested in drifts among the curves yielded by a single execution, not in drifts over multiple executions. A similar application is the identification of drifts within profile data, where typically one process execution yields a sequence of process curves of fixed size, like in spectroscopy when one curve is some intensity over time which is measured for different wavelengths [30] . One way to model process drifts is to model the evolution of the latent parameters w(t), like using a dynamical system. For instance, in control theory [31] , w(t) is considered as latent state of a system which evolves over the executions t and one observes a multivariate output Y (t) ∈ R |It| with Y (t) = Y t (I t ). Introducing a control vector u(t) ∈ R p , w(t) can be considered as state variable w(t) of the system that evolves over time and is influenced by a control vector u(t) ∈ R p such that ∂ t w(t) = h(w(t), u(t), t) and Y (t) = f (w(t)) holds for all t ∈ N. Here, however, one has to precisely model how the state w changes over executions and how it is affected by interventions u and has to solve challenging non-linear differential equations. However, as we will argue, the degradation of the curve can be described directly in curve space in many scenarios. Thus, we directly model the transformation of the process curves in curve space by letting certain support points of the curve move in a controlled way: Definition 2.1 (Support points). Let f : R k × R → R be an i-times differentiable function, i ∈ N, and ∂ i x f be the i-th derivative of f according to the second argument. Let x, y ∈ R n , then (x, y) is a support point of i-th order for f at w ∈ R k if ∂ i x f (w, x j ) = y j for all j ∈ [n]. Support points can be considered as points surpassed by the graph of f (w, •) : R → R (see visualization on the left in Figure 3 ). Typically, such support points are physically motivated and if latent properties of the process change, certain support points change their position in curve space. For instance, in a staking process, the position x(t) and value y(t) of the maximal force, i.e., where the first derivative is zero, starts shifting (see Figure 2 ). That is, we can describe this behavior by modelling the support points (x(t), y(t)) and (x(t), 0) of first and second order respectively, i.e. f (w(t), x(t)) = y(t) and ∂ 1 x f (w(t), x(t)) = 0. We formalize in Section 3 how we can use this to generate process curves and drifts synthetically. Data generation Let f : R k × R → R be as in Section 2 a proxy for the physical relations for given manufacturing process. In this section, we build our synthetization framwork upon the setup introduced in Section 2. Here, we neither focus on how w(t) behaves in latent space, nor on how f is formulated exactly. Instead of modeling the evolution of w(t) with a dynamic system, our idea is to model the behavior of support points over process executions in curve space and to seek for parameters w(t) using non-linear optimization satisfying the support point conditions from Definition 2.1. For the remainder of this section, we explain how w(t) can be computed given the support points. Thus, assume we have for each process execution Instead of modelling w(t) explicitly, we compute w(t) implicitly such that (3.1) is satisfied. For instance, if f is l + 2-times differentiable in its second argument and if ∂ 2 w ∂ i x f exists, we can solve (3.1) individually for all t ∈ [T ] using second-order quasi-Newton methods [32, Chapter 3] for the objective function t ∈ [T ] support points (x 1 (t), y 1 (t)), . . . (x l (t), y l (t)) with with x i (t), y i (t) ∈ R n i , that is, (3.1) ∂ i x f (w(t), x i j (t)) = y i j (t) ∀j ∈ [n i ]. (3.2) w(t) = arg min w∈R k l i=1 n i j=1 D i • ∂ i x f (w, x i j (t)) -y i j (t) where D 1 , . . . , D l are constants to account for the different value ranges of the functions ∂ i x f . By solving Thus, solving (3.2) for each t ∈ [T ], we obtain a sequence w(1), . . . , w(T ) ∈ R k and consequently, we get a sequence of functions f (w(1), •), . . . , f (w(t), •). Now, these functions can be evaluated on arbitrarily sets I t ⊂ R whose point not necessarily need to be equidistant. Setting C t = f (w(t), I t )+ϵ y ∈ R |It| , we finally obtain a sequence of process curves C 1 , . . . , C T . A compact overview of the data generation method is shown in Algorithm 1. Algorithm 1 Generation of process curves Input: f : R k × R → R, x i (1), y i (1), . . . x i (T ), y i (T ) ∈ R n i , i ∈ [l], x ∈ R, ∆x ∈ R >0 , m ∈ N. Output: Process curves C 1 , . . . , C T . 1: for t ∈ [T ] do 2: Compute solution w(t) for (3.2) using support points (x 1 (t), y 1 (t)), . . . , (x l (t), x l (t)) 3: I t ← {x + j • ∆x + ϵ x : j ∈ [m]} 4: C t ← f (w(t), I t ) + ϵ y 5: end for 6: return C 1 , . . . , C T x i j (t) j-th support point for ∂ i x f with j ∈ [n i ] i-th derivative of f with i ∈ [l] t-th process execution with t ∈ [T ] Fig. 4 . Short overview of our notation. Its left to show how to generate the support points as input for Algorithm 1. One way is to use support points of a real process curve dataset, and using Algorithm 1 to create semisynthetic copy of it. In a fully synthetic setting, the support points at execution t ∈ [T ], the support points (x i (t), y i (t)) can be sampled from a distribution on R n i respectively, whose statistical properties change over the temporal axis. For instance, y i (t) ∼ N µ i (t),σ with µ i : [T ] → R n i encoding the drift behavior over the temporal axis for the support points. Another free parameter of Algorithm 1 is the function f to use. In principle, f can be chosen from any parametrized function set, like B-splines, Gaussian processes [33] , neural networks [34] , or Kolmogorov-Arnold networks [35] . In Appendix B, we showcase in depth an example where f is a polynomial. Remark 3.1 (Multivariate data). Our theoretic framework extends naturally to multivariate time series data, where each dimension d ∈ [c] (or signal) has its own function f d . If they do not share their latent information w d (t), then Algorithm 1 can be executed for each dimension individually. If they share some latent information, then (3.2) can be extended by summing all support point conditions for all f 1 , . . . , f c . Remark 3.2 (Profile data). Our theoretic framework is also capable to generate profile data with drifts holding both, drifts within a profile and drifts over executions. This can be obtained, for instance, by describing how the support points should behave in each profile and for subsequent profiles. The temporal area under the curve Different usecases require different performance metrics to evaluate algorithms. In classification, for instance, sometimes avoiding false positives is, sometimes avoiding false negatives. However, when it comes to general benchmarking classifiers somewhat independently of their precise application in the sense to see how well their response correlates to the actual class label, the AUC [26] is frequently used. However, the vanilla AUC takes samples independently of their temporal context, that is, independent of samples from the previous and next process execution. Thus, we construct in this section a more suitable metric to measure the predictive power of machine learning models for process drift detection. In order to do so, we first formalize what we understand as a process drift and which assumptions we require. Let C 1 , . . . , C T be a sequence of process curves and let D ⊂ [T ] be the set of curve indices belonging to drifts. Our first assumption is that drifts, different from point anomalies, appear sequentially and can be uniquely decomposed into disjoint segments: The drift segments can be considered as a partition of the smallest consecutive drifts which cannot decomposed any further into smaller segments. Now, assume we also have the output s ∈ R T of a detector where each coordinate s t quantifies how likely the curve C t of the it-h process execution belongs to a drift, that is, the higher s t the more likely the detector classifies t ∈ D (see also Figure 5 ). By choosing a threshold τ ∈ R, we can construct a set D(s, τ Definition 4.1 (Drift segments). Let D ⊂ [T ]. Then a series of subsets D 1 , . . . , D k ⊂ D is a partition of drift segments if there exists 1 ≤ l 1 < h 1 < l 2 < h 2 < . . . , < l k < h k ≤ T such that for all i, we have D i = [l i , h i ] and D = ∪ k i=1 D i . ) := {t ∈ [T ] : s t ≥ τ } which serves as a possible candidate for D. Clearly, if τ 1 ≥ τ 2 , then D(s, τ 1 ) ⊆ D(s, τ 2 ). Its also straight-forward to see that for every τ , the set D(s, τ ) decomposes uniquely into drift segments D1 , . . . , Dl as defined in Definition 4.1 and that the length and number of these atomic segments depends on τ . Now, to quantify the predictive power of the detector yielding s, one needs to quantify how close D(s, •) is to D when τ varies. There are many established set-theoretic measurements that are widely used in practice to quantify the distance between two finite and binary sets A and B, like the Jaccard index |A∩B| |A∪B| , the Hamming distance |A \\ B| + |B \\ A|, or the Overlap coefficient |A∩B| min(|A|,|B|) just to name a few. Most metrics, however, have as a build-in assumption that the elements of the set are iid and hence the temporal context is largely ignored making them unsuitable for process drift detection. Moreover, for most detectors we have to select a discrimination threshold τ , making evaluation cumbersome as it requires to tune the threshold on a separate held-out dataset. Moreover, in most practical scenarios, D is only a small subset and thus the evaluation metric has to consider highly imbalanced scenarios as well. Clearly, detectors are required where all true drift segments D i are overlapped by predicted drift segments. For this, let L i := {j ∈ [l] : D i ∩ Dj ̸ = ∅}. Clearly, L i ∩ L i+1 ̸ = ∅ if D i and D i+1 both intersect with a predicted drift segment. Now, the set T i := ∪ j∈L i Dj which is the union of all predictive segments intersecting with D i serves as a candidate for D i . To measure how well D i is covered -or overlapped -by T i we define the soft overlap score inspired by the Overlap coefficient as follows: (4.1) sOLS(D i , s, τ ) := |T i | max(T i ∪ D i ) -min(T i ∪ D i ) + 1 Obviously, an sOLS of 1 is the best possible and this is reached if and only if T i = D i . It is easy to see that for fixed D i , the enlargement of T i beyond the boundaries of D i improves the overlap score, as |T i | increases and one of either max(T i ∪ D i ) ormin(T i ∪ D i ) increases as well. A special case is if D i is completely covered by T i , i.e. D i ⊆ T i , then it follows that T i is an interval as well and thus sOLS(D i , s, τ ) = 1. When T i enlarges, then the number of false positives, i. into account. To also take false negatives into account, the enumerator in (4.2) could be changed as follows, yielding our final definition of the overlap score: (4.2) OLS(D i , s, τ ) := |T i ∩ D i | max(T i ∪ D i ) -min(T i ∪ D i ) + 1 . Algorithm 2 illustrates in detail how the Overlap score OLS(D, s, τ ) can be computed algorithmically. Our score considers both, the OLS and the FPR, which mutually influence each Algorithm 2 Overlap score OLS(D, s, τ ) Input: D ⊂ [T ], s ∈ R T , τ ∈ R . Output: Overlap score . 1: D 1 , . . . , D k ← find drift segments of D 2: D1 , . . . , Dl ← find drift segments of D(s, τ ) 3: o ← 0 ∈ R k 4: for i ∈ [k] do 5: L i ← {j ∈ [l] : Dj ∩ D i ̸ = ∅} ▷ All predicted drift segments overlapping with D i 6: T i ← ∪ j∈L i Dj ▷ Union of all segments intersecting with D i 7: o i ← |T i ∩D i | max(T i ∪D i )-min(T i ∪D i )+1 ▷ fraction of overlap 8: end for 9: return 1 k k i=1 o i other. In the computation of the AUC, any threshold τ from [min t (s t ), max t (s t )] yields a pair of false positive rate FPR(D, s, τ ) and true positive rate TPR(D, s, τ ) which can be drawn as a curve in the space where FPR is on the x-axis and TPR on the y-axis. Similarly, we define the temporal area under the curve, or just TAUC, as the area under the FPR-OLS curve while the discrimination threshold τ varies. We refer to the soft TAUC, or just sTAUC, to the area under the FPR-sOLS curve (see Figure 7 ). Note that the integral of the curve can be computed using two different methods, the step rule and the trapezoidal rule and depending on which method is used, the value of the score may differ. We showcase this behavior in detail for trivial detectors in Appendix D. In Appendix C, we investigate in several synthetic cases in depth the differences and similarities between sTAUC, TAUC, and AUC. Experiments Next, we benchmark existing algorithms on data generated with our framework driftbench and reporting the TAUC. All datasets and algorithms used are available in the repository of driftbench. The goal of the benchmark is to provide a proof of concept for our score and data generation method, not to be very comprehensive on the model side. Thus, based on our literature research in Section 1 we have hand-selected a small set of typically used model patterns drift detectors used in practice consists of (see Section 5.1). The basic evaluation loop follows a typical situation from manufacturing, where process engineers have to identify time periods within a larger curve datasets where the process has drifted. Thus, all models consume as input a process curve dataset C 1 , . . . , C T and do not have access to the ground truth D, which is the set of curves belonging to a drift (see Section 5.3). Afterwards, each model predicts for each curve C t from this dataset a score s t ∈ R, and afterwards, the TAUC, sTAUC, and AUC are computed for s = (s 1 , . . . , s T ). To account for robustness, we generate each dataset of a predefined specification five times for a different random seed each, leading to slightly different datasets of roughly same complexity. All models are trained unsupervised, i.e. without any information of the true drift segments. 5.1. Algorithms. The algorithms used can be decomposed into multiple steps (see also Figure 8 ), but not all algorithms use all steps. First, there are may some features extracted from each curve. Afterwards, a sliding window collects and may aggregate these such that a score is computed. C 1 C 2 . . . C t . . . C T e 1 e 2 . . . e t . . . e T a 1 a 2 . . . a t . . . a T s 1 s 2 . . . s t . . . s T Feature extraction Windowing and aggregation Score computation Fig. 8 . A high-level overview of the elementary tasks of the detectors used. 5.1.1. Feature extraction. In this step, we use autoencoders [11] to compute a k-dimensional representation e t ∈ R k for each high-dimensional process curve C t with k small. The indention behind is to estimate an inverse of the unknown function f and to recover information about the support points used. Moreover, we also apply deterministic aggregations over the xinformation of each curve C t . 5.1.2. Windowing and aggregation. In this step, the algorithms may aggregate the data from the previous step using a fixed window of size m that is applied in a rolling fashion along the process iterations. One aggregation we use is to first compute for each coordinate j ∈ [k] of e t ∈ R k with t ≥ m the rolling mean a t,j = 1 m t i=t-m+1 e i,j . These values can then further be statistically aggregated, like by taking the maximum a t := max{a t,j : j ∈ [k]}. 5.1.3. Score computing. Goal of this step is to compute a threshold which correlates with the ground truth, that is, the larger the higher the possibility of a drift. Here, we may also aggregate previous features in a rolling fashion. The simplest aggregation we use is to compute the euclidean distance of subsequent elements s t = ∥a ta t-1 ∥ 2 which is just the absolute difference if a t and a t-1 are scalars. If a t is a scalar, we also can compute the rolling standard deviation, again over a window of size m, like this: s t = 1 m -1 t j=t-m+1 a j - 1 m t i=t-m+1 a i 2 . Another approach follows a probabilistic path by testing if a set of subsequent datapoints {a t-m+1 , . . . , a t } come from the same distribution as a given reference set. In our study, we use a windowed version [17] of the popular Kolmogorov-Smirnov test [36] , often called KSWIN, which makes no assumption of the underlying data distribution. However, this can only be applied when a t is a scalar. More particularly, we define two window sizes, m r for the reference data and m o for the observation. The windows are offset by constant δ > 0. We then invoke the KS-test and receive a p-value p t , which is small if the datasets come from different distributions. Thus, one way to derive a final score is to compute s t = log(1 + 1 pt ). Another probabilistic method we use in our study based on a multivariate statistical test is the Maximum Mean Discrepancy (MMD) [19] . This method uses feature mappings based on kernels, and calculates the distance between the means in these mappings. MMD also makes no assumption about the underlying distribution, and works on multidimensional data. We use this method in the same way using two windows as described in the KS-test. We also evaluate algorithms that derive their score based on a similarity search within {a 1 , . . . , a t }. Here, we use clustering algorithms, like the popular k-means algorithm, and use the euclidean distance to the computed cluster center of a t as s t . Another way is to fit a probability density function on s t , like a mixture of Gaussian distributions, and to set s t as the log likelihood of a t within this model. Algorithm Overview. Here is a short summary of the algorithms used in our benchmark study: • RollingMeanDifference(m r ) First, the rolling mean over a window of size m r is computed over all values for the respective curves in the window. Afterwards, the maximum value for each curve is taken and the absolute difference between two consecutive maximum values is computed. • RollingMeanStandardDeviation(m r ) First, the rolling mean over a window of size m r is computed over all values for the respective curves in the window. We also choose the maximum value of these computed values per curve. Then, we compute the standard deviation using the same window for this one-dimensional input. • SlidingKSWIN(m r , m o , δ): We compute the mean value for each curve and apply a sliding KS-test on this aggregated data. We use two windows of size m r and m o where the windows are offset by δ. • Cluster(n c ): A cluster algorithm performed on the raw curves using n c clusters where score is distance to the closest cluster center. • AE(k)-mean-KS(m r , m o , δ): First, an autoencoder is applied extracting computing k many latent dimensions. Afterwards, the mean across all k latent dimensions is computed. Finally, a sliding KS-test is applied with two windows of sizes m r and m o , where the windows are offset by δ. • AE(k)-MMD(m r , m o , δ): First, an autoencoder is applied extracting computing k many latent dimensions. Afterwards, a k-dimensional sliding MMD-test is applied with two windows of sizes m r and m o , where the windows are offset by δ. of staking processes (see also [20, A.1] ) where we used f (w, x) = 7 i=0 w i • x i as function to generate them. The dataset-2 consists of T = 10.000 curves, each called on |I] = 100 equidistant values between [0, 4], i.e., x = 0 and ∆x = 0.04. On the other hand, dataset-3 consists of T = 30.000 curves each having |I| = 400 values between [0, 4]. Both datasets have drifts that concern a movement of the global maximum together with drifts where only information of first order changes over time. In the generation process of dataset-1, we used f (w, x) = w 0 • x • sin(π • xw 1 ) + w 2 • x and generated T = 10.000 many curves, each having |I| = 100 datapoints. It only holds a single drift, where the global minimum at drifts consistently over a small period of time along the x-axis. In all datasets, the relative number of curves belonging to a drift is very small: roughly 1 percent in dataset-1, 2 percent in dataset-2, and 0.1 percent in dataset-3. Particularly, dataset-k has k many drift segments. To generate a drift segment [t 0 , t 1 ] for a given support point where the value should change linearly from a to b (see also Section B), we sampled from normal distributions N µ(t),σ with fixed σ and mean µ(t) =      a, if t < t 0 b • t-t 0 t 1 -t 0 + a, if t 0 ≤ t ≤ t 1 b, if t 1 < t . 5.4. Results. The result of our benchmark study is shown in Figure 10 . Generally, there is a discrepancy in detectors of the highest AUC and the highest TAUC. More concrete, the larger the number of true drift segments in a dataset is, the larger the discrepancy (see also Figure 11 ). For instance, the RandomGuessDetector reached the highest AUC score on dataset-1, where it ranges on all three datasets among the last ranks in the TAUC score. On all datasets, autoencoder-based systems reach among the best detectors for both, TAUC and AUC. Those using a multivariate test in their latent space reach better scores than these using an aggregation of multiple uni-variate tests. Although some cluster-based systems archive good AUC scores on dataset dataset-3, none of the benchmarked algorithms is capable to compute a score that can be used to recover the true drift segments, resulting in small TAUC scores for all algorithms (see also Figure 14 ). The respective predictions over the temporal dimension of the best detectors are shown in Appendix A in more detail, where it also becomes visible that detectors with higher TAUC better recover the true drift segments. Conclusion This work shows how algorithms designed to detect process drifts can be benchmarked in robust and reliable way. We have introduced a scalable and controllable data generation method that creates process curves datasets with drifts and a verified ground truth. In our approach, process curve datasets can be solely generated by modelling the behavior of support points over the temporal axis and using non-linear optimization. We then introduce and study the novel TAUC score which is particularly designed to evaluate the performance of drift detectors on their temporal consistency over sequential process executions. We proved the effectiveness of our approach in a small benchmark study. Our results reveal that existing algorithms often struggle with datasets containing multiple drift segments, underscoring the need for further research. 0.0 0.2 0.4 TAUC AE-MMD (lr=0.0001, num epochs=10) AE-MMD (lr=0.0001, num epochs=100) AE-MMD (lr=0.0001, num epochs=50) AE-mean-KSWIN (lr=0.0001, num epochs=10) AE-mean-KSWIN (lr=0.0001, num epochs=100) AE-mean-KSWIN (lr=0.001, num epochs=50) ClusterDetector (method=gaussian mixture, n centers=10) ClusterDetector (method=gaussian mixture, n centers=5) ClusterDetector (method=kmeans, n centers=10) ClusterDetector (method=kmeans, n centers=5) RandomGuessDetector RollingMeanDifferenceDetector (window size=20) RollingMeanDifferenceDetector (window size=40) RollingMeanStandardDeviationDetector SlidingKSWINDetector 0.25 0.50 0.75 sTAUC dataset-1 dataset-2 dataset-3 0.25 0.50 0.75 AUC 0.50 0.75 AUC 0.2 0.4 TAUC k = 1 (corr=0.74) 0.25 0.50 0.75 AUC 0.0 0.1 0.2 TAUC k = 2 (corr=0.71) 0.25 0.50 0.75 AUC 0.05 0.10 0.15 TAUC k = 3 (corr=0.47)   w i • x i with w ∈ R 6 . We simulate 2000 process executions and thus sample 2000 process curves. The shape of each curve is defined by its support points. We are only interested in its curvature in I = [0, 4]. First, we want to add a condition onto the start and end of the interval, namely that f (w, 0) = 4 and f (w, 4) = 5. Moreover, we would like to have a global maximum at x = 2, which means the first order derivative ∂ 1 x f (w, 2) = 4 i=1 i • w i • 2 i-1 should be zero and its second order derivate ∂ 2 x f (w, 2) = 3 i=1 i • (i -1) • w i • 2 i-2 should be smaller than zero. Here, we want it to be -1. Finally, we want to the curve to be concave at around x = -1. All in all, these conditions result into the following equations, some of them are visualized in Figure 15 : ∂ 0 x f (w, 2) = 7 ∂ 1 x f (w, 2) = 0 ∂ 2 x f (w, 2) = -1 ∂ 0 x f (w, 0) = 4 ∂ 0 x f (w, 4) = 5 ∂ 2 x f (w, 1) = -1 Then, we let the data drift at some particular features. We simulate a scenario, where the peak at x 0 1 and x 1 0 moves from the x-position 2 to 3 during the process executions t = 1000 until t = 1300. Thus, we let x 0 1 and x 1 0 drift from 2 to 3, resulting in a change of position of the peak. We let the corresponding y-values y 0 1 = 7 and y 1 0 = 0 unchanged. Now, we can solve each of the 2000 optimization problems, which results in 2000 sets of coefficients for each process curve, such that the conditions are satisfied. By evaluating f with the retrieved coefficients in our region of interest [0, 4], we get 2000 synthesized process curves with a drift present at our defined drift segment from t = 1000 until t = 1300. 0 250 500 750 1000 1250 1500 1750 2000 Process executions 0 1 2 3 4 x 0 0(t) x 0 1(t) x 0 2(t) t = 1000 t = 1150 t = 1300 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.0 4.5 5.0 5.5 6.0 6.5 7.0 t = 1000 t = 1300 t = 1150 x 0 1 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 x 0 250 500 750 1000 1250 1500 1750 2000 Pr oce ss exe cut ion s 4.0 4.5 5.0 5.5 6.0 6.5 7.0 Y Fig. 16. Visualization of the drift applied on x 0 1 in this example, with respective curves. The left figure shows how the x 0 i values change over time. Only x 0 1 changes, as by our drift definition from the process executions t = 1000 until t = 1300 linearly from 2 to 3, the others remain unchanged. The middle figure shows the respective curves, color-coded to the dots in the left figure. Appendix C. TAUC vs AUC In this section we explore in depth the similarities and differences of the TAUC introduced in Section 4 and the established AUC. This is done along synthetic predictions. C.1. Lagged prediction. The first example we look at is a typical scenario that appears if window-based approaches are used, namely that the prediction lags a bit behind of the true window, but still the detector overlaps a significant proportion of the drift segment (see Figure 17 . Other than the TPR, the sOLS rewards these predictors and thus the sTAUC shows a larger value than the AUC. C.2. Change point detection. Another typical scenario is that a detector shows significantly large values at the start and end of the true drift segment, but sag in between (see Figure 18 ). This could appear when using methods based on detecting change points. In principal, the detector correctly identifies the temporal context of the drift segment, although showing lower scores while the curves drift. Such predictions also score higher values in the sTAUC than the AUC. C.3. Varying length and position of predicted segments. A situation where the sTAUC coincides with the AUC mostly is in when only one true and predicted drift segment exist (see Figure 19 ). In cases where the center of the predicted segment coincides with the center of the true segment, the AUC and sTAUC match almost exactly when the length of the predicted segment is varied (see left graphic in Figure 20 ). If the predicted segment has fixed P denotes the portion of drifts in y and k denotes the number of drift segments in y. In case of the step function, the computed score will always be 0, since the constructed curve only contains one step from [0, 1) with a OLS-value of 0, and only reaches a OLS-value of P k when reaching a FPR of 1 on the x-axis. Hence, the area under this constructed curve is always 0. When using the trapezoidal rule, we linearly interpolate the two obtained trivial points of the curve, thus constructing a line from (0, 0) to (1, P K ). The TAUC is then given by the area under this line, which is equal to P 2k . Now suppose a detector which never indicates a drift, called NeverGuesser. Then we receive (0, 0) as our only point, which does not construct a curve and thus does not have an area under it. Hence, the TAUC for this trivial detection is 0 in both cases.  In order to investigate how the TAUC behaves with an increasing number of segments k in y, we simulate such inputs with a trivial detection and compute the resulting values for the TAUC. We choose an input length of n = 1000. When using the step rule, the TAUC is always 0 as expected, since the only step always retains its area under the curve of 0. But when looking at the obtained TAUC values when using the trapezoidal integration rule, we can clearly see the TAUC decreasing when k increases. This decreasing behaviour can be approximated by 1 2k , since the TAUC for a trivial detection with k segments in case of the trapezoidal rule can be computed with P 2k and 0 < P ≤ 1. Thus, the limit of the TAUC computed with the trapezoidal integration rule with increasing k follows as: lim k→∞ P 2k = 0 0 100 200 300 400 500 k 0.0 0.1 0.2 0.3 0.4 0.5 TAUC TAUC scores 1 2k Fig. 23 . Visualization of the TAUC with the trapezoidal integration rule, when increasing k, alongside an approximation 1 2k . The TAUC gets closer to 0 with increasing k. Fig. 1 . 1 Fig. 1. Overview of different kinds of time series data from manufacturing processes and drifts within. Fig. 2 . 2 Fig.2. Samples from a process curve (left) as well as a sequence of curve samples (right). Fig. 3 . 3 Fig. 3. Visualization of the data synthetization given a function f (w, x) = 5 i=0 w i • x i . Left figure shows f (w, •) solved for concrete x i , y i (red points).Right figure shows sequence f (w 1 , •), . . . , f (w 100 , •) where gaussian noise was added on one coordinate in y 1 (t) (corresponding coordinate x 1 (t) is marked with a dashed line). Fig. 5 . 5 Fig.5. Applying a process drift detector on each process curves yields a score s which needs to be compared to the ground truth D for each threshold τ . 2 D3Fig. 6 . 26 Fig. 6. Temporal arrangements of true and predicted drift segments as input for Algorithm 2. e. the time points t contained in some Di and in the complement D := [T ] \\ D of the ground truth D, enlarges as well. Thus, the predictive power of a detector is shown in the overlap score as well as the created false positive rate FPR(D, s, τ ) := | D(s, τ ) ∩ D| |D| . Example 4 . 2 .Fig. 7 . 427 Fig.7. The TPR, sOLS, and OLS when the FPR varies for the synthetic prediction on the left. 5. 3 .Fig. 9 . 39 Fig. 9. The datasets used in our benchmark study. The true drift segments are marked in green. Lower figures show selected curves, whose color encodes the process iteration t ∈ [T ] -blue marks smaller t values, red larger ones. Recall that dataset-k has k many drift segments. Fig. 10 .Fig. 11 .Figure 12 ,Fig. 12 .Fig. 13 . 1011121213 Fig. 10. Benchmark results on dataset-1, dataset-2, and dataset-3. Fig. 14 . 14 Fig. 14. Best detectors on dataset-3. i=0 Fig. 15 .Fig. 16 . 1516 Fig. 15 . Visualization of some process curves in the example dataset. The red dots indicate support points with first order information given. The green line visualizes the slope at the green dot, encoded by the condition for the first derivative. The purple dashed line indicates the curvature at the corresponding x-value, encoded by the condition for the second derivative. From t = 1000 to t = 1300, the x-value of the maximum moves from 2 to 3. Fig. 17 . 17 Fig. 17 . Prediction of a detector that lags behind the ground truth (left) and its curves underneath the TAUC and AUC (right). Fig. 18 . 18 Fig. 18 . Prediction of a detector that shows high scores at the boundary of the true drift segment only (left) and its curves underneath the TAUC and AUC (right). integration rule =0. 25 Fig. 21 . 21 Fig. 21 . Visualization of a concrete curve used to calculate the TAUC with its TAUC-score. Left figure shows the constructed curve when using the step rule, while the right figure shows the curve when calculating the TAUC using the trapezoidal integration rule. Fig. 22 . 22 Fig. 22. Visualization of the behaviour of the constructed curve for the TAUC on increasing number of segments k. The left figure shows that the TAUC for the computation with the step rule always remains 0. The right figure shows that the area under the line decreases with increasing k, resulting in a lower TAUC value in case of the trapezoidal integration rule."
}