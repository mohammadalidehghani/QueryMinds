<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MACHINE LEARNING IN NETWORK SECURITY USING KNIME ANALYTICS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">MuntherAbualkibash School of Information Security and Applied Computing</orgName>
								<orgName type="department" key="dep2">College of Technology</orgName>
								<orgName type="institution">Eastern Michigan University</orgName>
								<address>
									<settlement>Ypsilanti</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MACHINE LEARNING IN NETWORK SECURITY USING KNIME ANALYTICS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8694E780F83ABBF997401FD87BE2493B</idno>
					<idno type="DOI">10.5121/ijnsa.2019.11501</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Network Security</term>
					<term>KNIME</term>
					<term>NSL-KDD</term>
					<term>and Machine Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine learning has more and more effect on our every day's life. This field keeps growing and expanding into new areas. Machine learning is based on the implementation of artificial intelligence that gives systems the capability to automatically learn and enhance from experiments without being explicitly programmed. Machine Learning algorithms apply mathematical equations to analyze datasets and predict values based on the dataset. In the field of cybersecurity, machine learning algorithms can be utilized to train and analyze the Intrusion Detection Systems (IDSs) on security-related datasets. In this paper, we tested different machine learning algorithms to analyze NSL-KDD dataset using KNIME analytics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>In today's connected world, where billions of people access the internet, anything that depends on the internet for communication, or is connected to a computer or any type of smart device, can be affected by several kinds of cyber attacks. As a result, many organizations, either public or private, have to deal with continuous and complicated different types of cyber attacks and cyber threats. The fact that cyber threats and cyber attacks now permeate every facet of society shows why cybersecurity is crucially important.</p><p>Cybersecurity is the action of securing programs, networks, and systems from any cyberattacks. These cyberattacks are mainly intended at gaining access to, altering, or deleting critical data; stealing money from users; or stopping usual business operations.</p><p>Intrusion Detection System (IDS) is one of the important and dynamic areas to handle cyberattacks.IDS is an implementation or a technique which can detect an attack attempt by analyzing the activity of network or system then IDS will raise the alarm. Any system that can decide for further steps is named Intrusion Prevention System (IPS). The role of IDS is to raise the security level by identifying malicious and suspicious events that could be detected in a computer or network system.</p><p>One of the most popular study areas in intrusion detection is anomaly-based and signature-based detection. Anomaly-based intrusion detection talks about the case of detecting untypical events in the network traffic that do not follow the normal patterns. It is presumed that anything that is untypical or, in another word, anomalous could be critical and to some extent associated with some security events. Signature-based intrusion detection tasks is to detect attacks by looking for specific patterns where these detected patterns are referred to as signatures. <ref type="bibr" target="#b0">[1]</ref> This paper is organized as follows: Section two gives a brief introduction about Intrusion Detection Systems (IDSs). Section three talks about NSL-KDD dataset. Section four summarizes the tested machine learning algorithms. Section five presents the experiments and results. The last section is the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">INTRUSION DETECTION SYSTEMS(IDSS)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Intrusion Detection Systems Categories</head><p>IDSs can be recognized based on two different categories:</p><p> Host-based Intrusion Detection Systems (HIDS): They can scan and watch the system actions on which it has been installed. HIDS might detect any changes in the integrity of files of any file system and analyze log files to look for any malicious or suspicious activity.</p><p> Network-based Intrusion Detection Systems: They focus on scanning and watching the network infrastructure. They analyze the packets flow of the network and examining packets' headers and contents to detect any possible attack on the network.</p><p> As mentioned before, two different actions are applied by both types of IDS to analyze data: Signature-based Intrusion Detection Systems: Such systems can detect known attacks by comparing them with stored patterns, however, it can't recognize new attacks. So the detection will be based on signatures of known attacks as well as any rules determined by a system administrator.  Anomaly-based Intrusion Detection Systems: Such systems can create a model based on normal system activity, and then use the built model to evaluate observed activity to determine if the observed activity is an anomaly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Anomaly Detection Methods</head><p>There are many algorithms and methods from different classes used by researchers to implement anomaly detection in network traffic. Some techniques are implemented based on a statistical point of view where statistics are used to compute and to determine if the observed case is an anomaly <ref type="bibr" target="#b1">[2]</ref>. Other techniques are based on machine learning algorithms that are applied to detect an anomaly.</p><p>Machine learning methods can be classified into three categories:</p><formula xml:id="formula_0"></formula><p>Supervised learning: A training set have labelled examples and an algorithm will match a new observation with just one class.  Unsupervised learning: Training set does not have labels or any details about a possible group in it. In the time of training, the algorithm sets groups and determines its level of similarity.  Semi-supervised learning: Training set has a small amount of labelled example with a large number of unlabelled examples. In other words, semi-supervised learning takes place between supervised learning, where training data is labelled, and unsupervised learning, where training data is not labelled. Algorithms from the first two categories have been implemented in a network anomaly detection problem. It is expected that attacks can be detected since they are abnormal events and will be classified by the algorithm model. Models are used by machine learning algorithms to analyze network traffic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DATASETS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">NLS-KDD Dataset</head><p>Over the last decades, a few datasets have been utilized to examine network anomaly detection systems. The most well-known dataset is KDDcup99. This dataset contains about 4,900,000 samples where 300,000 represent 24 different attack types. Every sample is described by 41 features and labelled as either an attack or normal. However, KDDcup99 has been criticized by many researchers because it has many redundant records and irregularities <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>To fix this problem, a new dataset, NSL-KDD was proposed, that contains selected records of the entireKDDcup99 dataset. The differences between KDDcup99 and NSL-KDD are that the redundant records in NSL-KDD have been deleted from the training set to make sure that the built classifiers are not biased. Also, duplicated records have been excluded to have a better detection rate once applied to some methods. As a result, it is highly recommended to stop using the KDDcup99 dataset and to use the NSL-KDD dataset instead to evaluate machine learning algorithms because it solves the issues in the KDDcup99.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Attacks categories in the NSL-KDD dataset</head><p>There are four attacks categories represented in the NSL-KDD dataset:</p><p>1. A denial-of-Service attack (DoS) is an attack intended to freeze or powering down a machine or network by forcing it to be unreachable to its legitimate users. DoS attacks achieve this by flooding the target with traffic or transmitting it information that causes a crash. As a result, the DoS attack blocks intended users of the service or resource they looking for.</p><p>2. User to Root Attack (U2R) is an attack where the attacker logs in on the system with a normal user account then make the effort to find any vulnerability in the system and use it to obtain the root or the admin privileges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Remote to Local Attack(R2L</head><p>)is an attack where the attacker sends packets to a targeted machine in which the attacker does not have access to it to expose any vulnerability in the targeted the machines and exploit privileges that only a local user can have on that machine.</p><p>4. Probing Attack is an attack where the attacker scans a targeted machine as a means to find any vulnerability on that machine that can be used to compromise the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MACHINE LEARNING ALGORITHMS</head><p>There are many techniques in IDS are built on machine learning approaches. This paper will go over several machine learning algorithms that have been used in the cybersecurity research area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Decision Trees</head><p>Decision Trees algorithms are one of the used algorithms to solve classification where algorithms sort data into classes, like whether an event is an attack or not. Decision Trees are made up of nodes, branches, and leaves where every node presents as an attribute or feature and every branch present as a rule or decision, and every leaf presents as an outcome. We can look at the decision tree as a series of yes/no questions applied to our data resulting in a predicted class. There are many algorithms derived from the decision tree algorithm. Some of them are ID3, C4.5, J48, etc. The issue with ID3 algorithm is that the information might be overfitted.C4.5 is an enhanced version of ID3 and it handles the overfitting issue. J48is an open-source of C4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Random Forest</head><p>The random forest is a model structured from many decision trees. This model applies two key concepts that yield it the name random:</p><p> Random sampling of training data will be considered when creating trees, where each tree in a random forest learns from a random sample of the training data. The purpose behind training each tree on different samples, even though each tree may have high variance regarding a specific set of the training data, is that the entire forest will have lower variance without increasing the bias. During testing, predictions are formed by taking the predictions averages of each decision tree. These steps of training each learner on various bootstrapped subsets of the training data and then taking the predictions averages are called bagging, that is short for bootstrap aggregating.  Random subsets of features will be considered when dividing nodes in each decision tree. For example, if there are 4 features, at each node in each tree, only 2 random features will be taken into consideration for dividing the node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Naive Bayes</head><p>Naive Bayes is a classifier where the machine learning model is built based on probability to be used in classification using the Bayes theorem. For example, by applying Bayes theorem, we can calculate the probability of an attack to happen when an event has occurred.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Support Vector Machines (SVM)</head><p>Support vector machines are a supervised learning algorithm that can be applied in classification cases. It is usually applied to a small dataset because it takes a long time to process. SVM is built based on the concept of determining a hyperplane that best divides the features into several domains. For example, if we want to create a function (hyperplane) that will identify the two cases, such that whenever a server received so many packets is it going to be classified as an attack or normal? The following are the figures of two scenarios in which the hyperplane are drawn.</p><p>Figure <ref type="figure">3</ref>. SVM will come up with an optimal hyperplane that will classify the different classes</p><p>The points near the hyperplane are called: support vector points and the space between the vectors and the hyperplane are called: margins. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Artificial Neural Network</head><p>Artificial neural networks are one of the widely used algorithms in machine learning. They are brain-inspired systems that are designed to copy the way how humans learn. Neural networks contain input and output layers and also, it can have hidden layers that convert the input into something that the output layer can utilize. In Artificial Neural Network, if more data is used as a training set then it will become more accurate. It is similar when someone keeps doing a task over and over. Over time, that person becomes more efficient as well as makes a small number of mistakes.</p><p>Figure <ref type="figure">5</ref>. A simple neural network with a simple hidden layer</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Gradient Boosted Trees</head><p>The Gradient boosted trees used an ensemble of several trees to make more powerful prediction models for classification by building a series of trees where each tree is trained to try correcting mistakes in the previous tree in the series. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">k-Nearest Neighbor (kNN)</head><p>The k-Nearest-Neighbors algorithm of classification is one of the straight forward algorithms in machine learning. The classification relies on identifying similar data points in the training data then making a prediction based on their classifications. kNN is one of the algorithms that give better results on a small size data-sets that do not have several features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS AND RESULTS</head><p>Using machine learning algorithms in Intrusion Detection System (IDS) is an attracting research area for cyber security researchers around the world <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>. In this research, experiments were made based on classifying NSL-KDD dataset to either normal or attack. NSL-KDD dataset was downloaded from the webpage of the Canadian Institute for Cybersecurity (CIC) that is based at the University of New Brunswick <ref type="bibr" target="#b14">[15]</ref>. Subset files from the NSL-KDD dataset were used: KDDTrain+.arff and KDDTest+.arff.</p><p> KDDTrain+.arff has a dataset that is used for training purposes and the data is labelled as either normal or anomaly. This file is saved in ARFF format.</p><p> KDDTest+.arff has a dataset that is used for testing purposes and the data is labelled as either normal or anomaly. This file is saved in ARFF format.</p><p>The KDDTest+ dataset contains known and new attacks. New attacks are the ones that do not exist in KDDTrain+ dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Data Pre-processing</head><p>Data pre-processing is a crucial step in the journey of making a machine learning model. We have to do some preparation to make sure that we build our machine learning models without any issues. If there is no data pre-processing then our machine learning model won't work properly.</p><p>In any dataset, we need to distinguish something very important which is the difference between the independent variables and the dependent variables. In any machine learning algorithm or any model, independent variables are used to predict a dependent variable e.g., normal or anomaly. Also, we have to deal with cases where we have some missing data in the dataset. The most common idea to handle missing data in a column is to take the mean of that column. In other words, the mean of all the values in a column will replace the missing data in that column.</p><p>Furthermore, sometimes in the dataset, there will be a kind of variables that are called categorical variables because simply they contain categories. Since machine learning models are based on mathematical equations, therefore this would cause some problem if we keep the categorical variables, e.g., text, in the equations because we would only want numbers in the equations. As a result, we need to encode the categorical variables into numbers.</p><p>The next step features scaling, which is very important in machine learning when variables are not on the same scale, this will cause some issues in some machine learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Classification</head><p>Tables <ref type="table" target="#tab_2">1</ref> and <ref type="table">2</ref> show the results of applying different classification algorithms using KNIME to analyze the NSL-KDD dataset. KNIME is an open-source data analytics. It has a shapely graphical user interface that is easy to use and understand.</p><p>We tested several KNIME's machine learning algorithms using two different approaches: In the first approach, the KDDTrain+ has partitioned to 70% training set and 30% testing set so each algorithm is trained on the 70% portion and tested on the 30% portion.</p><p>In the second approach, each algorithm is trained using the entire KDDTrain+ and tested using the KDDTest+ dataset. The KDDTest+ dataset contains known and new attacks. New attacks are the ones that do not exist in KDDTrain+ dataset.</p><p>The tested machine learning algorithms will generate alerts that can be categorized as follows.</p><p> True positive which means an attack is predicted as an attack.  False-positive which means a normal network packet is predicted as an attack.  True negative which means a normal network packet is predicted as normal.</p><p> False-negative which means an attack is predicted as normal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Results</head><p>When KDDTrain+ is partitioned to 70% training set and 30% testing set and the 30% portion dataset is used for testing the algorithms, it has been noticed that the majority of the tested algorithms achieved a very high accuracy as shown in Table <ref type="table" target="#tab_2">1</ref>.</p><p>However, when KDDTest+ dataset is used, which contains both old and new attacks, a sudden decrease in the accuracy has been noticed on all the tested algorithms. The best accuracy achieved is 79% with Naive Bayes then 78% with Probabilistic Neural Network and Gradient Boost Tree algorithms. The result obviously shows that some of the tested machine learning algorithms are useful for detecting attacks on which they are trained but performs poorly on new attacks as shown in Table <ref type="table">2</ref>.  Figure 12. KNIME workflow using PNN Learner where KDDTrain+ Dataset is partitioned to 70% training set and 30% testing set Figure 13. KNIME workflow using Gradient Boosted Trees Learner where KDDTrain+ Dataset is partitioned to 70% training set and 30% testing set Figure 15. KNIME workflow using Decision Tree Learner on KDDTest+ Dataset Figure 16. KNIME workflow using Random Forest Learner on KDDTest+ Dataset </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>In this paper, different KNIME's machine learning algorithms that can be used in intrusion detection systems (IDSs) have been tested to analyze the NSL-KDD dataset. Also, an accuracy comparison of these algorithms is given. Every algorithm has its features that have a significant role in enhancing IDSs when compared to other algorithms. The results indicate that almost most of the tested machine learning algorithms used in this paper show excellent performance on detecting attacks using a dataset on which they are trained. However, the performance of the algorithms goes down when the testing dataset includes new attacks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Decision Trees of two levels.</figDesc><graphic coords="4,186.52,185.49,230.25,123.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Random forests and decision trees</figDesc><graphic coords="4,105.52,561.11,393.00,153.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Support vector points andmargins</figDesc><graphic coords="5,176.77,558.71,249.75,154.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Add new models to the ensemble sequentially</figDesc><graphic coords="6,95.40,504.29,413.25,137.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 11 .Figure 12 .</head><label>1112</label><figDesc>Figure 11. KNIME workflow using SVM Learner where KDDTrain+ Dataset is partitioned to 70% training set and 30% testing set</figDesc><graphic coords="10,89.48,482.84,425.10,88.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 14 .</head><label>14</label><figDesc>Figure 14. KNIME workflow using K Nearest Neighbor where KDDTrain+ Dataset is partitioned to 70% training set and 30% testing set</figDesc><graphic coords="11,85.05,187.69,424.75,131.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>The accuracy statistics on KDDTrain+ Dataset that is partitioned to 70% training set and 30% testing set.</figDesc><table><row><cell>Machine</cell><cell>Class</cell><cell>True</cell><cell>False</cell><cell>True</cell><cell>False</cell><cell>Accuracy</cell></row><row><cell>Learning</cell><cell></cell><cell>Positives</cell><cell>Positives</cell><cell>Negatives</cell><cell>Negatives</cell><cell></cell></row><row><cell>Algorithm</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Decision Tree</cell><cell>Attack Normal</cell><cell>17537 20191</cell><cell>30 34</cell><cell>20191 17537</cell><cell>34 30</cell><cell>0.998</cell></row><row><cell>Random Forest</cell><cell>Attack Normal</cell><cell>17532 20201</cell><cell>20 39</cell><cell>20201 17532</cell><cell>39 20</cell><cell>0.998</cell></row><row><cell>Naive Bayes</cell><cell>Attack Normal</cell><cell>18324 14936</cell><cell>2635 1897</cell><cell>14936 18324</cell><cell>1897 2635</cell><cell>0.880</cell></row><row><cell>Support</cell><cell>Attack</cell><cell>16527</cell><cell>655</cell><cell>19566</cell><cell>1044</cell><cell></cell></row><row><cell>Vector Machine</cell><cell>Normal</cell><cell>19566</cell><cell>1044</cell><cell>16527</cell><cell>655</cell><cell>0.955</cell></row><row><cell>(SVM)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Probabilistic</cell><cell>Attack</cell><cell>18467</cell><cell>807</cell><cell>16764</cell><cell>1754</cell><cell></cell></row><row><cell>Neural Network</cell><cell>Normal</cell><cell>16764</cell><cell>1754</cell><cell>18467</cell><cell>807</cell><cell>0.932</cell></row><row><cell>(PNN)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Gradient Boosted Trees</cell><cell>Attack Normal</cell><cell>20183 17514</cell><cell>57 38</cell><cell>17514 20183</cell><cell>38 57</cell><cell>0.997</cell></row><row><cell>K Nearest Neighbor</cell><cell>Attack Normal</cell><cell>20145 17493</cell><cell>78 76</cell><cell>17493 20145</cell><cell>76</cell><cell>0.996</cell></row></table><note><p>Figure 10. KNIME workflow using Naive Bayes Learner where KDDTrain+ Dataset is partitioned to 70% training set and 30% testing set</p></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The following figures show how to use KNIME workflow to build and run different KNIME's machine learning algorithms:  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Intrusion detection systems vulnerability on adversarial examples</title>
		<author>
			<persName><forename type="first">A</forename><surname>Warzyński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kołaczek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 Innovations in Intelligent Systems and Applications (INISTA)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The research of intrusion detection technology based on heuristic analysis. in 2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kehe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jianping</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cost-based modeling for fraud and intrusion detection: results from the JAM project</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Stolfo</surname></persName>
		</author>
		<idno>DISCEX&apos;00. 2000</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings DARPA Information Survivability Conference and Exposition</title>
		<meeting>DARPA Information Survivability Conference and Exposition</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A detailed analysis of the KDD CUP 99 data set</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tavallaee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Survey of Intrusion Detection Models based on NSL-KDD Data Set</title>
		<author>
			<persName><forename type="first">R</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pavithran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 Fifth HCT Information Technology Trends (ITT)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Meena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Choudhary</surname></persName>
		</author>
		<title level="m">A review paper on IDS classification using KDD 99 and NSL KDD dataset in WEKA</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>2017 International Conference on Computer, Communications and Electronics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Analysis of data pre-processing influence on intrusion detection using NSL-KDD dataset</title>
		<author>
			<persName><forename type="first">N</forename><surname>Paulauskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Auskalnis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 Open Conference of Electrical, Electronic and Information Sciences</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Intrusion Detection System Classification Using Different Machine Learning Algorithms On Kdd-99and Nsl-Kdd Datasets -Areview Paper</title>
		<author>
			<persName><forename type="first">Ravipati</forename><surname>Rama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Science &amp; Information Technology (IJCSIT)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Survey on Different Machine Learning Algorithms and Weak Classifiers Based on KDD And NSL-KDD Datasets</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Rama Devi Ravipati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Artificial Intelligence and Applications (IJAIA)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analysis of Intrusion Detection Dataset NSL-KDD Using KNIME Analytics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arafat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Cyber Warfare and Security</title>
		<imprint>
			<publisher>Academic Conferences International Limited</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A study on NSL-KDD dataset for intrusion detection system based on classification algorithms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dhanabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shantharajah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Research in Computer and Communication Engineering</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="446" to="452" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A detailed analysis on NSL-KDD dataset using various machine learning techniques for intrusion detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Revathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Malathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Engineering Research &amp; Technology (IJERT)</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1848" to="1853" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Analysis of KDD dataset attributes-class wise for intrusion detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="842" to="851" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Intrusion detection system by improved preprocessing methods and Naïve Bayes classifier using NSL-KDD 99 Dataset</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Deshmukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ghorpade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Padiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 International Conference on Electronics and Communication Systems (ICECS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Nsl-Kdd</forename><surname>Dataset</surname></persName>
		</author>
		<ptr target="https://www.unb.ca/cic/datasets/nsl.html" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
