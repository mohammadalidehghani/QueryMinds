<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Deep Learning and Machine Learning to Detect Epileptic Seizure with Electroencephalography (EEG) Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Haotian</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lin</forename><surname>Xi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ying</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhixiang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Northeast Yucai Foreign Language School Shenyang</orgName>
								<address>
									<settlement>Liaoning</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Northeast Yucai Foreign Language School Shenyang</orgName>
								<address>
									<settlement>Liaoning</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Engineering Science and Applied Math Northwestern University Evanston</orgName>
								<address>
									<region>IL</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">Shenyang Pharmaceutical University Liaoning</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Deep Learning and Machine Learning to Detect Epileptic Seizure with Electroencephalography (EEG) Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">74CCE88AFF2470FA0BA0EBEE9302D11C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Epileptic Seizure Detection</term>
					<term>Machine Learning</term>
					<term>Deep Learning</term>
					<term>Electroencephalography</term>
					<term>Convolutional Neural Network</term>
					<term>Recurrent Neural Network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The prediction of epileptic seizure has always been extremely challenging in medical domain. However, as the development of computer technology, the application of machine learning introduced new ideas for seizure forecasting. Applying machine learning model onto the predication of epileptic seizure could help us obtain a better result and there have been plenty of scientists who have been doing such works so that there are sufficient medical data provided for researchers to do training of machine learning models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction:</head><p>The prediction of epileptic seizure has always been extremely challenging in medical domain. However, as the development of computer technology, the application of machine learning introduced new ideas for seizure forecasting. Applying machine learning model onto the predication of epileptic seizure could help us obtain a better result and there have been plenty of scientists who have been doing such works so that there are sufficient medical data provided for researchers to do training of machine learning models. In our research, we applied traditional machine learning algorithms, such as Linear SVM, Logistic Regression, KNN (K Nearest Neighbors), and Neural Networks, like CNN (Convolutional Neural Networks), RNN (Recurrent Neural Networks), and LSTM (Long Short-Term Memory), for prediction. The emphasis of our research is to compare the AUC (Area Under the Curve) and accuracy of various models. The research result indicates that machine learning has made epileptic seizure prediction an achievable reality. Although still in testing stage, the method possesses grate reference value. This prediction may help patients to repress epileptic seizure before symptoms can be noticed. Therefore, it allows in time treatment for patients, reduces work pressure for medical workers, and brings more effective control for epileptic. In the future, through the accumulation of data and perfection of hardware, machine learning can be broadly applied in industrial fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works:</head><p>The Electroencephalography (EEG) is a widely used technology for measuring and monitoring human brains' activity. It is a noninvasive electrophysiology monitoring method, which recorded the electrical activity of human brain using the electrode placed along the scalp. Because of the voltage fluctuations caused by ion currents in brain neuronsIt, EEG can measure the activity of cerebral cortex. It is a graphic display of the voltage difference between both sides of brain along time. It represents the ratio measurement of activity. As a result, EEG data shown as a continuous time sequence waveform of extremely tiny voltage signal, always have micro wave amplitude. Although waveform recording is at cerebral cortex, it was influenced by the activity from deep subcortical.</p><p>In the research by Kiral-Kornek et.al <ref type="bibr" target="#b0">[1]</ref>, they use deep learning methods to predict seizure. First they use iEEG data train deep learning classifier to distinguish signals before and after seizure. And then they did the standard testing. Second, as in their paper, "classifier performance was tested on held-out iEEG data from all patients and benchmarked against the performance of a random predictor". Third, they modified the predicting system to adapt each patient's features. Hence, the prediction system was adjusted and tuned so that sensitivity or time in warning could be selected as priority by the patient. The result is this system can provide on time and functional seizure prediction. Also, in the paper by Antoniades, et.al <ref type="bibr" target="#b1">[2]</ref>, they decided to build deep learning model with automatic learning features. In particular, they considered to use CNN as deep learning method. It proved that these deep learning models can automatically learned IED data. The resulting model provided insights for various types of IEDs within the group, and was invariant to time differences between the IEDs. Moreover, the work by Thodoroff et.al <ref type="bibr" target="#b2">[3]</ref> points out that they applied methods with a considerable amount of data. They trained deep neural network with EEG data for predicting the seizure. At the same time, they collected spectral, temporal and spatial information for analysis seizure. Mostly, they focused on the cross-patient study of predicting the seizure. The main advantage of this deep learning model is that can generalize from patient to patient very well.</p><p>From these previous studies we can see applying machine learning methods on predicting seizure have many benefits; however we still have not found which method is the most effective way or time efficient way of seizure prediction. And that leads to our study during this research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset:</head><p>The dataset for this study is generated from the Epileptic Seizure Recognition Data Set under UCI Machine Learning repository <ref type="bibr" target="#b3">[4]</ref>. The dataset contains 500 patients' 4097 electroencephalograms (EEG) readings over 23.5 seconds. The 4097 data points are reshaped into 23 chunks with each chunk including 178 voltage signals corresponding to the brain activity within one second. Consequently, this multivariate time series dataset has 11500 subjects with each subject having a brain activity label regarding 178 features. 5 kinds of brain activities are seen in the dataset. We randomly select an instance under each category and visualize it in Fig. The detailed description of each activity can be found below. We also denote each class an abbreviation name:</p><p>Seizure: Seizure activity is recorded.</p><p>Tumor Area: Subject is diagnosed with tumor, and the EEG is collected from these epileptic brain areas.</p><p>Health Area: Subject is diagnosed with tumor however the EEG is collected from non-epileptic brain area.</p><p>Eyes Closed: Collected from the healthy subject when the eyes are keeping closed.</p><p>Eyes Open: Collected from the healthy subject when the eyes are keeping open.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pre-processing:</head><p>The dataset was pre-processed in the next step in order to downstream to the classifiers. We first investigate the missing data. As the data source is well organized and the EEG is carefully recorded, no missing data is found. As can be seen from Fig. <ref type="figure" target="#fig_1">1</ref>, the voltage distribution of an EEG reviews inconsistent range among different classes. The lowest point of Seizure is much lower compared with other classes. We standardized the voltage into the</p><formula xml:id="formula_0">interval of [-1,1].</formula><p>Our objective is in two-fold. In one fold, we would like to recognize Seizure from other activities. This is a binary classification task <ref type="bibr" target="#b4">[5]</ref>. We easily unified the labels other than Seizure into a single label. In the other fold, we aimed at validating whether machine learning and deep learning can be used in EEG recordings multi-labels classification. Hence, we kept the original label for this part. We also found that the dataset is balanced, which means each class is one-fifth of the overall. No further imbalanced-against method is needed in the multilabel task. For the binary classification, some techniques were applied to adjust the weights of majority class.</p><p>The entire dataset was stratified split into 8:2, training: testing. We applied different validation methods in machine learning and deep learning, which will be introduced later in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Machine Learning Classifiers:</head><p>We employed 6 machine learning classification methods to build the predictive model. Following classifiers were experimented: 2 linear classifiers: Supply Vector Machine with linear boundary (denoted as LinearSVM) and Logistic Regression (LR); 2 ensemble classifiers: Random Forest (RF) and Gradient Boost Decision Trees (GBDT); 1 probabilistic classifier: Naive Bayes (NB) and K Nearest Neighbors (KNN). 5-fold cross-validation was preformed to avoid over-fitting and tune parameters. There is almost no training time due to its principle. Euclidean distance was used to determine the neighbors <ref type="bibr" target="#b5">[6]</ref>.</p><p>Logistic Regression: Logistic regression is a type of generalized linear model <ref type="bibr" target="#b6">[7]</ref>. In logistic regression, the model is always trying to find a hyperplane to distinguish positive instance from negative. We applied L2-regularization to avoid over-fitting. One-versus-All scheme was used in the multi-labels classification. Weights of majority class were adjusted to compensate the imbalance.</p><p>LinearSVM: An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible <ref type="bibr" target="#b7">[8]</ref>. L2-regularization, One-versus-All were also applied. As there is nonprobabilistic, we converted the distance to decision boundary to form a probabilistic output.</p><p>Random Forest: A random forest consists of multiple decision trees, which bootstrap from subset randomly sampled entire dataset, to reduce the probability of over-fitting. We also limited the feature amounts under the square root of the complete set. Given that random forest classifier has many parameters to tune, we only tune two mainly factors: amount of estimators and max depth of each tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gradient Boosting Decision Tree:</head><p>Gradient Boosting is another method to ensemble decision trees. GBDT focus on using gradient optimization to reduce the error of previous generated parameters. Compared with random forest, GBDT is expected to have faster speed as it usually builds trees with smaller depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Deep Learning Neural Networks:</head><p>Recently, deep learning neural network such as convolutional neural network (CNN), recurrent neural network (RNN) and etc. show promising performance on one dimensional classification or prediction, such as speech recognition, stock price prediction. Therefore, we considered that using deep learning architecture to classify EEG recording. In this part, we will introduce 3 neural networks we deployed. As mentioned above, 20% has been set to be the held-out test set. We further stratified split training set into 8:2, to form a validation set.</p><p>As our objective is to validate that deep learning can be useful in the EEG prediction, instead of pursuing the best model to yield a state-of-the-art result. We didn't make all of our efforts to design the configuration of layers, tune parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convolutional Neural Network: A Convolutional neural network (CNN) is a deep</head><p>learning architecture that has multiple convolutional layers. CNN has been showing extremely promising usage in image classification, signal processing and etc. In the medical area, CNN presents its advantage in the support of decision making such as MRI image classification, drug relation detection. Other than the previous mentioned work, our input data is in 1-Dimension instead of 2 or 3-Dimensions. Although, recurrent neural network has a more common use in the 1-D classification task such as speech recognition, we explored whether a well-designed CNN is useful in seizure prediction with EEG. The architecture of our CNN is shown in Fig. <ref type="figure" target="#fig_2">2</ref>. Input data, which is a 178-feature 1-D list, was first fed into the convolutional layer. Then, we used max pooling to select the most important features, followed by the second convolutional layers with more kernels. Another max-pooling layer was used after the second convolutional layer. Then 4 fully-connected layers were used to learn the non-linear combinations of previous layers <ref type="bibr" target="#b8">[9]</ref>. 8 kernels were employed in the first convolutional layer, while we used 16 kernels in the second one <ref type="bibr" target="#b9">[10]</ref>. Kernel size and batch size were tuned to yield a more competitive result. Recurrent Neural Network: Recurrent Neural Network (RNN) is widely used in the classification or prediction with sequential data, such as stock price prediction and speech recognition. The strength of RNN is that it can 'memorize' the 'history' of sequential data and make accurate prediction. However, standard RNN network has drawback at vanishing gradient and incapable of memorizing long-distance input. Gated Recurrent Unit (GRU) and Long-Short Term Memory Network (LSTM) were designed to address the aforementioned drawback, respectively. In the experiment, we adopted both GRU and LSTM with same architecture. The only difference was how internal neurons were connected. We applied two layers of LSTM/GRU with 32 neurons followed by 2 fully connected layers to give classification results. A drop-out rate of 0.5 was set to avoid over-fitting. Batch size was also 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Evaluation:</head><p>In the binary classification, as the labels are imbalanced, besides accuracy, we adopted area under the receiver operating characteristic (AUC) to evaluate the performance.</p><p>In the multi-label classification, we employed precision on each class and an overall averaged accuracy to estimate our classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Tools:</head><p>Our pipeline was built on Python version 3.6.3. Machine learning classifiers, crossvalidation, data pre-processing, parameters tuning was implemented by Scikit Learn package.</p><p>We designed the architecture of deep neural networks with PyTorch. All experiments were deployed on Google CoLaboratory, which has dual CPU kernels and a GPU to expedite the computation time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1:</head><p>The performance of 6 machine learning classifiers and 3 deep learning networks on multi-label EEG classification. Precision on each label and average accuracy were reported. The best performance on seizure label and average accuracy were highlighted with bold-font. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results and Analysis:</head><p>In this section, we will report and compare the performance of 6 machine learning classifiers and 3 deep learning architectures on the held-out test set according to the evaluation methods mentioned in the previous section. As our experiments were 2-fold, Fig. <ref type="figure" target="#fig_3">3</ref> shows the results of binary classification, Tab. 1 demonstrates multi-label performance.</p><p>We first investigated results of binary classification. All 9 configurations yielded accuracy over 0.8. Except 2 linear methods, LR and linearSVM, all other had a competitive accuracy over 0.90. GBDT yielded the best performance of accuracy: 0.973 and AUC: 0.996, followed by RF's performance of accuracy: 0.965 and AUC 0.995. The ideal performance of these 2 classifiers inspired us that ensemble models of decision trees are a good fit for the seizure recognition. On the contrary, linear classifiers such as LR and linearSVM may not suitable for this task. As there were 11,500 features for one subject, linear models were easy to over-fit. The competitive results of both accuracy and AUC validated machine learning and deep learning models are useful in the seizure recognition.</p><p>We then revealed the performance of multi-label classification. Except, LR, linearSVM and KNN, all other configuration did a good work on distinguishing Seizure from other brain activities. They all yielded a high precision on Seizure of over 0.9. It is reasonable as all these configurations were well-performed in binary classification. Three deep neural networks all yielded an average accuracy over 0.70 while other machine learning classifiers didn't. GBDT had the best performance among machine learning classifiers with precision on Seizure: 0.966 and average accuracy 0.695. Three deep learning configurations had a higher average accuracy but were moderate at seizure recognition. The results demonstrated that if we were planning to recognize Seizure from all other brain activities, GBDT was the best fit. However, if we aimed at EEG classification, deep neural networks were the better candidate classifiers.</p><p>Next, we compared the difference among three deep neural networks. GRU and LSTM outperformed CNN on EEG classification in both seizure precision and average accuracy. It is reasonable as these two recurrent networks are good at handling time series data and could take both long and short memory data into consideration. However, these two recurrent networks were highly time-consuming. CNN spent less than 30 seconds to yielded this result. Although we deployed our configuration on Google Colaboratory with GPU on back-end, both recurrent networks need more than 30 minutes training time. We admitted that the results of our deep networks were biased due to the limitation of computational power.</p><p>We didn't spend enough efforts in parameter tuning and architecture design. While, current results still demonstrated that deep neural networks were better approaches to EEG classification compared with tradition machine learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Limitations and Future Work:</head><p>There are also some limitations in our work that can be improved in the future. First, we aimed at recognizing epileptic seizure in a one-second time range. However, in real study, it has more clinical meaning to identify seizure activity in real-time base. Second, we didn't make abundant efforts in the refinement of neural network. If the deep learning architecture is better designed, a better performance in multi-label classification is expected. Moreover, engineering features are widely involved in the EEG recording interpretation. We are planning to extract more engineering features, such as characteristics in frequency domain. A combination of features in both time and frequency domain can convey more information towards the classifiers. Finally, we plan to enlarge the population of our dataset to yield a more robust, reasonable and reliable result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion:</head><p>Our work demonstrates that machine learning classifiers and deep neural networks are useful in the recognition of Epileptic Seizure from EEG recording. Specifically, 2 ensemble classifiers, random forest and gradient boosting decision trees yield the best performance of both AUC and accuracy over 0.95. Deep neural networks significantly outperformed machine learning classifiers in the multi-label classification of brain activities. Our models showed potential usage in clinical decision making, such as identifying seizure in a timely manner.</p><p>Further study is needed to refine our networks to achieve a state-of-the-art result. A larger dataset is also important to validate the robustness of our models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>K</head><figDesc>Nearest Neighbors: KNN is a very intuitive model. The sample is classified based on the labels of its K nearest neighbors. Another advantage of the model is time efficiency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A demonstration of EEG recordings. An example of each brain activity was randomly selected and visualized. The activities from top to bottom are respectively: Seizure, Tumor Area, Health Area, Eyes Closed and Eyes Open.</figDesc><graphic coords="7,72.00,257.07,451.30,253.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The CNN model. Architecture contained 11500-long 1-D list as input layers, 1-D convolution layers, fullyconnected layers, max-pooling layers and 5 probabilistic results as output layers.</figDesc><graphic coords="8,72.00,361.83,451.30,181.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The performance of 6 machine learning classifiers and 3 deep learning networks on seizure recognition. Height of blue bars represents the accuracy, while yellow represent AUC. Y-axis had a cut-off as all values were over 0.5.</figDesc><graphic coords="9,72.00,284.60,451.30,169.09" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Epileptic seizure prediction using big data and deep learning: toward a mobile system</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kiral-Kornek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nurse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mashford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Karoly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baldassano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grayden</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>EBioMedicine</publisher>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="103" to="111" />
			<pubPlace>Vancouver</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep learning for epileptic intracranial EEG data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Antoniades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Spyrou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Took</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sanei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE 26th International Workshop on Machine Learning for Signal Processing</title>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2016-09">2016. September. 2016</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning robust features using deep learning for automatic seizure detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Thodoroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning for healthcare conference</title>
		<imprint>
			<date type="published" when="2016-12">2016. December</date>
			<biblScope unit="page" from="178" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="https://www.nlm.nih.gov/research/umls/index.html" />
		<title level="m">UMLS: UCI Machine Learning Repository</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Short-term favorable weather conditions are an important control of interannual variability in carbon and water fluxes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Et</forename><surname>Zscheischler</surname></persName>
		</author>
		<idno type="DOI">10.1002/2016JG003503</idno>
		<ptr target="https://doi.org/10.1002/2016JG003503" />
		<imprint>
			<date type="published" when="2016-08-08">2016. August 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Genome-scale cluster analysis of replicated microarrays using shrinkage correlation coefficient</title>
		<author>
			<persName><forename type="first">Jianchao</forename><surname>Yao</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2105-9-288</idno>
		<ptr target="https://doi.org/10.1186/1471-2105-9-288" />
		<imprint>
			<date type="published" when="2019-09-13">accessed September 13, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Logistic regression</title>
		<ptr target="https://en.wikipedia.org/wiki/Logistic_regression" />
	</analytic>
	<monogr>
		<title level="m">en.wikipedia.org</title>
		<imprint>
			<date type="published" when="2019-09-13">accessed September 13, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Support Vector Machine</title>
		<ptr target="https://docs.rapidminer.com/latest/studio/operators/modeling/predictive/support_vector_machines/support_vector_machine.html" />
	</analytic>
	<monogr>
		<title level="m">docs.rapidminer.com</title>
		<imprint>
			<date type="published" when="2019-09-13">accessed September 13, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Science Direct</title>
		<author>
			<persName><forename type="first">Hongyoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><surname>Et</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.nicl.2017.09.010</idno>
		<ptr target="https://doi.org/10.1016/j.nicl.2017.09.010" />
		<imprint>
			<date type="published" when="2019-09-13">accessed September 13, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">ImageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><surname>Et</surname></persName>
		</author>
		<ptr target="https://www.nvidia.cn/content/tesla/pdf/machine-learning/imagenet-classification-with-deep-convolutional-nn.pdf" />
		<imprint>
			<date type="published" when="2019-09-13">accessed September 13, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
