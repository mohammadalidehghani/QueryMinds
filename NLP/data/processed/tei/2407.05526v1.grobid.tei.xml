<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Can Machines Learn the True Probabilities?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-07-08">8 Jul 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jinsook</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Underwood International College</orgName>
								<orgName type="institution" key="instit2">Yonsei Univer- sity</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Underwood International College</orgName>
								<orgName type="institution" key="instit2">Yonsei Univer- sity</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Can Machines Learn the True Probabilities?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-07-08">8 Jul 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">B881CFE2D1449008035F0773BA6AF7BA</idno>
					<idno type="arXiv">arXiv:2407.05526v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>When there exists uncertainty, AI machines are designed to make decisions so as to reach the best expected outcomes. Expectations are based on true facts about the objective environment the machines interact with, and those facts can be encoded into AI models in the form of true objective probability functions. Accordingly, AI models involve probabilistic machine learning in which the probabilities should be objectively interpreted. We prove under some basic assumptions when machines can learn the true objective probabilities, if any, and when machines cannot learn them.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the standard AI model under uncertainty, how to measure the degree of uncertainty matters. This paper is about treating such measures in the form of probabilities. In particular, we focus on the true objective probabilities, if any. There are various probabilistic contexts in which the true objective probabilities matter. For example, causal relations of physical events are widely regarded as objective features of the world. Therefore, when causal relations are to be understood in terms of probabilities mainly due to various regularity issues, a probabilistic causal model should include an objective probability function that measures the true objective values about our world. This paper addresses the question of whether machines can learn the true objective probabilities from the data to perform such probabilistic reasoning. Under some basic assumptions, we prove that machines can learn the true objective probabilities if and only if the probabilities are directly observable by them. Roughly speaking, a true probability is directly observable by a machine when it can calculate the probability by the empirical frequency of a true popula-tion given to it.</p><p>The outline of the proof is as follows. After defining some main concepts, we identify the Success Criterion and the necessary condition for any machine to learn the true objective probabilities. From these conditions, we derive the theorem that learning implies the true guarantee of well-calibration. Roughly speaking, "truly guaranteed wellcalibration" means the following: when a machine collects data according to its subjective forecast along a stochastic path in which the associated events occur, the empirical frequency of the collected data matches the very probabilistic forecast of the machine with the true probability P -one. Now that the machine forecasts must indeed be true when the machine learns the true probabilities, this calibration property can then be understood as a calibration version of the strong law of large numbers without the independence assumption.</p><p>Note that there exist connections here among machine forecasting, well-calibration, and machine learning. While proving our theorems, therefore, we establish connections between the true guarantee of well-calibration and various settings of the real forecasting games between Nature and a machine. In this game, what Nature forecasts are the true objective probabilities, while what the machine forecasts are its own subjective probabilities. The machine loses when Nature deviates from the probabilistic forecasts of the machine. Bridged by the property of truly guaranteed wellcalibration, we then prove whether the machine learns the true probabilities or not under various settings of forecasting games.</p><p>With this proof, we provide the fundamental scope and limit of learning the true probabilities by AI machines. One important implication is that machines can relax the independent assumption among data to learn the true probabilities but cannot relax the assumption of identical distribution such as stationarity or ergodicity along a stochastic path where any associated events occur. Another implication is to show that the problem of computability is directly connected to the problem of complexity in the case of learning the true probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Notations and Definitions</head><p>In this section, we define some main concepts, including "machine learning" and "true objective probability". Adopting terminologies from <ref type="bibr" target="#b21">(Nilsson, 2011)</ref> and <ref type="bibr" target="#b2">(Boolos et al., 2002)</ref>, let us first define a machine as an artifact or device that can effectively calculate or compute any target function if there exist definite and explicit instructions to do so in principle. Since we focus on probability functions in this paper, we particularly mean by "an effectively calculating or computing device" a machine that can in principle assign a probability measure (a value of a probability function) to each state (an argument of the probability function) in a given domain, an event space of a sigma-field.</p><p>Definition 2.1. A function is effectively calculable or computable when there are definite and explicit instructions, following which its functional value can be calculated in principle for any given argument. <ref type="bibr" target="#b2">(Boolos et al. (2002)</ref>)</p><p>Two things merit to be taken into account with Definition 2.1. First, this notion of effective calculation or computation is an ideal one with no practical limits on time, expense, etc., necessary to calculate. Therefore, a proof of the limitation on effective calculation or computation of any function will imply a fundamental limit on computability that cannot be overcome by any practical real machine. Second, as <ref type="bibr" target="#b15">(Kozen, 1997)</ref> points out, this notion is an informal one, something that is supposed to be captured in common by all formalisms such as computation by Turing machines, by the λ -calculus and by the µ -recursive method, etc. Accordingly, once we adopt this notion of effective calculation or computation to define "learning", we can be flexible about which formalism would be encoded as instructions to complete a given learning task. Now, whatever such formalism is, machines can learn only if there exist some instructions followed by them to complete their tasks. So we can prove that it is impossible for machines to learn any target function under certain conditions in the following way: we first suppose that there exist some successful instructions to be encoded into machine programming to learn any given function under the conditions. We then show that this supposition leads to a conclusion that is impossible to satisfy. We thereby conclude that there cannot exist such instructions for the given function and, accordingly, that machines cannot learn it. This is a simple but clear way of proving the impossibility of learning without being committed to any complex procedure of constructing any formalism such as a Turing machine or λ-calculus, etc. Definition 2.2. A machine learns when it succeeds in effectively calculating or computing a target function, if any, after processing possibly infinite amounts of data.</p><p>The phenomenon of learning must be at least computational in its essence when acquired by a machine. We thus adopt the notion of computation to define what learning is in Definition 2.2. Inspired by the ideas of <ref type="bibr" target="#b30">(Turing, 1936)</ref> and <ref type="bibr" target="#b4">(Church, 1936)</ref>, we require that a machine be able to effectively calculate or compute a target function when the machine can learn the function.</p><p>In addition, we add the notion of success to Definition 2.2, which aims to capture the role of "learning" as an epistemic notion, not just a computational one. The epistemic notion of machine learning requires two components: if a machine learns, then (i) it must be indeed correct most of the time and (ii) it must be self-assured to be correct most of the time.</p><p>Learning is the phenomenon of knowledge acquisition. Once something is learned, knowledge about it is acquired. Now, knowledge must be a true representation, and it must be so not just by luck. We thus require that (i) what is effectively calculated or computed by a machine be true and further that it be true most of the time out of infinite opportunities to learn. In addition, if the machine admits errors too many times, say infinitely often, it cannot be said to learn. We thus require also that (ii) the machine be self-assured that what it calculates is correct most of the time. In sum, we provide the following Success Criterion:</p><p>(1) If a machine achieves computational success by learning, what it acquires in the end must be true to our world most of the time, which must be assured to the machine itself.</p><p>If what the machine computes turns out to be wrong or it admits errors repeatedly too often out of infinite opportunities to learn, then its computation cannot be considered successful. Later, we prove that the Success Criterion (1) is sufficient for learning in the case of computing true probabilities by Corollary 4.37. We also clarify there what we mean by "most of the time." Definition 2.3. A true probability is what collectively constitutes a probability space, a triple (Ω, F , p) of random variables S t 's in a joint true probability p of the stochastic process according to which Nature generates a sequence of actual data s t 's and each of these data is realized as such with the very true probability P .</p><p>Consider an enumerable set Ω t of ω i 's called states at time t with t ∈ N. For example, Ω t may be the set {ω s , ω c , ω r } where ω s denotes the state of sunny day, ω c the state of cloudy day and ω r the state of rainy day at date t. Also, consider the set Ω that consists of all the infinite sequences with a representative sequence ω = (S -1 0 (s 0 ), S -1 1 (s 1 ), S -1 2 (s 2 ), . . .). Here, S t (ω i ) is a random variable which has some numerical value s t ∈ ℜ according as which ω i 's are realized at time t in our world. Now, S t comes before S t+1 in time, and thus the sequence of S t 's represents a discrete-time stochastic process. Then Nature generates the actual data set {s 0 , s 1 , s 2 , . . .} with true probability P 's. So the probability function P , if any, becomes true to our world when it corresponds to whatever amounts to the rules according to which the actual data are realized in our world. Broadly speaking, this is in line with the correspondence theory of truth similarly in <ref type="bibr" target="#b29">(Tarski, 1944)</ref>. Remark 2.4. More detailed discussions on Definition 2.3, including examples, are provided in Appendix D. Now that we have defined learning and true probability, let us discuss under what conditions machines can or cannot learn the true probabilities. Before we move on, however, let us briefly mention how we can provide formal conditions for learning even though Definition 2.2 contains informal notions.</p><p>Recall from the second comment on Definition 2.1 that the general notion of computation has not been mathematically defined. This is why the Church-Turing thesis remains as a thesis, not as a theorem, given that it uses the general notion of computation. But the computability of any target function in each specific case can be formally specified by giving some definite and explicit instructions to derive the target function in each case, say by a Turing machine. Likewise, our general notion of machine learning cannot be mathematically defined because Definition 2.2 uses the general notion of computation and the informal notion of success. But this does not prevent us from mathematically analyzing the notion of machine learning on the true probabilities by proving what the necessary and sufficient conditions are to learn them. We can do so by giving some definite and explicit instructions to statistically derive the true probability function by a machine while satisfying the Success Criterion (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Kinds of Probabilities and Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Subjective vs. Objective Probabilities</head><p>Broadly speaking, probabilities can be divided into two kinds, subjective and objective ones. Subjective probability, say Π(A t+1 |ß t ), depends on each person's belief and thus possibly varies from person to person, while objective one, say P (A t+1 |ß t ), does not.</p><p>The standard theory of subjective probability was first developed by Ramsey and then further by De Finetti and Savage. Subjective probability is designed to represent a degree of belief possessed by a subject, say some person or, if possible, a machine. Hence subjective probability represents whatever is in any one's mind upon anything as long as his/her belief system is coherent, and so can be assigned even to what is merely imagined. For example, while arguing for cogito, ergo sum, <ref type="bibr" target="#b8">(Descartes, 2008)</ref> imagined an evil spirit that has devoted all its efforts to deceiving him. Descartes can assign some value of subjective probability to his imagination on the evil spirit in accordance with how likely it is to him that the imagination can be realized in this world, as long as Descartes' belief system remains coherent.</p><p>In contrast, objective probability, if any, is what must be determined by objective features of our world that do not vary from person to person. The best way to understand objective probability is to consider examples. Following <ref type="bibr" target="#b17">(Maher, 2010)</ref>, for example, suppose that a coin has the same face on both sides, that is, two-headed or two-tailed. When this coin is tossed infinitely often, its relative frequency surely converges to 1 or 0. Hence the limiting relative frequency here is either 1 or 0, depending on how our world turns out to be, which is an objective matter, and not on whatever we believe.</p><p>It should be noted that subjective and objective probabilities are conceptually bifurcated in two important ways. First, recall that subjective probability represents an aspect of someone's subjective belief, while objective probability does not. Hence the subjective probability of Descartes' demon is positive as long as it is believed at any degree that it could exist in our world. However, this does not necessarily imply that the true objective probability of Descartes' demon is positive, since it might be the case that such a demon is possible only in one's imagination but impossible in our real world. We will return to this potential bifurcation between subjective and objective probability in Section 4.1.</p><p>Second, there exists an asymmetric relation between subjective and objective probability: although the subjective probability of Descartes' demon does not necessarily bind its objective probability, the converse holds. (e.g. <ref type="bibr" target="#b16">(Lewis, 1980)</ref>) That is, once it is proven/assumed by any agent that the true objective probability of Descartes' demon is, say zero, then its subjective probability of the same agent is bound to this proven/assumed result on the objective probability and thus must be zero as well. From this asymmetric relationship, we derive Lemma 4.23 in Section 4.2.</p><p>Remark 3.1. More detailed discussions on various kinds of probabilities are provided in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">What is Implied by Learning the True Objective</head><p>Probabilities?</p><p>As we pointed out in Section 2, learning is the phenomenon of knowledge acquisition, and knowledge must be at least a true representation. In the case of human beings, the requirement of true representation is expressed as the requirement that (propositional) knowledge be at least a true belief (e.g. <ref type="bibr" target="#b14">(Hintikka, 1962)</ref>, <ref type="bibr" target="#b18">(Moore, 1985)</ref>). What then is the counterpart of such a requirement for machines?</p><p>In general, if a machine achieves computational success at t by learning, what the machine represents by learning must be at least true at that time. Then we denote the true representation of the machine about what is learned by the "true belief" of the machine, a legitimate analogue to the true belief of human beings. It is a belief analogue, for we haven't yet shown that machines have minds or that they have the same kinds of mental representations as human beings. It is nevertheless a legitimate belief analogue, since the computational models of machine intelligence are based on understanding human intelligence. (e.g. <ref type="bibr" target="#b24">(Pearl, 2018)</ref>, <ref type="bibr" target="#b26">(Russell, 1998)</ref>, <ref type="bibr" target="#b31">(Valiant, 1984;</ref><ref type="bibr">2008)</ref>)</p><p>That said, let us discuss the relation between belief and learning on the machine side: the knowledge acquired by machine learning must be at least a true belief. In <ref type="bibr" target="#b14">(Hintikka, 1962)</ref>, the knowledge of a person i refers to the knowledge of that person i on any proposition A. Likewise, machine's learning of the true objective probability P here refers to the knowledge acquired by any machine on the probabilistic proposition A p . If a machine learns the true probability as α, then the probabilistic proposition A p amounts to that the true objective probability P, if any, is what the very machine calculates as α. Here, we convert the nonpropositional learning into propositional learning. Now, just as a person i's knowledge on proposition A must satisfy the necessary condition that the person i's belief in A is true, machine learning of the true probability P must also satisfy the condition that the belief in A p of the machine is true. Note here that such a belief in A p is true when what has been calculated by the machine is indeed equal to the true probability P . Now, this calculated probability function by a machine is nothing more than the subjective probability of the machine. Therefore, the necessary condition for machine learning of true probability P requires a machine to hold a true belief whose truth condition is satisfied when its subjective probability is, in fact, in congruence with the true objective probability P . In short, if a machine learns the true objective probability P , then the subjective probability Π of the machine is actually equal to the true probability P . Remark 3.2. There has been a large literature in logic and economics whose discussion implies when a machine holds a true belief in the probabilistic proposition A p . We provide some literature in Appendix B.</p><p>Therefore, we obtain the following condition:</p><p>The Necessary Condition for any Machine to Learn the True Probability</p><p>(2) If a machine learns the true objective probability</p><formula xml:id="formula_0">P (A t+1 |ß t ), then Π(A t+1 |ß t ) = P (A t+1 |ß t )</formula><p>where Π(A t+1 |ß t ) denotes the subjective probability of the machine at time t.</p><p>We assume, without loss of generality, that the event A t+1 is an elementary event, for simplicity. So the event A t+1 is a singleton, i.e. {ω t+1 }.</p><p>Two things should be noted from (2): first, learning/knowledge is not necessarily equivalent to obtaining true fact that Π(A t+1 |ß t ) = P (A t+1 |ß t ), as the converse of condition (2) does not necessarily hold. Second, if a machine is wrong in calculating the true probability at time t so that Π(A t+1 |ß t ) = P (A t+1 |ß t ), then by modus tollens we can derive from (2) that the machine does not learn it at that time. However, this does not preclude the machine from learning it at any other time. Then what can be said about learnability in general? According to the Success Criterion (1), a machine cannot learn any target function if it is wrong most of the time, except for a few finite cases out of infinite opportunities to learn. But can a machine be said to learn if it is correct infinitely often but also wrong as that often? We give a negative answer to this question by proving theorems in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Can Machines Learn the True</head><p>Probabilities?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Learning the True Probabilities and Calibration</head><p>Let us start with a simple example in which a machine is trying to learn the true probability that it will rain tomorrow. A forecasting system is said to be well-calibrated if it assigns probability, say 30%, to rainy events in a test set whose long-term proportion that actually rains is 30%.</p><p>According to <ref type="bibr" target="#b7">(Dawid, 1982)</ref>, a forecasting machine is selfassured that its fairly arbitrary test set of forecasts is wellcalibrated. This is Theorem 4.1. In addition, we prove in Theorem 4.6 that if the machine learns the true probability, then this machine's forecasting is truly guaranteed to be well-calibrated. Now, let us assume that a machine has its own (not necessarily true in our context) probability distribution Π defined</p><formula xml:id="formula_1">over ß ∞ = ∞ t=0 ß t ,</formula><p>where ß t is denoted by the totality of the true facts up to day t. The probability forecasts Π(A t+1 |ß t ) it makes on day t are for events A t+1 's in ß t+1 and are ß tmeasurable. For each day t we have an arbitrary associated event A t ∈ ß t , say the event of raining on day t. We denote the indicator of A t+1 by Y t+1 = 1 {At+1} , and introduce Ŷt+1 = Π(A t+1 |ß t ), the probabilistic forecast of machines on day t+1. In addition, we introduce the new indicator variables ξ 1 , ξ 2 , . . . , at choice to denote the inclusion of any particular day t in the test set where ξ t = 1 if the day t is included in the test set and ξ t = 0 otherwise. Now, if we set the selection criterion to include any day into the test set as the assessed probability α on day t, then we have the following theorem. Theorem 4.1. Suppose that ξ t is ß t-1 measurable. Then, Π (p k</p><formula xml:id="formula_2">→ α) = 1 when k → ∞,</formula><p>where k: the number of days in the test set</p><formula xml:id="formula_3">p k = ( k t=1 ξ t ) -1 • ( k t=1 ξ t • 1 {At+1} ) ξ t := 1 Ŷt+1 = Π(A t+1 |ß t ) = α 0 Ŷt+1 = Π(A t+1 |ß t ) = α</formula><p>Here, let us use the terms as follows: machine forecasts are self-assured to be well-calibrated when Π (p k → α) = 1, while those are truly guaranteed to be so when P (p k → α) = 1. It should be noted then that even if the forecasting machine is self-assured to be well-calibrated, this does not necessarily imply that its forecasts are truly guaranteed to be well-calibrated. Recall from Section 3.1 that there is a conceptual bifurcation between subjective and objective probability.</p><p>Now, suppose that a machine tries to learn the true probability of a particular event A t+1 . If this machine indeed learns the true probability of the event as α, then the machine should correctly calculate the true probability of the same events repeatedly as α most of the time. Hence, the machine can construct a test set of those associated events A t+1 's whose sequentially correct probabilities are α. Then we can show further from Theorem 4.1 that the test set will be well-calibrated with true probability P -one. This is Theorem 4.6. In short, here "being correct as α" itself serves as what <ref type="bibr" target="#b7">(Dawid, 1982</ref>) calls a selection criterion.</p><p>However, note that if the size of ß t continues to grow as t goes to infinity, then ß t 's might be different for each t. Then P (A t+1 |ß t ) might not stay the same as α even for the same events A t+1 's across infinitely many t's. Now, in order for the correct probability α to work as a selection criterion, it should be that P (A t+1 |ß t ) stays the same as α at least for infinitely many t's even though ß t may vary as time passes. Therefore, we prove Lemma 4.5 from the following three assumptions. The justifications for the three assumptions are provided in Appendix C.</p><p>Assumption 4.2. ß t 's in P (A t+1 |ß t ) are the set of all the true facts up to time t. Assumption 4.3. No further knowledge requirement is imposed on condition ß t . Assumption 4.4. Once a probability of an event type E is established, its associated event tokens E t k 's occur at some infinite subsequence of time t k ' s, so that P (E t k ) does not vanish to zero as t k → ∞. It should be noted from Assumption 4.2 and Assumption 4.3 that if ß t is the set of known facts, the informa-tion on the associated events E t 's in ß t 's may not be independent of one another over time. Once E t has been known in the past at some time t 0 , the same events E t 's are more likely to be known afterwards. Repeatedly accumulated knowledge of the same events reinforces the probability that the very event will be known again in the future. However, this is not necessarily the case with the set of true facts. It will be clear in Lemma 4.5 why this independence condition matters. Lemma 4.5. For any α ∈ ℜ[0, 1], let E t denote the event token at time t ∈ N whose event type E almost surely determines the true probability of an event type A as α. Then, if for some subsequence t k 's, E t k 's are independent across t k 's and P (E t k ) = 0 for any t k , then P (E t i.o) = 1. Now that Lemma 4.5 has been established, P (A t+1 |ß t ) is truly guaranteed to stay as α infinitely often, and thus the machine has infinite opportunities to learn P (A t+1 |ß t ) as α. Theorem 4.6. Let us consider any arbitrary α ∈ ℜ[0, 1]. If a machine learns the true objective probability P (A t+1 |ß t ) as α, then P ( p k → α ) = 1. It should be noted that the notion of learning in Theorem 4.6 is flexible enough to allow for some finitely few potential errors, so that there can exist some t * &lt; ∞ such that P (A t+1 |ß t ) = α ∀t &lt; t * while processing the data to learn. Remark 4.7. More detailed discussions on Theorem 4.6 are provided in Appendix D. 4.2. Can Machines Learn the True Probabilities? Theorem 4.8. It is impossible to obtain a joint distribution for an infinite sequence of events that could have the wellcalibration property with subjective probability 1.</p><p>The basic idea in the proof of Theorem 4.8 starts with constructing a counterexample in which the true probability function P is deviated infinitely often from the subjective probability function Π in such a way that the wellcalibration property does not hold any longer.</p><p>Counterexample 1 Following <ref type="bibr" target="#b23">(Oakes, 1985)</ref>, let P be such as</p><formula xml:id="formula_4">P (A t |ß t-1 ) = f (Π(A t |ß t-1 )), with the func- tion f ([0, 1]) → [0, 1] being defined by f (x) = x + 1 2 (0 ≤ x ≤ 1 2 ), f (x) = 1 -x ( 1 2 &lt; x ≤ 1)</formula><p>for any event A t . Then, under P with P (Y I k = 1) = f (α) where Ŷt = α for a subsequence {t : t = I 1 , I 2 , . . .} and Y I k 's form a Bernoulli sequence, the well-calibration property does not hold.</p><p>Due to this counterexample from <ref type="bibr" target="#b23">(Oakes, 1985)</ref>, the machine forecaster cannot exclude the possibility that its test set may be mis-calibrated, and thus the machine can-not hold its subjective probability Πone of being wellcalibrated. Furthermore, if this artificially-imagined possibility of mis-calibration is a real possibility, then it is derived that no test set large enough can be guaranteed to be well-calibrated with the true probability P -one. Later in this section, we prove that if such an imagined possibility is a real one, then machines cannot learn. Meanwhile, we also prove mathematically how the <ref type="bibr" target="#b23">(Oakes, 1985)</ref> Counterexample paralyzes Dawid's Theorem 4.1, which amounts to the proof of Theorem 4.8. Remark 4.9. More detailed discussion on the Counterexample 1 is provided in Appendix D.</p><p>Lemma 4.10. Suppose that a machine constructs a test set by the assessed probability α. Then E |p ∞ -α| = 0 if and only if P (p k → α) = 1 where the expectation is taken with respect to the true probability P . Here, p ∞ = lim</p><formula xml:id="formula_5">k→∞ p k . Lemma 4.11. Let us fix α ∈ ℜ[0, 1]. Now, suppose that p ∞ exists. Then E [p ∞ -α] = 0 if and only if E[ lim k→∞ 1 k k-1 j=0 P (A tj +1 |ß tj ) -α] = 0. In general, E |p ∞ -α| ≥ E | lim k→∞ 1 k k-1 j=0 P (A tj +1 |ß tj ) -α|.</formula><p>Remark 4.12. By Lemma 4.10 and Lemma 4.11, we establish a connection between the true guarantee of wellcalibration and the real forecasting game between a machine and Nature. More discussions on such connection by Lemma 4.10 and Lemma 4.11 are provided in Appendix D. Definition 4.13. Nature is perverse when, for any fixed machine forecast α, P (A t+1 |ß t ) = α at least for infinitely many t's along the stochastic path of the test set.</p><p>By "at least i.o." in Definition 4.13, we mean that Nature deviates from α either (i) infinitely often or (ii) all but finitely often along the stochastic path of the test set. Thus, we clearly distinguish (i) from (ii). From now on, we mean by "infinitely often" that nature not only deviates infinitely often, but also does not deviate infinitely often. On the other hand, by "all but finitely often" we mean as usual. Then, if the true probability of Nature's perversity is zero, then we denote it by P (P (A t+1 |ß t ) = α at least i.o. along the path of the test set) = 0, which amounts to P (P (A t+1 |ß t ) = α at most for t &lt; ∞ along the path of the test set) = 1. Furthermore, if there is no confusion, we will simplify Nature's perversity by "P (A t+1 |ß t ) = α at least i.o." while omitting "along the path of the test set." Now, according to the Success Criterion (1), a machine fails to learn the true probability in case (ii), because the machine then makes wrong forecasts along the path except for a finite few of the infinite opportunities to learn. However, it seems unclear whether the machine can learn or not in case (i). On the one hand, the machine seems not to be able to learn because it makes too many errors, say infinitely many errors. On the other hand, it seems that the machine should be able to learn because it makes astronomically many correct forecasts, say infinitely often. Therefore, while adopting this definition, we clearly prove by Theorem 4.20 and Corollary 4.30 that a machine cannot learn the true probability even when it is correct infinitely often, if it is wrong that often.</p><p>Observation Provided that the machine forecast Π(A t+1 |ß t ) is fixed as some value α ∈ ℜ[0, 1], P ( ∆ t ) becomes the true second-order probability on the true first-order probability of such event A t+1 , that is, P ( ∆ t ) = P ( P (A t+1 |ß t ) = α ) where ∆ t denotes the event that the machine makes a correct forecast at t.</p><p>It should be noted here that the computable numbers by a machine are countably many (e.g. <ref type="bibr" target="#b30">(Turing, 1936)</ref>). Thus, the true second-order probability P here is a probability mass function on countable space and therefore satisfies the Kolmogorov axioms, although α may potentially be any real number in ℜ[0, 1].</p><p>Remark 4.14. More detailed discussions on the connection between true second-order probability and the forecasting game are provided in Appendix D.</p><p>Lemma 4.15. Let us consider the forecasting game between Nature and a machine. Also, let us further suppose that the structure of this game at any given time t, i.e. whether it is simultaneous or not, is certain to Nature. Now, by Assumption 4.2 and Assumption 4.3, let us suppose that ß t consists of the true facts, not necessarily knowledge. Then there exists a true second-order probability P such that 0 &lt; P (P (A t+1 |ß t ) = α) &lt; 1 if and only if the real forecasting game is a simultaneous-move game at time t. In particular, P (P (A t+1 |ß t ) = α) = 0 if and only if the machine moves first and then Nature moves later after observing what move the machine takes in the forecasting game at time t.</p><p>There are various theories of learning in games. (e.g. <ref type="bibr" target="#b22">(Nisan et al., 2007)</ref>) Therefore, what matters is what is aimed to learn through games and who are competing with each other in the games. In the standard model, a machine aims to learn what the optimal actions are to produce the minimized expected (total) loss or payoff, which is determined in a given environment, say financial market. In this case, a machine usually competes with other machines in the game. For example, in some online learning, a machine aims to learn a sequence of estimates which return the sub-linear regret, given that the loss functions are convex. It gets a possibly different amount of payoff/loss at each round of games along the stochastic path where the given sequence of games are played.</p><p>In our forecasting games, on the other hand, a machine aims to learn the true objective probability, if any, through games, and so the machine is competing with Nature in the game. Also, whoever wins a game, the winner/loser will get uniform payoff at every round along the path, for what counts is how many times the machine loses/wins along the path, not how much payoff it gets at each round along the path once it loses/wins. Theorem 4.16. In the forecasting game between a machine and Nature, the machine does not necessarily learn that it wins at each round of the game even though it indeed wins.</p><p>Thus, winning strategy is not equivalent to learning strategy. Now, in case when a machine does not learn that it wins/loses a game even though it indeed does so, it does not matter what it gets as payoff when it wins/loses because it cannot learn how much it gets at each round. What matters, on the contrary, is how many times it wins along the path, and this is why our game setting in Lemma 4.15 adopts a uniform payoff at each round. Theorem 4.17. Let us consider any arbitrary α ∈ ℜ[0, 1] for any machine forecast. If P (p k → α) = 1, then the true probability that Nature is perverse is zero with any of these forecasts α. (Case 3) (Case 1) Let us suppose that P (A t+1 |ß t ) = α at most finitely often along the stochastic path where the associated event A t+1 's occur. Then P (p k → α) = 1 where p k denotes the limiting relative frequency along the path.</p><p>(Case 2) Let us suppose that P (P (A t+1 |ß t ) = α just as in <ref type="bibr" target="#b23">(Oakes, 1985</ref>)) = 0. Then, P (p k → α) = 1 where p k denotes the limiting relative frequency along the stochastic path of the test set.</p><p>(Case 3) Let us suppose that P (P (A t+1 |ß t ) = α at least i.o. along the test set) = 0. Then P (p k → α) = 1 where p k denotes the limiting relative frequency along the path of the test set.</p><p>Regarding Theorem 4.17, it is worth noting the following three things: (i) (Case 1) is equivalent to the strong law of large numbers under a weaker assumption than i.i.d.: if the true probability P (A t+1 |ß t ) exists and P (A t+1 |ß t ) is identically distributed as α all but finitely often along the path, then the limiting relative frequency converges to the same P (A t+1 |ß t ) as α with true probability P -one. (ii) (Case 2) shows that if <ref type="bibr" target="#b23">(Oakes, 1985)</ref> holds with Π-subjective probability &gt; 0, then <ref type="bibr" target="#b7">(Dawid, 1982)</ref> does not hold, which amounts to the proof of Theorem 4.8. (iii) (Case 3) shows, combined with Theorem 4.6, that if P (P (A t+1 |ß t ) = α at most f.o. along the test set) = 1, then a machine cannot learn the true probability P (A t+1 |ß t ) as α. Thus, the third result (iii) has the following important implication for timeseries analysis: a machine cannot relax the assumption that the true probability P (A t+1 |ß t ) is identically distributed along the stochastic path, if the machine aims to learn the true probability P (A t+1 |ß t ). To learn, the machine needs some identical distributional assumptions such as stationarity or ergodicity.</p><p>Definition 4.18. Suppose that, with true probability P &gt; 0, Nature is perverse with some forecast α * . Then, Nature is uniformly perverse, when for any forecast α ∈ ℜ[0, 1], there exists no α = α * such that P ( P (A t+1 |ß t ) = α at least i.o.) = 0 for any event A t+1 .</p><p>In other words, when Nature deviates from forecasters for any event A t+1 , she does not discriminate against some forecasters in favor of the others whose forecasts α Nature decides to conform to all but finitely often for sure.</p><p>Theorem 4.19. Suppose that, for any α, there exists a true second-order probability P such that P (P (A t+1 |ß t ) = α ) &lt; 1 at least for infinitely many t's. Then, Nature is uniformly perverse.</p><p>Theorem 4.20. Suppose that, for any α, there exists a true second-order probability P such that P (P (A t+1 |ß t ) = α ) &lt; 1 at least for infinitely many t's. The machine cannot then learn the true objective probability P (A t+1 |ß t ) as α. Now, let us discuss what it means in Theorem 4.20 by the condition that the true second-order probability is strictly less than 1. Note from Lemma 4.15 that P (P (A t+1 |ß t ) = α) = 1 if and only if Nature moves first and then the machine moves later after observing what move Nature takes in the forecasting game at time t. Thus, it is clear from the condition of Theorem 4.20 why and when the machine fails to learn the true probability if Nature is uniformly perverse: when the machine cannot move later after observing the true move of Nature infinitely often, there always exists a real possibility that the machine may not be able to match Nature's move that often. Hence the machine cannot be truly guaranteed to be well-calibrated, which again implies the impossibility of machine learning. Since the machine cannot observe the true move of Nature in those forecasting games, the true probability is unobservable by the machine.</p><p>So far we have shown that it is of real possibility that Nature is perverse, and thus that no machines can learn the true objective probability. Now someone might argue that its proof holds only under the condition that Nature is uniformly perverse. Nature may not be uniformly perverse, however, but only selectively perverse, so that, for some forecast α 0 , Nature may decide to be benevolent enough to conform to that α 0 . Then it may be the case that the true probability of Nature being perverse is zero for this α 0 , and accordingly that machines may be given an opportunity to learn the true objective probability for that α 0 . Note, however, that it is entirely Nature's decision when she will be benevolent to a machine and when she will not. Therefore, it is still a random event to the machine whether Nature is perverse or not. If so, we will show further that, even if the true probability of Nature's being perverse is zero with some α 0 , a machine still cannot learn the true probability if it cannot learn which forecast is the right α 0 for any event A t+1 . Definition 4.21. A machine tolerates error at t while pursuing its goal of learning the true probability Lemma 4.23. Suppose that a machine aims to learn the true probability P (A t+1 |ß t ) and thus performs an effective calculation to return its result of Π(A t+1 |ß t ) as 0 for the true probability P (A t+1 |ß t ). Then, Π(A t+1 |ß t ) = 0 if and only if Π({P (A t+1 |ß t ) = 0}) = 1, for all but finitely many t's.</p><formula xml:id="formula_6">P (A t+1 |ß t ), when Π(A t+1 |ß t ) = α but Π({P (A t+1 |ß t ) = α}) &gt; 0 for some α ∈ ℜ[0, 1].</formula><p>Remark 4.24. In relation to <ref type="bibr" target="#b28">(Savage, 1972)</ref>, more discussions on Lemma 4.23 are provided in Appendix D.</p><p>Definition 4.25. Nature is selectively perverse, when ∃ α and α 0 = α such that P (P (A t+1 |ß t ) = α 0 at least i.o.) = 0 , while P (P (A t+1 |ß t ) = α at least i.o.) &gt; 0 for any other α = α 0 . Now, let us define Nature's decision to be selectively perverse at t to show by Lemma 4.28 that once Nature decides so at t, our real world remains as such.</p><p>Definition 4.26. Nature decides to be selectively perverse at t, when there exist forecasts α and α 0 = α such that P (A α0 (t + 1)|ß t ) = 0, while P (A α =α0 (t + 1)|ß t ) = 0 where A α (t + 1) denotes the event that, from t + 1 onward, Nature is perverse with the associated events A t 's whose assessed forecasts are α.</p><p>Definition 4.27. Suppose that Nature is selectively perverse so that she freely decides at any time whether to be perverse at any rate or not. Then, t s &lt; ∞ denotes a stopping time if t s is the last time that Nature changes her mind into non-perversity so that, for any α 0 with which Nature is not perverse with true probability P -one, P (A α0 (t + 1)|ß t ) = 0, ∀t &gt; t s . Note that t s is ß t -measurable, because ß t includes all the true facts up to t and so whatever Nature decides at t, say the event {P (A α0 (t+1)|ß t ) = 0} belongs to the set of true facts, ß t .</p><p>Lemma 4.28. Nature is selectively perverse if and only if there exists a stopping time t s for every forecast α 0 with which Nature is not perverse with true probability P -one so that P (A α0 (t + 1)|ß t ) = 0 ∀t &gt; t s , while there is no stopping time t s for any other α = α 0 . Lemma 4.29. Let us suppose that Nature is selectively perverse and that a machine learns which forecast is the right forecast α 0 for any associated A t 's with which Nature is not perverse with true probability P -one. The machine is then self-assured that the stopping time t s arrives for that α 0 . Corollary 4.30. Suppose that Nature is selectively perverse so that, with true probability P -one, she is not perverse with some machine forecasts α 0 . Furthermore, suppose that the machine is not self-assured that the stopping time t s arrives for each of those α 0 's. The machine cannot then learn the true objective probability P (A t+1 |ß t ) as α.</p><p>Note that along the stochastic path considered in Corollary 4.30, P (P (A t+1 |ß t ) = α 0 at least i.o.) = 0 ∀t &gt; t s . Now, for this α 0 ,</p><p>(3) lim sup t→∞</p><formula xml:id="formula_7">P (P (A t+1 |ß t ) = α 0 ) ≤ P (P (A t+1 |ß t ) = α 0 at least i.o) = 0</formula><p>Therefore, without loss of generality, letting t * ≥ t s with t * &lt; ∞, (4)</p><formula xml:id="formula_8">P (P (A t+1 |ß t ) = α 0 ) = 1, ∀t &gt; t * ≥ t s with t * &lt; ∞.</formula><p>Now, (4) means by Lemma 4.15 that the true probability is observable at any time t &gt; t * along this path. Then why is the machine still unable to learn the true probability, even though the machine can move after observing what move Nature takes at the forecasting games all along that path after t * ? According to Corollary 4.30, this is because the machine cannot be self-assured whether the true probability will remain observable at any time after t * +1 onward, even if the machine observes Nature's true move at time t * +1. Let us show this by the following Lemma 4.31. Lemma 4.31. Suppose that a machine is not self-assured of the stopping time t s for α 0 . The machine cannot then be self-assured whether the true probability will remain observable at any time after t * +1 onward, even if the machine observes Nature's true move at time t * +1.</p><p>From Theorem 4.20 and Corollary 4.30, we conclude that the impossibility of learning is derived under the assumption either that Nature is uniformly perverse or that Nature is selectively perverse but a machine is not self-assured of whether the stopping time arrives or not. What would then happen in the case where Nature is selectively perverse and a machine is self-assured of the stopping time t s when the t s indeed exists? We show in the following that a machine can learn the true probability in this case, and further that this is the only case in which a machine can learn it. Theorem 4.32. Suppose that a machine learns the true probability P (A t+1 |ß t ) as α. The machine is then selfassured that the stopping time t s arrives for α, while the machine is not self-assured that the stopping time t s arrives for α where such t s does not exist.</p><p>Let us now define when the true probability is directly observable based on the notion of population. The concept of population in Definition 4.34 is mainly indebted to <ref type="bibr">(von Mises, 1957;</ref><ref type="bibr" target="#b34">1967)</ref>. Since the true probability is defined as the empirical distribution of this population available to a machine, the probability is said to be directly observable by the machine. Definition 4.33. Let us consider a set S that consists of the sequence of events A t+1 's, {A t+1 } k-1 t=0 with k potentially infinite. Then, the set S is defined to be a population with k number of elements, when this set S is assumed to have a certain attribute of interest, and so an indicator variable 1 {At+1} is assigned to each event A t+1 where 1 {At+1} has a value 1 or 0 depending on whether the event A t+1 satisfies such an attribute or not, once the set S is collected. Then, the empirical distribution of the population S with respect to the given attribute is defined to be</p><formula xml:id="formula_9">1 k k-1 t=0 1 {At+1} .</formula><p>Definition 4.34. A machine directly observes P (A t+1 |ß t ) from the population S at t * if the following two conditions are satisfied: (i) a population S is in principle available to the machine. (ii) The machine calculates the empirical distribution of the population with respect to the given attribute, which is the true probability distribution of the event A t+1 . Now, in case where the sequence</p><formula xml:id="formula_10">{A t+1 } k-1 t=0 is a time- series, Definition 4.34 means that Π(A t * +1 |ß t * ) = 1 k k-1 t=0 1 {At+1} = P (A t * +1 |ß t *</formula><p>) with k = t * . Thus, when t * goes to infinity, the directly observable true probability becomes the limiting relative frequency, the representative objective true probability.</p><p>Theorem 4.35. Suppose that a machine is self-assured of the stopping time t s when there exists t s , but that the machine is not self-assured of the stopping time t s when no t s exists. The machine then directly observes the true probability P (A t+1 |ß t ) as α 0 .</p><p>Theorem 4.36. A machine directly observes the true probability P (A t+1 |ß t ) as α if and only if the machine learns the true probability P (A t+1 |ß t ) as α.</p><p>Two things should be noted from Theorem 4.36. First, whenever the true probability is not directly observable, a machine cannot learn the true probability. Now recall from Definition 2.1 that the machine is an ideal one with no practical limits on computational resources such as time or storage spaces. Therefore, this implies that no real machines, hindered by many practical limits in our world, can overcome this impossibility of learning either, whenever the true probability is not directly observable. Second, Theorem 4.36 also says that the true probability is directly observable by a machine whenever it can learn the true probability. Once a machine learns the true probability and so it is successfully computable, then the next question is how complex it is to compute. Now that the true probability is directly observable, this makes it easier to deal with the complexity problem. (e.g. Sorting algorithm) Thus, Theorem 4.36 directly connects the problem of computational solvability to the problem of complexity. Now, let us finish this section by adding one more claim that the Success Criterion (1) to compute the true probability is sufficient for learning it.</p><p>Corollary 4.37. If a machine calculates the true probability P (A t+1 |ß t ) correctly most of the time, which is selfassured to the machine, then the machine can learn the true probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have discussed so far when machines can learn the true probabilities and when they cannot. In summary:</p><p>• ∃ α * such that P ( Nature is perverse with α * ) &gt; 0 by Theorem 4.19. Now that Nature is perverse at least with one forecast α * ,</p><p>• (i) Nature is uniformly perverse: machines cannot learn by Theorem 4.20.</p><p>• (ii) Nature is selectively perverse: ∃ t s for each α 0 such that P ( Nature is perverse with α 0 ) = 0 by Lemma 4.28.</p><p>Then under (ii),</p><p>• (ii-1) Machines are not self-assured of the t s : machines cannot learn by Corollary 4.30.</p><p>• (ii-2) Machines are self-assured of the t s :</p><p>Then under (ii-2),</p><p>• (ii-2-1) t s actually does not arrive: machines cannot learn by Theorem 4.32.</p><p>• (ii-2-2) t s indeed arrives: machines can learn and this is the only case in which machines can learn by Theorem 4.35 and Theorem 4.36.</p><p>Before we close this section, let us add a few remarks. First, we emphasize that in this paper we have focused on the notion of "machine learning" that is not just a technical terminology, understood as an identification of a target function,</p><p>but also an epistemic one, a counterpart to "human learning." We focus on this epistemic notion of machine learning because we particularly mean by "machines" those artifacts that perform human-level intelligent behaviors.</p><p>Second, note that we do not need to specify how machines learn the true objective probabilities to prove the impossibility of machine learning on the true probabilities. Instead, we only need the necessary condition for any machine to learn the true objective probabilities if it learns them in any way. Thanks to this flexibility about how to learn, we come to have a powerful and robust result: no matter what kind of learning method a machine uses, it cannot learn the true objective probabilities that are not directly observable.</p><p>Lastly, let us emphasize again that our learning machine is an ideal device with no practical limits on time and storage space, etc. Therefore, the scope and limit of machine learning on true probabilities discussed in this paper are more fundamental than practical ones.</p><p>sions that were helpful in various ways to develop this paper. In particular, Tyler helped me pay attention to the idea of converting a non-propositional structure to a propositional one while learning, and Joe helped me open my eyes to the possibility of machine learning on the true probabilities. I discussed every detail of this paper with Jinho so that I insisted that he should be listed as a co-author. Jinho refused on the ground that he did not make direct contributions to mathematical proofs, with which I disagree. But Jinho has been right most of the time when we disagreed, so I decided to agree. Lastly, the author is grateful to three anonymous reviewers and a meta-reviewer. Their reviews were helpful in improving this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact Statement</head><p>This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proofs for Lemmas, Theorems and Corollaries</head><p>Proof of Theorem 4.1 A proof of Theorem 4.1 is suggested in <ref type="bibr" target="#b7">(Dawid, 1982)</ref>. A simpler one is as follows:</p><formula xml:id="formula_11">Let X t = ( t j=1 ξ j ) -1 • ξ t (Y t -Ŷt ). Since ( t j=1</formula><p>ξ j ) -1 , ξ t and Ŷt are ß t-1 -measurable, it follows that E(X t |ß t-1 ) = 0 where E is taken with respect to Π(•|ß t-1 ) and so that k t=1</p><p>X t is a martingale adapted to ß k-1 . Also, E((</p><formula xml:id="formula_12">k t=1 X t ) 2 ) = k t=1 E(X 2 t ) ≤ λ • E{ k t=1 (( t j=1 ξ j ) -1 • ξ i ) 2 } ≤ λπ 2 6</formula><p>, because Y t is an indicator variable and so var(Y t |ß t-1 ) is uniformly bounded above by some λ such that 0 ≤ λ &lt; ∞. Then, by the martingale convergence theorem, k t=1</p><p>X t converges with Π-probability one, which implies from Kronecker's lemma that, with Π-probability one,</p><formula xml:id="formula_13">p k -α = ( k t=1 ξ t ) -1 • k t=1 ξ t (Y t -Ŷt ) → 0 where Ŷt = α ∀t. Q.E.D.</formula><p>Proof of Lemma 4.5 Let A t be an event token at time t and P (A|E) = α be the true probability of event type A conditional on event type E whose event tokens are denoted by A t and E t , respectively. Then, by the definition of E with respect to A, P (A t+1 |E t ∈ ß t ) = α with true probability Pone. Now, once P (A t+1 |E t ∈ ß t ) is learned as such at some t 0 , then E t0 must have happened at that time and so P (E t0 ) = 0. Also, by Assumption 4.4, consider a subsequence of E t k 's where P (E t k ) = 0 for any t k &gt; t 0 . Then, for this subsequence, P (E t0 &amp;E t k ) = 0 for any t k &gt; t 0 , because E t k 's are independent of one another.</p><p>Here, E t k 's are independent for the following reason: recall that by definition, P (A t k +1 |E t k ∈ ß t k ) = α with true probability Pone. Then, note that ß t k includes the fact that</p><formula xml:id="formula_14">P (A t k-i +1 |E t k-i ∈ ß t-i ) = α for some i ≥ 1. Now,</formula><p>without loss of generality, let i = 1. Thus, we obtain</p><p>(1)</p><formula xml:id="formula_15">P ( P (A t k +1 | {P (A t k-1 +1 |E t k-1 ) = α} ∈ ß t k ) = α) = 1</formula><p>Now that E t k and E t k-1 are all included in ß t k by (1), to show that E t k 's are independent, we need to prove that</p><p>(2)</p><formula xml:id="formula_16">P ( {P (A t k +1 |ß t k ) = α} | {P (A t k-1 +1 |ß t k-1 ) = α}) = P ( {P (A t k +1 |ß t k ) = α}) But (2) is satisfied because P ( {P (A t k +1 |ß t k ) = α}) = 1 = P ( {P (A t k-1 +1 |ß t k-1 ) = α}).</formula><p>Now that P (E t0 &amp;E t k ) = 0, for any t k &gt; t 0 in this subsequence, we can always find some small enough ǫ &gt; 0 such that P (E t k ) &gt; ǫ. Therefore, the probability of the element in this subsequence does not vanish to zero, which implies that</p><formula xml:id="formula_17">lim s→∞ P (E t0 &amp;E ts ) = 0. Since lim s→∞ P (E t0 &amp;E ts ) = 0, ∞ s=1 P (E t0 &amp;E ts ) = ∞.</formula><p>Then, by the second Borel-Cantelli lemma,</p><formula xml:id="formula_18">P (E t0 &amp;E ts i.o.) = 1 for s &gt; 0, which means P (E t0 ∈ ß t0 &amp; E t k ∈ ß t k i.o.) = 1 for t k &gt; t 0 , the desired result. Q.E.D.</formula><p>Proof of Theorem 4.6 Suppose that, for infinitely many t's when P (A t+1 |ß t ) stays the same as α, machines learn this P (A t+1 |ß t ) as α at time t. Then, by the Success Criterion (1),</p><formula xml:id="formula_19">Π(A t k +1 |ß t k ) = α = P (A t k +1 |ß t k ) at</formula><p>least infinitely often out of those infinite opportunities at t's to learn. (We prove in Corollary 4.37 what we mean exactly by "most of the time." Here we tentatively mean "at least i.o." by it because machines are otherwise wrong too often to learn given the Success Criterion (1).) Thus we can construct a test set which consists of the subsequence of Π(A t k +1 |ß t k ) which is equal to P (A t k +1 |ß t k ) for those infinitely many t k 's. Let ξ t k +1 = 1 if and only if Π(A t k +1 |ß t k ) = P (A t k +1 |ß t k ) = α. Note that ξ t k +1 is ß t k -measurable, because machine forecasting α occurs at time t k . Then, by Theorem 4.1, with true probability P -one, p k</p><formula xml:id="formula_20">-α = ( k-1 j=0 ξ tj +1 ) -1 • k-1 j=0 ξ tj +1 (Y tj +1 -α) → 0, as k → ∞ where P is defined over ß ∞ = ∞ k=0 ß t k</formula><p>and ß t k is denoted by the totality of true facts up to day t k . Q.E.D.</p><p>Proof of Lemma 4.10 Clearly, if with P -probability one, p k → α, then E [p ∞α] = 0 where the mathematical expectation is taken with respect to the true probability P, but not vice versa. The reverse does not necessarily hold, because even though</p><formula xml:id="formula_21">P ( p k → α) &lt; 1, E [p ∞ -α] = 0 when [p k -α]</formula><p>converges to ±β = 0 with the equal probability as 1 2 (1 -P ) &gt; 0. However, with P -probability one, p k → α if and only if E |p ∞ -α| = 0, for the following reason: letting Λ ∞ denote the event that p k → α as k goes to infinity,</p><formula xml:id="formula_22">E |p ∞ -α| = P (Λ ∞ ) × |p ∞ -α| Λ + ∞ + (1 -P (Λ ∞ )) × |p ∞ - α| Λ - ∞ = 0 if and only if P (p k → α) = 1 where |p ∞ -α| Λ + ∞ denotes the value of |p ∞ -α| when Λ ∞ occurs, while |p ∞ - α| Λ -</formula><p>∞ denotes that when Λ ∞ does not occur. Here, the "if" part is clear. For the "only if" part, if</p><formula xml:id="formula_23">P (p k → α) &lt; 1, then (1 -P (Λ ∞ )) × |p ∞ -α| Λ - ∞ &gt; 0 while P (Λ ∞ ) × |p ∞ -α| Λ + ∞ = 0, which implies that E |p ∞ -α| = 0. Q.E.D.</formula><p>Proof of Lemma 4.11 By Fatou's lemma, E[lim inf k→∞ </p><formula xml:id="formula_24">1 k k-1 j=0 Y tj +1 |ß tj ] ≤ lim inf k→∞ E[ 1 k k-1 j=0 Y tj +1 |ß tj ] = lim inf k→∞ 1 k k-1 j=0 P (A tj +1 |ß tj ) ≤ lim sup k→∞ 1 k k-1 j=0 P (A tj +1 |ß tj ) ≤ E[lim sup k→∞ 1 k k-1 j=0 Y tj +1 |ß tj ]. Now,</formula><formula xml:id="formula_25">Y tj +1 ]-α = E [E [ lim k→∞ 1 k k-1 j=0 Y tj +1 |ß tj ] -α] = E[ lim k→∞ 1 k k-1 tj =0 P (A tj +1 |ß tj ) -α]. Therefore, E [p ∞ -α] = 0 if and only if E[ lim k→∞ 1 k k-1 tj =0 P (A tj +1 |ß tj )-α] = 0. Also, E |p ∞ -α| = E | lim k→∞ 1 k k-1 j=0 Y tj +1 -α| = E [E [| lim k→∞ 1 k k-1 j=0 Y tj +1 -α| |ß tj ]]. But note that E [E [| lim k→∞ 1 k k-1 j=0 Y tj +1 -α| |ß tj ]] ≥ E |E[ lim k→∞ 1 k k-1 j=0 Y tj +1 -α|ß tj ]| = E | lim k→∞ 1 k k-1 j=0 P (A tj +1 |ß tj ) -α| by Jensen's inequality. Therefore, E |p ∞ -α| ≥ E | lim k→∞ 1 k k-1 j=0 P (A tj +1 |ß tj ) -α|. Q.E.D.</formula><p>Proof of Lemma 4.15 Consider a simple two-player game (I, S i , u i (s)) between Nature (player i) and a representative machine (player -i) where I is the set of players {i, -i}, S i is the set of pure strategies s i 's for each player i, and u i (s) is the usual payoff function for player i. Since this is a probabilistic forecasting game, the pure strategy for each player s i can be any number in ℜ[0, 1]. But since the computable numbers by player -i are countably many, we restrict S i to be countable. For simplicity, let u i : S i × S -i → {-1, 1}. In other words, for each profile s = (s i , s -i ), if player i wins, she obtains 1, while she obtains -1 otherwise. When Nature (player i) succeeds in deviating from the machine forecast, Nature wins. Otherwise, the machine (player -i) wins. Thus, this is a kind of matching game with countably infinite state space.</p><p>First, let us note that the structure of the forecasting game is given to Nature, because the structure itself is something objective about the world and thus it belongs to the realm of Nature herself. In other words, it is certain to Nature whether Nature and the machine moves simultaneously or not in the game as follows: If the machine moves when Nature herself does not move yet, then it is certain to Nature that the machine moves first and thus that it is not a simultaneous game. If the machine does not move yet when Nature does not move either, then it is certain to Nature that the machine does not move first, and thus whether it is a simultaneous game or not depends on Nature herself. If Nature reveals herself to the machine even before the machine moves so that the machine can move after observing Nature's, it is certain to Nature that it is not a simultaneous game. Otherwise, it is certain to Nature that it is a simultaneous game.</p><p>(i) the proof of the "only if" part: first, let us fix machine forecast Π(A t+1 |ß t ) as α and then consider the relevant test set. Now, suppose that the forecasting game along the stochastic path of this test set is not a simultaneous-move game at time t. Then, either Nature or the machine moves first, and the rest moves later after observing what move the other opponent takes. Thus, the one who can observe the opponent's move can control their/her own forecasting to win the game, and so ∆ t occurs or does not occur at time t, which is certain to Nature because the structure of the game is given to Nature. Then, since ß t includes ∆ t or ¬∆ t as part of the true facts by Assumption 4.2, P (∆ t ∈ ß t ) = 1 or P (¬∆ t ∈ ß t ) = 1. Thus, it is either P ( P (A t+1 | ∆ t ∈ ß t ) = α ) = 1 or P ( P (A t+1 | ¬∆ t ∈ ß t ) = α ) = 0 respectively, according as Nature moves first or the machine moves first. Therefore, the true second-order probability P is neither strictly less than 1 nor strictly greater than 0.</p><p>(ii) the proof of the "if" part: again, let us fix the machine forecast Π(A t+1 |ß t ) as α and then consider the relevant test set. Now, suppose that the forecasting game is a simultaneous-move game at time t. Then, for any fixed value α ∈ ℜ[0, 1], it is not certain to Nature herself whether Π(A t+1 |ß t ) = α or not, because there exists no pure strategy Nash equilibrium in this simultaneous matching game. Thus, Nature cannot certainly control P (A t+1 |ß t ) to make it deviate from Π(A t+1 |ß t ) and so we obtain</p><p>(3) P ( P (A t+1 |ß t ) = α ) = 0.</p><p>(3) holds even though ß t of P (A t+1 |ß t ) in (3) includes ∆ t or ¬∆ t as part of the true facts by Assumption 4.2, if either of them indeed occurs at t. In the same logic, it is not certain to Nature that the machine can control Π(A t+1 |ß t ) to make it coincide with P (A t+1 |ß t ) and so we obtain ( <ref type="formula">4</ref>)</p><formula xml:id="formula_26">P ( P (A t+1 |ß t ) = α ) = 1.</formula><p>Clearly, any mixed strategy Nash equilibrium, if any, will lead to 0 &lt; P (P (A t+1 |ß t ) = α ) &lt; 1. Therefore, there exists the true second-order probability P such that 0 &lt; P (P (A t+1 |ß t ) = α ) &lt; 1.</p><p>Furthermore, if Nature moves first, then P ( P (A t+1 | ß t ) = α ) = 1, as we proved in (i). Therefore, if the machine does not move first, which amounts to either Nature moves first or the machine moves simultaneously with Nature, then clearly</p><formula xml:id="formula_27">P ( P (A t+1 | ß t ) = α) = 0. Q.E.D.</formula><p>Proof of Theorem 4.16 Consider the necessary condition (2) that if a machine learns the true objective probability P (A t+1 |ß t ), then Π(A t+1 |ß t ) = P (A t+1 |ß t ). Since this is just a necessary but not sufficient condition, the converse of (2) does not necessarily hold. Now, for any machine forecast α ∈ R[0, 1], suppose that P (A t+1 |ß t ) = α for infinitely many t's along the stochastic path where the associated A t+1 's occur but that P (A t+1 |ß t ) = α for infinitely many t * 's. Then, by Theorem 4.19, P (P (A t+1 |ß t ) = α i.o.) &gt; 0 for some event A t+1 . Thus, by (Case 3) of Theorem 4.17 and Theorem 4.6, the machine cannot learn the true probability P (A t+1 |ß t ), even though Π(A t+1 |ß t ) = α = P (A t+1 |ß t ) at infinitely many t * 's. Thus, the machine does not learn that it wins even though it indeed wins at t * 's. Clearly, the machine does not learn whether it wins at other t's than t * 's when it loses. Now, since the machine does not learn whether it wins or not at each round of game, the machine does not learn what its payoff is at each round. Furthermore, the machine is truly guaranteed to be well-calibrated along the path of t * 's and so this is the winning strategy in forecasting game between Nature and the machine (e.g. <ref type="bibr">(Foster &amp; Vohra, 1993)</ref>), but the machine still cannot learn the true probability P (A t+1 |ß t ). Thus, in this case, winning strategy is not equivalent to learning strategy. Q.E.D.</p><p>Proof of Theorem 4.17 First, let us recall the followings: by Nature's perversity with true probability 0, we mean that P ( M t at least i.o.) = 0 for any fixed α ∈ ℜ[0, 1]. Here, M t denotes a meta-event {P (A t+1 |ß t ) = α for any event A t+1 at time t} for such a fixed forecast α. Given this, let us consider the following three cases, according as how P (A t+1 |ß t ) actually varies with respect to α along the path of the test set. (Case 3) amounts to Theorem 4.17.</p><p>(Case 1) Let us suppose that P (A t+1 |ß t ) = α for finitely many t's along the stochastic path. Now, as in Theorem 4.1,</p><formula xml:id="formula_28">let X t = ( t j=1 ξ j ) -1 • ξ t (Y t -α).</formula><p>But, unlike in Theorem 4.1, ξ j = 1 here if P (A j+1 |ß j ) = α for all j along the stochastic path, not necessarily restricted to the test set. Now, consider those finite t's when P (A t+1 |ß t ) = α and denote the largest t among them by t m . Then,</p><formula xml:id="formula_29">P (A t+1 |ß t ) -α = E[Y t |ß t-1 ] -α = 0, ∀t &gt; t m along the stochastic path.</formula><p>Thus, E(X t |ß t-1 ) = 0 where expectation E is taken with respect to the true probability P (•|ß t-1 ) and so k t=tm+1 X t is a martingale adapted to ß k-1 at t &gt; t m along the path. Then, by the martingale convergence theorem and Kronecker's lemma, (</p><formula xml:id="formula_30">k-1 j=0 ξ tj +1 ) -1 • k-1 j=0</formula><p>ξ tj +1 (Y tj +1α) → 0 with true probability P -one.</p><p>(Case 2) Let us consider the case where with true probability P &gt; 0, P (A t+1 |ß t ) deviates from α in such a way as in <ref type="bibr" target="#b23">Oakes (1985)</ref> along the test set. Then, E |p ∞ -α| = 0 and so the calibration property is not truly guaranteed for the following reason: Let Λ o ∞ be the event that P (A t+1 |ß t ) deviates from α in such a way as in <ref type="bibr" target="#b23">Oakes (1985)</ref> along the test set. Then, since some subsequence of Y t 's along the test set forms Bernoulli whose relative frequency converges to f (α) = α,</p><formula xml:id="formula_31">p k does not converge to α when Λ o ∞ occurs. Now, let |p ∞ -α| + Λ o ∞ be the value of |p ∞ -α| when Λ o ∞ occurs, while |p ∞ - α| - Λ o ∞ be the value of |p ∞ -α| when Λ o</formula><p>∞ does not occur along the test set. Then, in the same logic as in Lemma 4.11, we obtain that</p><formula xml:id="formula_32">E |p ∞ -α| = P (Λ o ∞ )× |p ∞ -α| + Λ o ∞ + (1 -P (Λ o ∞ ))× |p ∞ -α| - Λ o ∞ = 0. Thus, P (p k → α) = 1.</formula><p>However, the converse does not hold, for there can be many other ways of how p k does not converge to α than in <ref type="bibr" target="#b23">Oakes (1985)</ref>. Hence it does not follow that P (Λ o ∞ ) &gt; 0, even if E |p ∞ -α| = 0. Now, suppose that with Π-subjective probability &gt; 0, P (A t+1 |ß t ) behaves in such a way as in <ref type="bibr" target="#b23">Oakes (1985)</ref>. Then, again in the same logic as in Lemma 4.11, we obtain that</p><formula xml:id="formula_33">E |p ∞ -α| = Π(Λ o ∞ )×|p ∞ -α| + Λ o ∞ + (1-Π(Λ o ∞ ))×|p ∞ -α| - Λ o ∞ = 0</formula><p>where expectation is now taken with respect to Π. Hence Π(p k → α) = 1. Therefore, we conclude that if <ref type="bibr" target="#b23">Oakes (1985)</ref> holds with Π-subjective probability &gt; 0, then <ref type="bibr" target="#b7">Dawid (1982)</ref> does not hold, which amounts to the proof for Theorem 4.8.</p><p>(Case 3) In general, suppose that the true probability of Nature's being perverse is not zero for any fixed forecast α on any associated events A t 's. In other words, suppose that P ( M t at least i.o. along the test set) &gt; 0 where M t is the meta-event that P (A t+1 |ß t ) = α. Then, we claim that this implies that E |p ∞ -α| = 0 where E is taken with respect to P .</p><p>First, suppose that p ∞ exists. Also, suppose that α = 0, because (Case 3) trivially holds if α = 0. Now let us consider an infinite subsequence of A t k 's, {A t k j } ∞ j=0 , which is conditionally identically distributed along the test set where M t occurs at least infinitely often. We can do this by Kolmogorov axioms 1 and 2 and Lemma 4.5 for the following reason: note that by Kolmogorov axioms 1 and 2 there always exists one β ∈ ℜ[0, 1] such that P (A|E) = β for any type event A and E, given that there exists probability of type event, if any. Then, for this β, P ( P (A t+1 |ß t ) = β i.o.) = 1 according to Lemma 4.5. Thus, we found one subsequence of {A t k } ∞ k=0 such that it is conditionally identically distributed as {P (A t k +1 |ß t k ) = β} ∞ k=0 . Now, fix α. Also, without loss of generality, suppose that β = α. Since β = α is arbitrary, from this subsequence we can consider another subsequence E A of {A t k j } ∞ j=0 with the true probability P &gt; 0 such that</p><formula xml:id="formula_34">E A = {P (A t k j +1 |ß t k j ) = β} ∞</formula><p>j=0 along the stochastic path of the test set in which M t occurs at least infinitely often. For reductio, let us suppose that Nature deviates α by picking numbers from uncountably many values of β's such that every value of β is equal to P (A t+1 |ß t ) only at most finitely many t's along the test set with true probability P -one. In other words, (5) For β ∈ ℜ[0, 1] where β = α, P (A t+1 |ß t ) = β at most for finitely many t's along the path of the test set where M t occurs at least infinitely often, with true probability P -one.</p><p>Note that there must be countably infinite number of different β's in (5). Let us denote each different β at each time along the path by β t k j , while letting β t k i = β t k j for i = j without loss of generality. Now, recall that p ∞ is assumed to exist along the stochastic path of the test set. Thus, inspired by this assumption, let us further assume that lim h→∞</p><formula xml:id="formula_35">1 h h-1 j=0 P (A t k j +1 |ß t k j )</formula><p>exists where P (A t k j +1 |ß t k j ) = β t k j or P (A t k j +1 |ß t k j ) = α along the path of the test set. Then, letting</p><formula xml:id="formula_36">ξ t k j := 1 P (A t k j +1 |ß t k j ) = α 0 P (A t k j +1 |ß t k j ) = β t k j (6) lim h→∞ 1 h h-1 j=0 P (A t k j +1 |ß t k j ) = lim h→∞ 1 h h-1 j=0 [ ξ t k j • P (A t k j +1 |ß t k j ) + (1 -ξ t k j ) • P (A t k j +1 |ß t k j )] = α • lim h→∞ 1 h h-1 j=0 ξ t k j + lim h→∞ 1 h h-1 j=0 (1 -ξ t k j ) • β t k j .</formula><p>Thus,</p><formula xml:id="formula_37">(7) lim h→∞ 1 h h-1 j=0 P (A t k j +1 |ß t k j ) = α, if and only if, lim h→∞ 1 h h-1 j=0 (1 -ξ t k j ) • β t k j = α • (1 -lim h→∞ 1 h h-1 j=0 ξ t k j ).</formula><p>In other words, if Nature deviates from machine forecasts by β t k j 's so that her deviating forecasts on average satisfy ( <ref type="formula">7</ref>) under ( <ref type="formula">5</ref>), then E |p ∞ -α| = 0 and thus the test set is truly guaranteed to be well-calibrated. But Nature then loses the repeated forecasting games along the path in the long run. So Nature has no reason to behave in this way with the true probability P -one. Let us then consider the following three cases:</p><formula xml:id="formula_38">(Case i) P (P (A t+1 |ß t ) = α) = 0 at least i.o.</formula><p>In this case, by Lemma 4.15, Nature observes machine forecasts α in each time t kj whenever the machine predicts P (A t+1 |ß t ) as α.</p><p>Now that 1 = lim sup t→∞ P (P (A t+1 |ß t ) = α) ≤ P (P (A t+1 |ß t ) = α at least i.o.),</p><p>Nature would choose the deviating value β t k j in such a way that she would not allow (7) to hold with true probability Pone. Thus, ( <ref type="formula">8</ref>) P ( lim</p><formula xml:id="formula_39">h→∞ 1 h h-1 j=0 (1 -ξ t k j ) • β t k j = α • (1 -lim h→∞ 1 h h-1 j=0 ξ t k j ) ) = 1.</formula><p>In other words, since Nature observes machine forecast α at every time, she would deviate each forecast α at t kj in such a way that (8) holds in the end. Otherwise, E |p ∞ -α| = 0, so Nature would lose in the long run. Therefore, we conclude due to ( <ref type="formula">8</ref>) that E |p ∞ -α| = 0 in case (i).</p><p>(Case ii)</p><formula xml:id="formula_40">P (P (A t+1 |ß t ) = α) = 1 at least i.o.</formula><p>In this case, by Lemma 4.15, Nature moves first so the machine cannot fail to match P (A t+1 |ß t ). But then,</p><formula xml:id="formula_41">1 = lim sup t→∞ P (P (A t+1 |ß t ) = α) ≤ P (P (A t+1 |ß t ) = α at least i.o.) = P (P (A t+1 |ß t ) = α at most f.o.</formula><p>), which contradicts ( <ref type="formula">5</ref>). Therefore, we exclude case (ii) under ( <ref type="formula">5</ref>).</p><p>(Case iii) 0 &lt; P (P (A t+1 |ß t ) = α) &lt; 1 at least i.o.</p><p>In this case, by Lemma 4.15, Nature moves simultaneously with the machine, so Nature has no reason to pick any particular β t k j ∈ ℜ[0, 1] at each t kj , for there exists no pure strategy Nash equilibrium. Hence any combination of {β t k j } ∞ j=0 is equally likely. Now, without loss of generality, let us fix α and ξ t k j for each t kj . Then we claim that (9) P (</p><formula xml:id="formula_42">1 h h-1 j=0 (1 -ξ t k j ) • β t k j → cα ) &lt; P ( 1 h h-1 j=0 (1 -ξ t k j ) • β t k j → cα -) ≤ 1 where c = 1 -lim h→∞ 1 h h-1 j=0</formula><p>ξ t k j for some fixed c, and cα ∈ C for some fixed α, and some set C such that ∀x ∈ C, x ∈ ℜ[0, 1] but C is countably infinite, and cα -is any real number in the set C/cα, the set C without cα.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>First, recall that lim</head><formula xml:id="formula_43">h→∞ 1 h h-1 j=0 (1 -ξ t k j ) • β t k j exists. Then, by definition, ∀ǫ &gt; 0, ∃ N 1 &lt; ∞ such that | 1 h h-1 j=0 (1 -ξ t k j ) • β t k j -cα| &lt; ǫ, ∀h &gt; N 1 , ∀ǫ &gt; 0, ∃ N i &lt; ∞ such that | 1 h h-1 j=0 (1 -ξ t k j ) • β t k j -c i α -| &lt; ǫ, ∀h &gt; N 2 . (1 = i ∈ N) Now, letting N = max(N 1 , N i ), ∀ǫ &gt; 0, (10) P ({ω ∈ ß ∞ = ∞ j=0 ß t k j : | 1 h h-1 j=0 [P (A t k j +1 |ß t k j ) = β t k j ] -cα | &gt; ǫ, ∀h &gt; N }) &lt; P ( ∞ i=0 {ω ∈ ß ∞ = ∞ j=0 ß t k j : | 1 h h-1 j=0 [P (A t k j +1 |ß t k j ) = β t k j ] -c i α -| &gt; ǫ, ∀h &gt; N }) ≤ 1.</formula><p>Therefore, we again obtain (8) by ( <ref type="formula">10</ref>). Now, we consider all possible cases under (5), all of which lead to E |p ∞α)| = 0. But this result is what we try to show in this proof anyway. Therefore, to continue to prove, let us accept that there exists such a set E A with true probability P &gt; 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Now, note that E</head><formula xml:id="formula_44">A = {ω ∈ ß ∞ = ∞ j=0 ß t k j : 1 {ω} = 1 when P (A t k j +1 |ß t k j ) = β = α for all t kj 's along the test set} ⊂ {ω ∈ ß ∞ = ∞ j=0 ß t k j : 1 {ω} = 1 when | lim h→∞ 1 h h-1 j=0 P (A t k j +1 |ß t k j ) -α| =</formula><p>0 for all t kj 's along the test set}.</p><p>Then, since P (E A ) &gt; 0, P ( | lim h→∞ 1 h h-1 j=0 P (A t k j +1 |ß t k j ) -α| = 0 for all t kj 's along the test set ) &gt; 0. Thus, since we found one subsequence of</p><formula xml:id="formula_45">{ 1 h h-1 j=0 P (A t k j +1 |ß t k j )} ∞</formula><p>h=1 as such along the test set with true probability P &gt; 0 and p ∞ exists,</p><formula xml:id="formula_46">P (| lim k→∞ 1 k k-1 t=0 P (A t+1 |ß t ) -α| = 0 along the test set) &gt; 0 for α = 0.</formula><p>Then, by the same reasoning as in Lemma 4.10,</p><formula xml:id="formula_47">E | lim k→∞ 1 k k-1 t=0 P (A t+1 |ß t ) -α| = 0. Now, by Lemma 4.11, we obtain that E |p ∞ -α| ≥ E | lim k→∞ 1 k k-1 t=0 P (A t+1 |ß t ) -α| = 0 when p ∞ exists. Clearly, when p ∞ does not exist, E |p ∞ -α| = 0.</formula><p>Therefore, we conclude that if</p><formula xml:id="formula_48">P (P (A t+1 |ß t ) = α at least i.o.) &gt; 0, then E |p ∞ -α| = 0. Q.E.D.</formula><p>Proof of Theorem 4.19 First, let us first note that with P -probability &gt; 0, P (A t+1 |ß t ) = 1 at least infinitely often for some event A t+1 . Otherwise, beyond the near future, all events A t+1 's would certainly continue to occur, with P -probability one, and thus there would be no uncertainty about any A t+1 's. Now, if this is the case, then we must stop here and simply conclude that no machine would be able to learn the true probability of any A t+1 , simply because there is no uncertainty for any machine to measure by the true probability in our world. Therefore, to continue to prove our main claim, we accept that P (P (A t+1 |ß t ) = 1 at least i.o.) &gt; 0 for some event A t+1 . Now, let us consider the test set where α * = 1. Then, along the stochastic path of this test set, P (P (A t+1 |ß t ) = α * at least i.o) &gt; 0. Therefore, we found some α * for which Nature is perverse with true probability P &gt; 0. Now, suppose that, for any α, P (P (A t+1 |ß t ) = α ) &lt; 1 at least for infinitely many t's. In other words, P (P (A t+1 |ß t ) = α ) &gt; 0 at least i.o. Then, 0 &lt; lim sup Proof of Theorem 4.20 Suppose that, for any α, P (P (A t+1 |ß t ) = α ) &lt; 1 at least for infinitely many t's. Then, by Theorem 4.17 and Theorem 4.19, E |p ∞ -α| = 0 and so P ( p k → α) = 1 for any α ∈ ℜ[0, 1] where P is the true objective probability defined over ß ∞ = ∞ t=0 ß t and the expectation E is taken with respect to this true probability P. Then, by Theorem 4.6, the machine cannot learn the true objective probability P (A t+1 |ß t ). Q.E.D.</p><p>Proof of Lemma 4.23 Suppose that the machine effectively calculates Π(A t+1 |ß t ) as α with the goal of learning the true value of P (A t+1 |ß t ). Then, by the necessary condition for learning, the machine must return Π(A t+1 |ß t ) which is congruent to P (A t+1 |ß t ) = α, in order to achieve this goal. Now, suppose further that the machine calculates at the same time Π({P (A t+1 | ß t ) = α}) = 0. Then the machine tolerates error by Definition 4.21.</p><p>However, by Theorem 4.6, the machine cannot tolerate errors infinitely often to achieve this goal of learning for the following reason: for any α ∈ ℜ[0, 1], suppose that Π(A t+1 |ß t ) = α but Π({P (A t+1 |ß t ) = α}) &gt; 0 infinitely often. Now, since it must be that P (A t+1 |ß t ) = Π(A t+1 |ß t ) = α to learn the true probability, it must also be by Theorem 4.6 that</p><formula xml:id="formula_49">P (p k → α) = Π (p k → α) = 1. But now, by assumption, Π({P (A t+1 |ß t ) = α}) &gt; 0 infinitely often, which leads to that 0 &lt; lim sup t→∞ Π({P (A t+1 |ß t ) = α}) ≤ Π({P (A t+1 |ß t ) = α} at least i.o).</formula><p>But this contradicts Π (p k → α) = 1 by the same reasoning as in the proof of (Case 3) in Theorem 4.17 while replacing P by Π and so the machine cannot learn the true probability by Theorem 4.6. Therefore, the machine cannot tolerate errors infinitely often if the machine aims to learn the true probability. Since α was arbitrary in ℜ[0, 1], let α = 0, the desired result. Q.E.D</p><p>Proof of Lemma 4.28 (i) Proof of "if" part: suppose that there exists a stopping time t s &lt; ∞ for some forecast α 0 such that P (A α0 (t + 1)|ß t ) = 0, ∀t &gt; t s , while there exists no stopping time for any other α = α 0 so that P (A α =α0 (t + 1)|ß t ) &gt; 0 at least infinitely often. Then, by the definition of A α0 (t + 1) and the law of iterated expectations, (11) P (A α0 (t + 1)) ց P ( lim t→∞ A α0 (t + 1)), because A α0 (t + 1) ց lim t→∞ A α0 (t + 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Now that lim</head><p>t→∞ A α0 (t + 1) is the event that P (A t+1 |ß t ) = α 0 at least i.o. and so that the limit exists, (12) 0 = lim t→∞ P (A α0 (t + 1)) = P (P (A t+1 |ß t ) = α 0 at least i.o.) for α 0 .</p><p>Also, in the same logic as for α 0 , (13) 0 &lt; lim t→∞ P (A α (t + 1)) = P (P (A t+1 |ß t ) = α at least i.o.) for any α = α 0 .</p><p>Thus, by Definition 4.25, Nature is selectively perverse.</p><p>(ii) Proof of "only if" part: suppose that Nature is selectively perverse. Then, by Definition 4.25, there must exist some α 0 such that P (P (A t+1 |ß t ) = α 0 at least i.o.) = 0. Now, for reductio, suppose that for any such α 0 there exists no stopping time t s so that P (A α0 (t + 1)|ß t ) &gt; 0 at least infinitely often. In other words, Nature keeps changing her mind infinitely often between perversity and non-perversity or Nature keeps being perverse all the way long. Then, by law of iterated expectation, P (A α0 (t + 1)) &gt; 0 at least infinitely often, which contradicts the selective perversity of Nature by the same reasoning as in (13). Q.E.D.</p><p>Proof of Lemma 4.29 For any given α 0 with which Nature is not perverse with true probability P -one, there exists t s &lt; ∞ for this α 0 by Lemma 4.28. Now, by assumption, machines learn that P (A α0 (t + 1)|ß t ) = 0 ∀t &gt; t s . Thus, Π(A α0 (t + 1)|ß t ) = 0 ∀t &gt; t s by the necessary condition for learning. Then, by Lemma 4.23 and the same reasoning as (11) in the proof of Lemma 4.28,</p><formula xml:id="formula_50">Π(P (A α0 (t + 1)|ß t ) = 0, ∀t &gt; t s ) = 1. Q.E.D.</formula><p>Proof of Corollary 4.30 (i) Suppose that Nature is selectively perverse so that P (A α0 (t + 1)|ß t ) = 0 ∀t &gt; t s for some α 0 by Lemma 4.28. However, since the machine is assumed not to be self-assured that the stopping time t s arrives for that α 0 , the machine cannot learn that P (A α0 (t + 1)|ß t ) = 0 ∀t &gt; t s by Lemma 4.29.</p><p>(ii) Now, note that if the machine learns P (A t+1 |ß t ) as α 0 , the machine also learns that P (P (A t+1 |ß t ) = α 0 at least i.o.) = 0 in the following way: first, by Theorem 4.6 and (Case 3) in Theorem 4.17, machine learning of the true probability P (A t+1 |ß t ) as α 0 mathematically implies that P (P (A t+1 |ß t ) = α 0 at least i.o.) = 0. Thus, once the machine learns the true probability P (A t+1 |ß t ) as α 0 , it cannot fail to effectively calculate the true probability P (A α0 (t + 1)) as 0, following Theorem 4.6 and (Case 3) in Theorem 4.17 as instructions. Then, by Definition 2.2, the machine learns that P (A α0 (t + 1)) = 0 in particular ∀t &gt; t s , so that P (A α0 (t + 1)|ß t ) = 0 ∀t &gt; t s while following law of iterated expectation as instruction. However, as we proved it in (i), the machine cannot learn that P (A α0 (t + 1)|ß t ) = 0 ∀t &gt; t s . Hence we conclude that the machine cannot learn the true objective probability P (A t+1 |ß t ) as α 0 either. Q.E.D.</p><p>Proof of Lemma 4.31 Suppose that the machine is not self-assured of the stopping time t s for α 0 . Then, ( <ref type="formula">14</ref>) Π(P (A α0 (t + 1)|ß t ) = 0, ∀t &gt; t s ) = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Now that lim</head><p>t→∞ P (A α0 (t + 1)) = P (P (A t+1 |ß t ) = α 0 at least i.o.) for this α 0 , (15) Π( P ( P (A t+1 |ß t ) = α 0 at least i.o.) = 0) = 1.</p><p>Then, since lim sup t→∞</p><formula xml:id="formula_51">P ( P (A t+1 |ß t )) = α 0 ) ≤ P ( P (A t+1 |ß t ) = α 0 at least i.o.) = 0, (16) Π( P ( P (A t+1 |ß t ) = α 0 ) = 1 ∀t &gt; t * ) = 1, for some t * &lt; ∞.</formula><p>Now, note that along the stochastic path considered in Corollary 4.30, P (P (A t+1 |ß t ) = α 0 at least i.o.) = 0 ∀t &gt; t s . Now, for this α 0 , (17) lim sup t→∞ P (P (A t+1 |ß t ) = α 0 ) ≤ P (P (A t+1 |ß t ) = α 0 at least i.o) = 0</p><p>Therefore, without loss of generality, letting t * ≥ t s with t * &lt; ∞, (18) P (P (A</p><formula xml:id="formula_52">t+1 |ß t ) = α 0 ) = 1, ∀t &gt; t * ≥ t s with t * &lt; ∞.</formula><p>Then, without loss of generality, let P (P (A t+1 |ß t ) = α 0 ) = 1 at t * +1 by ( <ref type="formula">18</ref>). Thus, ( <ref type="formula">16</ref>) and ( <ref type="formula">18</ref>) lead to the desired result by Lemma 4.15. Q.E.D</p><p>Proof of Theorem 4.32 Suppose that the machine learns the true probability. Since the machine cannot learn if Nature is uniformly perverse, Nature must then be selectively perverse so that the stopping time t s exists by Lemma 4.28. Then, by the (ii) part of Corollary 4.30 and Lemma 4.29, the machine is self-assured of the stopping time t s when t s exists. We now finish the proof of Theorem 4.32 by showing that if the machine learns the true probability, the machine is not self-assured of the stopping time t s when such t s does not exist.</p><p>Suppose that the machine is self-assured of the stopping time t s even though such t s does not exist. The machine is then wrong about t s , so it cannot learn the true probability along the path where P (A α (t + 1)|ß t ) &gt; 0 at least i.o. for the following reason: first, by Lemma 4.28, with true probability P &gt; 0, Nature is perverse to the forecast α along the path where there is no stopping time t s . Thus, P (P (A t+1 |ß t ) = α at least i.o.) &gt; 0 for such forecast α. Then, by the (Case 3) of Theorem 4.17 and then Theorem 4.6, the machine cannot learn that α. In other words, the world does not exist in the way that Nature allows the machine to learn the true probability. Notwithstanding, the machine has a wrong belief about the stochastic path of the true probability, and so cannot learn the true probability. Q.E.D.</p><p>Proof of Theorem 4.35 Suppose that the machine is self-assured of stopping time t s along the path where, for any given α 0 , P (A α0 (t + 1)|ß t ) = 0 ∀t &gt; t s . Then, along this path, the machine obtains</p><formula xml:id="formula_53">Π(P (A α0 (t + 1)|ß t ) = 0 ∀t &gt; t s ) =</formula><p>1 and so Π(A α0 (t + 1)|ß t ) = 0 ∀t &gt; t s by Lemma 4.23. Now, by the definition of A α0 (t + 1) and Lemma 4.23 again, Π(A t+1 |ß t ) = α 0 , ∀t &gt; t * &gt; t s for some t * &lt; ∞</p><p>Note also that P (A t+1 |ß t ) = α 0 , ∀t &gt; t * &gt; t s for some t * &lt; ∞ along this path.</p><p>(</p><formula xml:id="formula_54">) P (A t+1 |ß t ) = α 0 = Π(A t+1 |ß t ), ∀t &gt; t * with t * &lt; ∞.<label>19</label></formula><p>Then, as in Theorem 4.6, we can construct a test set along the stochastic path by the assessed α 0 as a selection criterion by <ref type="bibr">(19)</ref>. This test set is also truly guaranteed to be well-calibrated.</p><p>Thus, from this test set along the path, the machine obtains the following by Lemma 4.10 and Lemma 4.11, (ii) Proof of "only if" part: suppose that the machine directly observes the true probability P (A t+1 |ß t ) as α from the given population S at some time t * . The machine then effectively calculates Π(A t+1 |ß t ) as α at t * , while adopting the following as an instruction: recall that the given set S consists of the sequence of events A t+1 's, {A t+1 } k-1 t=0 with k potentially infinite. Since the set S is available in principle to the machine by the part (i) of Definition 4.34, there must exist some rule on how to collect the available set of events {A t+1 } k t=0 . Then let the machine build up the population S by collecting events while following the rule on how-to. Now, once collected by the machine to constitute the set S, it must have been observed whether each event has a certain attribute of interest or not, and so a value of the indicator variable 1 {At+1} must have been assigned accordingly to each event A t+1 by the machine. Then, let the machine calculate Π(A t+1 |ß t ) as α = 1 k k-1 t=0 1 {At+1} . Therefore, the machine effectively calculates Π(A t+1 |ß t ) as α.</p><p>Furthermore, note that 1 k k-1 t=0 1 {At+1} is defined to be P (A t+1 |ß t ) at t * by the part (ii) in Definition 4.34. The machine then cannot fail to compute P (A t+1 |ß t ) as α from the population S. Therefore, the machine learns the true probability P (A t+1 |ß t ) as α by Definition 2.2. Q.E.D.</p><p>Proof of Corollary 4.37 Let us first define what we mean by "most of the time" in the success criterion (1). by Lemma 4.10 and Theorem 4.17, machines cannot satisfy the calibration property when the test set is constructed by the selection criterion of an assessed probability α if P (P (A t+1 |ß t ) = α at least i.o.) &gt; 0. Therefore, in order to learn, the machines must return the correct calculations except a finite number of times out of infinite opportunities to learn. Thus, "most of the time" in the Success Criterion (1) should be "all but finitely often out of infinite opportunities to learn," which means that machines must be correct not just infinitely often while being wrong that often. Now suppose that the machine is correct most of the time when the machine aims to learn the true probability P (A t+1 |ß t ). Then, by the (Case 1) in Theorem 4.17, P (P (A t+1 |ß t ) = α at most f.o.) = 1. Thus, there exists a stopping time t s because P (P (A t+1 |ß t ) = α at least i.o.) = 0 if and only if there exists a stopping time t s for any machine forecast α by Lemma 4.28. Furthermore, suppose that the machine is self-assured that it is correct most of the time. Then, again by Lemma 4.28, Π( there exists a stopping time t s ) = 1. Thus, if the machine satisfies the Success Criterion (1), then it satisfies the condition of Theorem 4.35. Therefore, if the machine satisfies the Success Criterion (1), it can learn the true probability by Theorem 4.35 and Theorem 4.36. Q.E.D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Some Literature for the Necessary Condition in Sec. 3.2</head><p>There has been a large literature in logic and economics whose discussion implies when a machine holds a true belief in the probabilistic proposition A p . For example, while defining the concept of rationality in the economics model, <ref type="bibr" target="#b5">(Cogley &amp; Sargent, 2008;</ref><ref type="bibr" target="#b6">2009)</ref>, <ref type="bibr" target="#b27">(Sandroni, 2000)</ref>, <ref type="bibr" target="#b0">(Blume &amp; Easley, 2006;</ref><ref type="bibr">2008)</ref> and many others stipulate that an agent is rational when his/her partial beliefs are correct in the sense that his/her subjective probability distributions are congruent to the true probability distribution which Nature identifies as such. In other words, this means that a machine holds such a true belief in A p when it is rational, which entails that its subjective probability Π is equal to the true objective probability P.</p><p>Also, in probabilistic logic, <ref type="bibr" target="#b20">(Nilsson, 1986)</ref>, <ref type="bibr" target="#b13">(Halpern &amp; Fagin, 1994)</ref>, and many others follow the probabilistic version of the Tarskian semantic theory of truth in the following way: a formula describing the subjective probability of an agent is true when the agent's probability assignment corresponds to what the sentence in fact represents. For example, in <ref type="bibr" target="#b13">(Halpern &amp; Fagin, 1994)</ref>, a formula like w i (ϕ) ≥ 2w i (ψ) is true if, according to the probability assignment of the agent i, the event ϕ is at least twice as probable as ψ. Now, if we extend this idea to the true objective probability P if any, a formula such as w i (ϕ) = w(ϕ), where w i denotes the probability operator of the agent i and w does that of Nature, is true when, according to the assignment of the agent i's probability, the event ϕ is as probable as what Nature assigns on ϕ as the true probability value in our world.</p><p>It deserves to note from the economics literature when it becomes true that agent i's partial belief on the event ϕ has a degree w i (ϕ) which corresponds to the true objective probability w(ϕ). This is indeed true when the subjective probability of the agent i, w i (ϕ) is in congruence with the true objective probability w(ϕ), which again makes the formula w i (ϕ) = w(ϕ) true. Therefore, the condition for any agent to be rational (or rational machine in our context) in economics is equivalent to the truth condition for the formula in probabilistic logic. In other words, ß t is the historical path of true facts up to time t. To recognize that Assumption 4.2 is reasonable, recall that we are handling with objective probability true to our world. Therefore, its condition must also be true in our world. Otherwise, P (A t+1 |ß t ) cannot represent the true probability according to which the actual data are realized in our world. For example, if there works some special gravity force on Mars and so a fair coin lands on its edge as equally likely as on its head or tail, then the probability of the coin landing on the head conditional on this hypothesis will be 1 3 . However, if such a special gravity force actually does not exist on Mars, this conditional probability 1 3 cannot be true either, because its data would not be realized according to the probability of 1 3 in our world. Assumption 4.3 No further knowledge requirement is imposed on the condition ß t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Justifications for the Three Assumptions</head><p>To recognize that Assumption 4.3 is reasonable, note the following: If ß t is the set of known facts, then P (A t+1 |ß t ) can vary from person to person, as the set of events known to each person may be different, depending on who possesses what information. In order for P (A t+1 |ß t ) to be objective, however, P (A t+1 |ß t ) should not depend on each person. Therefore, we require that ß t consist of true facts, not necessarily knowledge.</p><p>Assumption 4.4 Once a probability of an event type E is established, its associated event tokens E t k 's occur at some infinite subsequence of time t k ' s, so that P (E t k ) does not vanish to zero as t k → ∞.</p><p>Here, "event token" refers to the event that ever occurs at some specific time and place, while "event type" refers to the abstract object with no specific space-time location. For example, cloudy weather in Denver is an abstract event type E with no time subscript, while cloudy weather in Denver on 29 May 2024 is a particular event token E t0 . Some literature (e.g. <ref type="bibr" target="#b12">(Halpern, 2016</ref>)) deals mainly with probability of token events, while some literature (e.g. <ref type="bibr" target="#b17">(Maher, 2010</ref>)) deals mainly with probability of type events. Assumption 4.4 establishes a connection between the probabilities of these two kinds of events.</p><p>In order to recognize that Assumption 4.4 is reasonable, consider now the following example: suppose that we try to predict the probability that some person i suffers from lung cancer caused by his/her smoking habit. As we discussed in the Introduction, this causal probability is objective, which is relevant to our discussion. Then, as long as the probability of the event type of having lung cancer from smoking is allowed to be considered for forecasting, we require that the true probability of the associated event tokens for some persons i's should not be completely zero from some time t 0 &lt; ∞ onward. In other words, although the true probability of such event tokens is allowed to be intermittently zero, the probability of the associated event tokens should not vanish to zero as k → ∞.</p><p>It might be pointed out that a particular person, say Mary, will die some time in the future, and that it will not make sense to consider the probability of Mary's suffering from lung cancer after that time any more. However, unless all generations of our human beings suddenly become extinct in the near future, we can consider the true probability of this event token at least for some person i at each time t. Hence it would make sense to forecast the probability of such an event token in each specific case, as t → ∞.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. More Detailed Remarks</head><p>Remark 2.4 Now, let F be the sigma-field generated by Ω and ω t = (S -1 0 (s 0 ), . . . , S -1 t (s t ), Ω t+1 , Ω t+2 , . . .) ∈ Ω denote a partial history through date t. Then, for any probability measure p t on F t , p t (ω t ) becomes the (marginal) probability of the partial history, and each ω t is assumed to be F t -measurable. Note then that p t (ω t ) = t τ =1 p(ω τ |F τ -1 ) for any t, and so p t (ω t ) = p(ω t |F t-1 )p t-1 (ω t-1 ). Furthermore, when s t is only either 0 or 1, S t (ω t ) becomes an indicator function for an event {ω t }. Then, provided that there indeed exists any true objective probability P , p({ω t }|F t-1 ) = P ({ω t }|F t-1 ) = E(S t (ω t ) = 1|F t-1 ) where the expectation E is taken with respect to this true probability P .</p><p>For example, let S t be an i.i.d. random variable whose value is 1 if the event {ω t } occurs at t and 0 otherwise. Then,</p><formula xml:id="formula_55">X n = n k=1</formula><p>S k will be the number of events that have occurred up to time n. Since S t is i.i.d., p({ω t }|F t-1 ) is same as</p><formula xml:id="formula_56">P ({ω t }) across time. Now, let lim n→∞ Xn n = lim n→∞ 1 n n k=1</formula><p>S k be the ratio of events that ever occur. Then, provided that this limit indeed exists, the dominated convergence theorem and Fubini's theorem imply that E{ lim</p><formula xml:id="formula_57">n→∞ 1 n n k=1 S k } = P ({ω t }).</formula><p>Thus, in the i.i.d. case, we can derive that with the true probability Pone, the true objective probability of the event {ω t } is the limiting relative frequency which is objective.</p><p>By stipulating that the true objective probability follows the rule on how Nature generates each actual data point, we emphasize that the true probability here is something objective, not subjective, but no more or no less than that. "Nature" is just a metaphor for describing the relationship of true probability with our objective world. Adopting the widely accepted statistical notion of a data-generating process, we intend to use the term "Nature" to refer to whatever is supposed to govern the underlying true objective process to generate the actual data. Given that Nature is simply a metaphor, it is important to emphasize that, in order to prove the possibility or the impossibility of machine learning on the true objective probabilities, we do not need to commit ourselves to whether there really exists such a thing as a true objective process: probability might be merely something subjective which has nothing to do with "Nature." If that is the case, then we conclude that p t = α ∀t &lt; n so that P (A t+1 |ß t ) = α ∀t &lt; n while processing the data to learn. Remark 4.9 Indeed, it may well be argued against the <ref type="bibr" target="#b23">(Oakes, 1985)</ref> Counterexample that, although it could be imagined so, Nature actually never behaves in that way. There is no reason why Nature is so perverse that she generates data in such a deviating way. The true objective probability of Nature being perverse may be simply zero. Then, Theorem 4.1 and Theorem 4.8 do not necessarily imply that a machine cannot learn the true probability. Theorem 4.8 shows only to the extent that if a machine can imagine such a counterexample, and thus it sincerely believes in such possibility, then its subjective probability of long-run mis-calibration is not zero. But recall the Descartes' Demon case from Section 3.1. A simple possibility of imagination does not necessarily imply a real possibility, namely that the true objective probability of it occurring in the actual world is not zero. Theorem 4.1 and Theorem 4.8 show only that if a machine cannot exclude such a counterexample, it cannot be self-assured to be well-calibrated with its own subjective probability 1. However, recall that there exists an asymmetric relation between subjective and objective probabilities: objective probability binds subjective probability, but not necessarily vice versa. Thus, if the true probability of Nature's perversity is proven to be zero, the machine can exclude such a possibility, and so its subjective probability on Oakes' counterexample will be zero as well. Then, from this it is derived neither that the machine cannot be self-assured to be well-calibrated nor that it cannot be truly guaranteed to be so, which implies that the impossibility of machine learning does not necessarily follow from Theorem 4.6.</p><p>Later by Theorem 4.19, we prove that such an imagined possibility of Nature's being perverse is a real one if the true probability is not observable. Meanwhile, we will also prove mathematically how <ref type="bibr" target="#b23">(Oakes, 1985)</ref> Counterexample paralyzes Dawid's Theorem 4.1, which amounts to the proof of Theorem 4.8. Note that if the true probability indeed escapes from the machine's forecast just as in <ref type="bibr" target="#b23">(Oakes, 1985)</ref>, Theorem 4.1 breaks down: Theorem 4.1 critically relies on the martingale property of k t=1 X t given ß k-1 where X t = ( t j=1 ξ j ) -1 • ξ t (Y t -Ŷt ), which was from E(X k |ß k-1 ) = 0. This martingale property, however, breaks down when P (A t+1 |ß t ) = E(Y t+1 |ß t ) = Ŷt+1 = Π(A t+1 |ß t ) for all t. Note that <ref type="bibr" target="#b7">(Dawid, 1982)</ref> takes it for granted that E(Y t+1 |ß t ) = Π(A t+1 |ß t ) = Ŷt+1 for all t. Therefore, if we relax this assumption, we can prove mathematically how <ref type="bibr" target="#b23">(Oakes, 1985)</ref> works against <ref type="bibr" target="#b7">(Dawid, 1982)</ref>, which will be shown from (Case 2) in the proof of Theorem 4.17.</p><p>Remark 4.12 Regarding Lemma 4.10 and Lemma 4.11, it deserves to note the following two things: first, note that we do not require any standard assumption such as the stochastic process to be i.i.d. along the historic path of the test set and so that P (A t+1 |ß t ) can vary along the path. Note also that unlike <ref type="bibr" target="#b0">(Blume &amp; Easley, 2006;</ref><ref type="bibr">2008)</ref>, etc., we do not require to consider all the associated events A t 's along the stochastic path, but that we consider only the events A t 's whose assessed probabilities are α. The set of those events A t 's is called a test set, because it is collected according to the selection criterion of being assessed constantly as α. Therefore, we do not assume any specific property of the stochastic process along the path in the test set, such as stationarity or ergodicity. We do not assume any specific properties because we include only the arbitrary subsequences of the stochastic process into the test set according to the subjective assessment. where expectation is taken with respect to the true probability P. Then, from this equation, we establish a connection between the true guarantee of well-calibration and the real forecasting game between a machine and Nature: (i) the true guarantee of well-calibration is connected to forecasting games between a machine and Nature, for what the machine forecasts is α while what Nature forecasts is P (A tj +1 |ß tj ) and thus whether | lim k→∞ 1 k k-1 j=0 P (A tj +1 |ß tj ) -α| = 0 holds or not is tied to how Nature and the machine play in the forecasting games along the stochastic path of the test set. In this game, the machine loses at time t whenever Nature succeeds in deviating from machine forecasting at that time. There is some literature which deals with the problem of well-calibration in various forecasting game settings. (e.g. <ref type="bibr">(Foster &amp; Vohra, 1993</ref>)) (ii) Also, note that, in the proof of Lemma 4.11, we take both the inner and outer expectations with respect to the true probability P while applying the law of iterated expectations. Thus, it is a real game, not any arbitrarily imaginary one, for | lim Remark 4.14 Now, let us establish a connection between the true second-order probability and the forecasting game between Nature and a machine. For simplicity, let us denote by ∆ t the event at time t that P (A t+1 |ß t ) = α for any machine forecast α. In other words, ∆ t denotes the event that the machine makes the correct forecast at time t, which amounts to that the machine wins the forecasting game at that time. Note here that, strictly speaking, the event ∆ t is a complex event which consists of two events, the event of {P (A t+1 |ß t ) = α} and the event of {Π(A t+1 |ß t ) = α} for the same functional value α while P (A t+1 |ß t ) and Π(A t+1 |ß t ) are two probability functions about the common event A t+1 , that is {∆ t } = {P (A t+1 |ß t ) = α = Π(A t+1 |ß t )}. However, since we consider only the test set along the stochastic path, here we take it that Π(A t+1 |ß t ) is fixed as α along the path.</p><p>Then, extending some notions from <ref type="bibr" target="#b11">(Gaifman, 1986)</ref>, let us derive a second-order probability, i.e. the probability of probability, from the outcomes of the forecasting game between Nature and the machine as follows: for any event A t+1 , the true second-order probability P is the probability of the meta-event that the first-order probability (either Nature's true forecast or the machine's subjective forecast) of A t+1 actually has a certain numerical value α ∈ ℜ[0, 1]. Thus, the true second-order probability P denotes P ( P (A t+1 |ß t ) = α ).</p><p>Here, it deserves to note that although we derive the notion of higher-order probabilities by extending some notions from <ref type="bibr" target="#b11">(Gaifman, 1986)</ref>, our notion is different from his in the following way: we do not distinguish the first-order and the secondorder probabilities while using the same notation as P, although <ref type="bibr" target="#b11">Gaifman(1986)</ref> uses P and PR operator to denote the second-order probability and the event on the first-order probability, respectively. This is because Gaifman's notions are different from ours in that (1) P in Gaifman denotes the agent subjective probability, while our second-order probability P can be a true objective one just like the first-order true probability, and that (2) his P R operator accepts a closed interval as one of its arguments, while our domain of the second-order probability P does not contain intervals of real numbers. Note that our domain of the second-order probability is assumed to be generated by the collection of all the singletons of the computable real values of the first-order true probability function P , and that it is assumed to be countable. Thus, the domain does not contain intervals of real numbers. (3) In addition, our notion of the first-order probability is not imprecise but precise one, so it is not supposed to be what belongs to any interval or any set of probability measures. Now, the probability space of the second-order probability is defined as (Ω, G, P ), in which Ω is the set of all the computable functional values for any given true first-order probability function P (A t+1 |β t ), G is a field generated by the collection of all the singletons in Ω, and P is the second-order probability with P : G → ℜ[0, 1]. Note here that Ω is countable and that Ω is the set of all the possible forecasts by machines on the event A t+1 given β t . Now, if the domain of the second-order probability is a sigma-field F generated by Ω, then the problem here is that the sigma-field F becomes uncountable given that Ω is countable. So, we should consider a field G, not sigma-field F for the probability space of the second-order probability P .</p><p>Here are some justifications for defending the use of a field G, not sigma-field F , as a domain of the second-order probability P : we do not require the domain of the second-order probability to include all the countably infinite unions, for the number of strategies a machine can use then becomes uncountable, which is contradictory to the fact that the set of numbers a machine can compute is countable. In our forecasting game, any singleton in Ω can be thought of as a pure strategy by the machine and any union of those singletons as a mixed strategy by the machine. Again, since the set of numbers a machine can compute is countable, a machine cannot compute uncountably many mixed strategies.</p><p>Remark 4.22 Recall from the necessary condition for learning in Section 3.2 that P (A t+1 |ß t ) = Π(A t+1 |ß t ) = α if the machine learns the true probability P (A t+1 |ß t ) as α. Definition 4.21 then means that while the machine calculates the value of Π(A t+1 |ß t ) as α to learn the true probability P (A t+1 |ß t ) at time t, the machine assigns its Πprobability &gt; 0 to the event that P (A t+1 |ß t ) = α, because the machine tolerates the error that the true value of P (A t+1 |ß t ) may not be very α at that time t. In Lemma 4.23, we prove that a machine cannot tolerate errors infinitely often if it aims to learn the true probability.</p><p>Remark 4.24 For example, in <ref type="bibr" target="#b28">(Savage, 1972)</ref>, a vacuous event is null, but not every null set is necessarily vacuous. Here, an event is null to an agent when the event is believed to be impossible to the very agent, and thus its subjective probability is zero to the agent. On the other hand, a vacuous event has absolute impossibility whose true objective probability is zero by the Kolmogorov axiom. Thus, the objective true probability of an absolutely impossible event here binds its subjective probability to zero, but not necessarily vice versa.</p><p>We now extend this idea in <ref type="bibr" target="#b28">(Savage, 1972)</ref> to all virtually impossible events. Here, note that absolute impossibility is assigned to a vacuous event by the Kolmogorov axiom, while virtual impossibility is assigned to any event whose true objective probability measure is zero by Nature. Thus, in Lemma 4.23, we derive that all virtually impossible events</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>Remark 4.22. In relation to Lemma 4.23, more detailed interpretation on Definition 4.21 is provided in Appendix D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>since p ∞ exists by the assumption, tj +1 |ß tj ) also exists and thus E tj +1 |ß tj ). Now, by the law of iterated expectations,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>t→∞P</head><figDesc>(P (A t+1 |ß t ) = α) ≤ P (P (A t+1 |ß t ) = α at least i.o). Thus, by Definition 4.18, Nature is uniformly perverse, which again means by Definition 4.13 that P ( Nature is perverse ) &gt; 0 for any α ∈ ℜ[0, 1]. Q.E.D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc>t+1 |ß t ) = α 0 ) = 1 if and only if P ( lim us gather the sequence of {A t+1 } ∞ t=t * along the path and call this set a population. The machine then effectively calculates the true probability P (A t+1 |ß t ) as α 0 by the empirical distribution out of this population by (20), which satisfies (i) in Definition 4.34. Also, this effective calculation of the empirical distribution must be successful in returning the true probability P (A t+1 |ß t ), for 1 n t * +n t=t * P (A t+1 |ß t ) in the right-hand side of (20) is equal to P (A t+1 |ß t ), ∀n and ∀t &gt; t * by (19), which satisfies (ii) in Definition 4.34. Therefore, by Definition 4.34, the machine directly observes the true probability P (A t+1 |ß t ) as α 0 . Q.E.D Proof of Theorem 4.36 (i) Proof of "if" part: follows directly from Theorem 4.32 and Theorem 4.35.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>Assumption 4.2 ß t 's in P (A t+1 |ß t ) are the set of all the true facts up to time t.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><figDesc>Second, by Lemma 4.10 and Lemma 4.11, we obtain that ifP (p k → α) = 1, then E | lim tj +1 |ß tj ) -α| = 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>P</head><figDesc>(A tj +1 |ß tj ) -α| = 0 is expected to hold with respect to the true probability P , not any other subjective probability Π.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The author is grateful to <rs type="person">Tyler Burge</rs>, <rs type="person">Michael Christ</rs>, <rs type="person">Philip Dawid</rs>, <rs type="person">Joseph Halpern</rs>, <rs type="person">Jinho Kang</rs>, <rs type="person">Steven Matthews</rs>, <rs type="person">Thomas Sargent</rs>, and <rs type="person">Byeong-uk Yi</rs> for discus-</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>no machines can learn the true objective probabilities simply because there exist no such things as true probabilities for machines to learn.</p><p>Remark 3.1 The standard theory of subjective probability was first developed by Ramsey and then further by De Finetti and Savage. Subjective probability is designed to represent a degree of belief possessed by a subject, say some person. Here, two words, degree and belief, deserve to be noted. First, subjective probability represents some aspects of belief. However, belief is an inner thought that, in principle, resists a direct observation, while probability quantification requires measurability. Note that the easiest method of measurement is by observation. Thus, in order for the degree of belief to be quantified as a probability measure, it works well if the unobservable is made observable. Here comes in the relationship between unobservable belief and observable action: belief causes action. According to <ref type="bibr" target="#b25">(Ramsey, 1931)</ref>, the strength of our belief can be judged in relation to how we should act in hypothetical situations. Given a preferential system on the lotteries of a set of conditions, the choice action under hypothetical circumstances will reveal the degree of belief of some relevant agent. In this vein, subjective probability represents whatever is in any one's mind upon anything as long as his/her belief system is coherent, and thus can be even assigned to what is merely imagined. For instance, while arguing for cogito, ergo sum, <ref type="bibr" target="#b8">(Descartes, 2008)</ref> imagined some evil spirit that has devoted all its efforts to deceiving him. Then, Descartes can assign some value of subjective probability to such imagination on the evil spirit, according to how likely it is to him that such imagination can be realized in this world, as long as Descartes' belief system is coherent.</p><p>Second, it is assumed that the degree of belief ranges between 0 and 1. For example, your belief that there will be rain tomorrow has a degree strictly less than 1 and thus is called a partial belief, because you have some unconfidence on future events. In addition to this quantitative usage of the term "belief", however, there is another categorical usage: "belief" refers to the proposition that something is the case or that something is not the case, or none of them. For instance, your belief in the Moorean fact that here is one hand represents either the case or not, or it is on suspension. Compared to partial belief, this qualitative belief is called belief simpliciter. As the term "belief" has these two faces, gradational quantitative and categorical qualitative ones, numerical degrees are assigned to partial belief, while truth values are assigned to belief simpliciter. In this paper, we abbreviate belief simpliciter by "belief" and denote partial belief by "partial belief" as it is.</p><p>In contrast, objective probability, if any, is what must be determined by objective features of the world that do not vary from person to person. Following <ref type="bibr">(Nagel, 1939)</ref> and <ref type="bibr" target="#b3">(Carnap, 1963)</ref>, we list chance, logical probability, and relative frequency as exhaustive examples of objective probability. The best way to clarify these concepts is to consider their examples. Following <ref type="bibr" target="#b17">(Maher, 2010)</ref>, for example, suppose that a coin has the same face on both sides, that is, two-headed or two-tailed. Provided further that it is completely uncertain what face value, head or tail, the coin has on both sides, the chance of getting head when tossed is 1 or 0, while its logical probability is 1 2 . Furthermore, when the coin is tossed infinitely often, its relative frequency surely converges to 1 or 0.</p><p>Here, the chance is either 1 or 0, depending on what our world is like, namely, whether the coin is indeed two-headed or two-tailed. Therefore, the chance is objective in the sense that it depends on real features of the coin, not on any personal inner thought. On the other hand, the logical probability is 1 2 , because it is logically implied from the given conditions that the coin has the same face value on both sides, but that whether it is two-headed or two-tailed is completely uncertain. Therefore, logical probability is also objective in the sense that it depends on the logical features of our world, not on us. Clearly, the relative frequency is what our world turns out to be, not whatever we believe. However, no matter what interpretation of probability is adopted among these three kinds, it is important to note that the true objective probability P in Definition 2.3 is a mathematical object that is supposed to represent any of them as long as they satisfy the Kolmogorov axioms.</p><p>Remark 4.7 It should be noted that Theorem 4.6 is our building block to prove when a machine cannot learn the true probability, because p ∞ in Theorem 4.6 denotes the limiting relative frequency along the test set, the representative true objective probability. We do not consider any limiting behavior of the relative frequency outside the test set, because learning as α per se is not possible outside the test set by the necessary condition for learning in Section 3.2. Therefore, if it is shown to be impossible that with P -probability one, p k → α along the stochastic path of the test set collected by the assessed α, then it is derived from Theorem 4.6 that the machine cannot learn the true probability. . .) = 1. Thus, Theorem 4.6 is not committed to what the machine engages in by the first n -1 number of data while "learning". This concept of machine learning is flexible enough to allow for some finitely few potential errors where also have a subjective probability Πzero infinitely often whenever the agent is self-assured that such events are truly impossible, for the subjective probability must be bound to the true objective probability Pzero, if any. Otherwise, the machine comes to tolerate error infinitely often, which makes it impossible for the machine to achieve its goal of learning the true probability.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">If you&apos;re so smart, why aren&apos;t you rich? belief selection in complete and incomplete markets</title>
		<author>
			<persName><forename type="first">L</forename><surname>Blume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Easley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="929" to="966" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Market selection and asset pricing. The Handbook of Financial Markets: Dynamics and Evolution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Blume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Easley</surname></persName>
		</author>
		<editor>T. Hens IV and K. Schenk-Hoppe</editor>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="403" to="438" />
			<pubPlace>North-Holland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">G</forename><surname>Boolos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName><surname>Computability</surname></persName>
		</author>
		<author>
			<persName><surname>Logic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Logical Foundations of Probability. The University of</title>
		<author>
			<persName><forename type="first">R</forename><surname>Carnap</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963">1963</date>
			<publisher>Chicago Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An unsolvable problem of elementary number theory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Church</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Mathematics</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="345" to="363" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The market price of risk and the equity premium: A legacy of the great depression</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cogley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sargent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Monetary Economics</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="454" to="476" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Diverse belief, survival and the market price of risk</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cogley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sargent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economic Journal</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="354" to="376" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The well-calibrated bayesian</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dawid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">379</biblScope>
			<biblScope unit="page" from="604" to="613" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Meditations on First Philosophy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Descartes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
	<note>Translated by Moriarty. M.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Asymptotic calibration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vohra</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="379" to="390" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A theory of higher order probabilities</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gaifman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TARK</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><surname>Causality</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reasoning about knowledge and probability</title>
		<author>
			<persName><forename type="first">J</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Computing Machinery</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="340" to="367" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Hintikka</surname></persName>
		</author>
		<author>
			<persName><surname>Knowledge</surname></persName>
		</author>
		<author>
			<persName><surname>Belief</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962">1962</date>
			<publisher>Cornell University Press</publisher>
			<pubPlace>Ithaca</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Kozen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Computability</forename><surname>Automata</surname></persName>
		</author>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A subjectivist&apos;s guide to objective chance. Studies in Inductive Logic and Probability</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
		<editor>R. Jeffrey</editor>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page" from="263" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Explication of inductive probability</title>
		<author>
			<persName><forename type="first">P</forename><surname>Maher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Philosophical Logic</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="593" to="616" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A formal theory of knowledge and action. Formal Theories of the Commonsense World</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Moore</surname></persName>
		</author>
		<editor>J. Hobbs and R. C. Moore,</editor>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Ablex Publishing Corp</publisher>
			<biblScope unit="page" from="319" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Principles of the theory of probability</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Encycl. Unif. Sc</title>
		<imprint>
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1939</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Probabilistic logic</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nilsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="71" to="87" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Artificial Intelligence: A New Synthesis</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nilsson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>California</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Algorithmic Game Theory</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roughgarden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Vazirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Self-calibrating priors do not exist</title>
		<author>
			<persName><forename type="first">D</forename><surname>Oakes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">390</biblScope>
			<biblScope unit="page">339</biblScope>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A personal journey into bayesian networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
		<respStmt>
			<orgName>UCLA Cognitive Systems Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>R-476</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Truth and probability. Studies in Subjective Probability</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ramsey</surname></persName>
		</author>
		<editor>Henry Kyburg and Howard smokler</editor>
		<imprint>
			<date type="published" when="1931">1931</date>
			<biblScope unit="page" from="25" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning agents for uncertain environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh Annual Conference on Computational Learning Theory</title>
		<meeting>the Eleventh Annual Conference on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="101" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Do markets favor agents able to make accurate predictions?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sandroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1303" to="1341" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The Foundations of Statistics</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Savage</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<publisher>Dover Publications</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The semantic conception of truth: and the foundations of semantics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tarski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy and Phenomenological Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="376" />
			<date type="published" when="1944">1944</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On computable numbers, with an application to the entscheidungsproblem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Turing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the London Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="230" to="265" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A theory of the learnable</title>
		<author>
			<persName><forename type="first">L</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1134" to="1142" />
			<date type="published" when="1984-11">Nov. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Knowledge infusion: In pursuit of robustness in artificial intelligence</title>
		<author>
			<persName><forename type="first">L</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc 28th Conference on Foundations of Software Technology and Theoretical Computer Science</title>
		<meeting>28th Conference on Foundations of Software Technology and Theoretical Computer Science</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="415" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Mises, R. Probability, Statistics and Truth. revised English edition</title>
		<imprint>
			<date type="published" when="1957">1957</date>
			<publisher>Macmillan</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Mathmatical Theory of Probability and Statistics. 2nd edition</title>
		<author>
			<persName><forename type="first">R</forename><surname>Von Mises</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1967">1967</date>
			<publisher>Academic Press Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
