<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Representation Learning for Electronic Health Records</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2019-09-19">19 Sep 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wei-Hung</forename><surname>Weng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
						</author>
						<title level="a" type="main">Representation Learning for Electronic Health Records</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-09-19">19 Sep 2019</date>
						</imprint>
					</monogr>
					<idno type="MD5">FD745724CE47157D51EC0078BBCC5AE0</idno>
					<idno type="arXiv">arXiv:1909.09248v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Information in electronic health records (EHR), such as clinical narratives, examination reports, lab measurements, demographics, and other patient encounter entries, can be transformed into appropriate data representations that can be used for downstream clinical machine learning tasks using representation learning. Learning better representations is critical to improve the performance of downstream tasks. Due to the advances in machine learning, we now can learn better and meaningful representations from EHR through disentangling the underlying factors inside data and distilling large amounts of information and knowledge from heterogeneous EHR sources.</p><p>In this chapter, we first introduce the background of learning representations and reasons why we need good EHR representations in machine learning for medicine and healthcare in Section 1. Next, we explain the commonly-used machine learning and evaluation methods for representation learning using a deep learning approach in Section 2. Following that, we review recent related studies of learning patient state representation from EHR for clinical machine learning tasks in Section 3. Finally, in Section 4 we discuss more techniques, studies, and challenges for learning natural language representations when free texts, such as clinical notes, examination reports, or biomedical literature are used. We also discuss challenges and opportunities in these rapidly growing research fields.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Learning Representations for Medicine and Healthcare</head><p>Medicine and healthcare has become one of the key applied machine learning research domains due to increasing adoption of electronic health records (EHR) and the increasing 1 MIT CSAIL, Cambridge, MA, USA. Correspondence to: Wei-Hung Weng &lt;ckbjimmy@mit.edu&gt;. power of computation <ref type="bibr" target="#b15">(Charles et al., 2013;</ref><ref type="bibr" target="#b124">Topol, 2019)</ref>. Researchers have framed various medical and healthcarerelated challenges as machine learning tasks and adopted various algorithms to tackle them with massive amounts of medical data <ref type="bibr" target="#b124">(Topol, 2019)</ref>. Some examples of commonlyseen topics in machine learning for medicine and healthcare research include diagnosis support <ref type="bibr" target="#b83">(Lipton et al., 2016;</ref><ref type="bibr">Choi et al., 2016c;</ref><ref type="bibr" target="#b55">Gulshan et al., 2016;</ref><ref type="bibr" target="#b43">Esteva et al., 2017)</ref>, outcome and risk prediction <ref type="bibr" target="#b48">(Ghassemi et al., 2014;</ref><ref type="bibr" target="#b46">Futoma et al., 2015;</ref><ref type="bibr">Choi et al., 2016a;</ref><ref type="bibr">Xiao et al., 2018b)</ref>, patient phenotyping <ref type="bibr" target="#b98">(Miotto et al., 2016;</ref><ref type="bibr" target="#b3">Baytas et al., 2017)</ref>, optimal decision making <ref type="bibr" target="#b111">(Raghu et al., 2017;</ref><ref type="bibr">Weng et al., 2017a;</ref><ref type="bibr" target="#b72">Komorowski et al., 2018)</ref>, and workflow improvement <ref type="bibr" target="#b59">(Horng et al., 2017;</ref><ref type="bibr">Chen et al., 2019a)</ref>.</p><p>Researchers have utilized various types of EHR data in addressing these tasks, such as lab measurements <ref type="bibr" target="#b107">(Pivovarov et al., 2015)</ref>, claims data <ref type="bibr" target="#b41">(Doshi-Velez et al., 2014;</ref><ref type="bibr" target="#b107">Pivovarov et al., 2015;</ref><ref type="bibr">Choi et al., 2016e)</ref>, clinical narratives <ref type="bibr" target="#b107">(Pivovarov et al., 2015;</ref><ref type="bibr">Weng et al., 2017b)</ref>, medical images <ref type="bibr" target="#b55">(Gulshan et al., 2016;</ref><ref type="bibr" target="#b43">Esteva et al., 2017;</ref><ref type="bibr" target="#b7">Bejnordi et al., 2017;</ref><ref type="bibr" target="#b86">Liu et al., 2017;</ref><ref type="bibr" target="#b108">Poplin et al., 2018;</ref><ref type="bibr" target="#b101">Nagpal et al., 2019)</ref>, as well as waveform signals <ref type="bibr" target="#b79">(Lehman et al., 2018)</ref>. Many efforts use multiple such modalities of available data.</p><p>For medical and healthcare applications, it is critical to develop robust techniques that can not only yield good performance on given tasks but also provide efficiency, reliability, and explainability <ref type="bibr" target="#b123">(Szolovits &amp; Pauker, 1978;</ref><ref type="bibr" target="#b122">Szolovits, 1982)</ref>, to improve the likelihood of their practical clinical deployment <ref type="bibr">(Chen et al., 2019b)</ref>. For example, applying an attention mechanism or interpretable models give us better explainability of the model behavior or the prediction <ref type="bibr" target="#b2">(Bahdanau et al., 2015;</ref><ref type="bibr" target="#b112">Ribeiro et al., 2016;</ref><ref type="bibr" target="#b87">Lundberg &amp; Lee, 2017)</ref>. Designing models with a robust optimization to tolerate adversarial examples provides the model reliability <ref type="bibr" target="#b90">(Madry et al., 2018)</ref>. Preprocessing data appropriately and making better data representations for algorithms allow us to develop models with better performance and also interpretability.</p><p>A good representation organizes the data in a way that machine learning algorithms can learn models with good performance from them. It also transforms the data into a form that provides human interpretability given a suitable model design. For example, the radial domain folding al-gorithm, an unsupervised multivariate clustering method developed by <ref type="bibr" target="#b67">(Joshi &amp; Szolovits, 2012)</ref>, abstracts the patient states and summarizes the patient physiology from vitals, labs, and clinical categorical data to a dense but rich representation using domain knowledge. The resulting model outperforms classical clinical scoring systems on the critical patient mortality prediction task while retaining human understandability of the representation. A good representation may also be derived from multimodal data sources <ref type="bibr">(Weng et al., 2019a)</ref>. <ref type="bibr" target="#b120">(Suresh et al., 2017)</ref> preprocessed, transformed, and represented the raw data from different modalities (static variables such as demographics, time-varying variables like vital signs and labs, and clinical narrative notes) into a representation for clinical intervention prediction tasks. They transformed the clinical notes into a low-dimensional vector of topic distributions to preserve the human interpretability of the representation. Therefore, having appropriate representations is essential for modeling since it provides the fundamental organization of the data in both a machine and human understandable language <ref type="bibr" target="#b8">(Bengio et al., 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">From Expert-curated to Learning-based Representations</head><p>From domain expert-curated to fully-automated approaches, healthcare information can be represented by different techniques for downstream modeling. Traditionally, researchers work heavily with medical experts on data preprocessing and curation to obtain meaningful feature sets (clinical variables) that are derived from domain knowledge. The commonly-used clinical scoring and grading models heavily rely on domain experts to identify and curate important clinical features. For example, APACHE (Acute Physiology and Chronic Health Evaluation) score <ref type="bibr" target="#b71">(Knaus et al., 1985)</ref> and SOFA (Sequential Organ Failure Assessment) score <ref type="bibr" target="#b129">(Vincent et al., 1996)</ref> for evaluating the patient severity in the intensive care unit (ICU) setting, CHADS2 score for stroke risk assessment in patients with atrial fibrillation <ref type="bibr" target="#b47">(Gage et al., 2001)</ref>, MELD (Model For End-stage Liver Disease) score for liver transplant <ref type="bibr" target="#b68">(Kamath et al., 2001)</ref>, and KDIGO (Kidney Disease Improving Global Outcomes) score <ref type="bibr" target="#b81">(Levey et al., 2005)</ref> for outcome prediction of acute kidney injury, are all scoring models with a small number of clinical predictors that are identified by domain experts or even randomized controlled trials. The advantage of such expert-intensive feature engineering is interpretability and explainability of developed models. However, such an approach is hard to generalize and scale up, and may not be able to capture hidden patterns inside complicated, heterogeneous data.</p><p>Instead of using problem-specific, manually curated predictors, adopting machine learning, specifically representation learning techniques, may help to represent data bet-ter for model development, with the potential to discover hidden patterns and new knowledge <ref type="bibr" target="#b37">(Davis et al., 1993;</ref><ref type="bibr" target="#b14">Caruana et al., 2015)</ref>. Through learning from data, machine learning techniques allow us to perform feature engineering with less expert effort. Taking clinical narratives as an example, we can learn the simple but powerful statisticsbased lexical features identified by natural language processing (NLP) techniques-bag-of-words or n-gram algorithms-to represent the unstructured free text in a machine understandable form for further model development without annotations from experts <ref type="bibr" target="#b91">(Marafino et al., 2014;</ref><ref type="bibr">Weng et al., 2017b)</ref>. It is also possible to integrate domain knowledge from existing knowledge bases, i.e., ontologies, while learning representations. We can utilize the general biomedical knowledge base, Unified Medical Language System (UMLS) Metathesaurus <ref type="bibr" target="#b12">(Bodenreider, 2004)</ref>, the Semantic Network <ref type="bibr" target="#b93">(McCray et al., 2001;</ref><ref type="bibr" target="#b92">McCray, 2003)</ref>, Medical Subject Headings (MeSH), or other biomedical knowledge bases to identify and transform the unstructured medical information into meaningful and machinecomprehensible representations. Clinical NLP systems such as Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) <ref type="bibr" target="#b115">(Savova et al., 2010)</ref>, MetaMap <ref type="bibr" target="#b1">(Aronson, 2001)</ref>, Clinical Language Annotation, Modeling and Processing Toolkit (CLAMP) <ref type="bibr" target="#b118">(Soysal et al., 2017)</ref>, and the Clinical Named Entity Recognition system (CliNER) <ref type="bibr" target="#b11">(Boag et al., 2018)</ref>, help annotate and extract clinically meaningful concepts from unstructured clinical texts and link them to standard terminologies, such as UMLS concept unique identifiers (CUIs), to obtain interpretable representations in a unified language. For example, <ref type="bibr">(Weng et al., 2017b)</ref> applied both simple lexical features and identified CUIs with semantic filtering to unstructured clinical free texts and obtained clinically meaningful representations for a downstream classification task. They demonstrated that the representation considering both language (lexical features) and domain knowledge (CUIs) outperformed other methods on the classification task, with clinical interpretability. The standardization of representation using ontology also provides a great opportunity to harmonize unstructured data in multiple datasets, which is essential for developing models across datasets <ref type="bibr" target="#b53">(Gong et al., 2017)</ref>.</p><p>Learning representations directly from raw data without extracting and mapping concepts to existing knowledge bases is an alternative to further reduce human involvement, which may increase the machine's potential for exploring and identifying hidden patterns inside the data. <ref type="bibr" target="#b45">(Fonarow et al., 2005)</ref> utilized the classification and regression trees algorithm (CART) to automatically create a series of clinically meaningful rules purely from data, and applied the rules to the mortality risk stratification problem for patients with acute decompensated heart fail-ure. We can also learn high-level abstract representations by disentangling the underlying factors and distilling large amounts of information in heterogeneous clinical data through advanced learning algorithms. Such abstract representations usually provide generalizable power for different machine learning scenarios such as semi-supervised learning, multitask learning <ref type="bibr">(Weng et al., 2019a)</ref>, transfer learning, and domain adaptation, which is useful for common medical and healthcare-related tasks where data are scarce or inaccessible for an intended application but similar data, say from other institutions, are more easily available. <ref type="bibr" target="#b48">(Ghassemi et al., 2014)</ref> applied the topic modeling algorithm, latent Dirichlet allocation (LDA) <ref type="bibr" target="#b9">(Blei et al., 2003)</ref>, to learn the latent representations of clinical progress notes and predict mortality in the critical care setting.</p><p>For time-series data, the hyper-parameters used for nonparametric multitask Gaussian processes can be the latent features <ref type="bibr" target="#b49">(Ghassemi et al., 2015)</ref>, and switching-state autoregressive models can also model the underlying state representations <ref type="bibr" target="#b50">(Ghassemi et al., 2017)</ref>.</p><p>Among various machine learning algorithms, deep learning-a family of neural network-based algorithms advocated by connectionism <ref type="bibr" target="#b113">(Rumelhart &amp; McClelland, 1986</ref>)-is the one that can learn more abstract representations through multiple non-linear transformations within a highly modularized framework <ref type="bibr" target="#b8">(Bengio et al., 2013;</ref><ref type="bibr" target="#b77">LeCun et al., 2015)</ref>. Learning representations using deep learning has achieved numerous successes in several domains with different data modalities, such as natural language in free text <ref type="bibr">(Mikolov et al., 2013b;</ref><ref type="bibr">a;</ref><ref type="bibr" target="#b75">Le &amp; Mikolov, 2014;</ref><ref type="bibr" target="#b13">Bojanowski et al., 2017;</ref><ref type="bibr" target="#b105">Peters et al., 2018;</ref><ref type="bibr" target="#b40">Devlin et al., 2019)</ref>, audio and speech processing <ref type="bibr" target="#b33">(Chung et al., 2016;</ref><ref type="bibr">Chung &amp; Glass, 2018)</ref>, and computer vision <ref type="bibr" target="#b73">(Krizhevsky et al., 2012)</ref>. Researchers in the medicine and healthcare domain are also making great efforts to approach problems using a deep learning approach <ref type="bibr" target="#b55">(Gulshan et al., 2016;</ref><ref type="bibr" target="#b141">Yala et al., 2017;</ref><ref type="bibr" target="#b32">Chung &amp; Weng, 2017;</ref><ref type="bibr" target="#b111">Raghu et al., 2017;</ref><ref type="bibr">Choi et al., 2016a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Basics of Deep Learning-based Representation Learning</head><p>Representation learning is one of the successful and exciting fields in recent machine learning research. The hallmark of contemporary machine learning has been to transform discrete problems and representations into continuous ones, where models are typically differentiable and therefore continuous optimization techniques-rather than combinatorial discrete methods-can be applied.</p><p>The goal of representation learning is to encode and represent (embed) raw input information into small, dense and distributed embedding vectors (embeddings) in a continu-ous vector space, where similar inputs can be mapped to nearby points, i.e. embedded close to each other. The inputs can be either dense or sparse, e.g., image pixels, audio segments, time points in time-series or irregularly occurring events, numbers, words, context, or clinical concepts, depending on the task, and the embeddings are usually computed via optimizing the parameters of neural network models given machine learning tasks, such as classification, regression, sequence prediction, next word prediction, and the corresponding objective functions. Such learned embeddings may capture semantic, linguistic, temporal or spatial relations between the inputs <ref type="bibr">(Mikolov et al., 2013b;</ref><ref type="bibr">a;</ref><ref type="bibr" target="#b73">Krizhevsky et al., 2012)</ref>, computed from statistical properties of the relations among the data. These representations can be used not only directly for similar information retrieval, such as a search for similar clinical cases, but also as inputs for various downstream machine learning tasks, such as clinical prediction and classification, due to their generalizability <ref type="bibr" target="#b32">(Chung &amp; Weng, 2017;</ref><ref type="bibr">Weng et al., 2017a)</ref>. Compared to traditional discrete encoding techniques such as one-hot encoding and the bagof-words model, the distributed representation learning approach better handles the issues of the curse of dimensionality, matrix sparsity, and feature dependency in the discrete encoding approach since the features can be embedded in a low-dimensional space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Mechanisms</head><p>Due to advances in neural network architecture design, we now can embed the raw input into a vector space using different network architectures based on characteristics of given tasks. For example, we use convolutional neural network (CNN)-based models, such as AlexNet, Inception, or ResNet, for computer vision problems to preserve spatial information <ref type="bibr" target="#b76">(LeCun et al., 1998)</ref>, recurrent neural network (RNN)-based models-conventional RNN, RNN with long short-term memory (LSTM) or gated recurrent units (GRU) <ref type="bibr" target="#b58">(Hochreiter &amp; Schmidhuber, 1997;</ref><ref type="bibr">Cho et al., 2014a)</ref>, and attention-based models like Transformer for free texts and time-series data to keep more sequential properties <ref type="bibr" target="#b128">(Vaswani et al., 2017;</ref><ref type="bibr" target="#b40">Devlin et al., 2019)</ref>. We may also adopt graph-based models for data with underlying network structure <ref type="bibr" target="#b70">(Kipf &amp; Welling, 2017)</ref>, or just simply use multilayer perceptrons (MLP) if the features are independent and identically distributed.</p><p>The function of neural networks can further be augmented by adding various techniques for different purposes, such as sequence-to-sequence (seq2seq) and encoderdecoder frameworks for learning structured information <ref type="bibr" target="#b121">(Sutskever et al., 2014;</ref><ref type="bibr">Cho et al., 2014a;</ref><ref type="bibr">b)</ref>, attention mechanisms for model interpretability <ref type="bibr" target="#b2">(Bahdanau et al., 2015;</ref><ref type="bibr" target="#b128">Vaswani et al., 2017)</ref>, or generative adversarial network (GAN) for data synthesis <ref type="bibr" target="#b54">(Goodfellow et al., 2014)</ref>.</p><p>Encoder-Decoder Architecture There are some fundamental neural network designs for representation learning with the deep learning approach. The most intuitive and general architecture is the encoder-decoder framework design, such as a sequence-to-sequence (seq2seq) or autoencoder model <ref type="bibr" target="#b57">(Hinton &amp; Salakhutdinov, 2006;</ref><ref type="bibr" target="#b121">Sutskever et al., 2014)</ref>. The encoder is simply a function that maps an input space to a latent space, and the decoder is another function that maps the latent space to a target space. One can design an encoder-decoder system using any neural network components, such as CNN or RNN, to encode the complex input into a compressed latent space representation, and decode the representation to a target output. The latent representations, i.e., embeddings, in the network layers between the encoder and decoder can therefore become the representation of the given input.</p><p>For example, seq2seq is a framework that takes a sequence of input data and transforms it into a latent representation, and decodes the representation to another sequence, such as in the task of English to French translation. Autoencoders form a family of neural network-based models-a special case of an encoder-decoder framework-to learn to transform a complex input into a compressed representation and then to translate that into a reconstruction of the input, minimizing reconstruction loss, i.e., the difference between the model input and output <ref type="bibr">(Rumelhart et al., 1986;</ref><ref type="bibr" target="#b57">Hinton &amp; Salakhutdinov, 2006)</ref>. Therefore, the decoder in an autoencoder framework is a structure that reverses the functionality of the encoder. For example, doing convolution while encoding and deconvolution while decoding using CNN as the components. Since the output and input for an autoencoder framework are the same, the method therefore become a common approach in unsupervised learning scenarios. The intuition behind this form of representation learning is that the compressed representation best captures the essence of the data while ignoring happenstantial variation.</p><p>Researchers also apply sparse autoencoders (SAE) and denoising autoencoders (DAE) to learn sparse representations and learn robust representations through noise injection <ref type="bibr" target="#b130">(Vincent et al., 2008)</ref>. Such variants of autoencoder are helpful when data are noisy or has significant missingness-for example, vital signs and lab measurements in the EHR.</p><p>To obtain task-specific representations for predictive models, the decoder can be replaced by other network components, such as fully connected layers, with an appropriately defined loss function (objective function), whose aim is to optimize the model via specific downstream auxiliary tasks. In this case, the learned representation will be biased to the given task. Using downstream auxiliary tasks is a common approach to learn patient state representations from EHR.</p><p>We will discuss this more in Section 4.</p><p>Learning Representations from Sequences Another mechanism of representation learning is to learn cooccurrence information from sparse inputs or sequences, such as sentences, paragraphs, documents, or time-series signal sequences. For example, two popular models in NLP belong to this category-word2vec and GloVe (Global Vectors) <ref type="bibr">(Mikolov et al., 2013b;</ref><ref type="bibr">a;</ref><ref type="bibr" target="#b104">Pennington et al., 2014)</ref>. The word2vec model uses unsupervised skip-gram and continuous bag-of-word (CBOW) algorithms to obtain the embedding in a vector space of the tokens in an online fashion. Skip-gram' objective is, for each word w(n), to minimize the difference of predicted and actual probabilities of tokens {w n-k , ..., w n-1 , w n+1 , ..., w n+k } within a window of size k of w(n). The objective of CBOW, on the other hand, aims to infer the current token w(n) from its nearby tokens {w n-k , ..., w n-1 , w n+1 , ..., w n+k } <ref type="bibr">(Mikolov et al., 2013b)</ref>. In either case, a single-layer neural network is trained to optimize these predictions, and its weight vector is taken to be the embedding of w(n). The GloVe model instead aims to learn the embedding space via precomputing the co-occurrence matrix of the whole corpus and factorizing it using the asynchronous stochastic gradient descent (SGD) algorithm <ref type="bibr" target="#b104">(Pennington et al., 2014)</ref>. These methods can also be generalized to any sequential data modalities.</p><p>Word-level representations can also be learned at the subword level, i.e., using character information <ref type="bibr" target="#b13">(Bojanowski et al., 2017)</ref>. The word representation with subword information may overcome the issue of outof-vocabulary or misspelled words and may better capture the semantics in word morphology <ref type="bibr" target="#b13">(Bojanowski et al., 2017;</ref><ref type="bibr">Weng et al., 2019b)</ref>. Many of medicine and healthcare NLP studies use either word2vec or GloVe to train the word or concept-level representations or adopt pre-trained word2vec or GloVe embeddings for their downstream tasks <ref type="bibr" target="#b131">(Wang et al., 2018)</ref>. However, the limitation of such approaches is that they determine a single embedding vector for all occurrences of a token and do not consider the context around the token, which may lead to the issue of word sense ambiguity.</p><p>Model Pre-training and Transfer Learning Learning representations from pre-trained models trained on large datasets, such as ImageNet, and using the features extracted from such models to modify the weights of a target model (fine-tuning), often called transfer learning, has been a relatively standard approach for computer vision tasks <ref type="bibr" target="#b73">(Krizhevsky et al., 2012)</ref>.</p><p>Recently, model pre-training has also dramatically reshaped the NLP community due to its ability to capture better semantics <ref type="bibr" target="#b60">(Howard &amp; Ruder, 2018)</ref> and allow transfer learning from large general domain language cor-pora to smaller domain-specific NLP tasks <ref type="bibr" target="#b40">(Devlin et al., 2019;</ref><ref type="bibr" target="#b60">Howard &amp; Ruder, 2018;</ref><ref type="bibr" target="#b142">Yang et al., 2019)</ref>. With large corpora, context-aware models such as ELMo (Embeddings from Language Model) <ref type="bibr" target="#b105">(Peters et al., 2018)</ref>, ULMFiT (Universal Language Model Finetuning) <ref type="bibr" target="#b60">(Howard &amp; Ruder, 2018)</ref>, GPT (Generative Pre-training Transformer) <ref type="bibr" target="#b110">(Radford et al., 2018)</ref>, BERT (Bidirectional Encoder Representations from Transformers) <ref type="bibr" target="#b40">(Devlin et al., 2019)</ref>, and XLNet <ref type="bibr" target="#b142">(Yang et al., 2019)</ref> can pre-train the language model in an unsupervised way and fine-tune the model using task-specific supervised learning with auxiliary tasks.</p><p>ELMo concatenates independently trained multi-layer LSTMs in two directions to learn a contextualized representation without supervision <ref type="bibr" target="#b105">(Peters et al., 2018)</ref>, ULMFiT first incorporates the ideas of pre-trained language model and fine-tuning for transfer learning in NLP <ref type="bibr" target="#b60">(Howard &amp; Ruder, 2018)</ref>, GPT adopts the multi-layer transformer decoder as language model <ref type="bibr" target="#b110">(Radford et al., 2018)</ref>, BERT also takes advantages of a multi-layer transformer but uses it as a bi-directional encoder to acquire the natural language representation via two general auxiliary language tasks-masked language model (MLM) and next sentence prediction <ref type="bibr" target="#b40">(Devlin et al., 2019)</ref>. Differently from BERT, which trains the model in a denoising autoencoder fashion with MLM, XLNet uses an autoregressive pretraining method to obtain representations that yield even better performance on multiple natural language benchmark tests <ref type="bibr" target="#b142">(Yang et al., 2019)</ref>. ULMFiT, GPT, BERT and XLNet are agnostic to downstream tasks and therefore very flexible for transfer learning in natural language problems. Such a pre-trained and fine-tuning framework and a contextualized learning scheme mitigates the issue of word sense ambiguity by considering the surrounding context in general language models, which is critical in medical and healthcare domains, and has become the main approach for learning the natural language representation for all kinds of NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Evaluation</head><p>The learned representations, or embeddings, can be evaluated in both quantitative and qualitative ways. For quantitative evaluation, downstream tasks are usually required.</p><p>For example, we can conduct the information retrieval task to identify the most similar cases or tokens given learned representations and queries <ref type="bibr" target="#b131">(Wang et al., 2018;</ref><ref type="bibr">Weng &amp; Szolovits, 2018;</ref><ref type="bibr" target="#b62">Hsu et al., 2018)</ref>. Such tasks can be evaluated by accuracy, precision at K, or other metrics for information retrieval-mean reciprocal rank (MRR), mean average precision (MAP), and normalized discounted cumulative gain (nDCG) <ref type="bibr" target="#b64">(Järvelin &amp; Kekäläinen, 2002)</ref>.</p><p>The quality of learned representations can also be evalu-ated by specific auxiliary measures based on the performance of the task. For instance, studies use accuracy, the area under the ROC curve (AUROC, or simply AUC), precision, recall, and F1-score for prediction tasks <ref type="bibr" target="#b98">(Miotto et al., 2016;</ref><ref type="bibr">Weng et al., 2017b)</ref>, area under the Precision-Recall Curve (PR-AUC) for prediction tasks with imbalanced data <ref type="bibr" target="#b28">(Choi et al., 2018)</ref>, or other task-specific metrics such as BLEU score for NLP tasks.</p><p>The qualitative evaluation of the learned representations can be done by retrieval of similar cases <ref type="bibr">(Weng &amp; Szolovits, 2018;</ref><ref type="bibr" target="#b62">Hsu et al., 2018;</ref><ref type="bibr">Weng et al., 2019b)</ref> or visualization <ref type="bibr">(Choi et al., 2016b;</ref><ref type="bibr" target="#b32">Chung &amp; Weng, 2017;</ref><ref type="bibr">Xiao et al., 2018b)</ref>. Similar case retrieval is an interpretable, case-based reasoning approach to evaluate the quality of representations. For example, <ref type="bibr">(Weng &amp; Szolovits, 2018;</ref><ref type="bibr">Weng et al., 2019b</ref>) listed a few queries with their closest neighbors in the embedding vector space to demonstrate that the learned representations do capture the semantics of the corpora.</p><p>Visualization instead requires dimensionality reduction algorithms to get the dimensions to be two or three, which is visualizable for human interpretation. Principal component analysis (PCA) is a linear method for visualization that finds the principal components of the data by transforming data points into a new coordinate system. The non-linear algorithm, t-Distributed Stochastic Neighbor Embedding (t-SNE), is an alternative when we want to explore or visualize the data with higher dimension <ref type="bibr" target="#b89">(Maaten &amp; Hinton, 2008)</ref>. t-SNE is able to map high-dimensional data into a low-dimensional manifold by creating an embedding that attempts to maintain local structure within the data. However, t-SNE itself cannot be a method to learn representations since the model doesn't retain distances but estimates probabilities. Instead, Uniform Manifold Approximation and Projection (UMAP) is another manifold learning model that does support transforming new data into the embedding vector space, which allows UMAP to perform representation learning <ref type="bibr" target="#b94">(McInnes &amp; Healy, 2018)</ref>. Google researchers provide Embedding Projector for visualizing the learned representation using different models.<ref type="foot" target="#foot_0">foot_0</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Learning Patient State Representations</head><p>Learning good patient state representations is a critical step in clinical machine learning before conducting downstream tasks since the raw clinical data are usually unstructured and sparse <ref type="bibr" target="#b61">(Hripcsak &amp; Albers, 2012)</ref>. It is helpful to discover cohort or disease phenotypes and to predict the outcome of interest through the process of pattern mining of given heterogeneous medical and healthcare data.</p><p>To learn patient state representations, researchers usually leverage supervised downstream tasks for optimization, such as classification or regression, although unsupervised settings may provide less performant but more generalizable representations. Researchers can take advantage of modularized neural network architectures to develop such end-to-end learning scenarios. For example, in the Deep Patient model, (Miotto et al., 2016) used a three-layer stacked DAE with sigmoid activation functions to encode patient representations using diagnoses, medications, procedures, lab test codes, and 300 LDA-transformed clinical note topics, from the longitudinal EHR of 704,857 patients. They evaluated the model through disease classification and patient disease tagging tasks using random forest classifiers. The results show that the deep patient representations yielded better predictions than raw EHR features and the representations learned from PCA and k-means algorithms.</p><p>In this section, we discuss several issues and challenges while learning effective patient state representations, such as modeling EHR temporality and time irregularity found in patient histories and hospital visits, modeling the EHR hierarchy, domain knowledge injection, and model interpretability. We also review recent related studies about patient state representation learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Temporality and Irregularity</head><p>The temporal information in EHRs is necessary for learning better patient state representations since health status and disease both progress over time. Learning time-aware representations is critical to improving the performance of clinical decision support task. <ref type="bibr" target="#b17">(Che et al., 2015)</ref> utilized a stacked autoencoder to discover patient phenotypes and learn patient-level representations from clinical time-series data. Additionally, they integrated the tree-based ICD ontology as prior knowledge to regularize parameters in the top layer of the neural network. Such prior-based regularization biases the model toward prior domain knowledge and benefits performance. <ref type="bibr" target="#b74">(Lasko et al., 2013)</ref> also used a stacked autoencoder on time-series uric acid measurements to classify gout and acute leukemia. Researchers used CNN-and RNN-based neural networks to tackle the complex temporality of medical events in EHR as well. (Cheng et al., 2016) adopted the CNN-based model for the issue of temporality. They used a four-layer 1D-CNN with observation and prediction windows to learn the patient representation and predict congestive heart failure and chronic obstructive pulmonary disease. (Nguyen et al., 2017) proposed the Deepr model, which is also a CNN-based network, to identify predictive clinical motifs in the longitudinal EHR to perform risk prediction and detect interpretable clinical patterns. Using RNN-based models, (Lipton et al., 2016) learned the patient representation via an LSTM on sequential lab measurements. Their model classified 128 diagnoses with 13 frequently but irregularly sampled measurements from patients in a pediatric ICU and outperformed other strong baseline models such as logistic regression and MLP with expert-curated features. In the Doctor AI model, (Choi et al., 2016a) developed a GRU model to encode the sequential patient history into a patient-visit representation to make the differential diagnosis (multilabel prediction) for the new visit. The Doctor AI disease progression model outperformed logistic regression and MLP on the multilabel prediction reported by recall@30. They also demonstrated that domain adaptation is possible using the proposed technique. The learned coefficients can be transferred as the initialization of a new task on a different dataset. (Choi et al., 2016d) also used the GRU model that encodes the patient visit-representation by aggregating the learned code-level representations in the longitudinal EHR and used the representation to predict heart failure. They designed different time intervals of the observation window and the prediction window as the training and testing data, respectively, for outcome prediction. Both GRU and time interval window design help the model outperform other methods such as logistic regression, SVM, MLP and k-nearest neighbor (KNN). (Suresh et al., 2017) learned the patient representation using either CNN or LSTM with combined features, including static information, time-series lab and vital data, and LDA-transformed unstructured clinical notes. They compared the performance on five ICU intervention prediction tasks among different model architectures, and showed that given the learned representations, CNN and LSTM network architectures are similarly effective. The clinical interpretability can also be evaluated by feature-level occlusion in LSTM, or by convolutional filters in CNN.</p><p>The issue of time irregularity may also be approached by tweaking the components of neural network architectures. The DeepCare model adopted the LSTM, pooling and word embedding to encode patient history, infer current illness and predict outcome <ref type="bibr" target="#b106">(Pham et al., 2016)</ref>. They used time decay and time parameterization on the forget gate in the LSTM unit to handle time irregularity. For each hospital admission, a single vector representation was learned.</p><p>They integrated the intervention information to augment prediction power for disease progression modeling, intervention recommendation and future risk prediction. Instead, <ref type="bibr" target="#b3">(Baytas et al., 2017)</ref> proposed a time-aware LSTM (T-LSTM) autoencoder to tackle irregularity of time and learn a patient-level representation given sequential records of a patient. The LSTM cell memory learns time decay to discount the memory content according to the elapsed time, which is in an unsupervised learning setting. This patient subtyping model does capture the underlying structures in the sequences with time irregularities. <ref type="bibr" target="#b16">(Che et al., 2017)</ref> developed a GRU-based 2D-RNN model that applies the concept of dynamic time warping to measure similarity between two temporal sequences to model the gate parameters in the GRU. These approaches are all useful to tackle the issue of time irregularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Hierarchy</head><p>Instead of flattening different sets of information in the EHR by simply concatenating all vector representations, utilizing the inherent multilevel structure, such as the diagnosis-treatment relationship, of EHR can be useful to learn the patient state representations. In the Multilevel Medical Embedding (MiME) model, authors considered the multilevel structure of EHR and the complex interaction between diagnosis and treatment codes to encode the patient representations <ref type="bibr" target="#b28">(Choi et al., 2018)</ref>. They used the same auxiliary prediction task as <ref type="bibr">(Choi et al., 2016d)</ref> and conducted experiments in different settings of data size and visit complexity (disease-treatment interactions). The patient-level MiME representations outperformed standard word-level representations <ref type="bibr" target="#b28">(Choi et al., 2018)</ref>, med2vec <ref type="bibr">(Choi et al., 2016b)</ref>, and GRAM conceptlevel representations <ref type="bibr" target="#b27">(Choi et al., 2017)</ref>. <ref type="bibr" target="#b29">(Choi et al., 2019)</ref> further developed a graph convolutional transformer (GCT) to capture the underlying EHR structure when the underlying explicit structure information is missing. For example, the information in claims data is usually flat and we have no clues which treatment is related to certain lab data. GCT can discover implicit underlying structure with a Transformer-based model design. <ref type="bibr">(Xiao et al., 2018b)</ref> proposed the CONTENT model that hybridizes both the deep neural network and the probabilistic generative model to preserve the long-term (global context) and short-term information (local context), respectively, in the EHR. The authors used RNN to capture short-term local context, and topic modeling to learn the long-term global context of a patient's medical history. Such time-aware patient representations yield better performance while predicting hospital readmissions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Domain Knowledge</head><p>As mentioned in the beginning of the chapter, we can leverage the machine learning methods to learn a good representation using domain knowledge <ref type="bibr" target="#b67">(Joshi &amp; Szolovits, 2012)</ref>. Unlike many other domains, the clinical and biomedical world has many invaluable biomedical knowledge bases, expert-curated ontologies and a metathesaurus-UMLS-containing SNOMED-CT, ICD, CPT, LOINC, and NDC terminologies to help us while conducting clinical medicine and healthcare machine learning tasks. Injecting the prior knowledge leverages the interpretability and robustness of the learned representations. One can regard such a process as adding model regularization or injecting a bias toward the experts' "thoughts" and human judgment. <ref type="bibr" target="#b17">(Che et al., 2015)</ref> implemented a prior-based graph Laplacian regularization that integrates the relational information in the ICD-9 ontology represented as a weighted graph. Yet the graph Laplacian approach requires the appropriate definition of distance on graphs, which is usually not available. Instead, in the GRAM model the authors used a knowledge directed acyclic graph (DAG) to encode the ICD-9 ontology into a vector representation that considers its hierarchical relationship <ref type="bibr" target="#b27">(Choi et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Interpretability</head><p>Neural network models are notoriously known as blackbox methods. However, there are actually some approaches that can uncover the black-box and obtain some interpretability of the neural network-based models. For clinical medicine and the healthcare domain, it is critical to have not only quantitative evaluation but also qualitative, interpretable evaluation to convince medical professionals to adopt the technique. Otherwise, machine learning solutions won't be able to turn into deployable and actionable clinical decision support systems even with superior performance.</p><p>Interpretability can be considered at three stages-before, during and after model development. We can use exploratory data analysis (EDA) and data visualization to provide data interpretability before modeling. During model development, we may also obtain insights from ruled-based models, example-based case-based reasoning, or mimicking the model through knowledge distillation. Last but not least, we can explain model behavior or predicted results by giving interpretations after model development. For example, using an attention mechanism or encodergenerator framework to highlight where is the most consequential input for a model's prediction <ref type="bibr" target="#b2">(Bahdanau et al., 2015;</ref><ref type="bibr" target="#b80">Lei et al., 2016)</ref>.</p><p>The attention mechanism has been used in learning patient state representations <ref type="bibr" target="#b27">(Choi et al., 2017;</ref><ref type="bibr" target="#b52">Girkar et al., 2018)</ref>. <ref type="bibr">(Choi et al., 2016c)</ref> further developed the RETAIN model using a reverse time attention mechanism to mimic clinician behavior by time-reversing the EHR events. Such a design means that recent hospital visits are likely to receive higher attention, which may yield clinically actionable results. Local Interpretable Model-agnostic Explanations (LIME) <ref type="bibr" target="#b112">(Ribeiro et al., 2016)</ref>, as well as SHapley Additive exPlanations (SHAP) <ref type="bibr" target="#b87">(Lundberg &amp; Lee, 2017)</ref>, can both provide the unified framework and visualizable explanations to interpret the model outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Learning Clinical Language Representations</head><p>Clinical narratives such as clinical notes, examination reports, and biomedical literature can also become materials for learning patient state representations. However, additional techniques and modeling strategies are required due to the unstructured and discrete, sparse nature of natural language. When building machine learning models based on text in EHRs, one may adapt general purpose NLP approaches or one can focus on using medical terminologies and knowledge bases.</p><p>Representations of natural language tokens, such as word, sentence, document, or concept vector representations (embeddings), can be learned from the free texts in EHR by various models for sequences and transfer learning mentioned in Section 2.1, such as word2vec, GloVE, ELMo, or BERT. These models can embed the discrete language tokens into a continuous vector space as distributed, dense embeddings depending on the distributional hypothesis that argues the words that occur in the same contexts tend to have similar semantics <ref type="bibr" target="#b56">(Harris, 1954)</ref>. The advantage of learning natural language token embeddings is to obtain generalizable representations for later use.</p><p>In the general domain, researchers pre-trained word2vec 2 , GloVe 3 , ELMo 4 and BERT 5 embeddings on Wikipedia and Google News corpora. Such embeddings are widely used in different general and specific natural language tasks as the initial model, whose parameters are then incrementally tuned using smaller but task-specific datasets available from specific domains.</p><p>For learning clinical language representations, the type of natural language token (e.g., words, sentences, documents, or medical concept tokens, terms, or phrases) and the source of learning data play important roles in yielding a better quality of representation. In this section, we discuss the representation learning of natural language tokens and clinical concepts, and the challenges and opportunities of learning language representations such as data insufficiency, domain knowledge injection, and crossdomain/modal resource utilization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Natural Language Tokens Representations</head><p>With the standard representation learning techniques, wordlevel language representations (word embeddings) have been widely used in various clinical NLP applications such as named entity recognition (NER) <ref type="bibr" target="#b39">(Dernoncourt et al., 2017)</ref>, medical synonym extraction, relation extraction 2 <ref type="url" target="https://code.google.com/archive/p/word2vec/">https://code.google.com/archive/p/word2vec/</ref> 3 <ref type="url" target="https://nlp.stanford.edu/projects/glove/">https://nlp.stanford.edu/projects/glove/</ref> 4 <ref type="url" target="https://allennlp.org/elmo">https://allennlp.org/elmo</ref> 5 <ref type="url" target="https://github.com/google-research/bert">https://github.com/google-research/bert</ref> </p><p>(RE), biomedical information retrieval, and abbreviation disambiguation <ref type="bibr" target="#b131">(Wang et al., 2018)</ref>. To learn word-level representations in the medical domain, <ref type="bibr" target="#b109">(Pyysalo et al., 2013)</ref> used skip-gram to train on PubMed, PMC texts and the Wikipedia corpus to obtain the word embeddings from both biomedical and general-domain large corpora<ref type="foot" target="#foot_1">foot_1</ref> . <ref type="bibr" target="#b97">(Minarro-Giménez et al., 2014)</ref> also applied skip-gram to multiple biomedical-related corpora, such as PubMed, Merck Manuals <ref type="bibr" target="#b6">(Beers et al., 1999)</ref>, Medscape, Wikipedia, and combined corpora, to learn the word embeddings.</p><p>Sentence, paragraph and document-level representations can also be adopted for developing clinical machine learning models. To build higher-level representations, we may use the bag-of-words representation that simply summarizes or averages the word vectors in the sentence, paragraph, or document <ref type="bibr">(Weng et al., 2017b)</ref>. However, such an approach discards the information between tokens in the lower language hierarchy, e.g., the relationship between words. Instead, we can use contextualized representation learning methods to develop context-aware langauge representations. For example, <ref type="bibr" target="#b62">(Hsu et al., 2018)</ref> learned the sentence and paragraph representations from the pre-trained embeddings of a Universal Sentence Encoder that further fine-tuned on their own radiology corpus for the radiology report retrieval task.</p><p>Data Insufficiency and Transfer Learning For learning higher-level language token representations, the techniques based on deep learning and neural networks are data hungry. Insufficient data is usually an obstacle while learning representations directly from EHR or conducting any clinical machine learning projects. To handle the issue, we may leverage existing knowledge bases, the complex hierarchical structure of given data, and we can take advantage of the transfer learning framework. Researchers have used the concept of transfer learning to tackle the problems of medical database encoding change <ref type="bibr" target="#b53">(Gong et al., 2017)</ref> and hospital-specific prediction tasks <ref type="bibr" target="#b138">(Wiens et al., 2014;</ref><ref type="bibr">Weng et al., 2017b)</ref>. <ref type="bibr" target="#b42">(Dubois et al., 2017)</ref> transferred the learned representation from the source task of drug code prediction to the target task of patient phenotype prediction, which provides more potential clinical impact.</p><p>Well-learned latent representations of larger corpora can serve as general pre-trained language models for transfer learning across different machine learning tasks. We can fine-tune the model by starting with pre-trained language models trained on vast general purpose corpora, and then incrementally fine-tuning these models using the typically smaller data sets available from medical corpora. <ref type="bibr" target="#b69">(Khin et al., 2018;</ref><ref type="bibr" target="#b144">Zhu et al., 2018)</ref> 7 applied pre-trained ELMo to medical texts for de-identification and other clinical NLP benchmark tasks <ref type="bibr" target="#b127">(Uzuner et al., 2011)</ref>. <ref type="bibr" target="#b78">(Lee et al., 2019)</ref> released the BioBERT model<ref type="foot" target="#foot_3">foot_3</ref> , which is trained on a general domain corpus and fine-tuned on biomedical text such as PubMed. <ref type="bibr" target="#b0">(Alsentzer et al., 2019)</ref> took one more step toward EHR by pre-training clinically oriented BERT models with clinical notes in the MIMIC-III database <ref type="bibr" target="#b66">(Johnson et al., 2016)</ref>, either all notes or focusing on discharge summaries, on top of BERT and BioBERT models, and demonstrates that the specialized clinical BERT models outperformed others in the clinical NLP tasks<ref type="foot" target="#foot_4">foot_4</ref> . <ref type="bibr" target="#b63">(Huang et al., 2019)</ref> also developed a clinical BERT model<ref type="foot" target="#foot_5">foot_5</ref> by fine-tuning the BERT model on EHR for the hospital readmission task. Such improvement on clinical specific tasks may result from the difference in linguistic features between general, biomedical and clinical narratives. <ref type="bibr" target="#b117">(Si et al., 2019)</ref> investigated the capability of a traditional word-or subword-level approach, e.g., word2vec, GloVe, fastText, and the contextualized methods like ELMo and BERT on a clinical concept extraction task and demonstrated that the contextualized methods achieve better performance on various benchmark tests in the i2b2 and SemEval datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Concept Representations</head><p>Biomedical concept representations contain abundant hidden relationships between each of them that cannot be simply represented by one-hot coding or natural language token representations <ref type="bibr">(Choi et al., 2016b)</ref>. For example, when we want to have the concept "congestive heart failure" in the embedding space, it can not be represented well simply using the word-level representation, which may represent the phrase using the average of three separate word vector representations for "congestive", "heart", and "failure" <ref type="bibr">(Weng et al., 2017b)</ref>. Instead, learning concept-level representations is an approach to tackle the issue. The advantage of concept-level representations is to alleviate the errors that result from word-level representations. The key to learning concept-level representations is the process of clinical concept identification and extraction from the clinical narratives. Next, concept standardization using ontology mapping is needed, which yields a complex training process and the necessity for ontology systems. Researchers may need to rely on a clinical concept extraction pipeline, such as cTAKES and MetaMap <ref type="bibr" target="#b115">(Savova et al., 2010;</ref><ref type="bibr" target="#b1">Aronson, 2001)</ref>, for ontology mapping to identify and extract UMLS CUIs from free text. However, using such concept extraction tools is likely to inject errors into the learning process, so further concept filtering and curation are inevitably needed <ref type="bibr" target="#b137">(Wiegreffe et al., 2019)</ref>.</p><p>With standard machine learning methods after concept extraction from the free texts, <ref type="bibr" target="#b38">(De Vine et al., 2014)</ref> derived the embeddings of UMLS CUIs from 348,566 medical journal abstracts using a skip-gram model 11 . <ref type="bibr" target="#b44">(Finlayson et al., 2014)</ref> learned the UMLS CUIs embedding using 20 million clinical notes spanning 19 years of data from Stanford Hospital and Clinics using co-occurrence based analyses 12 . <ref type="bibr" target="#b4">(Beam et al., 2018</ref>) also learned the UMLS CUIs embeddings, cui2vec, from medical billing codes, biomedical journal texts, and the clinical concept co-occurence matrix used in <ref type="bibr" target="#b44">(Finlayson et al., 2014)</ref> 13 . <ref type="bibr">(Choi et al., 2016e)</ref> learned three dense, low-dimensional embedding spaces of UMLS CUIs and billing codes from UMLS-processed journal abstracts, UMLS-processed clinical notes and claims data using the word2vec skip-gram framework 14 . <ref type="bibr" target="#b126">(Tran et al., 2015)</ref> used a restricted Boltzmann machine (RBM) to learn abstractions of ICD-10 codes on mental health patients to predict risk of suicide.</p><p>Considering the temporal and hierarchical properties of EHR information, researchers have developed advanced models that consider the more complicated nature of EHR structure to learn concept-level representations efficiently. The Med2Vec algorithm is a word2vec variant that learns representations of both code concepts and patient visits from EHR <ref type="bibr">(Choi et al., 2016b</ref>). It applies the skip-gram algorithm at a patient visit level, binarizes the diagnosis codes (ICD-9) that are grouped by the Clinical Classifications Software (CCS) grouper, medication codes (National Drug Codes (NDC)) and procedure codes (Category I of Current Procedural Terminology (CPT)) of each visit to learn both code-level and patient visit-level representations. (Choi et al., 2017) further proposed a graphbased model with attention mechanism (GRAM) to learn the clinically interpretable hierarchical ICD concept representation that yields better performance on the downstream tasks. (Luo et al., 2015) developed a novel framework, subgraph augmented non-negative tensor factorization (SANTF), that converts concepts inside clinical sentences into a graph representation with subgraphs that are clinically interpretable. They applied the SANTF model to lymphoma pathology reports and identified the graph and subgraph structure between concepts. (Mullenbach et al., 2018) learned medical code representations by an attentional convolutional network that can predict medical codes from clinical notes, which also provides the explainability of the predicted model output. (Beaulieu-Jones et al., 2019) adopted the hyperbolic space embedding within the Poincaré ball (Nickel &amp; Kiela, 2017), to encode the hierarchical property of the ICD ontology. The results demon-11 <ref type="url" target="https://github.com/clinicalml/embeddings/raw/master/DeVine_etal_200.txt.gz">https://github.com/clinicalml/embeddings/raw/master/DeVine_etal_2</ref> 12 <ref type="url" target="https://github.com/clinicalml/embeddings/raw/master/stanford_cuis_svd_300.txt.gz">https://github.com/clinicalml/embeddings/raw/master/stanford_cuis</ref> 13 <ref type="url" target="http://cui2vec.dbmi.hms.harvard.edu/">http://cui2vec.dbmi.hms.harvard.edu/</ref> 14 <ref type="url" target="https://github.com/clinicalml/embeddings/">https://github.com/clinicalml/embeddings/</ref> strated that the hyperbolic space embedding preserves the tree structure of the ICD ontology. Yet further investigation is required to see whether the performance and quality of hyperbolic space embeddings are better than Euclidean space embeddings. 4.3. Sources of Learning Data With varying levels of generalizability, representations can be learned from (1) a specific clinical corpus such as clinical notes or articles (e.g., MIMIC-III, i2b2 corpus, Merck Manual), (2) a general biomedical corpus (e.g., biomedical publications in PubMed), or (3) a general natural language corpus such as Wikipedia or Google news. The advantage of using a more specific corpus for training is that the learned representations can be highly optimized for the specific domain and purpose. For example, using the representations learned from clinical notes yields better performance on a clinical cross-domain translation task than those learned from the PubMed corpus and Wikipedia corpus <ref type="bibr">(Weng &amp; Szolovits, 2018;</ref><ref type="bibr">Weng et al., 2019b)</ref>. <ref type="bibr" target="#b0">(Alsentzer et al., 2019;</ref><ref type="bibr" target="#b117">Si et al., 2019</ref>) also demonstrated that fine-tuning the pre-trained BERT model on an EHR corpus outperformed the model trained on a general corpus and/or biomedical corpus on various clinical machine learning tasks. <ref type="bibr" target="#b131">(Wang et al., 2018)</ref> evaluated the performance of using different data sources for different clinical machine learning tasks. They concluded that the representations trained on an EHR corpus capture the semantics of clinical terms better and better aligned with experts' judgments than the representations learned from the general natural language corpus, such as the Wikipedia corpus, in a qualitative evaluation. However, there is no consensus about which approach is better according to quantitative evaluations. Most studies without specific downstream purposes choose to merge various data sources, such as PubMed journal abstracts, clinical notes, claims data, for concept-level representation learning <ref type="bibr" target="#b38">(De Vine et al., 2014;</ref><ref type="bibr" target="#b44">Finlayson et al., 2014;</ref><ref type="bibr">Choi et al., 2016e;</ref><ref type="bibr" target="#b4">Beam et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Domain Knowledge Injection</head><p>Domain knowledge can also be integrated not only for learning patient state representations but also natural language representations. <ref type="bibr" target="#b10">(Boag &amp; Kané, 2017)</ref> enhances the quality of clinical word2vec representation by injecting the knowledge from the UMLS Metathesaurus. The authors adopted the concept of dependency-based word embeddings <ref type="bibr" target="#b82">(Levy &amp; Goldberg, 2014)</ref>, which decouples word and context, to learn the domain knowledge-augmented wordlevel representation using both (word, context) and (word, CUI) pairs. <ref type="bibr" target="#b143">(Yu et al., 2016</ref>) also learned word representations that are augmented by retrofitting the word vectors built from MeSH terms.</p><p>A domain knowledge prior is helpful but not always available since hospitals may use their own in-house terminologies rather than standardized ontology systems, which makes concept mapping difficult. The bag-of-events method, which utilizes the biomedical concepts and relations in the ontology, is one of the approaches that can standardize the clinical concepts and mitigate such problems <ref type="bibr" target="#b53">(Gong et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Cross-domain and Multimodal Representations</head><p>Due to the heterogeneous nature of EHR, representations can also be learned with sources from different domains or modalities in EHR. <ref type="bibr">(Weng &amp; Szolovits, 2018;</ref><ref type="bibr">Weng et al., 2019b)</ref> applied the bilingual dictionary induction algorithm to align two natural language embeddings of different clinical language styles <ref type="bibr" target="#b36">(Conneau et al., 2018)</ref>, which are independently trained on non-parallel corpora, and performed cross-domain professional to consumer clinical language translation. Such a framework has been proven to be effective even in a cross-modal setting between speech and text corpora <ref type="bibr">(Chung et al., 2018;</ref><ref type="bibr" target="#b124">2019)</ref>. Researchers also learned the multimodal representation between image and text for the similar report retrieval task <ref type="bibr" target="#b62">(Hsu et al., 2018)</ref>, as well as for text generation from image input <ref type="bibr" target="#b85">(Liu et al., 2019)</ref>. <ref type="bibr">(Weng et al., 2019a)</ref> further utilized both the multimodal and multitask information to learn a better generalizable representation for pathology metadata prediction problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Representation learning is an important sub-field of machine learning for medicine and healthcare. Effective representation learning techniques allow us to obtain models with better performance and interpretability, taking advantage of the complex nature of the data and making do with the limited amount available. For a more general survey of using deep learning in EHR, please see <ref type="bibr" target="#b99">(Miotto et al., 2017)</ref> and <ref type="bibr">(Xiao et al., 2018a)</ref>. For medical imaging, we recommend to readers the review about deep learning in medical image analysis <ref type="bibr" target="#b84">(Litjens et al., 2017)</ref>.</p><p>As mentioned in the previous sections, there are several challenges from a machine learning perspective, such as data insufficiency, temporality and time irregularity, interpretability, and well-utilized cross-domain and cross-modal resources, that we can investigate more to improve the technique of representation learning <ref type="bibr" target="#b99">(Miotto et al., 2017;</ref><ref type="bibr">Xiao et al., 2018a;</ref><ref type="bibr" target="#b51">Ghassemi et al., 2018)</ref>. There are also other concerns that we should be aware of while learning representations for medicine and healthcare. Model biases and fairness are critical issues since the training data we use are usually noisy and biased <ref type="bibr" target="#b14">(Caruana et al., 2015;</ref><ref type="bibr" target="#b51">Ghassemi et al., 2018)</ref>. Model privacy is always a concern that we need to keep in mind and take care of due to emerging techniques of adversarial model attack and model stealing <ref type="bibr" target="#b125">(Tramèr et al., 2016;</ref><ref type="bibr" target="#b90">Madry et al., 2018)</ref>. Causality is usually not addressed in most clinical machine learning research, yet it is a critical component for clinical decision making. <ref type="bibr" target="#b65">(Johansson et al., 2016)</ref> proposed a deep learning framework for counterfactual inference that integrates the ideas of domain adaptation and representation learning.</p><p>One step further, we also need to consider how to bring the fruits of research to real products to improve workflow, integrate all information acquired by human and machine, and transform them into clinically actionable solution to improve health outcomes. These are the most important things that we should consider while conducting research on representation learning for medicine and healthcare <ref type="bibr" target="#b119">(Steiner et al., 2018;</ref><ref type="bibr">Chen et al., 2019a;</ref><ref type="bibr">b;</ref><ref type="bibr" target="#b116">Sayres et al., 2019)</ref>. This research field still has many unknown properties and deserves more investigation.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://projector.tensorflow.org/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1"><p>http://bio.nlplab.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_2"><p>https://github.com/noc-lab/clinical_concept_extraction</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_3"><p>https://github.com/dmis-lab/biobert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_4"><p>https://github.com/EmilyAlsentzer/clinicalBERT</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_5"><p>http://bit.ly/clinicalbert_weights</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Publicly available clinical bert embeddings</title>
		<author>
			<persName><forename type="first">E</forename><surname>Alsentzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Boag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mcdermott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Clinical Natural Language Processing (ClinicalNLP) Workshop at NAACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Effective mapping of biomedical text to the umls metathesaurus: the metamap program</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AMIA</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Patient subtyping via time-aware lstm networks</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Baytas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Beam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kompa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kohane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.01486</idno>
		<title level="m">Clinical concept embeddings learned from massive sources of medical data</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning contextual hierarchical structure of medical concepts with poincair\&apos;e embeddings to clarify phenotypes</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Beaulieu-Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kohane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Beam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>PSB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The merck manual. Disturbances in Newborns and Infants</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Beers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Berkow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Van Diest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Karssemeijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hermsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">F</forename><surname>Manson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balkenhol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2199" to="2210" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01">Jan. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Awe-cm vectors: Augmenting word embeddings with a clinical metathesaurus</title>
		<author>
			<persName><forename type="first">W</forename><surname>Boag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kané</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.01460</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Boag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sergeeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rumshisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02245</idno>
		<title level="m">CliNER 2.0: Accessible and accurate clinical concept extraction</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The unified medical language system (umls): integrating biomedical terminology</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>suppl 1):D267-D270</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adoption of electronic health record systems among us non-federal acute care hospitals: 2008-2012</title>
		<author>
			<persName><forename type="first">D</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Furukawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ONC data brief</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An rnn architecture with dynamic temporal matching for personalized predictions of parkinson&apos;s disease</title>
		<author>
			<persName><forename type="first">C</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<author>
			<persName><forename type="first">Z</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep computational phenotyping</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An augmented reality microscope with real-time artificial intelligence integration for cancer diagnosis</title>
		<author>
			<persName><forename type="first">P.-H</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gadepalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kadowaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nagpal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kohlberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hipp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">1453</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">How to develop machine learning models for healthcare</title>
		<author>
			<persName><forename type="first">P.-H</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature materials</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">410</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Risk prediction with electronic health records: A deep learning approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation: Encoder-decoder approaches</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Doctor ai: Predicting clinical events via recurrent neural networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schuetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MLHC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multilayer representation learning for medical concepts</title>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Searles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Coffey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tejedor-Sojo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Retain: An interpretable predictive model for healthcare using reverse time attention mechanism</title>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schuetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Using recurrent neural network models for early detection of heart failure onset</title>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schuetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="361" to="370" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gram: graph-based attention model for healthcare representation learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Multilevel medical embedding of electronic health records for predictive healthcare</title>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><surname>Mime</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Graph convolutional transformer: Learning the graphical structure of electronic health records</title>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Dusenberry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Flores</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.04716</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning lowdimensional representations of medical concepts</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-I</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AMIA CRI</title>
		<imprint>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Speech2Vec: A sequence-tosequence framework for learning word embeddings from speech</title>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning deep representations of medical images using siamese cnns with application to content-based image retrieval</title>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Machine Learning for Health</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Audio word2vec: Unsupervised learning of audio segment representations using sequence-to-sequence autoencoder</title>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-S</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Unsupervised cross-modal alignment of speech and text embedding spaces</title>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards unsupervised speech-to-text translation</title>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Word translation without parallel data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">What is a knowledge representation? AI magazine</title>
		<author>
			<persName><forename type="first">R</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shrobe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Medical semantic similarity with a neural language model</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Vine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sitbon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bruza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM international conference on conference on information and knowledge management</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1819" to="1822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neuroner: an easy-to-use program for named-entity recognition based on neural networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NAACL-HLT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Comorbidity clusters in autism spectrum disorders: an electronic health record time-series analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kohane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pediatrics</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="54" to="e63" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07025</idno>
		<title level="m">Learning effective representations from clinical notes</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dermatologist-level classification of skin cancer with deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kuprel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Novoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Swetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Blau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">542</biblScope>
			<biblScope unit="issue">7639</biblScope>
			<biblScope unit="page">115</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Building the graph of medicine from millions of clinical narratives</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lependu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">140032</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Risk stratification for in-hospital mortality in acutely decompensated heart failure: classification and regression tree analysis</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Fonarow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Yancy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Boscardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S A</forename><surname>Committee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="572" to="580" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A comparison of models for predicting early hospital readmissions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Futoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lucas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JBI</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="229" to="238" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Validation of clinical classification schemes for predicting stroke: results from the national registry of atrial fibrillation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Gage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Waterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boechler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Rich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Radford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">285</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2864" to="2870" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Unfolding physiological state: Mortality modelling in intensive care units</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rumshisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A multivariate timeseries modeling approach to severity of illness assessment and forecasting in icu with sparse, heterogeneous clinical data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pimentel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Clifton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Predicting intervention onset in the icu with switching state space models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AMIA CRI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schulam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Beam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00388</idno>
		<title level="m">Opportunities in machine learning for healthcare</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Predicting blood pressure response to fluid bolus therapy using attention-based neural networks for clinical interpretability</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">M</forename><surname>Girkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Uchimido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-W</forename><forename type="middle">H</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Workshop on Machine Learning for Health (ML4H)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Predicting clinical outcomes across changing electronic health record systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Guttag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Generative adversarial nets. NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gulshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Coram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Stumpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Widner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Madams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cuadros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title/>
		<author>
			<persName><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Z. S. Distributional structure. Word</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="146" to="162" />
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Creating an automated trigger for sepsis clinical decision support at emergency department triage using machine learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Horng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Nathanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS one</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">174708</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Universal language model finetuning for text classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Next-generation phenotyping of electronic health records</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hripcsak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Albers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="121" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Unsupervised multimodal representation learning across medical images and reports</title>
		<author>
			<persName><forename type="first">T.-M</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Boag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Workshop on Machine Learning for Health (ML4H)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Altosaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><surname>Clinicalbert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05342</idno>
		<title level="m">Modeling clinical notes and predicting hospital readmission</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Cumulated gain-based evaluation of ir techniques</title>
		<author>
			<persName><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Learning representations for counterfactual inference</title>
		<author>
			<persName><forename type="first">F</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Mimic-iii, a freely accessible critical care database</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Li-Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">160035</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Prognostic physiology: modeling patient severity in intensive care units using radial domain folding</title>
		<author>
			<persName><forename type="first">R</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AMIA</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A model to predict survival in patients with end-stage liver disease</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Wiesner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Malinchoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kremers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Therneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Kosberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>D'amico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Dickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hepatology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="464" to="470" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">A deep learning architecture for de-identification of patient notes: Implementation and evaluation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Khin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Burckhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Padman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.01570</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Apache ii: a severity of disease classification system</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Knaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Draper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Zimmerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Critical care medicine</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="818" to="829" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">The artificial intelligence clinician learns optimal treatment strategies for sepsis in intensive care</title>
		<author>
			<persName><forename type="first">M</forename><surname>Komorowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Badawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Faisal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1716</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Computational phenotype discovery using unsupervised feature learning over noisy, sparse, and irregular clinical data</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Lasko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Denny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS one</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">66341</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Biobert: pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Representation learning approaches to detect false arrhythmia alarms from ecg dynamics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Wei</forename></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MLHC</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Rationalizing neural predictions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Definition and classification of chronic kidney disease: a position statement from kidney disease: Improving global outcomes (kdigo)</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Levey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-U</forename><surname>Eckardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsukamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Coresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rossert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Zeeuw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Hostetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lameire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Eknoyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kidney international</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2089" to="2100" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Dependency-based word embeddings</title>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Learning to diagnose with lstm recurrent neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wetzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A survey on deep learning in medical image analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A A</forename><surname>Setio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ciompi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghafoorian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Sánchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="60" to="88" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Clinically accurate chest x-ray report generation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-M</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Boag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MLHC</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Detecting cancer metastases on gigapixel pathology images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gadepalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kohlberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Boyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Timofeev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Q</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.02442</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-I</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Subgraph augmented non-negative tensor factorization (santf) for modeling clinical narrative text</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hochberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Uzuner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1009" to="1019" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11">Nov. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Research and applications: N-gram support vector machines for scalable procedure and diagnosis classification, with applications to clinical free text data from the intensive care unit</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Marafino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Bardach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Dudley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">871</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">An upper-level ontology for the biomedical domain</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Genomics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="80" to="84" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Aggregating umls semantic types for reducing conceptual complexity</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Burgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in health technology and informatics</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">0 1</biblScope>
			<biblScope unit="page">216</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">UMAP: Uniform manifold approximation and projection for dimension reduction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03426</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Exploring the application of deep learning techniques on medical text corpora</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Minarro-Giménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Marin-Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Samwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in health technology and informatics</title>
		<imprint>
			<biblScope unit="volume">205</biblScope>
			<biblScope unit="page" from="584" to="588" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Deep patient: an unsupervised representation to predict the future of patients from the electronic health records</title>
		<author>
			<persName><forename type="first">R</forename><surname>Miotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kidd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Dudley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">26094</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Deep learning for healthcare: review, opportunities and challenges</title>
		<author>
			<persName><forename type="first">R</forename><surname>Miotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Dudley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Briefings in bioinformatics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Explainable prediction of medical codes from clinical text</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mullenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>NAACL-HLT</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Development and validation of a deep learning algorithm for improving gleason scoring of prostate cancer</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nagpal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Foote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wulczyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohtashamian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Wren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>npj Digital Medicine</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">A convolutional net for medical records</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wickramasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><surname>Deepr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE journal of biomedical and health informatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="30" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Poincaré embeddings for learning hierarchical representations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="page" from="1532" to="1543" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<title level="m">Deep contextualized word representations. NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Deepcare: A deep dynamic memory model for predictive medicine</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>PAKDD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Wiggins, C. H., and Elhadad, N. Learning probabilistic phenotypes from heterogeneous ehr data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pivovarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Perotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Angiolillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JBI</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="156" to="165" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poplin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Blumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Mc-Connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Webster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">158</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Distributional semantics resources for biomedical text processing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Moen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salakoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Languages in Biology and Medicine</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/languageunsupervised/languageunderstandingpaper.pdf" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main">Continuous state-space models for optimal sepsis treatment-a deep reinforcement learning approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Komorowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>MLHC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Why should i trust you?: Explaining the predictions of any classifier</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Parallel Distributed Processing: Explorations in the Microstructure of Cognition</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="1986">1986</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">6088</biblScope>
			<biblScope unit="page">533</biblScope>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Mayo clinical text analysis and knowledge extraction system (ctakes): architecture, component evaluation and applications</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Masanz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Ogren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Kipper-Schuler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Chute</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="507" to="513" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Using a deep learning algorithm and integrated gradients explanation to assist grading for diabetic retinopathy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sayres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Taly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rahimy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Blumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Coz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hammel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Rastegar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="552" to="564" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title level="m" type="main">Enhancing clinical concept extraction with contextual embedding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.08691</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">CLAMP-a toolkit for efficiently building customized clinical natural language processing pipelines</title>
		<author>
			<persName><forename type="first">E</forename><surname>Soysal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pakhomov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="331" to="336" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Impact of deep learning assistance on the histopathologic review of lymph nodes for metastatic breast cancer</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Truszkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gammage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Thng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Stumpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American journal of surgical pathology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1636</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Clinical intervention prediction and understanding with deep neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MLHC</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<title level="m" type="main">Artificial intelligence in medicine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Westview Press</publisher>
			<pubPlace>Boulder, CO</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Categorical and probabilistic reasoning in medical diagnosis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Pauker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="115" to="144" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">High-performance medicine: the convergence of human and artificial intelligence</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature medicine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">44</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Stealing machine learning models via prediction apis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tramèr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Juels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="601" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Learning vector representation of medical objects via emr-driven nonnegative restricted boltzmann machines (enrbm)</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JBI</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="96" to="105" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">2010 i2b2/va challenge on concepts, assertions, and relations in clinical text</title>
		<author>
			<persName><forename type="first">Ö</forename><surname>Uzuner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>South</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Duvall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="552" to="556" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">The sofa (sepsis-related organ failure assessment) score to describe organ dysfunction/failure</title>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Takala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Willatts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De Mendonc ¸a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bruining</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Reinhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thijs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intensive care medicine</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="707" to="710" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">A comparison of word embeddings for the biomedical natural language processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rastegar-Mojarad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JBI</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="12" to="20" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Mapping unparalleled clinical professional and consumer languages with embedding alignment</title>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD Health Day, KDD workshop on Machine Learning for Medicine and Healthcare</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Representation and reinforcement learning for personalized glycemic control in septic patients</title>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Machine Learning for Health</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Medical subdomain classification of clinical notes using a machine learning-based natural language processing approach</title>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Wagholikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Chueh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC medical informatics and decision making</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">155</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Multimodal multitask representation learning for pathology biobank metadata prediction</title>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-H</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.07846</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Unsupervised clinical language translation</title>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Clinical concept extraction for document-level coding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL BioNLP Workshop</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">A study in transfer learning: leveraging data from multiple hospitals to enhance hospital-specific predictions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wiens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="699" to="706" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Readmission prediction via deep contextual embedding of clinical concepts</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Dieng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS one</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">195024</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Using machine learning to parse breast pathology reports</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Salama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sollender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bardia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Coopey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Polubriaginof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Breast cancer research and treatment</title>
		<imprint>
			<biblScope unit="volume">161</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<title level="m" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Retrofitting word vectors of mesh terms to improve semantic similarity measures</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bernstam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Workshop on Health Text Mining and Information Analysis</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Clinical concept extraction with contextual word embedding</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Paschalidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tahmasebi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Workshop on Machine Learning for Health (ML4H)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
