<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">When Machine Learning Meets Privacy: A Survey and Outlook</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-11-24">24 Nov 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Liu</surname></persName>
							<email>bo.liu@uts.edu.au</email>
						</author>
						<author>
							<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
							<email>ming.ding@data61.csiro.au</email>
						</author>
						<author>
							<persName><roleName>CSIRO, Australia</roleName><forename type="first">Sina</forename><surname>Data61</surname></persName>
						</author>
						<author>
							<persName><surname>Shaham</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Technology</orgName>
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">FARHAD FAROKHI</orgName>
								<orgName type="institution" key="instit1">WENNY RAHAYU</orgName>
								<orgName type="institution" key="instit2">La Trobe University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">ZIHUAI LIN</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">University of Technology Sydney</orgName>
								<address>
									<addrLine>2007; Ming Ding, Data61</addrLine>
									<settlement>Ultimo</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">CSIRO</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution" key="instit1">Sina Shaham</orgName>
								<orgName type="institution" key="instit2">The University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">La Trobe University</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<settlement>Zihuai Lin</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">When Machine Learning Meets Privacy: A Survey and Outlook</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11-24">24 Nov 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">395CD7966A6399E9C32DE4E3975EDD20</idno>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
					<idno type="arXiv">arXiv:2011.11819v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>machine learning</term>
					<term>privacy</term>
					<term>deep learning</term>
					<term>differential privacy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The newly emerged machine learning (e.g. deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning (ML) is still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This paper surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field.</p><p>CCS Concepts: • Security and privacy → Privacy protections; Social network security and privacy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Since Facebook data privacy scandal in 2018 <ref type="bibr" target="#b153">[154]</ref>, privacy has once again become a dominant feature in people's minds. This motivates revisiting privacy challenges, particularly with the emergence of intelligent technologies thanks to the big data revolution. For example, newly emerged machine learning (ML) techniques, especially the unprecedented powerful deep learning, will have paradigm-shifting impacts on privacy preservation. A critical question that needs to be well investigated is: What are the privacy challenges and solutions associated with ML?</p><p>Some initial work has appeared in the literature with an emphasis on mitigating privacy risks during the machine learning process by paying special attention to the privacy challenges and risks associated with the ML models. In this regard, possible attack models <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b97">98,</ref><ref type="bibr" target="#b140">141,</ref><ref type="bibr" target="#b143">144,</ref><ref type="bibr" target="#b154">155]</ref> have been discussed and protection schemes <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b117">118,</ref><ref type="bibr" target="#b125">126,</ref><ref type="bibr" target="#b139">140]</ref> have been proposed. These works demonstrated both ML models and training datasets can be the target of privacy attacks, leading to sensitive information leakage. Meanwhile, researchers have also tried to use ML for privacy protection. As an example, the authors of <ref type="bibr" target="#b173">[174]</ref> have developed a method for automatic recognition of privacy-sensitive object classes and adjust users' privacy preference settings. In addition, there are also several works that develop new privacy protection schemes in the scenarios where ML is used for attacks <ref type="bibr" target="#b79">[80,</ref><ref type="bibr" target="#b80">81]</ref>. Overall, the current research has only scratched the surface, and there are major issues that require further investigation:</p><p>• ML could play different roles in a privacy protection problem, e.g., protection target, attack tool, and/or protection tool. It may even play multiple roles in the same problem. • ML systems and models have different types, each facing different privacy risks and requires different protection schemes. • There does not exist a unified privacy metric or notion. Although differential privacy (DP) <ref type="bibr" target="#b31">[32]</ref> is widely accepted in traditional privacy studies, it still has limitations in the context of ML, especially when considering unstructured data, such as text, image, and video.</p><p>In this context, a systematic study of privacy and ML is essential for future research efforts. Although there are several surveys on this topic <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b176">177]</ref>, The focus has been on a certain type of ML model or specific methods.</p><p>This study attempts to provide the first comprehensive survey on privacy in ML by investigating different scenarios/applications of privacy and ML. The main contributions of the paper are as follows:</p><p>• We divide the works in this area by the different roles of ML, i.e., ML as protection target (private ML), protection tool (ML enhanced privacy protection), attack tool (ML-based attack), and analyze the problems and solutions in each category. • For private ML, we categorize the attacks and protection schemes and then compare their difference. • For ML aided privacy protection and ML-based privacy attack, we not only discuss the existing works, but also provide insights on new techniques to achieve privacy preservation. • The study concludes with a discussion on the directions of future research in ML and privacy.</p><p>Through this comprehensive overview, we wish to prepare a solid ground for future research in this field.</p><p>The rest of the paper is organized as follows. Section 2 reviews basic concepts of machine learning system and models, and discusses the relationship between privacy and ML. In Section 3, we compare and classify existing privacy attacks and protection schemes in ML systems. Section 4 focuses on ML aided privacy protections, followed by the discussion of ML-based attack and corresponding privacy preservation schemes in Section 5. We present our outlook and propose some future directions for this promising research topic in Section 6. Finally, we conclude our work with a summary in Section 7.</p><p>Moreover, the abbreviations used in this paper are listed in Table <ref type="table" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRIVACY THREATS AND MACHINE LEARNING</head><p>In this section, we discuss the privacy threats in the context of machine learning, and further point out various roles of machine learning in the studies of user privacy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Machine Learning System and Models</head><p>ML refers to algorithms and statistical models used by computer systems to efficiently perform specific tasks without the use of explicit instructions. It relies on an automated learning process.</p><p>The ML algorithm constructs a mathematical model of sample data called a "training set" to make predictions or decisions <ref type="bibr" target="#b9">[10]</ref>. Depending on if the output is labelled in the training set, ML models can be divided into three different groups: supervised, unsupervised, and semi-supervised. As supervised learning is used by most practical machine learning algorithms, it will be explained here as an example.</p><p>A supervised ML model is a parameterized function 𝑓 𝜃 that maps input data ì 𝑥 ∈ X 𝑑 (generally a vector of features) to output data 𝑦 ∈ Y (label). For a classification problem, X 𝑑 is a 𝑑-dimensional vector space and Y is the set of classes. This function is trained to accurately predict the label of new data that have not seen before.</p><p>Moreover, we can divide the ML process into two stages:</p><p>(1) Model training: The training process of a machine learning model is to find the optimal parameters that can accurately capture the relationship between X and Y. To achieve this, a training dataset 𝐷 = { ì 𝑥 𝑖 , 𝑦 𝑖 } 𝑁 𝑖=1 with 𝑁 samples is needed. Then a loss function 𝐿 is adopted to quantify the difference between two outputs, i.e. the ground-truth one 𝑦 𝑖 and the predicted one 𝑓 𝜃 ( ì 𝑥 𝑖 ). The goal of training a model is to minimize this loss function, i.e.,</p><formula xml:id="formula_0">𝜃 ★ = arg min 𝜃 ( ∑︁ 𝑖 𝐿(𝑦 𝑖 , 𝑓 𝜃 ( ì 𝑥 𝑖 )) + Ω(𝜃 )),<label>(1)</label></formula><p>where Ω is a regularization term to penalize model complexity and avoid overfitting. (2) Model inference/prediction: After the model training is completed and the optimal parameters 𝜃 ★ are obtained, given an input ì 𝑥, the corresponding output can be calculated as 𝑦 = 𝑓 ★ 𝜃 ( ì 𝑥 𝑖 ). This prediction process is called inference. We can calculate the prediction accuracy of the model over a testing dataset 𝐷 𝑡 to measure the model's performance. Furthermore, according to the architecture of the ML systems, there are two different models, as shown in Fig. <ref type="figure" target="#fig_0">1:</ref> • Centralized learning: The training data is centralized in a machine or in a data center, and the centralized entity trains and hosts the models. For example, a researcher could use a cloud platform, to host datasets and train an AI model based on them. It goes without saying that the availability of all data in such a centralized method leads to high efficiency and accuracy <ref type="bibr" target="#b54">[55]</ref>. However, because the centralized operator has direct access to sensitive data, user privacy might be violated.</p><p>As the learning tasks become more and more complicated, many companies start to outsource the training process, i.e., outsourced learning, or ML-as-a-service. In this case, each user owns his/her training data while the service providers own the models and algorithms. The data holder outsources model creation to a cloud service such as Microsoft Azure ML and Amazon AWS ML, which automate the process of ML. "Users upload datasets, perform training, and make the resulting models available for use" <ref type="bibr" target="#b143">[144]</ref>. During this process, the users do not have any understanding of the details of model creation. The "ML provider is the entity that provides ML training codes to data holders" <ref type="bibr" target="#b143">[144]</ref>. • Distributed learning: Centralized learning is sometimes not a good option for several reasons:</p><p>(i) data is inherently distributed in some scenarios; (ii) data is too large to be stored in a single machine; (iii) users are not willing to share raw data; and (iv) users want to train the neural network with different instances to achieve better predication accuracy. In this case, ML can be conducted in a distributed manner, i.e., distributed learning. In general, distributed learning is used in a scenario of distributed training data sources and a centralized server.</p><p>There are several variations of distributed learning:</p><p>-Collaborative learning: Distributed learning involving such collaborations is known as collaborated learning. But the settings could be quite different in the literature. For example, the authors of <ref type="bibr" target="#b144">[145]</ref> proposed a collaborative learning framework that trains several classifiers "simultaneously on the same training data" to achieve better performance. On the other hand, in the collaborative learning model defined in <ref type="bibr" target="#b54">[55]</ref>, each participant uses its device to train a local AI model. It then shares a fraction of the parameters/coefficients of the model with the other users. Service operators can create a composite model by collecting these parameters and achieve almost the same accuracy as a model built using a centralized approach. The collaborative approach is "more privacy-friendly" because the dataset is not directly exposed. Also, if only a small part of the model parameters is shared and the parameters are truncated and/or obfuscated by DP mechanisms, the model exhibits convergence through experiments <ref type="bibr" target="#b139">[140]</ref>. -Federated learning: A popular framework for collaborative learning is Federated learning <ref type="bibr" target="#b68">[69]</ref> introduced by Google. There are currently two different federated learning settings: cross-device and cross-silo <ref type="bibr" target="#b67">[68]</ref>. The cross-device setting normally involves a very large number of mobile or IoT devices, while in the cross-silo settings it "might involve only a small number of relatively reliable clients" <ref type="bibr" target="#b67">[68]</ref>, e.g., multiple organizations. In a broader definition of federated learning that covers both settings, each device downloads the current model from a centralized server, improves it by learning from data on a local device, and then sums up the changes in a focused update. Here, "focused updates are updates" containing "the minimum information necessary for the specific learning task" <ref type="bibr" target="#b67">[68]</ref>. And then the shared model is updated by averaging all users' updates. Since all the training data will not leave local devices, and no updates from individual users are stored in the cloud, the privacy risk has been greatly reduced. -Split learning: Another collaborative learning framework is Split learning, in which each user trains the network up to a certain layer known as the cut layer and sends the weights to server. Mathematically speaking, these weights represent and compress the input data to some intermediate feature vectors. The server then trains the network for rest of the layers, and generates the gradients for the final layer, followed by error back-propagation until the cut layer. The gradient is then passed over to the users. The rest of the back-propagation is completed by the users <ref type="bibr" target="#b158">[159]</ref>. In split learning, "client-side communication costs are significantly reduced as the data to be transmitted is restricted to first few layers of the split neural network prior to the split". Although some collaborative learning models consider shared training data <ref type="bibr" target="#b144">[145]</ref>, which presents a significant privacy risk. In this survey, however, we consider the case that the local raw training data are not shared with the server or amongst users. In this learning process, the users can collaboratively learn a shared ML model, thus decoupling ML tasks from the storage of the data in a single device.</p><p>Overall, centralized learning is characterized by "globally stored data" and "globally trained model", as shown in Fig. <ref type="figure" target="#fig_0">1</ref>(a), while the distributed learning is characterized by "locally stored data" and "locally trained model", as shown in Fig. <ref type="figure" target="#fig_0">1(b)</ref>. Although there will be a global model in distributed learning, it is not trained globally, at least part of the model is trained by individual clients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Relationship of privacy and machine learning</head><p>In contrast to traditional privacy-related research frameworks, ML techniques open new challenges and opportunities to privacy protection. There has been some initial research embarking on this journey. The existing works can be divided into three categories according to the roles of ML in privacy.</p><p>First, making ML system private, i.e., ML system is the target of privacy protection. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>(a), this category 1 includes making both the ML system (model parameter) and data (training/test dataset and output data) private, since the privacy threat may happen in any stage of a data cycle, e.g. the training, publishing, or prediction of data. Most of the research in this group relies on the use of differential privacy in ML and deep learning models <ref type="bibr" target="#b43">[44]</ref>. For example, Shokri et al. <ref type="bibr" target="#b139">[140]</ref> developed a differentially private SGD algorithm and a distributed deep learning model training system. In such way, multiple entities can cooperatively learn a neural network.</p><p>Second, using ML to enhance privacy protection. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>(b), the privacy protection target is the data in this category 2 and ML is a tool to help privacy protection. For example, Liu et al. <ref type="bibr" target="#b81">[82]</ref> utilized ML to enhance private decision-making experience through ML. Orekondy et al. <ref type="bibr" target="#b113">[114]</ref> proposed an approach to categorize personal information in images and predict information leakage directly from images. Yuan et al. <ref type="bibr" target="#b174">[175]</ref> presented an ML approach to decide whether to share a picture with a specific requester for a particular context. Third, ML-based privacy attack, i.e., ML is used as an attack tool of the adversary, as shown in Fig. <ref type="figure" target="#fig_3">2(c</ref>). For example, recent researches have shown that deep learning methods can be used to detect object types, people's identities, and landmarks, from images posted on Internet. When the adversaries use this kind of powerful tools, conventional privacy protection methods would be over-powered, especially being challenged by the mighty deep learning tools. There have been very few works in this category. Liu et al. <ref type="bibr" target="#b79">[80]</ref> proposed schemes of applying adversarial perturbations images, so that ML systems cannot get private information from them.</p><p>Table <ref type="table" target="#tab_1">2</ref> summaries three categories of privacy protection problems involving ML systems. It is worth mentioning that one technique might belong to more than one category. For instance, ML might be used as attack and protection tools at the same time, which makes the problem more complicated. We will discuss this in more detail in the reminder of the paper. Fig. <ref type="figure" target="#fig_2">3</ref> summarizes the general taxonomy of the research papers presented in this work. We divide them according to the above mentioned three categories. In each category, we discuss the attack and threat models first and then analyze the works on privacy protection schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRIVATE MACHINE LEARNING</head><p>In this section, we will discuss the challenges and existing solutions in privacy preservation in ML, or simply stated, private ML.</p><p>We will first discuss attack and threat models, followed by detailed analysis of privacy preservation schemes, along with some comparisons at the end. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Attack and Threat Models</head><p>In this subsection, we analyze the attack models from three perspectives: the attack targets, the knowledge of the adversary, and the attack methods.</p><p>First, as we can see in Section 2, model and data are two important components in ML that correspond to two different categories of privacy attack targets, as shown in Fig. <ref type="figure" target="#fig_4">4</ref>:</p><p>(1) Training data privacy: In many cases, a user wants to keep the training data private while using a ML service. For example, for a medical study or a hospital having a model built out of the private medical profiles of some patients. A patient may want to use the model to make a prediction about whether she is likely to contract a certain disease, or the hospital may want to use the model to predict the probability of readmittance. In these cases, the training data is sensitive medical profiles and should not be revealed. Similar cases exist in other areas such as financial records. More specifically, training data privacy includes exact data value, certain features, statistical properties, or membership (whether a certain data is in the training set).  model which can accurately predict stock prices or insurance rates. The model is an important commercial and intellectual property. Another example is the commercial ML API services currently provided by Google, Amazon, Microsoft, and other companies. They charge the customers per API access. Revealing their models or algorithms will cause loss of revenue. In summary, the attack target can either be the model structure or parameters.</p><p>Second, the adversaries have different levels of knowledge according to their access to the information.</p><p>• White-box access: The adversary has access to the trained model, especially the model parameters.</p><p>• Black-box access: The adversary is an end-user and is only allowed to query the prediction model on his/her inputs through an appropriate interface.</p><p>Finally, the adversary can adopt different attack methods. Existing attack methods include model inversion (reverse engineering), shadow training models, and encoding information into models.</p><p>Next, we will group existing popular attack models by attack targets and analyze them from the above mentioned three aspects. An illustrative diagram of the attack models is presented in Fig. <ref type="figure" target="#fig_6">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Model Extraction Attack.</head><p>The model extraction attack targets at the duplication of (i.e., "steal") the AI model <ref type="bibr" target="#b154">[155]</ref>. The outcome of the attack will be a function 𝑓 ′ that is approximately the same as the initial function 𝑓 . An illustration of such an attack can be found in Fig. <ref type="figure" target="#fig_6">5(a)</ref>.</p><p>In this attack, the adversary only has black-box access with no prior knowledge of the ML model parameters or training data. Tramèr et al. <ref type="bibr" target="#b154">[155]</ref> used a shadow training scheme that can "extract target ML models with near-perfect fidelity for popular ML models" including logistic regression, decision trees, and neural networks, by equation-solving, path finding, or extending the Lowd-Meek approach <ref type="bibr" target="#b89">[90]</ref>.</p><p>There are several other works following this path. Oh et al. <ref type="bibr" target="#b110">[111]</ref> built meta-models to extract more model details such as the neural network architecture. Wang et al. <ref type="bibr" target="#b160">[161]</ref> designed an attack to steal the hyperparameters of the machine learning model. A hyperparameter is "used to balance the loss function and regularization term in the objective function". The adversary can obtain this value from the training set and model. Hua et al. <ref type="bibr" target="#b55">[56]</ref> "investigated reverse-engineering attacks on CNN models exploiting information leaks through memory and timing side-channels".</p><p>(a) Model Extraction Attack (b) Feature Estimation Attack (c) Membership Inference Attack (d) Model Memorization Attack   <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>. In practice, it can be implemented by model inversion attack, shadow model attack or power side-channel attack. An illustration of such an attack can be found in Fig. <ref type="figure" target="#fig_6">5(b)</ref>.</p><p>First, Model Inversion Attack mostly works in a white-box model, although it also can use blackbox attack <ref type="bibr" target="#b37">[38]</ref> with lower effectiveness. Fredrikson et al. <ref type="bibr" target="#b38">[39]</ref> showed a white-box attack that can "learn sensitive genomic information about individuals". The basic idea of <ref type="bibr" target="#b38">[39]</ref> is to complete the target feature vector "with each of the possible values, and then computes a weighted probability estimate that this is the correct value", given the knowledge of a linear regression model 𝑓 . Then in <ref type="bibr" target="#b37">[38]</ref> they extended the attack to facial recognition models to achieve two different targets: the reconstruction attack that produces "an image of the person associated with a given label" and the deblurring attack that generates the deblurred image of a certain individual given "an image containing a blurred-out face". The idea behind these attacks is "to use gradient descent (GD) to minimize a cost function involving 𝑓 ".</p><p>Overall, the model inversion attack works with a simple philosophy: we can reverse-engineer (find 𝑓 -1 ) by following the gradient in a trained network to adjust the weights and obtain the features for all classes in the network. Even for classes that we do not have prior information, we can still reproduce the prototype example. This type of attack suggests that any accurate deep learning machine, regardless of training methods, may leak information on the distinguishable classes. Extensive research has shown that generative adversarial network (GAN) generated sample data are similar to the training data. And thus, the results given by the model inversion attack may even "reveal more private information about the training data compared to the average samples" <ref type="bibr" target="#b7">[8]</ref>.</p><p>Second, Shadow Model Attack means the attacker trains other ML models to achieve the target. It can happen in either black-box or white-box way. For example, Ateniese et al. <ref type="bibr" target="#b7">[8]</ref> designed a "meta-classifier that can be trained to hack into other ML classifiers to infer patterns or private information from the training set", e.g. they were able to extract accent information from trained speech recognition systems. Hitaj et al. <ref type="bibr" target="#b54">[55]</ref> designed an attack in the context of collaborative learning. They consider the adversary is an insider of the collaborative learning process who wants to infer sensitive information from the peers. The adversary can see and use internal parameters of the model, so it is a white-box attack. The adversary uses GANs <ref type="bibr" target="#b44">[45]</ref> to extract and reconstruct information of the victim. "This process is similar to facial composite imaging used by the police to identify suspects, where the composite artist generates sketches based on eyewitness identification of the suspect's face. Although the composite artist (GAN) has never seen a real face, the final image is based on eyewitness feedback" <ref type="bibr" target="#b54">[55]</ref>.</p><p>Finally, Wei et al. <ref type="bibr" target="#b163">[164]</ref> proposed to use power side-channel attack on an FPGA-based convolutional neural network accelerator, which can successfully recover the input image using the power traces at the inference stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Membership Inference Attack.</head><p>Membership inference attack refers to acquiring the knowledge about whether a certain data record ( ì 𝑥 ★ , 𝑦 ★ ) belongs to the model's training dataset 𝐷 or not <ref type="bibr" target="#b97">[98,</ref><ref type="bibr" target="#b140">141]</ref>. An illustration of such an attack can be found in Fig. <ref type="figure" target="#fig_6">5(c</ref>).</p><p>Shokri et al. <ref type="bibr" target="#b140">[141]</ref> introduced a "black-box membership inference" that used a shadow training technique to imitate the behavior of the target model. The trained inference model is used "to recognize differences in the target model's predictions" on training and non-training inputs. They also found that overfitting, the structure and type of the model are the main factors that cause a model to be vulnerable to membership inference attack. Long et al. <ref type="bibr" target="#b88">[89]</ref> and Yeom et al. <ref type="bibr" target="#b172">[173]</ref> investigated "the relationship between overfitting and privacy leakage". Salem et al. <ref type="bibr" target="#b133">[134]</ref> proposed a membership inference attack method using an unsupervised binary classification, "which does not need to train any shadow model and does not assume knowledge of model or data distribution".</p><p>Membership inference attacks are also studied in Generative Adversarial Networks (GANs). For example, Liu et al. <ref type="bibr" target="#b83">[84]</ref> trained an attacker network to launch membership attacks against Variational Autoencoders (VAEs) and GANs. Hayes et al. <ref type="bibr" target="#b51">[52]</ref> focused on "generative models in ML-as-a-service applications and train GANs to recognize training inputs".</p><p>Melis et al. <ref type="bibr" target="#b97">[98]</ref> studied membership inference in collaborative learning. The attack is achieved by "analyzing periodic updates to the shared model during training". The reason that this attack is effective is that the gradients in neural networks are based on features, "thus observations of the participants' gradient updates can be used to infer the feature values, which are in turn based on these participants' private training data". Wang et al. <ref type="bibr" target="#b162">[163]</ref> considered membership inference attack "against the user-level privacy on the federated learning framework by the attack from a malicious server. The proposed attack framework exploits GAN with a multi-task discriminator, which simultaneously discriminates category, reality and client identity of input samples, and doing so recovers user-specific private data".</p><p>3.1.4 Model Memorization Attack. Song et al. <ref type="bibr" target="#b143">[144]</ref> first proposed the model memorization attack that targets recovering the exact feature values on individual samples. They consider a "malicious ML provider" specialized in model-training for the customers. In such a business model, the provider does not observe the training, but has access to the resulting model. He can steal the sensitive samples and encode the values into the model parameters or outputs. Another malicious party can retrieve sensitive information from the model during model serving. An illustration of such an attack can be found in Fig. <ref type="figure" target="#fig_6">5(d)</ref>.</p><p>Model memorization attack can happen both in white-box and black-box cases. In the white-box case, Song et al. <ref type="bibr" target="#b143">[144]</ref> proposed several techniques for the adversary to encode sensitive data into the models. (1) LSB encoding: the adversary can encode the "training dataset in the least significant (lower) bits of the model parameters". (2) Correlated value encoding: the adversary can "gradually encode information while training model parameters". For instance, "the adversary can add a malicious term to the loss function which maximizes the correlation between the parameters and the data he wants to encode". (3) Sign encoding: similar to correlated value encoding, the adversary can use "the sign of model parameters to interpret as bit strings", e.g., positive parameters represent 1 and negative parameters represent 0.</p><p>In the black-box case, the adversary is assumed to have no access to the model parameters. They designed a scheme in which the adversary can "augment the training dataset with synthetic inputs whose labels encode the critical information". Then the information is leaked via the outputs of these added inputs.</p><p>Model memorization attack studies how malicious training algorithms deliberately create models that leak information about their training data sets. "This threat model is more generous to the adversary, so it can extract more information about the training data than any other attack" <ref type="bibr" target="#b143">[144]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Private Machine Learning Schemes</head><p>In this subsection, we present several private ML schemes, including encryption, obfuscation, and aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Encryption. Encryption or cryptography-based methods can be divided into two groups:</head><p>• Encrypting training data. The mainstream technique is homomorphic encryption. As adding homomorphic encryption to the process will make the process at least an order of magnitude slower, initially it is applied on training data for relatively simple classifiers <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b46">47]</ref>. For example, Graepel et al. <ref type="bibr" target="#b46">[47]</ref> found that training over encrypted data is possible when the training algorithm can be expressed as a low degree polynomial. Bost et al. <ref type="bibr" target="#b12">[13]</ref> applied this technique in three classifiers: hyperplane decision, Naive Bayes and decision trees. Then researchers try to extend the work to deep neural networks (DNN). Dowlin et al. <ref type="bibr" target="#b28">[29]</ref> proposed CryptoNets which demonstrates how to efficiently convert learned neural networks to make it applicable to encrypted input data. While Hesamifard et al. <ref type="bibr" target="#b53">[54]</ref> proposed a framework to train the neural network over encrypted data. Li et al. <ref type="bibr" target="#b76">[77]</ref> investigate the case of collaborative learning where datasets are encrypted with different keys, and propose a solution based on multi-key fully homomorphic encryption (FHE).</p><p>• Encrypting ML model. The encryption technique is also used to protect the model privacy. Phong et al. <ref type="bibr" target="#b125">[126]</ref> proposed to use "additively homomorphic encryption on the gradients". The scheme can prevent information leakage to the "honest-but-curious cloud server" in the condition of collaborative deep learning.</p><p>Overall, training neural networks especially DNNs over encrypted data is still challenging. Computational complexity is a major challenge. The network is slow even when trained on plaintext. Adding homomorphic encryption to a process will make it at least an order of magnitude slower. Since the level of the computed polynomial is proportional to the number of backpropagation steps done, the deceleration is more likely to get worse. Another challenging aspect of encryption is the lack of data scientists' ability to examine data and train models, correct mislabelled items, add functionality, and further tune the network <ref type="bibr" target="#b28">[29]</ref>.</p><p>Secure multi-party computation (SMC) is the extension of encryption under the multiparty setting. In SMC, multiple non-colluding parties use a combination of encryption and oblivious transfer to privately finish the computation without seeing the individual components. For ML, it means to compute model updates without having access to both the data and the model.</p><p>SMC has been used for a variety of traditional ML models, including decision trees <ref type="bibr" target="#b6">[7]</ref>, linear regression <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b106">107,</ref><ref type="bibr" target="#b134">135,</ref><ref type="bibr" target="#b135">136]</ref>, logistic regression <ref type="bibr" target="#b142">[143,</ref><ref type="bibr" target="#b169">170]</ref>, Naive Bayes classifiers <ref type="bibr" target="#b156">[157]</ref>, and 𝑘-means clustering <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b61">62]</ref>.</p><p>In general, SMC techniques impose non-trivial computational overheads and their application to privacy-preserving neural networks especially deep learning remains a challenging task. Se-cureML <ref type="bibr" target="#b100">[101]</ref> is a recent example of SMC. It uses "two-party computations to privately train logistic regression models and neural networks".</p><p>In summary, SMC based method can cover both data/model privacy concerns, at the cost of communication overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Obfuscation/Perturbation (Differential Private Learning).</head><p>Obfuscation mechanisms in the context of privacy protection in ML aim at reducing the precision of the data or model. It is can be achieved by adding noises to the model parameters or the original dataset. It is very popular because the DP scheme is usually implemented by obfuscation in practical applications.</p><p>The obfuscation can be applied to the model or data. When obfuscation mechanism is for the model, it has another name in the community, i.e., differentially private machine learning. There are some early works on traditional machine learning with differential privacy. For example, Rubinstein et al. <ref type="bibr" target="#b131">[132]</ref> proposed differentially-private support vector machine (SVM) learning mechanisms by adding noise to the output classifier and they yield close approximations to the non-private SVM. Chaudhuri et al. <ref type="bibr" target="#b17">[18]</ref> provided the model objective perturbation to produce deferentially private empirical risk minimization (ERM) classifier. Song et al. <ref type="bibr" target="#b145">[146]</ref> derived differentially private SGD for general convex objectives and validated the effectiveness of the approach using logistic regression for classification. One of the well-known early methods of implementing differential privacy in deep learning is <ref type="bibr" target="#b139">[140]</ref>. They trained the ML model "in a distributed manner by updating the selected local gradients and adding noise to them within the privacy budget of each parameter". Based on this work, Abadi et al. <ref type="bibr" target="#b1">[2]</ref> introduced "a simpler differential private SGD (DPSGD) algorithm that ensures DP by cutting the gradients to a maximum 𝑙 2 norm for each layer". And then add the noise bounded by the "𝑙 2 norm-clipping-bound". It was shown that "high-quality models can be trained through privacy under a moderate privacy budget" with the DPSGD algorithm. In DPSGD, the DP noise is added to the gradients and the whole training process involves multiple iterations. Therefore, it is important to compute the overall privacy loss of the training, i.e, privacy accounting. Although the composition theorem <ref type="bibr" target="#b32">[33]</ref> can be used to generate the overall privacy loss, it can be quite loose. Abadi et al. <ref type="bibr" target="#b1">[2]</ref> introduced a moments accountant method that can track privacy loss across multiple training iterations and generate a tighter bound. Another closely related notion is Rényi differential privacy, which "offers quantitatively accurate way of tracking cumulative privacy loss" throughout a multi-round DP mechanisms <ref type="bibr" target="#b99">[100]</ref>.</p><p>Prior to <ref type="bibr" target="#b94">[95]</ref>, all considered methods used "record-level differential privacy as a framework to protect private information". In many real-world work environments, users have multiple data sources. They may be relevant and should be protected as a whole. Therefore, in some cases, the DPSGD method results in a loss of privacy at a higher level (e.g., user level). McMahan et al. <ref type="bibr" target="#b94">[95]</ref> introduced a "user level differential private algorithm called the DP-FedAvg algorithm to protect all the data of a user". Instead of limiting the "contribution of a single record", the DP-FedAvg algorithm limits the contribution of the user data set to the learning model. The DPSGD algorithm was "combined with the FederatedAveraging algorithm" from <ref type="bibr" target="#b13">[14]</ref> which uses a server that performs model averaging.</p><p>Obfuscation on training data has not been investigated extensively in the context of ML, because it has been deemed as similar to traditional big data privacy. One notable research from Zhang et al. <ref type="bibr" target="#b178">[179]</ref> proposed an obfuscate function and applied it to the training data before feeding them to the model training task. This function adds random noise to existing samples, or augments the dataset with new samples. By doing so, sensitive information about the properties of individual samples, or statistical properties of a group of samples, is hidden. Meanwhile, the model trained from the obfuscated dataset can still achieve high accuracy.</p><p>Apart from the above-mentioned works, there are other research works in the closely relevant area, such as tensor/matrix factorizations and functional optimization schemes. In more detail, the authors of <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b59">60]</ref> discussed differentially private algorithms for tensor decomposition, in both centralized and distributed settings <ref type="bibr" target="#b59">[60]</ref>. The authors of <ref type="bibr" target="#b39">[40]</ref> applied a DP framework in the matrix factorization process with four different possible perturbation: input perturbation, private stochastic gradient perturbation, alternating least squares (ALS) with output perturbation, and output perturbation. The authors of <ref type="bibr" target="#b177">[178]</ref> proposed a functional mechanism framework to achieve an 𝜖-DP in analyses, which involves solving an optimization problem with a perturbed objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Aggregation.</head><p>Aggregation is a technique that generally comes along with distributed/collaborated learning, in which multiple parties join a machine learning task while wishing to keep their respective dataset private.</p><p>Aggregation can be applied both in and after the training process. It often works together with the encryption scheme (especially SMC) when used during the training process. For example, Pathak et al. <ref type="bibr" target="#b120">[121]</ref> proposed an aggregation scheme for independently trained classifiers. They average the parameters using DP and SMC. But they do not consider the accuracy of their approach formally. The first part of later research <ref type="bibr" target="#b139">[140]</ref> also focuses on aggregation. They reduce the communication costs and improve the model accuracy by selectively "sharing a subset of parameters in each round of communication".</p><p>Another popular framework using aggregation for collaborative learning is federated learning <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b93">94]</ref> introduced by Google, which has been described before.</p><p>Compared with <ref type="bibr" target="#b139">[140]</ref>, federated learning considers different constraints on the training dataset, i.e., Non-IID, unbalanced, and massively distributed, which is claimed to be more practical in some scenarios such as using mobile devices for the local training.</p><p>Federated learning algorithm introduces techniques for quickly and safely aggregating gradients. This scheme focuses on optimizing the communication efficiency of the aggregation process and making the protocol robust against adversaries. However, it lacks guarantees on the amount of user information leakage during training.</p><p>Bonawitz et al. <ref type="bibr" target="#b11">[12]</ref> enhance the privacy of federated learning by leveraging SMC to compute sums of model parameter updates, i.e., federated Learning with secure aggregation.</p><p>On the other hand, using aggregation schemes for privacy protection in ML after the training process, i.e., using ensembles of models is also reasonable. If an ensemble contains enough of models, and each model is trained with disjoint subsets of the training data in a distributed manner, then "any predictions made by most of the models should not be based on any particular part of the training data" <ref type="bibr" target="#b0">[1]</ref>. The private aggregation of teacher ensembles (PATE) is based on this idea <ref type="bibr" target="#b115">[116]</ref>. In more detail, the ensemble is seen as a set of "teachers" for a new "student" model. The student is linked to the teachers only by their prediction capabilities. And the student is trained by "querying the teachers about unlabelled examples". The prediction result is disjoined from the training data through this process. Therefore the data privacy can be protected. The privacy budget for PATE is much lower than traditional DP ML approaches. But it may not work in many practical scenarios as it relies on an unlabelled public dataset.</p><p>Until now, the above works consider aggregation from the perspective of the model. Dwork et al. <ref type="bibr" target="#b33">[34]</ref> proposed a scheme that aggregates the prediction output rather than the model. In more details, they partition the dataset 𝐷 into several subsamples 𝐷 1 , . . . , 𝐷 𝑟 and run a nonprivate learning algorithm on each of those subsamples to obtain predictors 𝑓 1 , . . . , 𝑓 𝑟 , then use a differentially private aggregation technique on values 𝑓 1 (𝑥), . . . , 𝑓 𝑟 (𝑥) and output the result. This subsample-and-aggregate technique is easy to implement as it does not require a new learning algorithm. It focuses on training data privacy via private prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Summary on Private ML</head><p>In this subsection, we sum up the key points on private ML.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Discussions of attack models.</head><p>We summarize the attack models and related papers in Table <ref type="table" target="#tab_2">3</ref> and Table <ref type="table" target="#tab_3">4</ref>. The attack models listed in Section 3.1 are not interdependent. For example, many attacks might be launched on top of the model extraction attack, because it converts the condition from black-box to white-box. Once the black-box attack is finished, the adversary can continue to launch the white-box attack, e.g., a model inversion attack followed by a model extraction attack.</p><p>3.3.2 Attack models and protection schemes. Table <ref type="table" target="#tab_4">5</ref> summarizes the private ML schemes and their effectiveness against different attacks in different situations. Generally speaking, encryption can maintain the adversary's knowledge to a black-box case, thus it is effective to white-box attacks like model inversion attack. Obfuscation <ref type="bibr" target="#b178">[179]</ref> influences most attacks as it blurs the information to reduce the privacy risk at the cost of utility. Aggregation is mostly used in distributed systems and often comes along with the other schemes. Another important question is the relationship of attack models, protection schemes and DP. Among all the mentioned attack schemes, the membership inference attack works along with DP, because the DP definition makes individuals indistinguishable. The other attack models cannot be well countered and evaluated by DP. For example, model inversion uses the output of a model to infer certain features of the hidden input. From a DP perspective, it does not necessarily lead to privacy breaches. For example, in a face recognition scenario, a single person is associated with an output class of the model. As all training images for this class include various photos of the same person, an adversary can orchestra a model inversion attack by creating an artificial image capturing the average information from the person's photos. In most of the cases, this average can be identified as that person. In summary, the average of the features produced by the model inversion can represent the entire output class at most. It does not construct a particular member of the training data set. Moreover, given an input and a model, it determines whether to use that particular input to train the model.</p><p>Therefore, model inversion attack is even effective with DP applied collaborative learning <ref type="bibr" target="#b139">[140]</ref> and Federated learning <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b93">94]</ref>. Because DP is being applied to the parameters of the model, and the granularity is set at the record/instance level. However, once the model becomes accurate, it must eventually contain noise added to the learning parameters. Model inversion attack works as long as the model can accurately classify the class and will generate representations of that class. It should be noted that the DP scheme proposed in <ref type="bibr" target="#b139">[140]</ref> can only prevent the recovery of specific elements, that is, membership inference attack.</p><p>Overall, the DP criterion cannot provide comprehensive privacy evaluation in private machine learning, due to the complexity of the data (unstructured and multimedia data) and privacy protection target (not only membership, but also features of the dataset). Therefore, defining new privacy metrics and criteria is still an open question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Privacy in Distributed Learning Systems.</head><p>Training ML in a distributed manner can naturally provide a certain level of privacy protection, as the local training data points are usually not shared among users. Moreover, different privacy protection schemes in centralised learning, such as encryption, perturbation, can be easily extended to the distributed learning settings <ref type="bibr" target="#b168">[169]</ref>. In this sense, private ML in distributed systems have a lot in common with that of centralised ML. But there are several special features.</p><p>• Distributed ML requires some forms of data sharing among the training nodes because distributed ML is fundamentally different from stand-alone ML. Such shared data, albeit not raw data, could take the forms of model parameters, feature vectors, classification results, etc., and such data would still reveal users' privacy from an information theory point of view. Hence, we need to carefully design the data sharing mechanism in distributed ML. • SMC and aggregation are quite often adopted in the distributed ML systems. However, the above mechanisms are not adequate to protect users' privacy, especially when there exist inside attackers <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b104">105]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3.4</head><p>Backdoor attacks and privacy. Some recent work raised the awareness of backdoor attacks against machine learning and deep learning systems, where misclassification behaviours are hidden in models and can be triggered by specific inputs. Gu et al. <ref type="bibr" target="#b48">[49]</ref> introduced BadNets that builds a backdoor in DNN models by injecting a square-like trigger with a fixed location to some training data with a target label. Ahmed et al. <ref type="bibr" target="#b132">[133]</ref> extended this work by using dynamic trigger patterns and locations. Liu et al. <ref type="bibr" target="#b86">[87]</ref> proposed a backdoor attack called the Trojan attack, which reverseengineers the target model to synthesize training data so that it does not require access to the original training set. Yao et al. <ref type="bibr" target="#b171">[172]</ref> proposed a latent backdoor attack method in which they embed the backdoors in teacher models to survive the transfer learning process. In general, current backdoor attacks are mostly considered to be security risks, e.g., it may cause various severe consequences in critical ML applications like autonomous driving. But we can also expect potential privacy risks in the future, for example, backdoor attacks against authentication systems that might enable an adversary to access sensitive information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MACHINE LEARNING AIDED PRIVACY PROTECTION</head><p>In this section, we will focus on the case that ML is used to help privacy protection. We will first discuss traditional data privacy risks and threats. These threats have existed for a while, but the newly emerging ML gives us new tools to combat them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Attack and Threat Models</head><p>Along with the proliferation of the mobile network, people spend more and more time on the Internet, using web-based applications, mobile applications and social networks. These all pose privacy risks. For example, online photo sharing has become more popular than any time before. Users are increasingly sharing their images on various social media, such as Facebook, Google+ and Flickr. Shared images can reveal sensitive information about people and their surroundings <ref type="bibr" target="#b147">[148,</ref><ref type="bibr" target="#b175">176]</ref>. Consider a person sharing a photo of a family gathering. Not only this photo can expose the people who may or may not wanted to be in the picture, but it can also reveal sensitive information about the family such as religious beliefs, traditions, and food habits. Therefore, sharing photos online can severely violate privacy and disclose sensitive information <ref type="bibr" target="#b36">[37]</ref>.</p><p>Major traditional privacy attacks include identification attacks, inference attacks, and linkage attacks, as shown in Fig. <ref type="figure" target="#fig_8">6</ref>.</p><p>(1) Identification attack: Identification attack identifies a user's name or identity-based on some public dataset <ref type="bibr" target="#b75">[76]</ref>. It is also called re-identification <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b57">58]</ref> when anonymisation is reversed. Such kind of attack is illustrated in Fig. <ref type="figure" target="#fig_8">6</ref>(a). ( <ref type="formula">2</ref>) Inference attack: This type of attack aims at "analyzing data in order to illegitimately gain knowledge about a subject" <ref type="bibr" target="#b69">[70]</ref>. Such an attack is illustrated in Fig. <ref type="figure" target="#fig_8">6</ref>(b). ( <ref type="formula">3</ref>) Linkage attack: The adversary aims to achieve a target's information by correlating multiple data sources. For example, Narayanan et al. <ref type="bibr" target="#b103">[104]</ref> showed that an adversary "can identify a subscriber's record in the Netflix Prize dataset", linking it to an Internet Movie Database. Such an attack is illustrated in Fig. <ref type="figure" target="#fig_8">6(c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Machine Learning Aided Privacy Protection Schemes</head><p>Many privacy protection schemes have been introduced. Obfuscation/perturbation <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b139">140]</ref>, anonymization <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, reducing information sharing <ref type="bibr" target="#b81">[82,</ref><ref type="bibr" target="#b141">142]</ref>, and cryptographic mechanisms <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b126">127]</ref> are the major technologies. However, the traditional privacy protection schemes focus on structured data, such as an entry in the databases <ref type="bibr" target="#b161">[162]</ref>. With the introduction of new applications such as Internet of Things (IoT) and vehicular networks, both the volume and the complexity of the data is increasing. Traditional protection schemes cannot handle all cases and it also becomes more difficult for both common users and even data curators to understand the risk, select correct schemes and manage their privacy.</p><p>Under these circumstances, ML has been introduced to enhance privacy protection during the past few years. The efforts including research in several aspects.</p><p>• Privacy risk assessment and prediction: Assess and predict the privacy risk for the user during the processes of "access" and "sharing". As shown in Fig. <ref type="figure" target="#fig_9">7</ref>(a), ML is used to evaluate both the input and output data streams to find the risk and then privacy protection schemes can be deployed accordingly. • Personal privacy management assistant: This includes privacy policy evaluation, user preference prediction and management, as shown in Fig. <ref type="figure" target="#fig_9">7(b</ref>). • Private data release: Publish datasets with privacy guarantee. The schemes are generally adopted by data curators rather than an individual user, as shown in Fig. <ref type="figure" target="#fig_9">7(c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Privacy</head><p>Risk Assessment and Prediction. The privacy risk exists either when the user is just accessing the application (passively collected information by malicious attackers) or sharing on social networks (actively sharing information). In both cases, ML can help to prevent the loss of sensitive information. An illustration of such a defence mechanism is shown in Fig. <ref type="figure" target="#fig_9">7(a)</ref>.</p><p>Website and application privacy risk prediction: ML can make browsing the websites safer. The proposed browser extension in <ref type="bibr" target="#b136">[137]</ref> collects information about websites that users visit and provides feedback to users based on ML to let them know the privacy quality of the site. Manek et al. <ref type="bibr" target="#b91">[92]</ref> proposed a method based on a Bayesian classifier to detect and identify websites that can be malicious or threatening to the privacy of users. The proposed approach analyzes online reviews written for websites to decide whether they are reliable or not.</p><p>The work in <ref type="bibr" target="#b41">[42]</ref> uses an SVM classifier to rate the privacy risks of applications. The results indicate that privacy risks can be identified with over 90% accuracy. Understanding the privacy risks of mobile phone applications with the aid of ML have been considered in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b45">46]</ref>.</p><p>Identifying sensitive information when sharing: Identifying sensitive information in multimedia data has been difficult in the past. With the help of the state-of-the-art ML techniques, users can prevent loss of their personal information while sharing their photos on social media.</p><p>Squicciarini et al. <ref type="bibr" target="#b146">[147]</ref> considered visual-content features and images' metadata to develop and contrast several learning models. The ML models can classify the photos and evaluate the degree of sensitivity so as to make the decision based on past decisions of the users. Yu et al. <ref type="bibr" target="#b173">[174]</ref> proposed a tool called "iPrivacy (image privacy)" to reduce the burden of specifying privacy setting by users when they are sharing photos online. iPrivcy utilizes ML to automate the process. It finds privacysensitive objects from images and classifies them according to their privacy sensitivity. Based on the classification, iPrivacy notifies the users if there are objects, which should be suppressed/masked due to privacy concerns before sharing. Moreover, iPrivacy provides privacy settings recommendation based on user preferences and shared images. Orekondy et al. <ref type="bibr" target="#b112">[113]</ref> proposed the first large-scale private images dataset, with pixel and instance level annotations. And they proposed the first model to automatically redaction various private information. Hasan et al. <ref type="bibr" target="#b50">[51]</ref> proposed a method to automatically identify bystanders "solely based on the visual information present in an image".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Personal Privacy Management Assistant.</head><p>As the user connectivity increases and web applications become ubiquitous, the responsibility of privacy management transfers more and more to individuals. Unfortunately, given the complexity of the environments and the lack of awareness about privacy attacks by adversaries, it is improbable that the users can manage and fine-tune their privacy preferences correctly <ref type="bibr" target="#b92">[93]</ref>. Therefore, there is an immediate need to develop automated privacy management systems to help users in protecting their privacy. An illustration of such a defence mechanism is shown in Fig. <ref type="figure" target="#fig_9">7(b)</ref>.</p><p>The authors of <ref type="bibr" target="#b2">[3]</ref> indicate that users continuously modify their privacy requirements to reach their expected level of privacy, and also, appropriately change their privacy preferences. Moreover, mobile and web applications are attempting to customize their services according to individual preferences to grant personalized experience to customers. Such a customized service results in potential risk for the users <ref type="bibr" target="#b121">[122]</ref>. This evidence points to the fact that it is crucial to develop assistants to help users with the management of their privacy configurations. ML can be an invaluable asset in this regard. For example, it can help users to manage their privacy configurations and reduce the burden of time and human resources required to ensure the preservation of privacy.</p><p>We have divided the applications of ML for privacy management in two broad categories: (i) privacy policy evaluation, and (ii) user preference prediction and management.</p><p>Privacy policy evaluation: Users are usually prompted to agree with the provider's privacy policies when almost using any software and web applications. Privacy policies provide complete information on the collection, storage, and sharing of personal data. Therefore, they are critical to the privacy of users. Unfortunately, most of this information is written using technical jargon and challenging to read terms. Hence, most of the readers prefer to accept the policy unconditionally without thoroughly realizing the consequences <ref type="bibr" target="#b23">[24]</ref>. To help users with the decision making, Costante et al. <ref type="bibr" target="#b24">[25]</ref> developed a system to evaluate the completeness of privacy policies based on preferences of the users. The system uses natural language processing to analyze and verify the existence of the privacy measures that users specify, and also, assess the level of completeness. Nugent et al. <ref type="bibr" target="#b107">[108]</ref> graded the privacy policies that the users encounter based on factors such as security, cookies, and purpose which helps users to check the results and identify if their desired privacy requirements are satisfied. Tesfay et al. <ref type="bibr" target="#b152">[153]</ref> proposed an ML approach to "summarize the long privacy policies" into a short paragraph so that it is readable and understandable for users. Shayegh et al. <ref type="bibr" target="#b138">[139]</ref> considered methods to improve the privacy notices given to users in IoT networks. With the aid of ML, the authors extract notice and choice statements from the privacy policies for IoT devices, so as to help users to better understand the implications of privacy notices. Lebanoff et al. <ref type="bibr" target="#b72">[73]</ref> investigated automatic detection of vague contents on privacy policies and used GANs to characterize the vagueness of sentences.</p><p>User Privacy Preference Prediction and Management: Another difficulty in user privacy protection is caused by the fact that each user has a different privacy sensitivity and preference. Nowadays, applications often provide many functionalities with different levels of privacy guarantees. While installing the applications, users are usually prompted for permissions to access resources that have an impact on their privacy. It is important that the users can well coordinate their own privacy preference with the actual privacy risk.</p><p>ML techniques are implemented to predict user privacy preferences and help decision making. It was initially proved feasible as some early studies found that user privacy preferences are related to some statistical and environmental parameters. For example, the quantitative research in <ref type="bibr" target="#b165">[166]</ref> uncovered that a significant number of users would rather prevent at least one permission request involved in the study. Also, several works have shown that the context of the applications is highly related to user privacy preferences <ref type="bibr" target="#b111">[112,</ref><ref type="bibr" target="#b164">165]</ref>. Lee et al. <ref type="bibr" target="#b74">[75]</ref> surveyed 172 participants and uncovered contextual factors that violate the privacy of users in IoT.</p><p>Based on the contextual factors and features, ML models can be developed to predict user privacy preferences and take privacy management decision. Mehrpouyan et al. <ref type="bibr" target="#b96">[97]</ref> used openness, conscientiousness, neuroticism, extroversion, and agreeableness as inputs to ML models to predict desired users' preferences. Das et al. <ref type="bibr" target="#b25">[26]</ref> generated ML models of people's privacy preferences and expectations.</p><p>Wijesekera et al. <ref type="bibr" target="#b164">[165]</ref> proposed a run-time permission system to infer privacy requirements of users automatically. The proposed system grants the resource allocation permission based on the type of the application requesting the permissions, the request time, and in what circumstances it is requested. Liu et al. <ref type="bibr" target="#b81">[82]</ref> investigated ML to enhance privacy decision-making experience.</p><p>The results show that providing users with "recommendations based on clusters of like-minded users and using predictive models of people's privacy preferences work to the users' satisfaction". Wijesekera et al. <ref type="bibr" target="#b165">[166,</ref><ref type="bibr" target="#b166">167]</ref> built a classifier to work as a middle-man and make privacy decisions on behalf of users. The classifier adjusts and preserves privacy by changes that happen in the context predicated on the past behaviors of the users.</p><p>Orekondy et al. <ref type="bibr" target="#b113">[114]</ref> proposed a method named "Visual Privacy Advisor" that "extends this concept to image" contents. They classify "personal information in images into 68 attributes and train models that directly predict such information from images". A user study has been done to understand the privacy preferences with respect to these attributes. They also proposed models that "predict user specific privacy score from images". Yuan et al. <ref type="bibr" target="#b174">[175]</ref> presented an ML approach to decide whether to share a picture with a specific requester at a particular context, and if yes, at which granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Private Data</head><p>Release. Database release is currently an important process in data analytic applications. Different entities generate different types of data, e.g., health data from medical centers. Then, such data will be transmitted to data custodians such as government agencies. Then, the data custodian maintains a platform that organizes, stores and provides data access to data consumers, such as other government departments, individuals, analysts, etc. Privacy preservation processing is highly required when the data custodians release the data. An illustration of such a defence mechanism is shown in Fig. <ref type="figure" target="#fig_9">7</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(c).</head><p>A frequently used traditional private data release mechanism is obfuscation by adding noise to the original dataset. Whereas the ML techniques provide a new solution to this problem, i.e., using a generative neural network (GNN) or generative adversarial network (GAN) <ref type="bibr" target="#b44">[45]</ref> to generate synthetic dataset <ref type="bibr" target="#b3">[4]</ref>.</p><p>Although the technique of GNN itself has existed for a while, using it for private data release has just been linked to privacy preservation very recently. Denton et al. <ref type="bibr" target="#b26">[27]</ref> used the GAN framework in the context of image processing to generate natural synthetic images. Gregor et al. <ref type="bibr" target="#b47">[48]</ref> introduced a model called "Deep Recurrent Attentive Writer (DRAW)" to create synthetic images. The principal idea of the approach is to use two recurrent neural networks as encoder and decoder trained endto-end with SGD. Vinyals et al. <ref type="bibr" target="#b159">[160]</ref> proposed a generative model predicated on recurrent neural network architecture. The approach combines the natural processing ML tools with computer vision for the generation of natural scenes. Using generative models has also been considered for the generation of audios. Oord et al. <ref type="bibr" target="#b157">[158]</ref> introduced a DNN model to produce raw audios and applied the approach to "text-to-speech and validated by human listeners for natural sounding". A modified version of the proposed model is used for singing synthesis in <ref type="bibr" target="#b10">[11]</ref>. Kulkarni et al. <ref type="bibr" target="#b70">[71]</ref> created spatiotemporal trajectories in large scale by training the models based on realistic data, and then, creating synthetic data using the trained models. The authors investigate the utility-privacy trade-off of the approach by experiments. Ouyang et al. <ref type="bibr" target="#b114">[115]</ref> proposed a non-sequential nonparametric generative model for spatiotemporal trajectories. The authors generate "synthetic data by training a generative adversarial neural network, which can learn geographic patterns". Liu et al. <ref type="bibr" target="#b85">[86]</ref> aim at the addition of geo-privacy protection layer for publication of spatiotemporal datasets based on synthetic trajectory generation. Choi et al. <ref type="bibr" target="#b22">[23]</ref> proposed an approach for the generation of synthetic patient records based on GANs and autoencoders. In this work, the performance of the proposed generative model is examined by comparing the generated synthetic patient records with the real data. Cheung et al. <ref type="bibr" target="#b20">[21]</ref> used GNNs for the transformation of sensitive images so that they can preserve privacy of individuals. The authors focus on the generation of synthetic facial images and how they can be used for classification of actual images. Zhang et al. <ref type="bibr" target="#b179">[180]</ref> proposed a novel approach based on GNNs to increase privacy of users while releasing semantic rich data such as text, image, and video. Triastcyn et al. <ref type="bibr" target="#b155">[156]</ref> used GAN to generating artificial data that retain statistical properties of the real data while reducing the risk of information disclosure. Sun et al. <ref type="bibr" target="#b148">[149]</ref> proposed GAN-based head inpainting obfuscation technique to preserve the identity of users when sharing their photos online. Huai et al. <ref type="bibr" target="#b56">[57]</ref> considered the differentially private release of crowdsourcing data. They proposed the PrisCrowd approach "in which the data collector learns about underlying patterns of the data and then samples a set of candidate synthetic data from the learned density. The synthetic data are subjected to a privacy test and the ones that pass will be released".</p><p>Overall, the latest deep learning techniques show the ability to synthesize fake dataset that is statistically similar to the original one. This technique can be used for private data release. Fig. <ref type="figure" target="#fig_10">8</ref> presents the generative model framework used for privacy preservation of rich semantic data. The process can best be explained by an example. Consider a clinical data sharing scenario, in which the data curator instead of directly releasing the data, trains a deep generative model using the original data in a differentially private manner, and then publishes synthetic dataset generated by the model. In a more general case, the data curator may publish the deep generative model from which "an unlimited amount of synthetic data for arbitrary analysis tasks" can be produced <ref type="bibr" target="#b170">[171]</ref>. The use of generative models can significantly increase the privacy of users as the training process of the models can be conducted based on synthetic data instead of the real data belonging to individuals. Meanwhile, the utility of the dataset can be guaranteed as the statistical similarity of models trained based on synthetic data and realist data has been shown repeatedly in the literature. For example, Park et al. <ref type="bibr" target="#b119">[120]</ref> proved the statistical similarity of the generated synthetic tabular data and original data. Xu et al. <ref type="bibr" target="#b170">[171]</ref> developed training deep neural networks for the generation of synthetic data that closely resemble the actual medical records of patients. Although research in GNNs for privacy preservation is in its initial stages, the outlook of the approach is promising. Generation of synthetic data is particularly crucial as traditional methods such as anonymity and obfuscation are ineffective for privacy preservation of semantic-rich data. Moreover, this approach is not associated with the drawbacks of other traditional anonymization approaches such as having background knowledge or linking the data to other sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Summary on ML-aided Privacy Protection</head><p>The three different groups of ML aided privacy protection schemes introduced in Subsection 4.2 work in various stages of privacy protection. Privacy risk assessment and prediction is a pre-process before privacy protection, that identifies what do we need to protect. Personal privacy management assistants help to improve access control over sensitive information. Private data release can be applied directly to the data. These protection schemes do not have a one-on-one relationship with the attack models listed in Subsection 4.1. They can be effective against multiple attack models and will work best if combined correctly in specific scenarios.</p><p>The two main types of ML models used for privacy protection are classification and object detection. Classification is used for privacy risk prediction and assessment. Object detection is used for identifying sensitive information. Additionally, schemes discussed in 4.2.1 do not directly provide privacy protection. They are currently playing a supporting role, and other subsequent privacy protection schemes are still needed.</p><p>GNN opens a new direction for privacy protection research, especially for unstructured data such as image and video. But it is still challenging, as there are no unified metrics for privacy measurements in those complicated cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">MACHINE LEARNING-BASED PRIVACY ATTACKS AND CORRESPONDING PROTECTION SCHEMES</head><p>Besides serving as a privacy protection tool, ML can also be used as an attack tool. It urges us to revisit the definition and scope of privacy. In particular, the emerging deep learning technique can "automatically collect and process millions of photos or videos to extract private/sensitive information from social networks" <ref type="bibr" target="#b79">[80]</ref>. Traditional privacy-preserving methods are over-powered when combating deep learning tools. It is time to seriously discuss new threats and corresponding solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Attack and Threat Models</head><p>The riskiest personal information leakage source is the social network. While there are a variety of social network platforms enriching people's interactivity and relationship, the shared posts including check-ins, activities, thoughts (tweets, status updates, etc.), pictures, videos often come along with sensitive information. The information poses high privacy risks and they are likely to hand over their privacy unintentionally. A growing number of companies and start-ups specialize in analyzing shared pictures on social media to exploit them for commercial purposes or selling them to other companies. Therefore, the most advanced DNNs have been used to launch privacy attacks.</p><p>For example, the adversary can use geo-location information to initiate a localized attack that focuses on finding the position and time information of the person. Gu et al. and Mahmud et al. <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b90">91]</ref> showed a dangerous attack that is designed to "find important locations such as homes and workplaces". There have been some researches discussing the home location identification problem, either based on the "content of the posts" <ref type="bibr" target="#b19">[20]</ref>, or the "geo-tags in the check-ins" <ref type="bibr" target="#b21">[22]</ref>. And "the research shows that the identification accuracy might be over 90% in many cases" <ref type="bibr" target="#b80">[81]</ref>.</p><p>Besides the simple location information, multimedia data poses more risk under the attack of ML tools. Companies apply advanced DNNs to cluster photos or infer preference of users to facilitate marketers to send targeted ads <ref type="bibr" target="#b98">[99,</ref><ref type="bibr" target="#b129">130]</ref>. DNNs are considered one of the most practical tools in ML as they take advantage of efficient training algorithms and large datasets which enables them to outperform other existing ML techniques. The power of such ML tools has become a problem itself that may compromise the privacy of photos once they are shared on social media and a challenging problem that needs to be addressed. The privacy of sensitive data, photos and videos become more crucial in IoT networks, as users might not even be aware of their information such as pictures and videos being recorded. For instance, areas controlled under surveillance cameras can severely compromise user privacy as people lose control of how their photos and videos are being captured and managed. It is likely that the surveillance system applies techniques such as face recognition and detection to identify the users without their permission. Pew Internet survey in 2014 reported that over 91 percent of participants "strongly agree" or "agree" that "they have lost their control over how their personal information is being collected and used by companies" <ref type="bibr" target="#b16">[17]</ref>.</p><p>Major ML attack models include re-identification attacks and inference attacks, as shown in Fig. <ref type="figure" target="#fig_11">9</ref>. These attack models are different from those described in Section 4 in the sense that ML is used as an attack tool here.</p><p>• The re-identification attack can be launched by face recognition techniques. The recent advance in DNN makes it more harmful from two aspects. First, the process becomes automatic with high accuracy <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b150">151,</ref><ref type="bibr" target="#b167">168]</ref>. Second, traditional protection schemes such as obfuscation no longer work effectively <ref type="bibr" target="#b95">[96,</ref><ref type="bibr" target="#b108">109]</ref>. An illustration of the re-identification attack can be found in Fig. <ref type="figure" target="#fig_11">9</ref>(a). • Inference attack has also become more powerful when equipped with ML. ML classifiers can be used to infer a target user's private information (e.g., location, occupation, hobby, political view) from its public data (e.g., twitters, movie rating scores) <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22]</ref>. Moreover, a series of research work have demonstrated how the advanced artificial neural networks can be used as an adversarial tool to detect sensitive information in images, including people's age <ref type="bibr" target="#b62">[63]</ref>, relationship <ref type="bibr" target="#b149">[150]</ref> and vehicle license plates <ref type="bibr" target="#b180">[181]</ref> from ordinary or even obfuscated images. An illustration of the inference attack can be found in Fig. <ref type="figure" target="#fig_11">9(b</ref>). Therefore, it is quite urgent to accelerate the research on privacy protection schemes against ML aided attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Protection Schemes Against ML-based Attacks</head><p>There has been some preliminary research in this area. For privacy protection against traditional ML attack, Liu et al. <ref type="bibr" target="#b80">[81]</ref> designed community-based information sharing scheme that changes the overall spatial and temporal features so that the clustering-based privacy attack <ref type="bibr" target="#b82">[83]</ref> no longer works.</p><p>The problem becomes more challenging when deep learning is involved. The solutions may come from a better understanding of deep learning itself. Some researchers recently found that there are limitations to deep learning. Specifically, "it is proved to be vulnerable to some well-designed inputs termed adversarial examples" <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b137">138]</ref>. Szegedy et al. <ref type="bibr" target="#b151">[152]</ref> first discovered that the superposition of "imperceptible noise onto the original image" would mislead DNNs to the wrong classification. Then, Goodfellow et al. <ref type="bibr" target="#b44">[45]</ref> proposed the "fast gradient sign method (FGSM) that can be used to generate this type of adversarial examples". Other algorithms to generate such noise can be found in <ref type="bibr" target="#b71">[72,</ref><ref type="bibr" target="#b102">103,</ref><ref type="bibr" target="#b130">131]</ref>.</p><p>According to <ref type="bibr" target="#b118">[119]</ref>, the primary reason for why neural networks are vulnerable to adversarial examples is the linear nature of the neural networks. The authors formalize the space of adversaries against DNNs, which are mostly originated from ML techniques itself. In simple words, ML is used as a tool to breach the ML classifiers. Kurakin et al. <ref type="bibr" target="#b71">[72]</ref> focused on adversarial training and how they can be scaled to large datasets. Sharif et al. <ref type="bibr" target="#b137">[138]</ref> proposed an algorithm for manufacturing adversarial examples based on ML to disable DNN detection systems from finding objects in shared photos. Additionally, a significant point about adversarial examples is its transferability property <ref type="bibr" target="#b44">[45]</ref>. It means that if they are able to fool one model, they are often likely to mislead another model with a different set of parameters and architecture <ref type="bibr" target="#b151">[152]</ref>. This is even true if the other model is trained on a different training set or model <ref type="bibr" target="#b116">[117]</ref>. This leads to the idea of universal perturbation <ref type="bibr" target="#b101">[102,</ref><ref type="bibr" target="#b127">128]</ref>. It is even possible to "generate adversarial examples that fool both human and computer alike". Elsayed et al. <ref type="bibr" target="#b34">[35]</ref> exploited ML to construct adversarial examples that transfer from models created based on computer vision to the human visual system. The authors generated adversarial examples without utilizing the parameters of the model's architecture, and then mimic the visual processing of humans using ML.</p><p>Enlighted by the idea of adversarial examples, researchers started to focus on the generation of adversarial examples based on ML to improve the privacy of users against attacks mostly based on DNNs. Liu et al. <ref type="bibr" target="#b87">[88]</ref> proposed an algorithm that is against automatic detection using adversarial examples based on the "Faster RCNN framework". Jia et al. <ref type="bibr" target="#b64">[65]</ref> proposed a two-phase framework called AttriGuard to defend against attribute inference attacks launched by a classifier. Liu et al. <ref type="bibr" target="#b79">[80]</ref> investigated schemes for using adversarial examples in ML systems so that they cannot identify the sensitive information from images. Oh et al. <ref type="bibr" target="#b109">[110]</ref> set up a game-theoretical framework and studied the effectiveness of adversarial image perturbations for privacy protection. Li et al. <ref type="bibr" target="#b77">[78]</ref> proposed to use adversarial perturbation for face de-identification. Friedrich et al. <ref type="bibr" target="#b40">[41]</ref> proposed a privacy-preserving shareable representation of medical texts for a de-identification classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Summary on Privacy Protection against ML</head><p>Previously, the common understanding of privacy protection is to prevent human adversaries from knowing some sensitive information about people. For example, obfuscating faces in images is a well-researched topic. However, the situation has dramatically changed recently. First, the growth of data volume has reached a point where it is physically impossible for anyone to browse everything with their eyes. Second, as a result, people increasingly rely on machines with advanced algorithms to extract relevant information of interest. Third, the booming of ML open source community makes ML tools easy to be obtained by anyone. This brings up a new problem, that is, it is now possible to automatically process data to infer sensitive user information, such as personal identity, social relationships, location, and context. Indeed, ML has recently been used by malicious parties as an efficient tool to launch new types of privacy attacks, especially for social media data. Therefore, we would expect that privacy protection against machines is as important as privacy protection against humans.</p><p>ML-based privacy attacks are more challenging to defend against, due to three main reasons. First, the average user is not aware of the capability of state-of-the-art ML methods in extracting personal information. Second, privacy in some contexts such as multimedia data is not obvious. Third, privacy threats also arise from organizations and government sectors that collect and analyze data on a large scale. Therefore, we need to prevent ML algorithms from automatically mining private information, either intentionally or unintentionally.</p><p>In summary, privacy protection against the fast-evolving ML techniques is the most challenging task among all three categories we discussed in the paper. The methodology is to exploit the weakness and limitations of ML methods. Although there have been some initial solutions to this problem using adversarial machine learning, there are still many research problems that require further investigations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">OUTLOOK AND FUTURE DIRECTIONS</head><p>Significant previous work focuses on making ML algorithms differentially private to preserve the privacy of training sets. However, we should be aware that machine learning, as a whole, also provide potent tools for privacy research (not just for the training datasets), both from attack and defense perspectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Perturbation in Deep Learning</head><p>The goal of perturbation in deep learning is to train a model while ensuring DP concerning information about individual training examples. Theoretically, the noise can be added to either the input data, the model parameters (through gradient updates), or the model output. In practical, the majority of work proposed to inject noise into gradients. The main disadvantage of this group of methods is that amount of injected noise is dependent on the number of training epochs, and it potentially can accumulate too much noise due to the significant number of parameters.</p><p>Directly adding noise to input data is an option, but it is similar to a typical big data privacy problem and does not closely related to deep learning. Output perturbation and objective perturbation seem to be reasonable directions in the future.</p><p>Output perturbation adds noise to the output of the ML system, e.g., the logits at the prediction stage. This method is fast and easy to implement. However, it can suffer from degradation from an attack of repeated querying by an adversarial. Therefore, it is important to restrict the number of queries <ref type="bibr" target="#b128">[129]</ref>. One potential solution is to use output perturbation in certain intermediate outputs, such as the teacher voting output in PATE frame work <ref type="bibr" target="#b115">[116]</ref>.</p><p>Objective perturbation is one of the most effective methods for differential privacy ML. This technique adds a random linear term to the objective function. Objective perturbation has been extensively studied in convex optimization. Recently, Iyengar et al. <ref type="bibr" target="#b60">[61]</ref> has provided a practical algorithm for differentially private convex optimization, which is a big step towards practical deployment of this technique. Moreover, Neel et al. <ref type="bibr" target="#b105">[106]</ref> has extended this approach to non-convex optimization problems. Despite the success in traditional ML, applying objective perturbation to deep neural network is still challenges due to several obstacles: 1) the sensitivity calculation is difficult because the objective functions of deep learning models are mostly non-convex and do not have closed-form expressions; 2) the privacy guarantee is implicitly based on the rank-one assumption on the Hessian of the loss, which is difficult to verify; 3) the privacy guarantee holds only at the exact minima (at least the approximate minima as proposed in <ref type="bibr" target="#b60">[61]</ref>) of the optimization problem, which is hard to be guaranteed in practical deep learning systems. One possible solution is to use a convex approximation of the loss function <ref type="bibr" target="#b123">[124]</ref>. However, the approximation error might outweigh the reduced perturbation due to smaller sensitivity. It is expected to see more effective methods following this path.</p><p>Moreover, instead of perturbing the final output, it is also possible to add noise to the middle layers of the neural networks. Lecuyer et al. <ref type="bibr" target="#b73">[74]</ref> proposed the PixelDP framework that includes a DP noise layer in the DNN. Although the purpose of PixelDP is "to increase robustness to adversarial examples", the idea can be further investigated to serve for privacy preservation. For example, PixelDP scheme enforces that the output prediction function is DP provided the input changes on a small number of pixels (when the input is an image). Potential extensions to PixelDP include: 1) enforcing DP for given different input samples so that it can provide privacy preservation for the training set against membership inference attacks; 2) adding DP noise to the hidden layer of an autoencoder. With the post-processing property of DP, the output of the autoencoder remains to be DP as well. This idea is briefly mentioned in <ref type="bibr" target="#b73">[74]</ref>. But we can further explore it in different applications. For instance, we can protect a social network image by generating a perturbed version using this autoencoder with a DP guarantee.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Defending ML-based Privacy Attack: Adversarial Examples</head><p>As we have discussed in Section 5, when ML is used as a privacy attack method, adversarial examples become a powerful way of privacy protection. Despite the preliminaries work on this topic, there are several issues that need to be solved:</p><p>• Adversarial example generation methods fall into two categories of attack scenarios: whitebox and black-box. The research of using an adversarial example for privacy protection usually assumes that the deep learning model is known, using the white-box setting. In practice, the black-box scenario seems to be a more realistic assumption, e.g., the latest black-box adversarial generation methods such as ZOO <ref type="bibr" target="#b18">[19]</ref>, N attack <ref type="bibr" target="#b78">[79]</ref> and AdvFlow <ref type="bibr" target="#b27">[28]</ref>, could be potentially used for privacy protection. • It is still hard to evaluate the effectiveness of this mechanism with respect to privacy and utility. The existing works use the change of ML outputs (labels) to evaluate the privacy protection methods. We need to prompt more concise and better evaluation metrics. • There have been some recent research works that connect the DP framework and adversarial example <ref type="bibr" target="#b73">[74]</ref>. The PixelDP algorithm <ref type="bibr" target="#b73">[74]</ref> proposed to add a DP-noise to the input or any middle layer to the network's architecture to provide guaranteed robustness against adversarial examples., In more details, if we consider "a DNN's input (e.g., images) as databases in DP parlance, and individual features (e.g., pixels) as rows in DP", randomizing the output prediction function to enforce DP can guarantee the robustness of predictions against adversarial examples. PixelDP cannot effectively preserve privacy in the training set as the input changes are restricted to "a small number of pixels" <ref type="bibr" target="#b73">[74]</ref>. Phan et al. <ref type="bibr" target="#b124">[125]</ref> proposed a heterogeneous Gaussian Mechanism (HGM) that can preserve DP in training data and provide provable robustness against adversarial examples at the same time. They further proposed the stochastic batch mechanism in <ref type="bibr" target="#b122">[123]</ref> that can retain higher model utility and is more scalable to large DNNs and datasets, compared with HGM. Overall, the interplay among DP, adversarial example and certified robustness would be a very interesting future topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">ML-aided Privacy Protection: GAN and VAE</head><p>Excessive amounts of unstructured data including images, videos, audios and texts are being generated constantly and are being used by the government and a wide range of industries. According to the projections of the international data corporation, unstructured data will constitute approximately 80 percent of worldwide data by 2025. Unstructured data, especially image and videos, often containing rich personal information, play a key role in the future privacy preservation ecosystem.</p><p>And the problem of private data release for unstructured data will be a hot topic in the future. We expect GAN to play an important role in this area, as it has demonstrated the capability to preserve high utility for ML algorithms while protecting sensitive information in the dataset. Moreover, GAN, as part of VAE, might also be used for privacy protection for a signal data entry (i.e., an image). In this case, we can encode an original data entry and then decode it with some additional privacy protection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>This study surveys the literature on privacy in the context of machine learning. By classifying the existing research into three groups: (i) private machine learning, (ii)machine learning aided privacy protection, and (iii) privacy protection against machine learning attack, we comprehensively review the state-of-art techniques on this topic and draw several conclusions as follows.</p><p>• The private machine learning problem has drawn the most attention recently. In this category of research works, many try to use the differential privacy criterion during the analysis. However, DP notation cannot provide comprehensive privacy evaluation due to the complexity of the data and privacy protection target. Therefore, how to define new privacy metrics and notations is still an open question. • The research on machine learning aided privacy protection is gaining momentum these days.</p><p>For example, using GNN to generate synthetic datasets opens the new direction for privacy protection research, especially for unstructured data such as image and video. • Research on protection schemes against ML-based privacy attack is in its infancy. But it is expected to fly in the future due to the proliferation of AI techniques in every corner of the future networks. Currently, mainstream technology in this category is the adversarial example/perturbation technique.</p><p>We believe our timely study will shed valuable light on the research problems associated with privacy and machine learning. With the increasing attention paid to this topic, we would expect to see increasing research activities in this area.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Centralized and distributed ML systems: (a) centralized learning; (b) distributed learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Three different categories of research problems in privacy and ML: (a) Privacy of ML model and data; (b) ML enhanced privacy protection; (c) ML-based privacy attack.</figDesc><graphic coords="6,95.04,84.68,283.46,108.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The proposed taxonomy of privacy and ML.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 2 )</head><label>2</label><figDesc>Model privacy: There are also privacy concerns about the ML model including the model parameters, and training algorithms. For example, a financial institution may hold a sensitive (a) Privacy of the ML model. (b) Privacy of the underlying data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Two different types of privacy attack targets in ML: (a) Model privacy; (b) Training data privacy.</figDesc><graphic coords="8,98.63,89.66,121.57,136.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Different attack models targeting ML.</figDesc><graphic coords="9,140.50,432.05,233.34,60.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>3. 1 . 2</head><label>12</label><figDesc>Feature Estimation Attack. A feature estimation attack aims to estimate certain features 𝑥 ★ 𝑖 ∈ ì 𝑥 ★ or statistical properties such as 𝑎𝑣𝑔( ì 𝑥 ★ ) of the training dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Different privacy attack and threat models.</figDesc><graphic coords="17,315.31,89.67,100.28,52.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. ML-aided privacy protection schemes.</figDesc><graphic coords="18,58.60,94.20,138.59,71.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Privacy preserving framework based on generative model approach.</figDesc><graphic coords="21,148.38,383.23,189.24,167.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Different privacy attack and threat models when ML is used as the attack tool.</figDesc><graphic coords="23,52.18,95.66,189.25,66.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Summary of acronyms used in the paper.</figDesc><table><row><cell>CNN</cell><cell>convolutional neural network</cell></row><row><cell>DNN</cell><cell>deep neural network</cell></row><row><cell>DP  *</cell><cell>differential privacy</cell></row><row><cell>ERM</cell><cell>empirical risk minimization</cell></row><row><cell cols="2">FGSM fast gradient sign method</cell></row><row><cell>FHE</cell><cell>fully homomorphic encryption</cell></row><row><cell>GAN</cell><cell>generative adversarial network</cell></row><row><cell>GNN</cell><cell>generative neural network</cell></row><row><cell>IoT</cell><cell>Internet of things</cell></row><row><cell>ML</cell><cell>machine learning</cell></row><row><cell>SGD</cell><cell>stochastic gradient descent</cell></row><row><cell>SMC</cell><cell>secure multi-party computation</cell></row><row><cell>SVM</cell><cell>support vector machine</cell></row><row><cell>VAE</cell><cell>variational autoencoder</cell></row><row><cell></cell><cell></cell></row></table><note><p>* DP in this survey is used as the abbreviation for Differential Privacy, not deep learning.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Three categories of privacy protection problems in the context of ML.</figDesc><table><row><cell>Category</cell><cell>Role of ML in Privacy Protection</cell></row><row><cell>Private ML</cell><cell>Protection target</cell></row><row><cell>ML enhanced Privacy Protection</cell><cell>Protection tool</cell></row><row><cell>ML-based Privacy Attack</cell><cell>Attack tool</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Summary of Attack Models.</figDesc><table><row><cell cols="2">Adversary features</cell><cell cols="4">Model Extraction Feature Estimation Membership Inference Model Memorization</cell></row><row><cell>Knowledge</cell><cell>Black-box White-box</cell><cell>✓</cell><cell>✓ ✓</cell><cell>✓</cell><cell>✓</cell></row><row><cell></cell><cell>Model</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Target</cell><cell>Data features Exact data values</cell><cell></cell><cell>✓</cell><cell></cell><cell>✓</cell></row><row><cell></cell><cell>Membership</cell><cell></cell><cell></cell><cell>✓</cell><cell></cell></row><row><cell></cell><cell>Model inversion</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell></row><row><cell>Scheme</cell><cell>Shadow training Encoding</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Comparisons of Attack Methods.</figDesc><table><row><cell>Attack and Threat</cell><cell>ME</cell><cell>FE</cell><cell>MI</cell><cell>MM</cell><cell>Adversary's Knowledge</cell><cell>Attack Method</cell><cell>System Settings</cell></row><row><cell>[155]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>Black-box</cell><cell>Shadow training</cell><cell>ML-as-a-service</cell></row><row><cell>[111]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>Black-box</cell><cell>Metamodel</cell><cell>Centralised</cell></row><row><cell>[161]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>Black-box</cell><cell>Hyperparameter-stealing</cell><cell>Centralised</cell></row><row><cell>[56]</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>Black-box</cell><cell>Reverse-engineering</cell><cell>Centralised</cell></row><row><cell>[39]</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell>White-box</cell><cell>Model inversion</cell><cell>Centralised</cell></row><row><cell>[38]</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell>Black-box</cell><cell>Model inversion</cell><cell>Centralised</cell></row><row><cell>[8]</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell>White-box</cell><cell>Shadow training</cell><cell>Centralised</cell></row><row><cell>[55]</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell>White-box</cell><cell>GAN</cell><cell>Distributed</cell></row><row><cell>[164]</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell>Black-box</cell><cell>Power side-channel attack</cell><cell>Centralised</cell></row><row><cell>[141]</cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell>Black-box</cell><cell>Shadow training</cell><cell>Centralised</cell></row><row><cell>[84]</cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell>White-box</cell><cell>Shadow training</cell><cell>Centralised</cell></row><row><cell>[134]</cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell>Black-box</cell><cell>Unsupervised binary classification</cell><cell>ML-as-a-service</cell></row><row><cell>[52]</cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell>White/Black-box</cell><cell>GAN</cell><cell>Centralised</cell></row><row><cell>[98]</cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell>White-box</cell><cell>Gradient-based</cell><cell>Distributed</cell></row><row><cell>[144]</cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell>White/Black-box</cell><cell>Encoding</cell><cell>Centralised</cell></row><row><cell cols="7">ME: Model Extraction; FE: Feature Estimation; MI: Membership Inference; MM: Model Memorization.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Comparisons of Private ML Schemes.</figDesc><table><row><cell>Private ML Schemes</cell><cell>ME</cell><cell>FE</cell><cell>MI</cell><cell>MM</cell><cell>Categories</cell><cell>Methods</cell><cell>System Settings</cell></row><row><cell>[13, 15, 29, 47, 54, 77]</cell><cell></cell><cell>✓</cell><cell></cell><cell>✓</cell><cell>Encryption</cell><cell>Homomorphic encryption (training data)</cell><cell>Centralised</cell></row><row><cell>[126]</cell><cell></cell><cell>✓</cell><cell></cell><cell>✓</cell><cell>Encryption</cell><cell>Homomorphic encryption (model)</cell><cell>Distributed</cell></row><row><cell>[7, 16, 30, 66, 101, 157, 170]</cell><cell></cell><cell>✓</cell><cell></cell><cell>✓</cell><cell>Encryption</cell><cell>SMC</cell><cell>Distributed</cell></row><row><cell>[132]</cell><cell>✓</cell><cell></cell><cell>✓</cell><cell></cell><cell>Obfuscation</cell><cell>DP SVM</cell><cell>Centralised</cell></row><row><cell>[18]</cell><cell>✓</cell><cell></cell><cell>✓</cell><cell></cell><cell>Obfuscation</cell><cell>DP ERM</cell><cell>Centralised</cell></row><row><cell>[146]</cell><cell>✓</cell><cell></cell><cell>✓</cell><cell></cell><cell>Obfuscation</cell><cell>DP-SGD for convex objectives</cell><cell>Centralised</cell></row><row><cell>[140]</cell><cell>✓</cell><cell></cell><cell>✓</cell><cell></cell><cell>Obfuscation</cell><cell>DPSGD</cell><cell>Distributed</cell></row><row><cell>[2]</cell><cell>✓</cell><cell></cell><cell>✓</cell><cell></cell><cell>Obfuscation</cell><cell>DPSGD</cell><cell>Centralised</cell></row><row><cell>[100]</cell><cell>✓</cell><cell></cell><cell>✓</cell><cell></cell><cell>Obfuscation</cell><cell>multi-round DP</cell><cell>Centralised</cell></row><row><cell>[95]</cell><cell>✓</cell><cell></cell><cell>✓</cell><cell></cell><cell>Obfuscation</cell><cell>DP-FedAvg</cell><cell>Distributed</cell></row><row><cell>[179]</cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell>Obfuscation</cell><cell>Training data obfuscation</cell><cell>Centralised</cell></row><row><cell>[121]</cell><cell>✓</cell><cell></cell><cell>✓</cell><cell>✓</cell><cell>Aggregation/Obfuscation</cell><cell>DP+Aggregation</cell><cell>Distributed</cell></row><row><cell>[69, 94]</cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell>Aggregation</cell><cell>Federated learning</cell><cell>Distributed</cell></row><row><cell>[12]</cell><cell></cell><cell></cell><cell>✓</cell><cell>✓</cell><cell>Aggregation/Encryption</cell><cell>Federated learning + SMC</cell><cell>Distributed</cell></row><row><cell>[118]</cell><cell></cell><cell></cell><cell>✓</cell><cell>✓</cell><cell>Aggregation</cell><cell>PATE</cell><cell>Centralised</cell></row><row><cell>[34]</cell><cell></cell><cell></cell><cell>✓</cell><cell></cell><cell>Aggregation/Obfuscation</cell><cell>Output aggregation + DP</cell><cell>Centralised</cell></row><row><cell cols="7">ME: Model Extraction; FE: Feature Estimation; MI: Membership Inference; MM: Model Memorization.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2020.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>ACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2020.When Machine Learning Meets Privacy: A Survey and Outlook</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the Protection of Private Information in Machine Learning Systems: Two Recent Approches</title>
		<author>
			<persName><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Úlfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Brendan Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/CSF.2017.10</idno>
		<ptr target="https://doi.org/10.1109/CSF.2017.10" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Computer Security Foundations Symposium (CSF&apos;17</title>
		<meeting>IEEE Computer Security Foundations Symposium (CSF&apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Brendan</forename><surname>Martín Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><surname>Talwar</surname></persName>
		</author>
		<idno type="DOI">10.1145/2976749.2978318</idno>
		<ptr target="https://doi.org/10.1145/2976749.2978318" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;16)</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Privacy and human behavior in the age of information</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Acquisti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Brandimarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Loewenstein</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aaa1465</idno>
		<ptr target="https://doi.org/10.1126/science.aaa1465" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">347</biblScope>
			<biblScope unit="page" from="509" to="514" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Differentially Private Mixture of Generative Neural Networks</title>
		<author>
			<persName><forename type="first">Gergely</forename><surname>Acs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claude</forename><surname>Castelluccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emiliano</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristofaro</forename></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2018.2855136</idno>
		<ptr target="https://doi.org/10.1109/TKDE.2018.2855136" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1109" to="1121" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On k-anonymity and the curse of dimensionality</title>
		<author>
			<persName><forename type="first">C</forename><surname>Charu</surname></persName>
		</author>
		<author>
			<persName><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st international conference on Very large data bases (VLDB&apos;05</title>
		<meeting>the 31st international conference on Very large data bases (VLDB&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="901" to="909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Anonymizing tables</title>
		<author>
			<persName><forename type="first">Gagan</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomás</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnaram</forename><surname>Kenthapadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rina</forename><surname>Panigrahy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilys</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Database Theory</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="246" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Privacy-preserving data mining</title>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakrishnan</forename><surname>Srikant</surname></persName>
		</author>
		<idno type="DOI">10.1145/342009.335438</idno>
		<ptr target="https://doi.org/10.1145/342009.335438" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD international conference on Management of data (SIGMOD&apos;00)</title>
		<meeting>the ACM SIGMOD international conference on Management of data (SIGMOD&apos;00)<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="439" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers</title>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Ateniese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luigi</forename><forename type="middle">V</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelo</forename><surname>Spognardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Villani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domenico</forename><surname>Vitali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Felici</surname></persName>
		</author>
		<idno type="DOI">10.1504/IJSN.2015.071829</idno>
		<ptr target="https://doi.org/10.1504/IJSN.2015.071829" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Security and Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="137" to="150" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mining apps for abnormal usage of sensitive data</title>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Vitalii Avdiienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandra</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Gorla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Zeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siegfried</forename><surname>Arzt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Rasthofer</surname></persName>
		</author>
		<author>
			<persName><surname>Bodden</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICSE.2015.61</idno>
		<ptr target="https://doi.org/10.1109/ICSE.2015.61" />
	</analytic>
	<monogr>
		<title level="m">Proceedings International Conference on Software Engineering (ICSE&apos;15)</title>
		<meeting>International Conference on Software Engineering (ICSE&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="426" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning (Information Science and Statistics)</title>
		<meeting><address><addrLine>New York, Inc., Secaucus, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A neural parametric singing synthesizer</title>
		<author>
			<persName><forename type="first">Merlijn</forename><surname>Blaauw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Bonada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH&apos;17)</title>
		<meeting>the Annual Conference of the International Speech Communication Association (INTERSPEECH&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="4001" to="4005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Practical secure aggregation for privacy-preserving machine learning</title>
		<author>
			<persName><forename type="first">Keith</forename><surname>Bonawitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Kreuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Marcedone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarvar</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karn</forename><surname>Seth</surname></persName>
		</author>
		<idno type="DOI">10.1145/3133956.3133982</idno>
		<ptr target="https://doi.org/10.1145/3133956.3133982" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;17)</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1175" to="1191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Bost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ada</forename><surname>Raluca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shafi</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><surname>Goldwasser</surname></persName>
		</author>
		<title level="m">Proceeding of The Network and Distributed System Security Symposium (NDSS&apos;15)</title>
		<meeting>eeding of The Network and Distributed System Security Symposium (NDSS&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Machine Learning Classification over Encrypted Data</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Communicationefficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eider</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blaise</forename><surname>Agüera Y Arcas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the 20th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Privacy-preserving remote diagnostics</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Brickell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">E</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmett</forename><surname>Witchel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM conference on Computer and communications security (CCS&apos;07</title>
		<meeting>the 14th ACM conference on Computer and communications security (CCS&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="498" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Secure two-party k-means clustering</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Bunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafail</forename><surname>Ostrovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM conference on Computer and communications security (CCS&apos;07</title>
		<meeting>the 14th ACM conference on Computer and communications security (CCS&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="486" to="497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Public Perceptions of Privacy and Security</title>
		<ptr target="http://www.pewinternet.org/2014/11/12/public-privacy-perceptions/" />
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<publisher>Pew Research Center</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Differentially private empirical risk minimization</title>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Monteleoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1069" to="1109" />
			<date type="published" when="2011-03">2011. Mar (2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models</title>
		<author>
			<persName><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinfeng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security</title>
		<meeting>the 10th ACM Workshop on Artificial Intelligence and Security</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">You are where you tweet: a content-based approach to geo-locating twitter users</title>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyumin</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM international conference on Information and knowledge management (CIKM&apos;10)</title>
		<meeting>ACM international conference on Information and knowledge management (CIKM&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="759" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning Sensitive Images Using Generative Models</title>
		<author>
			<persName><forename type="first">Sen-Ching Samson</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herb</forename><surname>Wildfeuer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Nikkhah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Waitian</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th IEEE International Conference on Image Processing</title>
		<meeting>the 25th IEEE International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4128" to="4132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Friendship and mobility: user movement in location-based social networks</title>
		<author>
			<persName><forename type="first">Eunjoon</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the ACM International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1082" to="1090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generating Multi-label Discrete Patient Records using Generative Adversarial Networks</title>
		<author>
			<persName><forename type="first">Edward</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Biswal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Malin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><forename type="middle">F</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v68/choi17a.htmlhttp://arxiv.org/abs/1703.06490" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Machine Learning for Healthcare Conference</title>
		<meeting>the Machine Learning for Healthcare Conference</meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On-line trust perception: What really matters</title>
		<author>
			<persName><forename type="first">Elisa</forename><surname>Costante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><forename type="middle">Den</forename><surname>Hartog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milan</forename><surname>Petkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Socio-Technical Aspects in Security and Trust</title>
		<meeting>the 1st Workshop on Socio-Technical Aspects in Security and Trust</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A machine learning solution to assess privacy policy completeness (short paper)</title>
		<author>
			<persName><forename type="first">Elisa</forename><surname>Costante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milan</forename><surname>Petkovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><forename type="middle">Den</forename><surname>Hartog</surname></persName>
		</author>
		<idno type="DOI">10.1145/2381966.2381979</idno>
		<ptr target="https://doi.org/10.1145/2381966.2381979" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;12)</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;12)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="91" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Personalized privacy assistants for the internet of things: Providing users with notice and choice</title>
		<author>
			<persName><forename type="first">Anupam</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Degeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Smullen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>Sadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pervasive Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="35" to="46" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep generative image models using a laplacian pyramid of adversarial networks</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS&apos;15)</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="1486" to="1494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Hadi M Dolatabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName><surname>Leckie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.07435</idno>
		<title level="m">AdvFlow: Inconspicuous Black-box Adversarial Attacks using Normalizing Flows</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Dowlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Gilad-Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><surname>Lauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Naehrig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Wernsing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Machine Learning (ICML&apos;16)</title>
		<meeting>the 33rd International Conference on Machine Learning (ICML&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="342" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Privacy-preserving multivariate statistical analysis: Linear regression and classification</title>
		<author>
			<persName><forename type="first">Wenliang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunghsiang S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shigang</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1137/1.9781611972740.21</idno>
		<ptr target="https://doi.org/10.1137/1.9781611972740.21" />
	</analytic>
	<monogr>
		<title level="m">SIAM Proceedings Series</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="222" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Differential privacy: A survey of results</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on theory and applications of models of computation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kobbi</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the theory of cryptography conference (TCC&apos;06)</title>
		<meeting>the theory of cryptography conference (TCC&apos;06)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="265" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The algorithmic foundations of differential privacy</title>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="211" to="407" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Privacy-preserving Prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theory</forename></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v75/dwork18a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Machine Learning for Healthcare Conference</title>
		<meeting>the Machine Learning for Healthcare Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adversarial examples that fool both computer vision and time-limited humans</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Gamaleldin F Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shreya</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><surname>Sohl-Dickstein</surname></persName>
		</author>
		<idno>2018-Decem. 3910-3920</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS&apos;18)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fundamental limits on adversarial robustness</title>
		<author>
			<persName><forename type="first">Alhussein</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning (ICML&apos;15)</title>
		<meeting>International Conference on Machine Learning (ICML&apos;15)</meeting>
		<imprint>
			<publisher>Workshop Deep Learning</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The dark side of social networking sites: An exploration of the relational and psychological stressors associated with Facebook use and affordances</title>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">J</forename><surname>Moreland</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2014.11.083</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2014.11.083" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="168" to="176" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Model inversion attacks that exploit confidence information and basic countermeasures</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ristenpart</surname></persName>
		</author>
		<idno type="DOI">10.1145/2810103.2813677</idno>
		<ptr target="https://doi.org/10.1145/2810103.2813677" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;15)</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;15)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1322" to="1333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Lantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ristenpart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd USENIX Security Symposium</title>
		<meeting>the 23rd USENIX Security Symposium</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="17" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A differential privacy framework for matrix factorization recommender systems</title>
		<author>
			<persName><forename type="first">Arik</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shlomo</forename><surname>Berkovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><forename type="middle">Ali</forename><surname>Kaafar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="425" to="458" />
			<date type="published" when="2016-12">2016. Dec 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Adversarial learning of privacy-preserving text representations for de-identification of medical records</title>
		<author>
			<persName><forename type="first">Max</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arne</forename><surname>Köhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Wiedemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1584</idno>
		<ptr target="https://doi.org/10.18653/v1/p19-1584" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL&apos;20)</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics (ACL&apos;20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5829" to="5839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Keeping Context in Mind: Automating Mobile App Access Control with User Interface Inspection</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zizhan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sencun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasant</forename><surname>Mohapatra</surname></persName>
		</author>
		<idno type="DOI">10.1109/INFOCOM.2019.8737510</idno>
		<ptr target="https://doi.org/10.1109/INFOCOM.2019.8737510" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Communications (INFOCOM&apos;19)</title>
		<meeting>IEEE International Conference on Computer Communications (INFOCOM&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2089" to="2097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Privacy-Aware Adaptive Data Encryption Strategy of Big Data in Cloud Computing</title>
		<author>
			<persName><forename type="first">Keke</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meikang</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="DOI">10.1109/CSCloud.2016.52</idno>
		<ptr target="https://doi.org/10.1109/CSCloud.2016.52" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of 3rd IEEE International Conference on Cyber Security and Cloud Computing (CSCloud&apos;16)</title>
		<meeting>3rd IEEE International Conference on Cyber Security and Cloud Computing (CSCloud&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="273" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Defense Against the Dark Arts: An overview of adversarial example security research and future research directions</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.04169</idno>
		<idno>arXiv:1806.04169</idno>
		<ptr target="http://arxiv.org/abs/1806.04169" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS&apos;14)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Checking app behavior against app descriptions</title>
		<author>
			<persName><forename type="first">Alessandra</forename><surname>Gorla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilaria</forename><surname>Tavecchia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Zeller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Software Engineering (ICSE&apos;14</title>
		<meeting>the 36th International Conference on Software Engineering (ICSE&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">ML confidential: Machine learning on encrypted data</title>
		<author>
			<persName><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristin</forename><surname>Lauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Naehrig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Information Security and Cryptology (ICISC&apos;12)</title>
		<meeting>the International Conference on Information Security and Cryptology (ICISC&apos;12)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">DRAW: A recurrent neural network for image generation</title>
		<author>
			<persName><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML&apos;15)</title>
		<meeting>the 32nd International Conference on Machine Learning (ICML&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1462" to="1471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Badnets: Identifying vulnerabilities in the machine learning model supply chain</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Garg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.06733</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">We know where you are: Home location identification in location-based social networks</title>
		<author>
			<persName><forename type="first">Yulong</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weidong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxing</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCCN.2016.7568598</idno>
		<ptr target="https://doi.org/10.1109/ICCCN.2016.7568598" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Computer Communications and Networks (ICCCN&apos;16</title>
		<meeting>the 25th International Conference on Computer Communications and Networks (ICCCN&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Automatically Detecting Bystanders in Photos to Reduce Privacy Risks</title>
		<author>
			<persName><forename type="first">Rakibul</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apu</forename><surname>Kapadia</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP40000.2020.00097</idno>
		<ptr target="https://doi.org/10.1109/SP40000.2020.00097" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;20)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="318" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">LOGAN: Membership Inference Attacks Against Generative Models</title>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Danezis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emiliano</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristofaro</forename></persName>
		</author>
		<idno type="DOI">10.2478/popets-2019-0008</idno>
		<ptr target="https://doi.org/10.2478/popets-2019-0008" />
	</analytic>
	<monogr>
		<title level="m">Proceedings on Privacy Enhancing Technologies (PETS&apos;19)</title>
		<meeting>on Privacy Enhancing Technologies (PETS&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="133" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Re-identification attacks-A systematic literature review</title>
		<author>
			<persName><forename type="first">Jane</forename><surname>Henriksen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Bulmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheridan</forename><surname>Jeary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Information Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1184" to="1192" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Privacy-preserving Machine Learning as a Service</title>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Hesamifard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Takabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Ghasemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><forename type="middle">N</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings on Privacy Enhancing Technologies (PETS&apos;19</title>
		<meeting>on Privacy Enhancing Technologies (PETS&apos;19</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="123" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep Models under the GAN: Information leakage from collaborative deep learning</title>
		<author>
			<persName><forename type="first">Briland</forename><surname>Hitaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Ateniese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Perez-Cruz</surname></persName>
		</author>
		<idno type="DOI">10.1145/3133956.3134012</idno>
		<ptr target="https://doi.org/10.1145/3133956.3134012" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;17)</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;17)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="603" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Reverse engineering convolutional neural networks through side-channel information leaks</title>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiru</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G Edward</forename><surname>Suh</surname></persName>
		</author>
		<idno type="DOI">10.1145/3195970.3196105</idno>
		<ptr target="https://doi.org/10.1145/3195970.3196105" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Design Automation Conference (DAC&apos;18)</title>
		<meeting>the Design Automation Conference (DAC&apos;18)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>Part F1377</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Privacy-aware Synthesizing for Crowdsourced Data</title>
		<author>
			<persName><forename type="first">Mengdi</forename><surname>Huai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenglin</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence<address><addrLine>California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="2542" to="2548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Attacks on Anonymization-Based Privacy-Preserving: A Survey for Data Mining and Data Publishing</title>
		<author>
			<persName><forename type="first">Nermin</forename><surname>Abou-El-Ela Abdou Hussien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hesham</forename><forename type="middle">A</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName><surname>Hefny</surname></persName>
		</author>
		<idno type="DOI">10.4236/jis.2013.42012</idno>
		<ptr target="https://doi.org/10.4236/jis.2013.42012" />
	</analytic>
	<monogr>
		<title level="j">Journal of Information Security</title>
		<imprint>
			<biblScope unit="volume">04</biblScope>
			<biblScope unit="page" from="101" to="112" />
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Improved Algorithms for Differentially Private Orthogonal Tensor Decomposition</title>
		<author>
			<persName><forename type="first">Hafiz</forename><surname>Imtia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP.2018.8461303</idno>
		<ptr target="https://doi.org/10.1109/ICASSP.2018.8461303" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP&apos;18)</title>
		<meeting>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP&apos;18)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2201" to="2205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Distributed Differentially Private Algorithms for Matrix and Tensor Factorization</title>
		<author>
			<persName><forename type="first">Hafiz</forename><surname>Imtiaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
		<idno type="DOI">10.1109/JSTSP.2018.2877842</idno>
		<ptr target="https://doi.org/10.1109/JSTSP.2018.2877842" />
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Signal Process</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1449" to="1464" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Towards practical differentially private convex optimization</title>
		<author>
			<persName><forename type="first">Roger</forename><surname>Iyengar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">P</forename><surname>Near</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Om</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhradeep</forename><surname>Thakurta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lun</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2019.00001</idno>
		<ptr target="https://doi.org/10.1109/SP.2019.00001" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;19)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;19)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-05">2019. 2019-May</date>
			<biblScope unit="page" from="299" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Privacy-preserving distributed k-means clustering over arbitrarily partitioned data</title>
		<author>
			<persName><forename type="first">Geetha</forename><surname>Jagannathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><forename type="middle">N</forename><surname>Wright</surname></persName>
		</author>
		<idno type="DOI">10.1145/1081870.1081942</idno>
		<ptr target="https://doi.org/10.1145/1081870.1081942" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Knowledge Discovery and Data Mining (KDD&apos;05</title>
		<meeting>the ACM International Conference on Knowledge Discovery and Data Mining (KDD&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="593" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Age recognition in the wild</title>
		<author>
			<persName><forename type="first">Amirhossein</forename><surname>Jahanbekam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Bauckhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Thurau</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICPR.2010.104</idno>
		<ptr target="https://doi.org/10.1109/ICPR.2010.104" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pattern Recognition (ICPR&apos;10)</title>
		<meeting>the International Conference on Pattern Recognition (ICPR&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="392" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Zhanglong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Elkan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7584</idno>
		<ptr target="http://arxiv.org/abs/1412.7584" />
		<title level="m">Differential Privacy and Machine Learning: a Survey and Review</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">AttriGuard: A practical defense against attribute inference attacks via adversarial machine learning</title>
		<author>
			<persName><forename type="first">Jinyuan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Zhenqiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th USENIX Security Symposium (USENIX&apos;18</title>
		<meeting>the 27th USENIX Security Symposium (USENIX&apos;18</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="513" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Preserving model privacy for machine learning in distributed systems</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linke</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanpeng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuguang</forename><surname>Fang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPDS.2018.2809624</idno>
		<ptr target="https://doi.org/10.1109/TPDS.2018.2809624" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distrib. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1808" to="1822" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Person recognition in personal photo collections</title>
		<author>
			<persName><forename type="first">Joon</forename><surname>Seong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (CVPR&apos;15</title>
		<meeting>the IEEE International Conference on Computer Vision (CVPR&apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3862" to="3870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Advances and Open Problems in Federated Learning</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Brendan</forename><surname>Peter Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurélien</forename><surname>Avent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><surname>Bennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitin</forename><surname>Arjun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Bhagoji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Bonawitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><surname>Cummings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Rafael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><forename type="middle">El</forename><surname>D'oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Rouayheb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrià</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Badih</forename><surname>Gascón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Ghazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Gruteser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaoyang</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lie</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhouyuan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tara</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauri</forename><surname>Javidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Konečný</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farinaz</forename><surname>Korolova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanmi</forename><surname>Koushanfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tancrède</forename><surname>Koyejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Lepoint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prateek</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehryar</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayfer</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rasmus</forename><surname>Özgür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariana</forename><surname>Pagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Raykova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weikang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><forename type="middle">U</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziteng</forename><surname>Stich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananda</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Theertha Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praneeth</forename><surname>Tramèr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianyu</forename><surname>Vepakomma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.04977</idno>
		<ptr target="http://arxiv.org/abs/1912.04977" />
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Konečný</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Richtárik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananda</forename><surname>Theertha Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><surname>Bacon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05492</idno>
		<ptr target="http://arxiv.org/abs/1610.05492" />
		<title level="m">Federated Learning: Strategies for Improving Communication Efficiency</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Inference attacks on location tracks</title>
		<author>
			<persName><forename type="first">John</forename><surname>Krumm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pervasive Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="127" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">Vaibhav</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natasa</forename><surname>Tagasovska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Vatter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Garbinato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.12801</idno>
		<ptr target="http://arxiv.org/abs/1811.12801" />
		<title level="m">Generative Models for Simulating Mobility Trajectories</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Adversarial machine learning at scale</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR&apos;19)</title>
		<meeting>the International Conference on Learning Representations (ICLR&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Automatic Detection of Vague Words and Sentences in Privacy Policies</title>
		<author>
			<persName><forename type="first">Logan</forename><surname>Lebanoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1387</idno>
		<ptr target="https://doi.org/10.18653/v1/D18-1387" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3508" to="3517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Certified robustness to adversarial examples with differential privacy</title>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Lecuyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaggelis</forename><surname>Atlidakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roxana</forename><surname>Geambasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suman</forename><surname>Jana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;19)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;19)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="656" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Privacy preference modeling and prediction in a simulated campuswide IoT environment</title>
		<author>
			<persName><forename type="first">Hosub</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfred</forename><surname>Kobsa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Pervasive Computing and Communications (PerCom&apos;17</title>
		<meeting>the IEEE International Conference on Pervasive Computing and Communications (PerCom&apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="276" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Privacy leakage of location sharing in mobile social networks: Attacks and defense</title>
		<author>
			<persName><forename type="first">Huaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suguo</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohui</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuemin</forename><surname>Sherman Shen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TDSC.2016.2604383</idno>
		<ptr target="https://doi.org/10.1109/TDSC.2016.2604383" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Dependable Secure Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="646" to="660" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Multi-key privacypreserving deep learning in cloud computing</title>
		<author>
			<persName><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><forename type="middle">Zhi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siu</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Yiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.future.2017.02.006</idno>
		<ptr target="https://doi.org/10.1016/j.future.2017.02.006" />
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="76" to="85" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">AnonymousNet: Natural face de-identification with measurable privacy</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPRW.2019.00013</idno>
		<ptr target="https://doi.org/10.1109/CVPRW.2019.00013" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW&apos;19)</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019-06">2019. 2019-June (2019</date>
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Yandong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML&apos;19</title>
		<meeting>the International Conference on Machine Learning (ICML&apos;19</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3866" to="3876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Adversaries or allies? Privacy and deep learning in big data era</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianqing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanlei</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1002/cpe.5102</idno>
		<ptr target="https://doi.org/10.1002/cpe.5102" />
	</analytic>
	<monogr>
		<title level="m">Concurrency Computation</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">5102</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Home location protection in mobile social networks: a community based method (short paper)</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanlei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Information Security Practice and Experience (ISPEC&apos;17)</title>
		<meeting>the International Conference on Information Security Practice and Experience (ISPEC&apos;17)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="694" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Silence is Golden: Enhancing Privacy of Location-Based Services by Content Broadcasting and Active Caching in Wireless Vehicular Networks</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanlei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianqing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longxiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">H</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVT.2016.2531185</idno>
		<ptr target="https://doi.org/10.1109/TVT.2016.2531185" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Veh. Technol</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="9942" to="9953" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Mining checkins from location-sharing services for client-independent IP geolocation</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoxue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuezhi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoming</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K K</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<idno type="DOI">10.1109/INFOCOM.2014.6847987</idno>
		<ptr target="https://doi.org/10.1109/INFOCOM.2014.6847987" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Communications (INFOCOM&apos;14</title>
		<meeting>IEEE International Conference on Computer Communications (INFOCOM&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="619" to="627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Generative model: Membership attack, generalization and diversity</title>
		<author>
			<persName><forename type="first">Kin Sum</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Gao</surname></persName>
		</author>
		<idno>CoRR, abs/1805.09898</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A survey on security threats and defensive techniques of machine learning: A data driven view</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wentao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName><surname>Leung</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2018.2805680</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2018.2805680" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="12103" to="12117" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">trajGANs: Using generative adversarial networks for geo-privacy protection of trajectory data (Vision paper)</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanzhou</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clio</forename><surname>Andris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Location Privacy and Security Workshop</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Trojaning Attack on Neural Networks</title>
		<author>
			<persName><forename type="first">Yingqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqing</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yousra</forename><surname>Aafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Chuan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.14722/ndss.2018.23291</idno>
		<ptr target="https://doi.org/10.14722/ndss.2018.23291" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Network and Distributed Systems Security Symposium (NDSS&apos;18)</title>
		<meeting>Network and Distributed Systems Security Symposium (NDSS&apos;18)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Protecting Privacy in Shared Photos via Adversarial Examples Based Stealth. Security and Communication Networks</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1155/2017/1897438</idno>
		<ptr target="https://doi.org/10.1155/2017/1897438" />
		<imprint>
			<date type="published" when="2017">2017. 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<author>
			<persName><forename type="first">Yunhui</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Bindschaedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyue</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haixu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><forename type="middle">A</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04889</idno>
		<ptr target="http://arxiv.org/abs/1802.04889" />
		<title level="m">Understanding Membership Inferences on Well-Generalized Learning Models</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Adversarial learning</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
		<idno type="DOI">10.1145/1081870.1081950</idno>
		<ptr target="https://doi.org/10.1145/1081870.1081950" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Knowledge Discovery and Data Mining (KDD&apos;05)</title>
		<meeting>the ACM International Conference on Knowledge Discovery and Data Mining (KDD&apos;05)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="641" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Home location identification of twitter users</title>
		<author>
			<persName><forename type="first">Jalal</forename><surname>Mahmud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Drews</surname></persName>
		</author>
		<idno type="DOI">10.1145/2528548</idno>
		<ptr target="https://doi.org/10.1145/2528548" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">47</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Detection of fraudulent and malicious websites by analysing user reviews for online shopping websites</title>
		<author>
			<persName><forename type="first">P</forename><surname>Asha S Manek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Deepa Shenoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Chandra Mohan</surname></persName>
		</author>
		<author>
			<persName><surname>Venugopal</surname></persName>
		</author>
		<idno type="DOI">10.1504/ijkwi.2016.078712</idno>
		<ptr target="https://doi.org/10.1504/ijkwi.2016.078712" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Knowledge and Web Intelligence</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">171</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Personality trait development from age 12 to age 18: Longitudinal, cross-sectional, and cross-cultural analyses</title>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">T</forename><surname>Robert R Mccrae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">D</forename><surname>Terracciano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carol</forename><forename type="middle">J</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><forename type="middle">De</forename><surname>Mills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Fruyt</surname></persName>
		</author>
		<author>
			<persName><surname>Mervielde</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.83.6.1456</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.83.6.1456" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="1456" to="1468" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Federated Learning of Deep Networks using Model Averaging</title>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eider</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blaise</forename><surname>Agüera Y Arcas</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.2841713</idno>
		<ptr target="https://doi.org/10.1063/1.2841713" />
	</analytic>
	<monogr>
		<title level="j">Arxiv</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">91118</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Learning Differentially Private Recurrent Language Models Without Lossing Accuracy</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>H Brendan Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/585597.585599</idno>
		<ptr target="https://doi.org/10.1145/585597.585599" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Learning Representations (ICLR&apos;18)</title>
		<meeting>the 6th International Conference on Learning Representations (ICLR&apos;18)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="39" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<author>
			<persName><forename type="first">Richard</forename><surname>Mcpherson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.00408</idno>
		<title level="m">Defeating image obfuscation with deep learning</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Measuring Personality for Automatic Elicitation of Privacy Preferences</title>
		<author>
			<persName><forename type="first">Ion</forename><surname>Hoda Mehrpouyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><forename type="middle">Soledad</forename><surname>Madrazo Azpiazu</surname></persName>
		</author>
		<author>
			<persName><surname>Pera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Privacy-Aware Computing (PAC&apos;17</title>
		<meeting>the IEEE Symposium on Privacy-Aware Computing (PAC&apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="84" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Exploiting unintended feature leakage in collaborative learning</title>
		<author>
			<persName><forename type="first">Luca</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emiliano</forename><surname>De Cristofaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;19)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;19)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="691" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Your online interests: Pwned! a pollution attack against targeted advertising</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anmol</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Udi</forename><surname>Weinsberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenke</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;14</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="129" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Rényi Differential Privacy</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Mironov</surname></persName>
		</author>
		<idno type="DOI">10.1109/CSF.2017.11</idno>
		<ptr target="https://doi.org/10.1109/CSF.2017.11" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Security Foundations Symposium (CSF&apos;17)</title>
		<meeting>the IEEE Computer Security Foundations Symposium (CSF&apos;17)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="263" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">SecureML: A system for scalable privacy-preserving machine learning</title>
		<author>
			<persName><forename type="first">Payman</forename><surname>Mohassel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;17)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="19" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Universal adversarial perturbations</title>
		<author>
			<persName><forename type="first">Mohsen</forename><surname>Seyed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alhussein</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><surname>Frossard</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.17</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2017.17" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR&apos;17)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="86" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Deepfool: a simple and accurate method to fool deep neural networks</title>
		<author>
			<persName><forename type="first">Seyed-Mohsen</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alhussein</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR&apos;16)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2574" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">How To Break Anonymity of the Netflix Prize</title>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
		<idno>Dataset. cs/0610105</idno>
		<ptr target="http://arxiv.org/abs/cs/0610105" />
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning</title>
		<author>
			<persName><forename type="first">Milad</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Houmansadr</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2019.00065</idno>
		<ptr target="https://doi.org/10.1109/SP.2019.00065" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;19)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="739" to="753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">Oracle Efficient Private Non-Convex Optimization</title>
		<author>
			<persName><forename type="first">Seth</forename><surname>Neel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Vietri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwei</forename><forename type="middle">Steven</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01783</idno>
		<ptr target="http://arxiv.org/abs/1909.01783" />
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Privacy-preserving ridge regression on hundreds of millions of records</title>
		<author>
			<persName><forename type="first">Valeria</forename><surname>Nikolaenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Udi</forename><surname>Weinsberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stratis</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Joye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Boneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nina</forename><surname>Taft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;13)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;13)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="334" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Assesing Completeness of Solvency and Financial Condition Reports through the use of Machine Learning and Text Classification</title>
		<author>
			<persName><forename type="first">Ruairí</forename><surname>Nugent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Faceless person recognition: Privacy implications in social media</title>
		<author>
			<persName><forename type="first">Joon</forename><surname>Seong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV&apos;16)</title>
		<meeting>European Conference on Computer Vision (ECCV&apos;16)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="19" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Adversarial image perturbation for privacy protection a game theory perspective</title>
		<author>
			<persName><forename type="first">Joon</forename><surname>Seong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision (ICCV&apos;17)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV&apos;17)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1491" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Towards reverse-engineering black-box neural networks</title>
		<author>
			<persName><forename type="first">Joon</forename><surname>Seong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Explainable AI: Interpreting, Explaining and Visualizing Deep Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="121" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">SmarPer: Context-Aware and Automatic Runtime-Permissions for Mobile Devices</title>
		<author>
			<persName><forename type="first">Katarzyna</forename><surname>Olejnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Italo</forename><surname>Dacosta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joana</forename><forename type="middle">Soares</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Huguenin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><forename type="middle">Emtiyaz</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><forename type="middle">Pierre</forename><surname>Hubaux</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2017.25</idno>
		<ptr target="https://doi.org/10.1109/SP.2017.25" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;17)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1058" to="1076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Connecting Pixels to Privacy and Utility: Automatic Redaction of Private Information in Images</title>
		<author>
			<persName><forename type="first">Tribhuvanesh</forename><surname>Orekondy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2018.00883</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2018.00883" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;18)</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;18)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="8466" to="8475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Towards a Visual Privacy Advisor: Understanding and Predicting Privacy Risks in Images</title>
		<author>
			<persName><forename type="first">Tribhuvanesh</forename><surname>Orekondy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2017.398</idno>
		<ptr target="https://doi.org/10.1109/ICCV.2017.398" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV&apos;17)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3706" to="3715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">A non-parametric generative model for human trajectories</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">S</forename><surname>Rosenblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenzhuo</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI&apos;18</title>
		<meeting>the International Joint Conference on Artificial Intelligence (IJCAI&apos;18</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3812" to="3817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Semi-supervised knowledge transfer for deep learning from private training data</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Úlfar</forename><surname>Erlingsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Learning Representations (ICLR&apos;19)</title>
		<meeting>the 5th International Conference on Learning Representations (ICLR&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07277</idno>
		<ptr target="http://arxiv.org/abs/1605.07277" />
		<title level="m">Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Practical black-box attacks against machine learning</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Berkay Celik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
		<idno type="DOI">10.1145/3052973.3053009</idno>
		<ptr target="https://doi.org/10.1145/3052973.3053009" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Asia Conference on Computer and Communications Security (ASIACCS&apos;17)</title>
		<meeting>the ACM Asia Conference on Computer and Communications Security (ASIACCS&apos;17)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="506" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">The limitations of deep learning in adversarial settings</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Berkay Celik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananthram</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE European Symposium on Security and Privacy</title>
		<meeting>the IEEE European Symposium on Security and Privacy</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="372" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Data synthesis based on generative adversarial networks</title>
		<author>
			<persName><forename type="first">Noseong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmoud</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kshitij</forename><surname>Gorde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sushil</forename><surname>Jajodia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkyu</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngmin</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.14778/3231751.3231757</idno>
		<ptr target="https://doi.org/10.14778/3231751.3231757" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1071" to="1083" />
		</imprint>
	</monogr>
	<note>VLDB Endowment</note>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Multiparty differential privacy via aggregation of locally trained classifiers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Manas</surname></persName>
		</author>
		<author>
			<persName><surname>Pathak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS&apos;10</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1876" to="1884" />
		</imprint>
	</monogr>
	<note>Shantanu Rane, and Bhiksha Raj</note>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Privacy, security and trust issues arising from cloud computing</title>
		<author>
			<persName><forename type="first">Siani</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Azzedine</forename><surname>Benameur</surname></persName>
		</author>
		<idno type="DOI">10.1109/CloudCom.2010.66</idno>
		<ptr target="https://doi.org/10.1109/CloudCom.2010.66" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd IEEE International Conference on Cloud Computing Technology and Science (CloudCom&apos;10)</title>
		<meeting>the 2nd IEEE International Conference on Cloud Computing Technology and Science (CloudCom&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="693" to="702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Scalable Differential Privacy with Certified Robustness in Adversarial Learning</title>
		<author>
			<persName><forename type="first">Nhathai</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">My</forename><forename type="middle">T</forename><surname>Thai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoming</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dejing</forename><surname>Dou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.09822</idno>
		<ptr target="http://arxiv.org/abs/1903.09822" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning (PMLR&apos;20)</title>
		<meeting>the 37th International Conference on Machine Learning (PMLR&apos;20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Adaptive laplace mechanism: Differential privacy preservation in deep learning</title>
		<author>
			<persName><forename type="first">Nhathai</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xintao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dejing</forename><surname>Dou</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2017.48</idno>
		<ptr target="https://doi.org/10.1109/ICDM.2017.48" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Data Mining (ICDM&apos;17)</title>
		<meeting>IEEE International Conference on Data Mining (ICDM&apos;17)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="385" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Heterogeneous Gaussian mechanism: Preserving differential privacy in deep learning with provable robustness</title>
		<author>
			<persName><forename type="first">Hai</forename><surname>Nhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh</forename><forename type="middle">N</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dejing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xintao</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">My</forename><forename type="middle">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Thai</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/660</idno>
		<idno type="arXiv">arXiv:1906.01444</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/660" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Joint Conference on Artificial Intelligence (IJCAI&apos;19)</title>
		<meeting>International Joint Conference on Artificial Intelligence (IJCAI&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="4753" to="4759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Privacy-Preserving Deep Learning via Additively Homomorphic Encryption</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phong</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshinori</forename><surname>Aono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takuya</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiho</forename><surname>Moriai</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIFS.2017.2787987</idno>
		<ptr target="https://doi.org/10.1109/TIFS.2017.2787987" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1333" to="1345" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Cryptographic techniques for privacy-preserving data mining</title>
		<author>
			<persName><forename type="first">Benny</forename><surname>Pinkas</surname></persName>
		</author>
		<idno type="DOI">10.1145/772862.772865</idno>
		<ptr target="https://doi.org/10.1145/772862.772865" />
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="12" to="19" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Generative Adversarial Perturbations</title>
		<author>
			<persName><forename type="first">Omid</forename><surname>Poursaeed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isay</forename><surname>Katsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bicheng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2018.00465</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2018.00465" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;18)</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;18)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4422" to="4431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<title level="m" type="main">Sampling Attacks: Amplification of Membership Inference Attacks by Repeated Queries</title>
		<author>
			<persName><forename type="first">Tribhuvanesh</forename><surname>Shadi Rahimian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Orekondy</surname></persName>
		</author>
		<author>
			<persName><surname>Fritz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.00395</idno>
		<ptr target="http://arxiv.org/abs/2009.00395" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Private-by-design advertising meets the real world</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Reznichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Francis</surname></persName>
		</author>
		<idno type="DOI">10.1145/2660267.2660305</idno>
		<ptr target="https://doi.org/10.1145/2660267.2660305" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;14</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="116" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Adversarial Diversity and Hard Positive Generation</title>
		<author>
			<persName><forename type="first">Andras</forename><surname>Rozsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><forename type="middle">M</forename><surname>Rudd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terrance</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPRW.2016.58</idno>
		<ptr target="https://doi.org/10.1109/CVPRW.2016.58" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPW&apos;16)</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPW&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="410" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title level="m" type="main">Learning in a Large Function Space: Privacy-Preserving Mechanisms for SVM Learning</title>
		<author>
			<persName><forename type="first">I P</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">L</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nina</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><surname>Taft</surname></persName>
		</author>
		<idno>1. 65-100 pages</idno>
		<ptr target="http://repository.cmu.edu/jpc" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title level="m" type="main">Dynamic Backdoor Attacks Against Machine Learning Models</title>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Salem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqing</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.03675</idno>
		<ptr target="http://arxiv.org/abs/2003.03675" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models</title>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Salem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Humbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Berrang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Backes</surname></persName>
		</author>
		<idno type="DOI">10.14722/ndss.2019.23119</idno>
		<ptr target="https://doi.org/10.14722/ndss.2019.23119" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Network and Distributed Systems Security Symposium (NDSS&apos;19)</title>
		<meeting>Network and Distributed Systems Security Symposium (NDSS&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Privacy preserving regression modelling via distributed computation</title>
		<author>
			<persName><forename type="first">Ashish</forename><forename type="middle">P</forename><surname>Sanil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">F</forename><surname>Karr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerome</forename><forename type="middle">P</forename><surname>Reiter</surname></persName>
		</author>
		<idno type="DOI">10.1145/1014052.1014139</idno>
		<ptr target="https://doi.org/10.1145/1014052.1014139" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD&apos;04)</title>
		<meeting>the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD&apos;04)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="677" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<author>
			<persName><forename type="first">Phillipp</forename><surname>Schoppmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Borja</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Doerner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samee</forename><surname>Zahur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Evans</surname></persName>
		</author>
		<title level="m">Secure Linear Regression on Vertically Partitioned Datasets. IACR Cryptology Eprint Archive 2016</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</author>
		<idno type="DOI">10.1145/505282.505283</idno>
		<ptr target="https://doi.org/10.1145/505282.505283" />
	</analytic>
	<monogr>
		<title level="j">Machine Learning in Automated Text Categorization. Comput. Surveys</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition</title>
		<author>
			<persName><forename type="first">Mahmood</forename><surname>Sharif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sruti</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lujo</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">K</forename><surname>Reiter</surname></persName>
		</author>
		<idno type="DOI">10.1145/2976749.2978392</idno>
		<ptr target="https://doi.org/10.1145/2976749.2978392" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;16)</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1528" to="1540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Toward an approach to privacy notices in IoT</title>
		<author>
			<persName><forename type="first">Parvaneh</forename><surname>Shayegh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sepideh</forename><surname>Ghanavati</surname></persName>
		</author>
		<idno type="DOI">10.1109/REW.2017.77</idno>
		<ptr target="https://doi.org/10.1109/REW.2017.77" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 25th International Requirements Engineering Conference Workshops (REW&apos;17)</title>
		<meeting>the IEEE 25th International Requirements Engineering Conference Workshops (REW&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="104" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Privacy-preserving deep learning</title>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;15</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;15</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1310" to="1321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Membership Inference Attacks Against Machine Learning Models</title>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Stronati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2017.41</idno>
		<ptr target="https://doi.org/10.1109/SP.2017.41" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;17)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;17)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Hiding in the mobile crowd: Location privacy through collaboration</title>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Theodorakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panos</forename><surname>Papadimitratos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><forename type="middle">Pierre</forename><surname>Hubaux</surname></persName>
		</author>
		<idno type="DOI">10.1109/TDSC.2013.57</idno>
		<ptr target="https://doi.org/10.1109/TDSC.2013.57" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Dependable Secure Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="266" to="279" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Secure logistic regression of horizontally and vertically partitioned distributed databases</title>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Aleksandra B Slavkovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">M</forename><surname>Nardi</surname></persName>
		</author>
		<author>
			<persName><surname>Tibbits</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDMW.2007.114</idno>
		<ptr target="https://doi.org/10.1109/ICDMW.2007.114" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Data Mining (ICDM&apos;07</title>
		<meeting>the IEEE International Conference on Data Mining (ICDM&apos;07</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="723" to="728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Machine learning models that remember too much</title>
		<author>
			<persName><forename type="first">Congzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ristenpart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
		<idno type="DOI">10.1145/3133956.3134077</idno>
		<ptr target="https://doi.org/10.1145/3133956.3134077" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;17)</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;17)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="587" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Collaborative learning for deep neural networks</title>
		<author>
			<persName><forename type="first">Guocong</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chai</surname></persName>
		</author>
		<idno>Decem. 1832-1841</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS&apos;18)</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent with differentially private updates</title>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamalika</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
		<idno type="DOI">10.1109/GlobalSIP.2013.6736861</idno>
		<ptr target="https://doi.org/10.1109/GlobalSIP.2013.6736861" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Global Conference on Signal and Information Processing</title>
		<meeting>the IEEE Global Conference on Signal and Information Processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="245" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Toward automated online photo privacy</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Squicciarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cornelia</forename><surname>Caragea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Balakavi</surname></persName>
		</author>
		<idno type="DOI">10.1145/2983644</idno>
		<ptr target="https://doi.org/10.1145/2983644" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Web</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Analyzing images&apos; privacy for the modern web</title>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">C</forename><surname>Squicciarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cornelia</forename><surname>Caragea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Balakavi</surname></persName>
		</author>
		<idno type="DOI">10.1145/2631775.2631803</idno>
		<ptr target="https://doi.org/10.1145/2631775.2631803" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM Conference on Hypertext and Social Media (HT&apos;14</title>
		<meeting>the 25th ACM Conference on Hypertext and Social Media (HT&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="136" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Natural and Effective Obfuscation by Head Inpainting</title>
		<author>
			<persName><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqian</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seong</forename><surname>Joon Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2018.00530</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2018.00530" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;18</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;18</meeting>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="5050" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">A domain based approach to social relation recognition</title>
		<author>
			<persName><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.54</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2017.54" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR&apos;17)</title>
		<meeting>the 30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="435" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Face detection using deep learning: An improved faster RCNN approach</title>
		<author>
			<persName><forename type="first">Xudong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2018.03.030</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2018.03.030" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="page" from="42" to="50" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>ICLR&apos;14</note>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welderufael B Tesfay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toru</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shinsaku</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jetzabel</forename><surname>Kiyomoto</surname></persName>
		</author>
		<author>
			<persName><surname>Serna</surname></persName>
		</author>
		<title level="m">Read but Don&apos;t Agree: Privacy Policy Benchmarking using Machine Learning and the EU GDPR. Companion Proceedings of the The Web Conference</title>
		<imprint>
			<date type="published" when="2018">2018. 2018 2 (2018</date>
			<biblScope unit="page" from="163" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Facebook privacy breach</title>
		<ptr target="https://www.ft.com/content/87184c40-2cfe" />
	</analytic>
	<monogr>
		<title level="j">Financial Times</title>
		<imprint>
			<biblScope unit="page">381</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note>Financial Times</note>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Stealing machine learning models via prediction APIs</title>
		<author>
			<persName><forename type="first">Florian</forename><surname>Tramèr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Juels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">K</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ristenpart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th USENIX Security Symposium (USENIX&apos;16</title>
		<meeting>the 25th USENIX Security Symposium (USENIX&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="601" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Generating artificial data for private deep learning</title>
		<author>
			<persName><forename type="first">Aleksei</forename><surname>Triastcyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boi</forename><surname>Faltings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CEUR Workshop</title>
		<meeting>the 2019 CEUR Workshop</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2335</biblScope>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Privacy-preserving naive bayes classification</title>
		<author>
			<persName><forename type="first">Jaideep</forename><surname>Vaidya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murat</forename><surname>Kantarcoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Clifton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="879" to="898" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<title level="m" type="main">WaveNet: A Generative Model for Raw Audio</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno>CoRR abs/1609.03499</idno>
		<ptr target="http://arxiv.org/abs/1609.03499" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<monogr>
		<title level="m" type="main">Split learning for health: Distributed deep learning without sharing raw patient data</title>
		<author>
			<persName><forename type="first">Praneeth</forename><surname>Vepakomma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Swedish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.00564</idno>
		<ptr target="http://arxiv.org/abs/1812.00564" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2015.7298935</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2015.7298935" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;15)</title>
		<meeting>the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Stealing Hyperparameters in Machine Learning</title>
		<author>
			<persName><forename type="first">Binghui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Zhenqiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gong</forename></persName>
		</author>
		<idno type="DOI">10.1109/SP.2018.00038</idno>
		<ptr target="https://doi.org/10.1109/SP.2018.00038" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;18)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;18)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="36" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Privacy-preserving data publishing: A survey on recent developments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P S</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Surveys</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Beyond Inferring Class Representatives: User-Level Privacy Leakage from Federated Learning</title>
		<author>
			<persName><forename type="first">Zhibo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengkai</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hairong</forename><surname>Qi</surname></persName>
		</author>
		<idno type="DOI">10.1109/INFOCOM.2019.8737416</idno>
		<ptr target="https://doi.org/10.1109/INFOCOM.2019.8737416" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Communications (INFOCOM&apos;19</title>
		<meeting>IEEE International Conference on Computer Communications (INFOCOM&apos;19</meeting>
		<imprint>
			<date type="published" when="2019-04">2019. 2019-April (2019</date>
			<biblScope unit="page" from="2512" to="2520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">2018. I know what you see: Power side-channel attack on convolutional neural network accelerators</title>
		<author>
			<persName><forename type="first">Lingxiao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3274694.3274696</idno>
		<ptr target="https://doi.org/10.1145/3274694.3274696" />
	</analytic>
	<monogr>
		<title level="m">ACM International Conference Proceeding Series</title>
		<imprint>
			<biblScope unit="page" from="393" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Android permissions remystified: A field study on contextual integrity</title>
		<author>
			<persName><forename type="first">Primal</forename><surname>Wijesekera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Baokar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashkan</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Egelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Beznosov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th USENIX Security Symposium (USENIX&apos;15)</title>
		<meeting>the 24th USENIX Security Symposium (USENIX&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="499" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">The Feasibility of Dynamically Granted Permissions: Aligning Mobile Privacy with User Preferences</title>
		<author>
			<persName><forename type="first">Primal</forename><surname>Wijesekera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Baokar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lynn</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Reardon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Egelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Beznosov</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2017.51</idno>
		<ptr target="https://doi.org/10.1109/SP.2017.51" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy (SP&apos;17)</title>
		<meeting>the IEEE Symposium on Security and Privacy (SP&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1077" to="1093" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Contextualizing privacy decisions for better prediction (and protection)</title>
		<author>
			<persName><forename type="first">Primal</forename><surname>Wijesekera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Reardon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irwin</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lynn</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><forename type="middle">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Good</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Beznosov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Egelman</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173574.3173842</idno>
		<ptr target="https://doi.org/10.1145/3173574.3173842" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Factors in Computing Systems (CHI&apos;18)</title>
		<meeting>the Conference on Human Factors in Computing Systems (CHI&apos;18)</meeting>
		<imprint>
			<date type="published" when="2018-04">2018. 2018-April. 268</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Can we still avoid automatic face detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Wilber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Shmatikov</surname></persName>
		</author>
		<author>
			<persName><surname>Belongie</surname></persName>
		</author>
		<idno type="DOI">10.1109/WACV.2016.7477452</idno>
		<ptr target="https://doi.org/10.1109/WACV.2016.7477452" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV&apos;16</title>
		<meeting>the IEEE Winter Conference on Applications of Computer Vision (WACV&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">The value of collaboration in convex machine learning with differential privacy</title>
		<author>
			<persName><forename type="first">Nan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farhad</forename><surname>Farokhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><forename type="middle">Ali</forename><surname>Kaafar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Symposium on Security and Privacy</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="304" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Privacy-preservation for Stochastic Gradient Descent Application to Secure Logistic Regression</title>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tadanori</forename><surname>Teruya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junpei</forename><surname>Kawamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Sakuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Kikuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual Conference of the</title>
		<meeting>the 27th Annual Conference of the</meeting>
		<imprint>
			<publisher>Japanese Society for Artificial Intelligence</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="6" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<monogr>
		<title level="m" type="main">Synthesizing Tabular Data using Generative Adversarial Networks</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalyan</forename><surname>Veeramachaneni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.11264</idno>
		<ptr target="http://arxiv.org/abs/1811.11264" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Latent backdoor attacks on deep neural networks</title>
		<author>
			<persName><forename type="first">Yuanshun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haitao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><forename type="middle">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1145/3319535.3354209</idno>
		<ptr target="https://doi.org/10.1145/3319535.3354209" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer and Communications Security (CCS&apos;19)</title>
		<meeting>the ACM Conference on Computer and Communications Security (CCS&apos;19)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2041" to="2055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Privacy risk in machine learning: Analyzing the connection to overfitting</title>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Yeom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irene</forename><surname>Giacomelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<idno type="DOI">10.1109/CSF.2018.00027</idno>
		<ptr target="https://doi.org/10.1109/CSF.2018.00027" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Computer Security Foundations Symposium (CSF&apos;18)</title>
		<meeting>the IEEE Computer Security Foundations Symposium (CSF&apos;18)</meeting>
		<imprint>
			<date type="published" when="2018-07">2018. 2018-July. 268-282</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">IPrivacy: Image Privacy Protection by Identifying Sensitive Objects via Deep Multi-Task Learning</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengzhong</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianping</forename><surname>Fan</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIFS.2016.2636090</idno>
		<ptr target="https://doi.org/10.1109/TIFS.2016.2636090" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forensics Security</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1005" to="1016" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Context-dependent privacy-aware photo sharing based on machine learning</title>
		<author>
			<persName><forename type="first">Lin</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joël</forename><surname>Theytaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Touradj</forename><surname>Ebrahimi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-58469-0_7</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-58469-0_7" />
	</analytic>
	<monogr>
		<title level="m">IFIP Advances in Information and Communication Technology</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">502</biblScope>
			<biblScope unit="page" from="93" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Privacy-aware image classification and search</title>
		<author>
			<persName><forename type="first">Sergej</forename><surname>Zerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Siersdorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Demidova</surname></persName>
		</author>
		<idno type="DOI">10.1145/2348283.2348292</idno>
		<ptr target="https://doi.org/10.1145/2348283.2348292" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR&apos;12)</title>
		<meeting>the International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR&apos;12)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">A survey on collaborative deep learning and privacy-preserving</title>
		<author>
			<persName><forename type="first">Dayin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dakui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinqiao</forename><surname>Shi</surname></persName>
		</author>
		<idno type="DOI">10.1109/DSC.2018.00104</idno>
		<ptr target="https://doi.org/10.1109/DSC.2018.00104" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 3rd International Conference on Data Science in Cyberspace (DSC&apos;18)</title>
		<meeting>the IEEE 3rd International Conference on Data Science in Cyberspace (DSC&apos;18)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="652" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">Functional mechanism: Regression analysis under differential privacy</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaokui</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marianne</forename><surname>Winslett</surname></persName>
		</author>
		<idno type="DOI">10.14778/2350229.2350253</idno>
		<ptr target="https://doi.org/10.14778/2350229.2350253" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Very Large Data Bases (VLDB&apos;12)</title>
		<meeting>the International Conference on Very Large Data Bases (VLDB&apos;12)</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1364" to="1375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<monogr>
		<author>
			<persName><forename type="first">Tianwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zecheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruby</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.01860</idno>
		<ptr target="http://arxiv.org/abs/1807.01860" />
		<title level="m">Privacy-preserving Machine Learning through Data Obfuscation</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<monogr>
		<title level="m" type="main">Differentially Private Releasing via Deep Generative Model</title>
		<author>
			<persName><forename type="first">Xinyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shouling</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.01594</idno>
		<ptr target="http://arxiv.org/abs/1801.01594" />
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Principal visual word discovery for automatic license plate detection</title>
		<author>
			<persName><forename type="first">Wengang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIP.2012.2199506</idno>
		<ptr target="https://doi.org/10.1109/TIP.2012.2199506" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="4269" to="4279" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
