<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A comprehensive review of Quantum Machine Learning: from NISQ to Fault Tolerance</title>
				<funder ref="#_2jnqaDn">
					<orgName type="full">Pritzker School of Molecular Engineering</orgName>
				</funder>
				<funder>
					<orgName type="full">International Business Machines</orgName>
					<orgName type="abbreviated">IBM</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-03-31">31 Mar 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yunfei</forename><surname>Wang</surname></persName>
							<email>yunfeiwang0214@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Junyu</forename><surname>Liu</surname></persName>
							<email>junyuliu@uchicago</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Martin A. Fisher School of Physics</orgName>
								<orgName type="institution" key="instit2">Brandeis University</orgName>
								<address>
									<postCode>02453</postCode>
									<settlement>Waltham</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Chicago Quantum Exchange</orgName>
								<address>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">The University of Chicago</orgName>
								<address>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Kadanoff Center for Theoretical Physics</orgName>
								<orgName type="institution" key="instit1">Pritzker School of Molecular Engineering</orgName>
								<orgName type="institution" key="instit2">The University of Chicago</orgName>
								<address>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">The University of Chicago</orgName>
								<address>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A comprehensive review of Quantum Machine Learning: from NISQ to Fault Tolerance</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-03-31">31 Mar 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">17219D3B0C0DF57EDC769DF735C8C279</idno>
					<idno type="arXiv">arXiv:2401.11351v2[quant-ph]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-25T17:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Quantum machine learning, which involves running machine learning algorithms on quantum devices, has garnered significant attention in both academic and business circles. In this paper, we offer a comprehensive and unbiased review of the various concepts that have emerged in the field of quantum machine learning. This includes techniques used in Noisy Intermediate-Scale Quantum (NISQ) technologies and approaches for algorithms compatible with fault-tolerant quantum computing hardware. Our review covers fundamental concepts, algorithms, and the statistical learning theory pertinent to quantum machine learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Quantum machine learning represents a highly promising realm in contemporary physics and computer science research, with far-reaching implications spanning quantum chemistry <ref type="bibr" target="#b107">[108]</ref>, artificial intelligence <ref type="bibr" target="#b88">[89]</ref>, and even high-energy physics <ref type="bibr" target="#b6">[7]</ref>. Nevertheless, it remains in its nascent stages of development. This is evident from the absence of a precise definition for quantum machine learning. Some describe it as the convergence of quantum computing and machine learning, wherein machine learning algorithms are executed on quantum devices. In simpler terms, it can be thought of as the quantum counterpart to classical machine learning.</p><p>In recent times, artificial intelligence, exemplified by technologies like ChatGPT, has become an integral part of everyday life. It's entirely plausible that, in the future, we will harness artificial intellegence in an even wider array of applications, including medical diagnostics, education, and aiding scientific research. Much of artificial intellegence's success hinges on machine learning, a departure from traditional computer programs that entail crafting explicit instructions to directly solve problems <ref type="bibr" target="#b111">[112]</ref>. Machine learning models, on the other hand, are trained on real-world data stored in a dataset (often denoted as D), acquiring the ability to tackle problems autonomously. This represents a departure, in a sense, from the conventional von Neumann model of digital computing.</p><p>Researchers might initially wonder why there's a need for quantum machine learning when its classical counterpart has demonstrated impressive performance. One of the primary rationales stems from the fact that classical machine learning relies heavily on linear algebra procedures <ref type="bibr" target="#b17">[18]</ref>. For instance, classical machine learning can address problems like identifying the optimal hyperplane to separate two data clusters by employing matrix inversion techniques. Quantum mechanics, at its core, is inherently grounded in linear algebra, where we construct a Hilbert space (H) of a system described by an Hermitian operator known as the Hamiltonian ( Ä¤) <ref type="bibr" target="#b113">[114]</ref>. Over time, it has become evident that quantum computing has the potential to dramatically enhance a computer's problem-solving capabilities in certain specific scenarios. To illustrate, consider the task of matrix inversion again. Classical computers typically require computational efforts with a complexity of O(N log N ) to accomplish this, while quantum computers can leverage algorithms like the Harrow-Hassidim-Lloyd algorithm (HHL) algorithm <ref type="bibr" target="#b57">[58]</ref>, which has a complexity of O((log N ) 2 ), leading to significant speedup, in certain conditions like sparsity, fault-tolerance, small condition numbers, and fast interfaces between classical and quantum processors. Although there is no known explicit realizations of HHL algorithm at the large scale at the moment, it is still an exciting direction deserves further studies, especially when quantum devices are fast developing with more and more capabilities.</p><p>Due to its vague definition, quantum machine learning encompasses a broader spectrum of topics. For instance, quantum (shadow) tomography <ref type="bibr" target="#b1">[2]</ref> has gained prominence, focusing on the characterization of a given quantum state by accumulating data from various measurements. This involves determining the minimum number of identical quantum state copies needed to extract sufficient information about the state's properties. Another facet involves machine learning for quantum physics, which entails employing (perhaps classical) machine learning tools to explore various aspects of quantum physics. Additionally, some developments in both quantum algorithms and quantum hardware are often encompassed within the broader umbrella of quantum machine learning.</p><p>Although these topics may not directly align with the narrow definition of quantum machine learning outlined earlier, they hold substantial promise for its future development. To illustrate, within the narrow sensed field of quantum machine learning, a significant challenge is known as the input/output problem. In particular, the output problem pertains to the task of comprehending the solution generated by a quantum algorithm, and this aligns closely with the domain of shadow tomography. And by harnessing the capabilities of classical machine learning to gain deeper insights into quantum physics, it might lead to advancements in quantum computing too. In this review, we primarily focus on quantum machine learning in its narrower sense, which pertains to execute quantum algorithms designed for machine learning purposes.</p><p>Presently, we find ourselves in what's referred to as (perhaps the end of) the noisy intermediate scale quantum or NISQ era of quantum computing. Quantum computers are susceptible to background noise, which imposes limitations on our ability to construct quantum computers with sufficient depth for executing tasks demanding fast and precise computations. The quantum computers available today can only handle on the order of around 100 qubits, and they all exhibit noise, making it challenging to derive tangible benefits for our daily lives.</p><p>The solution to this predicament is known as quantum error correction (QEC) code <ref type="bibr" target="#b112">[113]</ref>. Think of QEC as a safeguard for quantum information. Typically, quantum information is lost once it's measured, which becomes especially likely in noisy environments. However, information protected by QEC can persist if it remains undamaged within certain limits. It's worth noting that all error correction codes have their constraints, implying that information will inevitably be lost if it's severely damaged. Nevertheless, error correction provides a protective buffer zone against such losses.</p><p>Our objective is to implement QEC codes across all quantum devices, ushering in an era of fault-tolerant quantum computing (FTQC) in the future. This trajectory parallels the history of classical computing, where, before the invention of classical error correction, scaling up and running useful algorithms on classical computers was also a formidable challenge <ref type="bibr" target="#b28">[29]</ref>. Today, we can reliably operate classical computers everyday. Given the promising advancements in quantum error correction in recent times, our optimism about the future of quantum computing remains steadfast.</p><p>However, when it comes to machine learning, classical machine learning doesn't inherently reject noise <ref type="bibr" target="#b87">[88]</ref>. The widely recognized learning algorithm, known as stochastic gradient descent, explicitly incorporates noise, and surprisingly, this noise addition actually enhances its performance. To grasp this concept, consider that noise can effectively steer us away from saddle points, offering an automatic mechanism for avoiding them. In a way, one can interpret this as machine learning's ability to withstand and even benefit from noise. Consequently, this insight suggests that running certain machine learning algorithms on current (NISQ) quantum devices could have some significance. This prospect promises to enrich our present-day experiences significantly, especially considering the challenges associated with constructing QEC, which could take a few years to become fully integrated. Prior to entering the era of fault-tolerant quantum computing, we'll have the opportunity to experiment with quantum devices and apply machine learning techniques, adding a vibrant dimension to our current scientific research.</p><p>In addition to discussing the current applications of quantum capabilities for machine learning, we should also let our imaginations soar. The era of fault-tolerant quantum computing (FTQC) is a foreseeable future, and it's crucial to look ahead at what challenges we can tackle with quantum machine learning on FTQC devices. One of the most renowned and valuable algorithms in this context is the Harrow-Hassidim-Lloyd (HHL) algorithm <ref type="bibr" target="#b57">[58]</ref>. Additionally, there are other algorithms that can be deployed to address a range of problems, such as principal component analysis <ref type="bibr" target="#b17">[18]</ref>.</p><p>Beside the optimistic future that quantum machine learning has, there are also a number of controversial issues with the subject. For example, some might argue that the variational quantum algorithm will not work in some circumstance. People working on quantum landscapes theory observed the famous barren plateau phenomena which leads to a kind of no-go theorem <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b85">86]</ref>. It amounts to situations that are hard to find minimum when we optimizes our objective function by gradient descent with randomized variational circuits. Debates indeed exist regarding whether quantum algorithms can consistently deliver exponential speedups. Some argue that quantum speedup is only guaranteed when dealing with quantum information. When it comes to classical information, it's conceivable to design classical machine learning models capable of achieving comparable average prediction accuracy <ref type="bibr" target="#b120">[121,</ref><ref type="bibr" target="#b65">66]</ref>. In such cases, the computational complexity difference between classical and quantum approaches may, at worst, be a modest polynomial factor. This debate underscores the importance of carefully assessing the specific problem and context when considering the potential advantages of quantum algorithms. However, the landscape shifts when the objective is to attain a low worst-case prediction error. In this scenario, it becomes feasible to achieve an exponential divergence in computational complexities between classical and quantum approaches. This underscores the potential superiority of quantum algorithms when stringent requirements for worst-case accuracy are in play. This phenomenon can be viewed as a manifestation of classical effects casting their "shadow" in the quantum realm. It should come as no surprise to individuals well-versed in quantum theory that quantum predictions tend to align with classical theory when dealing with systems possessing a high degree of freedom. This approach can also be applied to tackle a critical issue in variational quantum algorithms known as the "output problem," often referred to as the classical shadow.</p><p>Indeed, it is truly heartening and captivating to witness the evolution of quantum computing beyond celebrated algorithms like Shor's factoring algorithm <ref type="bibr" target="#b116">[117]</ref> and Grover search <ref type="bibr" target="#b49">[50]</ref>. Algorithms like HHL <ref type="bibr" target="#b57">[58]</ref> offer a versatile blueprint, shedding light on how quantum computers hold the potential to deliver significant acceleration for fundamental tasks like clustering, pattern-matching, and principal component analysis. However, as Scott Aaronson aptly noted in his paper <ref type="bibr" target="#b0">[1]</ref>, the pursuit of these speedups will still demand significant effort and ingenuity, as nature continues to present challenges that compel us to work diligently for these advancements.</p><p>We have structured our review as follows. In section 2, we focus on the historical and ongoing developments in Quantum Machine Learning (QML) during the Noisy Intermediate-Scale Quantum (NISQ) era. Within this era, one of the central frameworks is the Variational Quantum Algorithm (VQA) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b107">108]</ref>, which we explore in detail in section 2.1. VQA comprises four key elements: the choice of an objective function (discussed in section 2.1.1), the employment of Parameterized Quantum Circuits (PQC) with adjustable parameters optimized by classical algorithms (covered in section 2.1.2), measurement strategies (explored in section 2.1.3), and the classical optimizer responsible for minimizing the objective function (explained in section 2.1.4). Subsequently, we provide insights into the construction of the Quantum Neural Tangent Kernel (QNTK) <ref type="bibr" target="#b86">[87]</ref> in section 2.2, offering a theoretical foundation for quantum neural networks and an understanding of stochastic gradient descent dynamics from first principles. Finally, we address the issue of barren plateaus in section 2.3, approaching this topic through the lens of quantum landscape theory <ref type="bibr" target="#b26">[27]</ref>. Additionally, we present an alternative formulation of laziness <ref type="bibr" target="#b85">[86]</ref>, providing another perspective on the same problem.</p><p>In section 3, our focus shifts to quantum algorithms that have the potential for exponential speedup in the Fault-Tolerant Quantum Computing (FTQC) era. We begin by introducing Quantum Phase Estimation (QPE) <ref type="bibr" target="#b28">[29]</ref> in section 3.1, where we also delve into the Quantum Principal Component Analysis (QPCA) program <ref type="bibr" target="#b90">[91]</ref>. Subsequently, we present a counterpoint regarding the attainability of exponential speedup for programs such as the recommendation system in section 3.2. Moving on to section 3.3, we introduce the pivotal Harrow-Hassidim-Lloyd (HHL) algorithm <ref type="bibr" target="#b57">[58]</ref>, which opens up possibilities for various new quantum machine learning algorithms. In section 3.3.1, we illustrate a visionary perspective on the future of machine learning algorithms with the aid of Carleman linearization <ref type="bibr" target="#b89">[90]</ref> and the HHL algorithm. Finally, in section 3.4, we introduce Quantum Random Access Memory (QRAM), focusing on theoretical designs <ref type="bibr" target="#b55">[56]</ref>, practical implementation efforts <ref type="bibr" target="#b53">[54]</ref>, and its necessity in certain algorithms <ref type="bibr" target="#b17">[18]</ref>.</p><p>In section 4, we delve into various topics that amalgamate quantum principles with statistical learning theory. Our primary focus is on shadow tomography <ref type="bibr" target="#b1">[2]</ref> in section 4.1, where we explore the motivation behind shadow tomography and delve into the construction of the theorem. A pivotal subject inspired by shadow tomography, the classical shadow formalism <ref type="bibr" target="#b40">[41]</ref>, is thoroughly discussed in section 4.2. Moving on to section 4.2.1, we examine the application of classical shadow as an efficient quantum-to-classical information converter <ref type="bibr" target="#b65">[66]</ref>. In section 4.3, we then shift our attention to the applications of Quantum Machine Learning (QML) in the study of quantum data and quantum simulators <ref type="bibr" target="#b17">[18]</ref>.</p><p>It's essential to note that our review doesn't encompass various topics, including quantum machine learning algorithms whose advantages stem from sampling-related statements, the studies of quantum error corrections, quantum memory, and designs of quantum data centers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Noisy intermediate-scale quantum (NISQ) era</head><p>The concept of the NISQ era, which stands for Noisy Intermediate-Scale Quantum, was introduced by John Preskill in 2018 <ref type="bibr" target="#b109">[110]</ref>. It's essential to understand that NISQ is primarily a hardware-oriented definition and doesn't inherently imply a specific time frame. In NISQ devices, quantum circuits are implemented, where all gates adhere to a predefined graph G, with qubits represented by nodes in this graph. These gates typically operate on one or two qubits. Due to the noise associated with each gate operation, NISQ algorithms are naturally constrained to shallow circuit depths <ref type="bibr" target="#b11">[12]</ref>.</p><p>On the other hand, "near-term" algorithms are those designed for quantum devices expected to be available in the next few years, and this term doesn't explicitly refer to the absence of Quantum Error Correction (QEC). The notion of what constitutes the "near-term" can be subjective because different researchers may have varying opinions on how many years can be considered "near-term." Predicting experimental progress in quantum computing is always challenging, and such predictions can be influenced by human biases. Algorithms developed for near-term hardware may become unfeasible if hardware advancements do not align with the algorithm's experimental requirements <ref type="bibr" target="#b16">[17]</ref>.</p><p>The majority of existing NISQ algorithms leverage quantum computers' capabilities through a hybrid quantum-classical approach. These algorithms involve offloading the classically challenging aspects of certain computations to a quantum computer while performing the remaining tasks on a suitably powerful classical device. They operate by iteratively adjusting the parameters of a parametrized quantum circuit, making them known as Variational Quantum Algorithms (VQA) ( <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b25">26]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Variational quantum algorithm (VQA)</head><p>The concept of Variational Quantum Algorithms (VQA) was initially introduced to address certain quantum chemistry challenges, notably through the well-known Variational Quantum Eigensolver (VQE) <ref type="bibr" target="#b96">[97,</ref><ref type="bibr" target="#b107">108,</ref><ref type="bibr" target="#b130">131]</ref>. Additionally, VQA includes the Quantum Approximate Optimization Algorithm (QAOA) <ref type="bibr" target="#b43">[44]</ref>, which is designed for solving combinatorial optimization problems. Interestingly, reference <ref type="bibr" target="#b4">[5]</ref> shows that VQE combined with filtering operators can be more efficient and accurate than standard VQE and QAOA in the context of combinatorial optimization.</p><p>It's crucial to emphasize that, as of now, there is no established quantum advantage for Variational Quantum Algorithms (VQA) employing NISQ devices. As previously outlined, VQA can be divided into four primary components: 1) the objective function; 2) the parameterized quantum circuit (PQC); 3) the measurement scheme; and 4) the classical optimizer. This breakdown is visually represented in FIG. <ref type="figure" target="#fig_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Objective function</head><p>The Hamiltonian, a Hermitian operator, plays a pivotal role in governing the time evolution of a physical system through SchrÃ¶dinger equation. Its expectation value provides the energy associated with a quantum state, making it a common target for minimization in VQA, often used to find the ground state of a system. However, when we aim to solve problems unrelated to real physical systems, we can construct a Hamiltonian that encodes the information we seek to extract.</p><p>In the context of VQA, the specific choice of the Hamiltonian is not particularly significant. One can select any Hermitian operator and designate it as the Hamiltonian, then attempt to find the ground state. However, an essential property that the operator must possess is the ability to decompose into several operators that can be measured by the quantum processor. We will explore this concept in more detail in section 2.1.3.</p><p>Constructing the objective function O, it is natural to employ the expectation value of the Hamiltonian:</p><formula xml:id="formula_0">â¨Hâ© U (Î¸) â¡ â¨0| U â  (Î¸)HU (Î¸) |0â© .<label>(1)</label></formula><p>It's important to note that we initialize our qubits in the state |0â© and subsequently evolve them using the parameterized quantum circuit (PQC). As shown in Eqn. 1, the objective function depends on the unitary time evolution operator, making it a function of classical tunable parameters denoted as Î¸. In some situations, it can be advantageous to utilize objective functions other than the Hamiltonian expectation value. Consequently, we have some flexibility in the specific form of the objective function, but we require that the objective function O be a function of Î¸ and â¨Hâ© U (Î¸) , expressed as O Î¸ , {â¨Hâ© U (Î¸) } .</p><p>In fact, the selection of the objective function is a critical factor in achieving the desired convergence in VQA. Barren plateaus, where gradients vanish, are closely tied to the choice of the cost function. Therefore, a poor choice can result in a failure to locate a minimum of the objective function through gradient descent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(i) Pauli strings</head><p>The most natural approach to representing our Hamiltonian involves expressing it as a linear combination of basic tensor products of Pauli matrices: Ï i , with Ï i taking values from the set {I, Ï x , Ï y , Ï z }. These tensor products are commonly referred to as Pauli strings, defined as</p><formula xml:id="formula_1">P = â n j=1 Ï (j)</formula><p>i , where the index j corresponds to different qubits. This representation is well-suited because the Pauli matrices Ï i collectively form a basis for all Hermitian 2 by 2 matrices and serve as the generators of the special unitary group SU <ref type="bibr" target="#b1">(2)</ref>. The Hamiltonian, then, can be decomposed as H = M k=1 c k Pk . In this decomposition, the complex coefficient c k pertains to the k-th Pauli string, and the total number of Pauli strings, denoted as M , is contingent upon the specific form of the Hamiltonian under consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(ii) Fidelity</head><p>Rather than optimizing with respect to the expectation value of an operator, certain VQAs necessitate a subroutine for optimizing the state obtained from the PQC U (Î¸), denoted as |Î¨â© U (Î¸) , with respect to a target state, denoted as |Î¨â©. We then define fidelity as the following:</p><formula xml:id="formula_2">F Î¨, Î¨ U (Î¸) â¡ | â¨Î¨|Î¨ U (Î¸) â© | 2 = â¨Proj Î¨ â© U (Î¸)</formula><p>, which is the expectation value of the projection operator on the target state Î¨: Proj Î¨ = |Î¨â©â¨Î¨| . Conventionally, VQA involves minimizing the objective function. In this context, it is natural to use infidelity, represented as 1 -F Î¨, Î¨ U (Î¸) , or alternatively, the negative fidelity, denoted as -â¨Proj Î¨ â© U (Î¸) . The expression of objective functions based on fidelities is commonly utilized in state preparation algorithms in quantum optics <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b77">78]</ref> and quantum machine learning <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b106">107]</ref>.</p><p>Additional objective functions can also be developed, and any cost function expressed operationally can be considered a viable option <ref type="bibr" target="#b16">[17]</ref>. Two examples include the Conditional-Value-at-Risk (CVaR) <ref type="bibr" target="#b12">[13]</ref> and the Gibbs objective function <ref type="bibr" target="#b82">[83]</ref>. These two forms can be simplified to the mean energy, denoted as â¨Hâ© . Importantly, their performance is at least as effective as utilizing the mean energy <ref type="bibr" target="#b82">[83,</ref><ref type="bibr" target="#b12">13]</ref>. The authors of <ref type="bibr" target="#b93">[94]</ref> extend VQE to be applicable to a large class of nonlinear problems, including nonlinear differential equations, and show, for example, that quantum circuits can be exponentially more efficient (in terms of expressivity) than classical matrix product states.</p><p>2.1.2. Parameterized quantum circuits (PQC) Next, we delve into the second critical component of a VQA, which is the quantum circuit responsible for generating the state that optimally satisfies the defined objective. As described above, it prepares the state by an act of unitary that depends on classical parameters: Î¸ , hence, it is called the parameterized quantum circuit: PQC.</p><p>The state prepared is defined as the following: |Î¨(Î¸)â© = U (Î¸) |Î¨ 0 â© , where |Î¨ 0 â© is some initial state, for example, |0â© ân , where n is the number of qubits. As remarked earlier, n should be quite small, due to the limited ability of the NISQ devices, we can only accommodate very shallow circuits. In some VQAs, it is convenient to use other initialization states. We can use a unitary operator (for example, a rotation operator) P (Ï), and the initial state:</p><formula xml:id="formula_3">|Î¨ 0 â© = P (Ï) |0â© ân .</formula><p>Similar to the variational principle in quantum wave mechanics, which aims to obtain the wave function with the lowest possible energy, a deep understanding of the physical system can significantly assist us in creating a better initial guess. For instance, if we seek an approximation of the ground state of a potential that exhibits even parity, it's advisable to start with an initial guess that also possesses even parity. It's important to recognize that the choice of the initial state can significantly impact the performance of a VQA in terms of convergence speed and how closely the final state approximates the optimal solution for the problem at hand. This influence is particularly evident in a simple example. Hence, in most cases, your initial step should involve examining the Hamiltonian or the observable of interest to identify any inherent symmetries.</p><p>In the NISQ era, we face significant limitations in terms of the number of qubits we can effectively use. Therefore, it's essential to consider the quantum hardware on which our VQA runs. Constructing problem-inspired initial states can be computationally expensive when using native gates. Consequently, most ansÃ¤tze developed so far fall into one of two categories: problem inspired ansÃ¤tze and hardware efficient ansÃ¤tze <ref type="bibr" target="#b16">[17]</ref>. The categorization depends on the structure and intended application of the ansÃ¤tze. The PQC shown in FIG. <ref type="figure" target="#fig_1">2</ref> and FIG. <ref type="figure" target="#fig_0">1</ref> are examples of the second kind, hardware efficient ansÃ¤tz. Note that these two circuits are also the same circuit for quantum neural network. We will now discuss both of them below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(i) Problem-inspired ansÃ¤tze</head><p>In the problem-inspired ansÃ¤tze approach, we utilize the evolution by a unitary operator, denoted as G(t), with a Hermitian generator Ä : G(t) = e -iÄt . These operators are derived from the properties or symmetries of the system under consideration and are used in constructing the PQC. Implementing such unitary transformations directly can be challenging. Therefore, one often employs a technique called the Suzuki-Trotter (ST) expansion or decomposition <ref type="bibr" target="#b119">[120]</ref>. This method provides a general approach to approximate complex and challenging-to-implement unitary transformations. In practice, the more we know about the Hamiltonian to be Trotterized, the less number of gates is needed to implement this method <ref type="bibr" target="#b73">[74]</ref>. Two mostly used ansÃ¤tze of this kind is the unitary coupled cluster (UCC) for quantum chemistry and the quantum approximate optimization algorithm (QAOA).</p><p>(a) Unitary Coupled Cluster (UCC) Historically, the Unitary Coupled Cluster (UCC) ansÃ¤tze were among the earliest proposed and implemented approaches, as discussed in reference <ref type="bibr" target="#b122">[123]</ref>. The core concept behind UCC is to introduce quantum correlations into the Hartree-Fock approximation. Interestingly, in 2014, it was demonstrated that representing UCC on a classical computer is computationally inefficient <ref type="bibr" target="#b136">[137]</ref>. However, during the same year, researchers took advantage of quantum resources and successfully realized the UCC ansÃ¤tze as a PQC using a photonic processor <ref type="bibr" target="#b107">[108,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b16">17]</ref>. (b) Quantum Approximate Optimization Algorithm (QAOA)</p><p>The Quantum Approximate Optimization Algorithm (QAOA) shares strong connections with quantum annealing and adiabatic quantum computing. Adiabatic quantum computing, in brief, leverages the adiabatic theorem in quantum mechanics, which asserts that a quantum state undergoing slow variations in a timedependent Hamiltonian will evolve only by a phase. Consequently, one can devise a Hamiltonian that evolves over time, transitioning from an easily prepared system to a system capable of encoding problems to be solved. The energy eigenstate naturally evolves from the initially prepared state to one that solves the target problem. QAOA can be viewed as an approach that resembles Trotterized adiabatic quantum computing <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b43">44]</ref>.</p><p>For combinatorial optimization problems featuring strict constraints, you can introduce penalty terms in the cost function. However, this approach may not be the most efficient in practice since it can still lead to solutions that violate certain hard constraints. A variant of QAOA aimed at addressing these constraints is also discussed in previous works <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>(ii) Hardware efficient ansÃ¤tze While computational studies have demonstrated that problem inspired ansÃ¤tze can yield rapid convergence to a satisfactory solution state, their experimental realization can present challenges. Quantum computing devices are subject to various experimental limitations, including factors like coherence time, limited gate fidelity, and constrained gate set. To give an example on how bad the situation is, <ref type="bibr" target="#b99">[100]</ref> illustrates that current quantum hardware is not well-suited for implementing deep and highly connected circuits, which are essential for approaches like the UCC and similar methods designed for applications beyond basic demonstrations, such as simulating more complex molecules like Hydrogen molecule. Human computation capabilities have allowed us to understand the properties of the hydrogen atom and, using manual calculations and the Born-Oppenheimer approximation, we can even compute some characteristics of hydrogen molecules. So, with problem-inspired ansÃ¤tze on current devices, computers haven't significantly expanded our understanding beyond what we already knew through traditional human-driven calculations. Alternatively, a class of hardware-efficient ansÃ¤tze has been proposed to accommodate device constraints <ref type="bibr" target="#b70">[71]</ref>. The idea is to make good use of a limited number of quantum gates and a particular qubit connection topology. Typically, the gate set used in quantum circuits includes a two-qubit entangling gate and up to three single-qubit gates. The circuit is then built by assembling blocks of single-qubit gates and entangling gates, which are applied in parallel to multiple or all qubits. Each of these blocks is often referred to as a "layer", and the ansatz circuit typically comprises multiple such layers.</p><p>The complete VQA program can be broadly conceptualized as a shallow quantum circuit.</p><p>In this circuit, we iteratively apply rotation gates denoted as R x,y,z (Î¸ â ) = e iÎ¸ â X â , with parameters determined by classical values Î¸ k , followed by the utilization of CNOT gates represented as W k . A basic illustration of this concept is presented in FIG. <ref type="figure" target="#fig_1">2</ref>. Putting all gates together into one unitary operator, we will have</p><formula xml:id="formula_4">U = L â=1 W â U â (Î¸ â ) = L â=1 W â exp iÎ¸ â X â .<label>(2)</label></formula><p>The Î¸ â represent the variational parameters, while U â are unitary operators with X â denoting the Hermitian operators. Usually, X â takes the form of a Pauli operator, and U â consists of rotation operators that act on individual qubits. On the other hand, W â represents the multi-qubit gates responsible for entangling qubits in the circuit. For example, W â might be a CNOT gate, CZ gate, or similar multi-qubit gates commonly used in superconducting qubits <ref type="bibr" target="#b76">[77]</ref>. In line with this methodology, the "Alternating Layered AnsÃ¤tze" is a specific instance of hardware-efficient ansÃ¤tze. It comprises layers of single-qubit rotations and blocks of entangling gates that entangle only a local set of qubits. These entangling gate blocks are shifted every alternating layer in the circuit. The selection of these gates, their interconnections, and their order in the circuit significantly impact the portion of the Hilbert space that the ansatz explores and the rate at which it converges for a given problem <ref type="bibr" target="#b16">[17]</ref>.</p><p>Instead of strictly choosing between problem-inspired and hardware-efficient ansÃ¤tze modalities, some PQC designers have adopted an intermediate approach. For instance, they use an exchange-type gate, which can be natively implemented in transmons, to construct a PQC that respects the symmetry of the variational problem. This approach results in ansatz circuits with particularly low parameter counts, making them suitable for quantum chemistry problems like Hydrogen and LiH molecules.</p><p>2.1.3. Measurements Now, we move into the third stage of VQA, which is the measurement stage. The output of quantum circuits is a quantum state, and in order to optimize it on a classical computer, we must extract classical information from it. This involves estimating the expectation value of the objective function â¨ Ãâ© U Î¸ . The most direct approach is to apply a unitary operator to the quantum state, transforming it into the diagonal basis of the observable Ã, and then calculate the probability of measuring the state with a corresponding eigenvalue of Ã. For experimental details of this approach, see <ref type="bibr" target="#b76">[77,</ref><ref type="bibr" target="#b51">52]</ref>. However, this direct approach is limited by the NISQ devices currently available, as transforming the state into the diagonal basis can be computationally expensive. Below, we introduce alternative methods that is more NISQ-friendly.</p><p>(i) Measurement of Pauli string.</p><p>Given that most observables can be efficiently expressed as a sum of Pauli strings, a straightforward application is to focus on measuring these Pauli strings. Transforming a state from the computational basis to the diagonal basis of Ï x or Ï y is relatively simple and can be accomplished using Hadamard gates.</p><p>The Pauli string:</p><formula xml:id="formula_5">P = kâK Ï(k)</formula><p>where k refers to k th qubit, expectation value is:</p><formula xml:id="formula_6">â¨ P â© = kâK Ï z (k) Å¨ ,</formula><p>where Å¨ refers to the product of rotations according to the specific form of the Pauli string. In practice, it's only feasible to take a finite number of single-shot measurements, denoted as N s , of the quantum state. This enables the estimation of expectation values within a finite margin of error. For more information on error of the measurements, see <ref type="bibr" target="#b60">[61]</ref>.</p><p>(ii) Measurement of overlaps.</p><p>Some VQA would require to measure a unitary's overlap with a quantum state |Ïâ© : â¨Ï| U |Ïâ© . Since this is not an observable, it has both real and imaginary components. The Hadamard test is a method capable of evaluating such a quantity on a quantum computer using just one additional qubit. This involves applying a control qubit with control over the extra qubit and applying the target unitary operator U to the quantum state. However, this method does require ample quantum resources to implement the control unitary. An alternative approach, as proposed by the authors of <ref type="bibr" target="#b98">[99]</ref>, involves decomposing U into a sum of Pauli strings and making measurements with respect to these Pauli strings individually. Another approach is applicable when U can be expressed as a product of unitaries, denoted as U k , which act locally on a few qubits. This involves finding classical means to express</p><formula xml:id="formula_7">U k as U k = V â  k DV k ,</formula><p>where D is a diagonal matrix and V k represents unitaries that can be applied to |Ïâ© to determine the overlap. This last approach will lead us naturally to the last part of this section.</p><p>(iii) Classical shadows.</p><p>This technique leverages both the quantum and classical properties of particles. As multiple copies of quantum states' dynamics converge into classical behaviors over time.</p><p>When dealing with an unknown quantum state represented as Ï, the objective is to predict M expectation values, denoted as Tr( Ãi Ï), where</p><formula xml:id="formula_8">1 â¤ i â¤ M [62].</formula><p>This method consists of two steps. Initially, a random unitary transformation, denoted as U , is applied to the state Ï, resulting in the transformation Ï â U ÏU â  . In the second step, all qubits are measured in the computational basis. These two steps are repeated multiple times using different random unitaries U . It's important to note that these random unitaries are selected to be efficiently computable on a classical computer. Through post-processing of the measurement results, it is possible to obtain a "classical shadow," which serves as a classical representation of the quantum state. Research suggests that a classical shadow of size on the order of log M is sufficient to predict all M expectation values simultaneously. This method draws inspiration from the study of shadow tomography <ref type="bibr" target="#b2">[3]</ref>, which will be explored further in section 4.1. As mentioned in the introduction, this is an example of the application of other topics in quantum machine learning (shadow tomography) on the narrow sensed quantum machine learning described before.</p><p>2.1.4. Optimization Finally, we arrive at the part where we optimize the classical parameters. This optimization process does not differ significantly from other multi-variable optimization problems, so we can employ classical optimization methods <ref type="bibr" target="#b16">[17]</ref>. The challenge here, as mentioned earlier, is that in the NISQ era, we are constrained by the limited coherence time of quantum computers. This means that implementing deep analytical gradient descent circuits may not be feasible. Additionally, to achieve high precision in the mean value of an observable, a substantial number of measurements are required. Due to the high sampling rate, the measurement process becomes the bottleneck in the overall runtime. Therefore, an ideal optimizer for PQC should aim to minimize the number of measurements needed to be effective. At last, it's crucial for the optimizer to be robust in noisy data environments and maintain precision even with limited measurements taken.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(i) Stochastic gradient descent</head><p>The technique of gradient descent for locating local minima is a prevalent method in various machine learning applications, particularly in machine learning. While Bayesian learning is intuitively appealing, gradient descent is much more computationally practical.</p><p>The essence of this section can be summarized as follows: when presented with an objective function or loss function, denoted as L, our goal is to identify its minima.</p><p>The specific form of the loss function is not the primary focus here, but for illustration purposes, one of the most common choices is the mean squared error (MSE) loss:</p><formula xml:id="formula_9">L MSE â¡ 1 2 (z(x Î´ ; Î¸) -y Î´ ) 2 .<label>(3)</label></formula><p>In machine learning, the term z(x Î´ ; Î¸) typically represents the final output, and y Î´ corresponds to the supervised learning data. In the context of VQA, consider a simple example where z(x Î´ ; Î¸) = â¨Ïâ© U (Î¸) and y Î´ = 0. Therefore, minimizing the loss function is equivalent to minimizing the objective function. All the parameters are encapsulated in the vector Î¸.</p><p>The core principle of gradient descent is to rapidly approach the minimum when we are far from it and take smaller steps when we are close to the minimum. To determine how far we are from the minimum, we rely on the gradient of the loss function. If the gradient has a large magnitude, it signifies that we are far from the minimum, whereas a small gradient indicates proximity to the minimum. Consequently, we update the parameter values based on the gradient's magnitude:</p><formula xml:id="formula_10">Î¸ i (t + 1) â¡ Î¸ i (t) -Î· âL(Î¸) âÎ¸ i Î¸ i =Î¸ i (t) .<label>(4)</label></formula><p>This update will necessarily decrease the loss function <ref type="bibr" target="#b111">[112]</ref>. So, the iterative application of these updates will gradually bring us closer to a local minimum. However, a significant challenge with this method is the need for a substantial number of measurements. To tackle this problem, stochastic gradient descent (SGD) offers a modification to the standard parameter update rule, where it utilizes L St which serves as an approximation of the loss function. For instance, you can compute the gradient using a finite number of measurements, as described in the work by <ref type="bibr" target="#b56">[57]</ref>. In machine learning, L St can be thought of as the loss function computed based on a subset of the training data. These subsets within the training data are randomly divided into equal-sized partitions <ref type="bibr" target="#b111">[112]</ref>.</p><p>(ii) Gradient-free optimization There are additional gradient-free optimization approaches that we can explore. Here are a few of these methods, along with their respective references:</p><p>(a) Evolutionary Algorithms: This technique involves data sampling to estimate the gradient of expected fitness, which is then used to adjust parameters in the direction of steepest improvement <ref type="bibr" target="#b133">[134,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b138">139]</ref>.</p><p>(b) Reinforcement Learning: In this method, reinforcement learning is initially applied to optimize parameters, as seen in the case of QAOA parameters. It employs a reinforcement learning framework to discover the most effective "policy" that maximizes the expected total discounted reward <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b135">136,</ref><ref type="bibr" target="#b129">130]</ref>. (c) Sequential Minimal Optimization (SMO): In the field of machine learning, SMO has been highly effective for optimizing the parameter landscape of highdimensional support vector machines. SMO divides the optimization task into smaller components for which analytical solutions can be derived <ref type="bibr" target="#b108">[109,</ref><ref type="bibr" target="#b100">101,</ref><ref type="bibr" target="#b104">105]</ref>.</p><p>Also, in <ref type="bibr" target="#b15">[16]</ref>, the authors present variational quantum algorithms for real and imaginary time evolution that are more efficient than previous proposals, where they use Sequential Minimal Optimization for time evolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Quantum neural tangent kernel</head><p>It is important to highlight that the circuits used in quantum machine learning are identical to those employed in variational quantum algorithms (see Fig. <ref type="figure" target="#fig_1">2</ref>). Therefore, in this section, we introduce a theory regarding the quantum neural tangent kernel (QNTK), which investigates the dynamics of VQA circuits from first principles <ref type="bibr" target="#b86">[87]</ref>. This can also be understood as an extension of the first-principle theory for classical machine learning <ref type="bibr" target="#b111">[112]</ref>.</p><p>Consider an initially prepared state, denoted as |Î¨ 0 â©, and apply the unitary operator of the circuit to it (see Eqn. ( <ref type="formula" target="#formula_4">2</ref>)</p><formula xml:id="formula_11">): |Ï(Î¸)â© = U (Î¸) |Î¨ 0 â© = L â=1 W â exp iÎ¸ â X â |Î¨ 0 â© .</formula><p>Here, â represents the layer of the quantum machine learning system. The output of the quantum neural network is then defined as:</p><formula xml:id="formula_12">z i;Î´ â¡ z i (Î¸, x Î´ ) = â¨Î¨ 0 (x Î´ )| U â  O i U |Î¨ 0 (x Î´ )â© .</formula><p>We use the mean squared loss (see Eqn. <ref type="bibr" target="#b2">(3)</ref>. We defined the error factor or residual training error Îµ as the part in the parenthesis. The value of y i;Î± is given by the supervised learning database.</p><p>However, it can be easily set to 0 if one's task is to solve problems like VQE. The gradient descent equation is shown in Eqn. <ref type="bibr" target="#b3">(4)</ref>. We then consider the update of the output:</p><formula xml:id="formula_13">d Â¯zi;Î´ = d Â¯Îµi;Î´ â¡ âz i;Î´ âÎ¸ â (DÎ¸ â ) = dz i;Î´ dÎ¸ â -Î· âL A âÎ¸ â = -Î· j,Î±,â Îµ i â² ;Î± âÎµ i;Î´ âÎ¸ â âÎµ i â² ;Î± âÎ¸ â = -Î· j,Î± Îµ i â² ;Î± K i,i â² Î´,Î± ,<label>(5)</label></formula><p>The variational angles Î¸ â are then updated step by step, labeled by t, according to the derivative of the loss function with respect to Î¸ â . Î· is defined as the learning rate, which is assumed to be a small (less than 1), positive number. The learning rate determines the size of the step that we take to update our parameters. One can calculate the update of the loss function L and prove that it decreases indefinitely every time we update our parameters, which is also a fact in classical machine learning <ref type="bibr" target="#b111">[112]</ref>. In Eqn. <ref type="bibr" target="#b4">(5)</ref> it is easy to show that the update of the output is mathematically in the exact same form as the update of the residual training error d Â¯Îµi;Î´ . One then defines the quantum neural tangent kernel (QNTK):</p><formula xml:id="formula_14">K i,i â² Î´,Î± â¡ â âÎµ i;Î´ âÎ¸ â âÎµ i â² ;Î± âÎ¸ â . (<label>6</label></formula><formula xml:id="formula_15">)</formula><p>If the QNTK is a constant, then Eqn. ( <ref type="formula" target="#formula_13">5</ref>) has a closed form solution. In the continuous limit, the residual error Îµ(t) will be a decaying exponential with -Î·K as its exponent. So we eventually will have a guaranteed convergence of the output z i;Î± to the supervised data y i;Î± if the QNTK K i,i â² Î´,Î± is a constant. However, the final assumption is not always true. To wit, with the expression of the output z i,Î± , one can analytically calculate the QNTK and prove that the QNTK is highly fluctuating in the variational angles Î¸, rather than being a constant <ref type="bibr" target="#b86">[87]</ref>. This fluctuation implies that we have obtained representation learning. In the terminology of the kernel method (NTK) of classical machine learning, it means that the feature map itself is changing. This indicates that we are extracting features from all of our training data to update our output, and we cannot obtain a closed-form solution for Îµ(t) in this case.</p><p>However, we can address this problem if we can determine when the QNTK is approximately a constant. If we can achieve this, we will have a partial success and can implement perturbation theory to achieve convergence.</p><p>An instance where the QNTK remains nearly constant is referred to as "lazy training". This occurs when the variational angles are nearly unchanged <ref type="bibr" target="#b86">[87,</ref><ref type="bibr" target="#b32">33]</ref>:</p><formula xml:id="formula_16">Î¸ â = Î¸ * â + Î´Ï .</formula><p>If Î¸ â remains approximately constant, indicating lazy training with minimal movement, the QNTK tends to be nearly constant as well. In such cases, the QNTK expression can be expanded with respect to Î¸ â for predictable dynamics, akin to classical scenarios <ref type="bibr" target="#b111">[112]</ref>.</p><p>Another scenario involves assuming certain characteristics of the quantum neural network. Firstly, we assume that our variational ansatz U is sufficiently randomly sampled from the unitary group. This enables integration over all samples of U in terms of ensembles, leading to a closed formula for K. This assumption is known as the k-design assumption, commonly applied in various fields such as cryptography and black hole physics. The term "k-design" reflects the prediction accuracy up to the k th moment compared to the uniform distribution of the unitary group, indicating a completely random choice of U .</p><p>Upon performing the integral, it is deduced that the average QNTK, denoted as K, is proportional to the number of layers L:</p><formula xml:id="formula_17">K = L Tr(O 2 i ) N 2 â L .<label>(7)</label></formula><p>Hence, we can infer that the QNTK increases with the depth of our quantum neural network. Additionally, the standard deviation of QNTK, denoted as âK, is proportional to â L. This implies that the relative deviation becomes very small as we approach the limit where L â« 1:</p><formula xml:id="formula_18">âK K â¼ O( 1 â L ) Lâ«1 --â âK K âª 1 . (<label>8</label></formula><formula xml:id="formula_19">)</formula><p>This phenomenon is known as the "frozen limit," suggesting that if one employs the k-design assumption, randomly samples the unitary, and ensures that the quantum neural network is sufficiently deep, a nearly frozen QNTK is obtained. This scenario is commonly referred to as a "deep quantum neural network."</p><p>As K is also proportional to N 2 (refer to Eqn. ( <ref type="formula" target="#formula_17">7</ref>)), for certain operators such as the Pauli matrices, where the trace scales as N , K eventually becomes proportional to L/N . This implies that if L is not comparable to the Hilbert space dimension N , a small QNTK is obtained, leading to slow convergence. This undermines the practicality of the model, akin to an alternative statement of the barren plateaus phenomena.</p><p>Nonetheless, this model remains useful, as even when not operating at the frozen limit, it provides an approximate means to gauge the speed of gradient descent. For example, to determine which variational ansatz runs the fastest without actually executing them, one can calculate their QNTK and select the one with the largest value. It also enables the estimation of operation time and the number of iterations required for the gradient descent program using Eqn. <ref type="bibr" target="#b6">(7)</ref>, facilitating hardware design improvements. Moreover, some late-time behaviors of QNTK also been recently captured in <ref type="bibr" target="#b137">[138]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Quantum landscapes and barren plateaus</head><p>Although VQA have been implemented in recent years to address problems in quantum chemistry and similar domains, it remains unclear how well this algorithm will perform in general or under what circumstances VQA might fail. In this section, we introduce barren plateaus as a type of no-go theorem that highlights conditions under which VQA is expected to underperform.</p><p>The process of training parameters in the Quantum Machine Learning (QML) model often involves minimizing a loss function and traversing a non-convex landscape in search of its global minimum, as extensively discussed in <ref type="bibr" target="#b26">[27]</ref>. Quantum landscape theory, as outlined in <ref type="bibr" target="#b8">[9]</ref>, seeks to comprehend the properties of QML landscapes and explores strategies for engineering them. Notably, local minima and barren plateaus are focal points of investigation within quantum landscape theory Akin to classical ML <ref type="bibr" target="#b26">[27]</ref>, the quantum loss landscape may contain numerous local minima. In a manner similar to classical cases, the overall non-convex optimization can become NP-hard <ref type="bibr" target="#b19">[20]</ref>. Various approaches have been proposed to mitigate issues related to local minima. For instance, variable structure Quantum Neural Networks (QNNs), as introduced in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b80">81]</ref>, dynamically adjust the model's prior by expanding and contracting during optimization, transforming certain local minima into saddle points. Additionally, there is evidence of the overparametrization phenomenon in QML <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b78">79]</ref>. In this scenario, a computational phase transition occurs as the optimization progresses, leading to the disappearance of spurious local minima when the number of parameters surpasses a critical value.</p><p>Not only are local minima a concern in QML, but there is also the intriguing phenomenon of a barren plateau in quantum landscapes <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b59">60]</ref>. A barren plateau is characterized by the loss landscape becoming, on average, exponentially flat concerning the problem size. In this scenario, the valley housing the global minimum exponentially diminishes with the problem size, forming what is known as a narrow gorge <ref type="bibr" target="#b8">[9]</ref>. Consequently, exponential resources, such as an increased number of shots, are needed to traverse through the landscape. This impact on resource requirements complicates the QML algorithm's complexity and can potentially undermine quantum speedup, as quantum algorithms typically aim to avoid the exponential complexity associated with classical algorithms.</p><p>The barren plateau phenomenon was first studied in deep hardware-efficient QNNs <ref type="bibr" target="#b97">[98]</ref>, where they arise due to the high expressivity of the model <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b26">27]</ref>. By making no assumptions about the underlying data, deep hardware-efficient architectures aim to solve a problem by being able to prepare a wide range of unitary evolutions. In other words, the prior over the hypothesis space is relatively uninformed. Barren plateaus in this unsharp prior are caused by ignorance or the lack of sufficient inductive bias, and therefore a means to avoid them is to input knowledge into the construction of the QNN -making the design of QNNs with good inductive biases for the problem at hand a key solution. Various strategies have been developed to address these barren plateaus, such as clever initialization <ref type="bibr" target="#b125">[126]</ref>, pretraining, and parameter correlation <ref type="bibr" target="#b59">[60]</ref>. These are also examples of adding a sharper prior to one's search over the over-expressive parameterizations of hardware-efficient QNNs. The authors of <ref type="bibr" target="#b27">[28]</ref> studied the barren plateau problem for parameterized quantum circuits of the quantum tensor network architecture and show, for example, that classical optimization of these circuits can be exponentially more efficient than using a quantum computer.</p><p>Other mechanisms have been linked to barren plateaus <ref type="bibr" target="#b26">[27]</ref>. Simply defining a loss function based on a global observable (i.e., observables measuring all qubits) leads to barren plateaus even for shallow circuits with sharp priors <ref type="bibr" target="#b97">[98]</ref>, while local observables (those comparing quantum states at the single-qubit level) avoid this issue <ref type="bibr" target="#b97">[98,</ref><ref type="bibr" target="#b124">125]</ref>. The latter is not due to bad inductive biases but rather to the fact that comparing objects in exponentially large Hilbert spaces requires an exponential precision, as their overlap is usually exponentially small.</p><p>While entanglement is one of the most important quantum resources for information processing tasks in quantum computers, it can also be detrimental for QML models <ref type="bibr" target="#b26">[27]</ref>. QNNs (or embedding schemes) that generate too much entanglement also lead to barren plateaus <ref type="bibr" target="#b115">[116,</ref><ref type="bibr" target="#b94">95,</ref><ref type="bibr" target="#b105">106]</ref>. Here, the issue arises when one entangles the visible qubits of the QNN (those that one measures at the QNN's output) with a large number of qubits in the hidden layers. Due to entanglement, the information of the state is stored in non-local correlations across all qubits, and hence the reduced state of the visible qubits concentrates around the maximally mixed state. This type of barren plateau can be solved by taming the entanglement generated across the QNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">Influence of background noise</head><p>The existence of hardware noise during quantum computations is a distinctive feature of NISQ computing <ref type="bibr" target="#b26">[27]</ref>. Despite this reality, many QML studies overlook noise in analytical calculations and numerical simulations, while still asserting near-term compatibility of the methods. It is imperative to consider the impact of hardware noise in QML analyses, especially for those aiming to achieve quantum advantage with currently available hardware <ref type="bibr" target="#b26">[27]</ref>.</p><p>Noise introduces errors in the information as it propagates through a quantum circuit, particularly affecting deeper circuits with longer run-times <ref type="bibr" target="#b26">[27]</ref>. This impact extends to all aspects of quantum models, including the dataset preparation scheme and circuits used for computing quantum kernels. In the case of Quantum Neural Networks (QNNs), noise can impede their trainability <ref type="bibr" target="#b127">[128,</ref><ref type="bibr" target="#b126">127]</ref>, leading to noise-induced barren plateaus where relevant features are exponentially suppressed with increasing circuit depth. The consequence is a deformation of the model's inductive bias and an effective reduction in the dimension of the quantum feature space. Despite the significant influence of quantum noise, its effects remain largely unexplored, especially regarding its impact on the classical simulability of QML models <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>Addressing issues induced by noise may necessitate <ref type="bibr" target="#b26">[27]</ref>: (1) reducing hardware error rates, (2) implementing partial quantum error correction <ref type="bibr" target="#b23">[24]</ref>, or (3) utilizing QNNs that are relatively shallow (i.e., with depth growing sub-linearly in the problem size) <ref type="bibr" target="#b127">[128]</ref>, such as Quantum Convolutional Neural Networks (QCNNs). While error mitigation techniques <ref type="bibr" target="#b123">[124,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b41">42]</ref> can enhance the performance of QML models in the presence of noise, they may not completely resolve noise-induced trainability issues <ref type="bibr" target="#b126">[127]</ref>. Another approach involves engineering QML models with noise-resilient properties <ref type="bibr" target="#b79">[80,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b114">115]</ref>, such as ensuring that the position of minima remains unchanged despite noise.</p><p>However, another study suggests that noise in VQAs might be beneficial for their performance. Drawing inspiration from classical machine learning, where noise is intentionally introduced to enhance the performance of the gradient descent algorithm, this phenomenon is akin to stochastic gradient descent. It has been observed that gradient descent tends to perform better under the influence of noise, as the noise helps in avoiding saddle points that could hinder the algorithm's progress <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b69">70]</ref>. In the absence of noise, the algorithm may converge directly to the saddle point. However, when noise is introduced, perturbations around the points prevent convergence towards these unstable fixed points.</p><p>In the study <ref type="bibr" target="#b87">[88]</ref>, this discussion was extended to quantum noise. Through experiments, the researchers found that the noisy case outperformed the noiseless counterparts, providing a toy model illustration to support their argument. This suggests that, while implementing quantum error correction is crucial for making quantum devices fault-tolerant, in certain QML applications, eliminating all noise may not be necessary. As long as the noise remains below a certain threshold, it may prove not detrimental but rather helpful for QML programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Laziness</head><p>Theoretically one can understand barren-plateau phenomenon as the following. A typical gradient descent algorithm will look like</p><formula xml:id="formula_20">Î¸ â (t + 1) -Î¸ â (t) = -Î· âL âÎ¸ â â¡ Î´Î¸ â .<label>(9)</label></formula><p>The observation <ref type="bibr" target="#b97">[98]</ref> is that if our variational ansatz is highly random, according to the k-design integral formula <ref type="bibr" target="#b110">[111,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b83">84,</ref><ref type="bibr" target="#b35">36]</ref>, the derivative of the loss function is generally suppressed by the dimension of the Hilbert space N . This might lead to a situation where the variation of the loss function during gradient descent is very small, denoted as Î´L â¡ L(t + 1) -L(t) âª 1 for the step t. An alternative theoretical term used to describe the quantum barren plateau, based on the large suppression in Eqn. <ref type="bibr" target="#b8">(9)</ref>, is laziness <ref type="bibr" target="#b85">[86]</ref>. In the quantum context, the suppression comes from the dimension of the Hilbert space, while in the classical case, the suppression is associated with the width of classical neural networks.</p><p>To be more precise, laziness refers to small Î´Î¸ Âµ , and the barren plateau refers to small Î´L. The authors of <ref type="bibr" target="#b85">[86]</ref> demonstrate that laziness may not necessarily imply the quantum barren plateau. This insight is derived from the perspectives of overparametrization theory and representation learning theory through the QNTK <ref type="bibr" target="#b86">[87]</ref>. In the context of quantum neural networks, overparametrization refers to the condition K â O(1) in Eqn. <ref type="bibr" target="#b6">(7)</ref>.</p><p>The paper <ref type="bibr" target="#b85">[86]</ref> emphasizes that in variational circuits with a sufficiently large number of trainable angles, gradient descent dynamics can still be efficiently executed, even in the presence of the exponential suppression of variational angle updates (laziness). On the other hand, the only limitation is the precision, where noises might affect the performance significantly. The authors also highlight that laziness is not exclusive to quantum machine learning but is observed in overparametrized classical neural networks with large widths as well. The efficiency of large-width neural networks is substantiated by the neural tangent kernel theory, and similar principles apply to their quantum counterparts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Fault tolerant quantum computation (FTQC) algorithms</head><p>In the Fault-Tolerant Quantum Computation (FTQC) era, we envision a future where we have fully implemented quantum error correction. In this era, one of the most prominent and impactful applications is Shor's algorithm <ref type="bibr" target="#b116">[117]</ref>. This algorithm has the remarkable ability to efficiently factorize large numbers, a capability that could potentially break the majority of the public-key cryptography systems currently used on the internet. Additionally, quantum computers, as originally envisioned by Richard Feynman <ref type="bibr" target="#b44">[45]</ref>, have the potential to significantly accelerate the simulation of quantum physics and chemistry.</p><p>Despite these two remarkable applications, quantum computers have historically faced a problem of having limited use cases. While these two applications are groundbreaking, there is no concrete evidence that quantum computers will revolutionize our lives in the same way that classical computers have done <ref type="bibr" target="#b0">[1]</ref>.</p><p>Recently, a series of newly proposed quantum algorithms have emerged, offering exciting possibilities for quantum computation. Among them, the Harrow-Hassidim-Lloyd (HHL) algorithm, introduced by its authors in 2008 <ref type="bibr" target="#b57">[58]</ref>, has gained significant attention. These novel algorithms not only hold the potential for significant speedups compared to classical counterparts but also show promise in addressing practical problems. These applications span various domains, including machine learning, clustering, classification, and the analysis of extensive datasets <ref type="bibr" target="#b0">[1]</ref>. Although, significant challenges are related to many algorithms designed for quantum machine learning, including dequantization and fast interfaces between classical and quantum processors.</p><p>In this section, we will concentrate on a few selected quantum algorithms and delve into their applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Quantum phase estimation and quantum principle component analysis</head><p>In the realm of quantum computing, quantum phase estimation is a pivotal quantum algorithm primarily designed to estimate the phase associated with an eigenvalue of a provided unitary operator <ref type="bibr" target="#b101">[102]</ref>. The necessity to exponentiate the density matrix within quantum principle component analysis (PCA) aligns with the requirement for phase estimation.</p><p>In a formal context, suppose a unitary operator U and its corresponding eigenvector |Ïâ© . The relationship is represented as: U |Ïâ© = e i2ÏÎ¸ |Ïâ© . Here, without loss of generality, we assume 0 â¤ Î¸ &lt; 1 . and the objective of Quantum Phase Estimation (QPE) is to accurately determine the value of Î¸ while minimizing the number of operations required. The concept involves generating a binary approximation of Î¸ through the application of quantum Fourier transformation. The preparatory steps are illustrated in FIG. <ref type="figure" target="#fig_2">4</ref>. Beginning with |Ïâ© and n qubits initialized in the |0â© state: |0â© ân â |Ïâ© . First one applies Hadamard gates to all |0â© qubits:</p><formula xml:id="formula_21">H ân |0â© ân = 1 2 n/2 (|0â© + |1â©) ân = 1 2 n/2</formula><p>2 n-1 k=0 |kâ© . One then decomposes k : k = n-1 j=0 k j 2 j . The next step involves applying the unitary operator U to |Ïâ© while maintaining control over the other qubits. Practically, one applies U 2 j on |Ïâ© , only if k j = 1 , for 0 â¤ j â¤ n -1 . Finally, this sequence of operations results in the state:</p><formula xml:id="formula_22">1 2 n/2 2 n-1 k=0 |kâ© |Ïâ© â 1 2 n/2 2 n-1 k=0 |kâ© U k |Ïâ© = |kâ© U k 0 2 0 U k 1 2 1 . . . U k n-1 2 n-1 |Ïâ© = 1 2 n/2 2 n-1 k=0 e i2ÏkÎ¸ |kâ© |Ïâ© . (10)</formula><p>The eigenstate |Ïâ© is not needed at this stage. We proceed with the quantum Fourier transformation on the qubits |kâ© :</p><formula xml:id="formula_23">1 2 n/2 2 n-1 k=0 e i2ÏkÎ¸ |kâ© = 1 2 n 2 n -1<label>x=0</label></formula><formula xml:id="formula_24">2 n-1 k=0 exp -i2Ïk 2 n (x -2 n Î¸) |xâ© . (<label>11</label></formula><formula xml:id="formula_25">)</formula><p>Now, one estimates Î¸ by rounding 2 n Î¸ to the nearest integer. If 2 n Î¸ can be expressed as an integer, then one will obtain a precise result after performing measurements. On the other hand, If Î¸ cannot be accurately expressed up to n th order binary, QPE will have an error. So the larger n is, the smaller the error is. Because we have more space to approximate Î¸ . The good news is the error of QPE estimation is always bounded <ref type="bibr" target="#b101">[102]</ref>. By approximating Î¸, it's possible to find the eigenvalue of the unitary operator. Consequently, since unitary operators can always be expressed as an exponential of a Hermitian operator, one can also determine the eigenvalue of the Hermitian matrix. This is the principle behind how quantum PCA calculates both the eigenvectors and eigenvalues of the density matrix.</p><p>One of the most fascinating applications in quantum machine learning is Quantum Principal Component Analysis. This method, akin to the popular Principal Component Analysis (PCA) used by companies like Netflix, enables the analysis of users' preferences to offer tailored film recommendations. In a mathematical sense, the data provided by users is represented as vectors: v j , in a d dimensional vector space. PCA's objective is to identify the ideal axes for grouping this data into clusters. Another application could involve generating these vectors based on the fluctuations in stock prices for all stocks in the market, analyzing changes from discrete times t i to t i+1 <ref type="bibr" target="#b17">[18]</ref>. Classically, this program is done as the following <ref type="bibr" target="#b17">[18]</ref>. First, one calculate the covariance matrix: C = j v j v T j , where T represents the transverse matrix. In principle, one can understand the covariance matrix as a manifestation of the correlation between different component of the data. Now, one can diagonalize the covariance matrix and find its eigenvectors c k and corresponding eigenvalue e</p><formula xml:id="formula_26">k : C = k e k c k c â  k .</formula><p>If only a few of the eigenvalues c k are large, and the remainder are small or zero, then the eigenvectors corresponding to those eigenvalues are called the principal components of C . In more mathematical terms, if the diagonalized covariance matrix is sparse, then the non-zero eigenvalues are called the principle components. Each principal component represents an underlying common trend or form of correlation in the data, and decomposing a data vectors v in terms of principal components, If only a few of the eigenvalues c k are significantly large, and the rest are considerably small or zero, then the eigenvectors linked to these eigenvalues are termed the principal components of C In more technical terms, if the diagonalized covariance matrix is sparse, the non-zero eigenvalues represent the principal components. Each principal component characterizes an underlying common trend or form of correlation within the data. Decomposing a data vector v into these principal components through the equation: v = k á¹½k c k , enables compression of data representation and the anticipation of future behavior. Classical algorithms for PCA possess computational complexity and query complexity scaling as O(d 2 ) .</p><p>In the quantum version of this program, the initial step involves mapping these vectors v j into quantum states: |v j â© . This mapping is facilitated by quantum random access memory (QRAM), a concept that will be further detailed in section 3.4. A d dimensional vector can be encoded in log d qubits. Assuming every vector v j is equally probable or is randomly selected from a dataset containing N vectors the resulting density matrix is: Ï = 1 N j |v j â©â¨v j | . This density matrix essentially serves as the quantum equivalent of the covariance matrix C in the classical scenario. The subsequent step for quantum principal component analysis involves implementing two methods: density matrix exponentiation and quantum phase estimation. The former maps the density matrix Ï into a unitary operator: U DME = e -iÎ¸Ï , which enables us to utilize QPE to evaluate the eigenvalues and eigenstates.</p><p>The latter method aims to find the eigenvectors and eigenvalues of the density matrix written in U DME . By repeatedly sampling data and using the two aforementioned techniques, one can take any quantum version of a data vector |v j â© and decompose it into its principal components: |v j â© â k v k |c k â© . It's important to note that quantum principle component analysis scales as O(log 2 d) in both computational complexity and query complexity, which represents a significant speedup compared to the classical version. In the study conducted in <ref type="bibr" target="#b66">[67]</ref>, the researchers present experimental evidence showcasing quantum advantage in PCA. However, a crucial prerequisite for this advantage is the availability of quantum data sourced from physical experiments, capable of generating density matrices. This contrasts with classical devices relying on QRAM for data processing. And the quantum advantage is measured in the number of queries to get the density matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Classical algorithm framework for dequantizating QML models</head><p>Despite the development of exciting quantum algorithms in QML, there are still open problems whether known QML algorithms provide new exponential speedups over classical algorithms for practically relevant instances of machine learning problems <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b39">40]</ref>. This uncertainty is rooted in the challenge of identifying the source of this speedup. Some arguments suggest that QML's exponential acceleration is solely attributed to its state preparation assumptions. Notably, the concept of "dequantization" has emerged, involving the development of classical algorithms that mimic the sampling assumptions of QML programs. Authors in this domain have created classical algorithms, often referred to as the dequantization of QML programs, which closely resemble their quantum counterparts but exhibit only polynomial differences in complexity. One notable example of dequantization involves the quantum recommendation system.</p><p>The work by Kerenidis and Prakash on the quantum recommendation system <ref type="bibr" target="#b71">[72]</ref> was noteworthy for addressing the caveats associated with the HHL algorithm, as pointed out by Scott Aaronson <ref type="bibr" target="#b0">[1]</ref>. They presented a comprehensive quantum algorithm directly comparable to classical algorithms. Initially, Kerenidis and Prakash's quantum algorithm demonstrated exponential speedup compared to the best-known classical algorithms, but its provable exponential nature was uncertain. In 2019, Tang <ref type="bibr" target="#b120">[121]</ref> introduced a classical algorithm that dequantized the quantum recommendation systems algorithm with only polynomially slower runtime, providing clarity on the provable nature of the speedup. These works highlighted the insight that the data structure fulfilling state preparation assumptions can also fulfill â 2norm sampling assumptions (as defined in section 2.2 of <ref type="bibr" target="#b120">[121]</ref>). More precisely, this is a log-dimension time classical randomized linear algebra algorithms in the sample and query input model, which is an analogue of quantum state preparation assumptions coming from, for example, in most cases, QRAM). Consequently, a classical algorithm aiming to "match" the quantum algorithm can leverage these assumptions.</p><p>In 2020, the authors of <ref type="bibr" target="#b31">[32]</ref> introduced an algorithmic framework for quantum-inspired classical algorithms focusing on close-to-low-rank matrices. This work generalized the series of results initiated by Tang's quantum-inspired algorithm for recommendation systems <ref type="bibr" target="#b120">[121]</ref>. The motivation for these classical algorithms stemmed from quantum linear algebra algorithms and the quantum singular value transformation (SVT) framework <ref type="bibr" target="#b46">[47]</ref>. The proposed classical algorithms for SVT exhibited runtime independent of input dimension under suitable quantum-inspired sampling assumptions. The results provided compelling evidence that, in the corresponding QRAM data structure input model, quantum SVT does not deliver exponential quantum speedups.</p><p>In 2021, the authors of <ref type="bibr" target="#b121">[122]</ref> introduced a new input model termed SQ access, representing a form of l2-norm sampling assumption. They developed a model to dequantize two influential QML algorithms, namely quantum principal component analysis <ref type="bibr" target="#b92">[93]</ref> and quantum supervised clustering <ref type="bibr" target="#b91">[92]</ref>. In essence, they provided classical algorithms that, with classical SQ access assumptions replacing quantum state preparation assumptions, replicated the bounds and runtime of the corresponding quantum algorithms, albeit with a polynomial slowdown.</p><p>On the other hand, in <ref type="bibr" target="#b66">[67]</ref> the authors point out that the assumption in <ref type="bibr" target="#b121">[122]</ref> does not work in the quantum physics environment setup, and it is possible that there are still quantum advantages with exponential separation. In <ref type="bibr" target="#b66">[67]</ref>, their quantum advantages are measured in terms of the number of queries to access the quantum state requiring principle component analysis. In <ref type="bibr" target="#b121">[122]</ref>, It presupposes the capability to retrieve any element of the exponentially large density matrix with exponentially precise accuracy, within a time frame that is polynomial. Achieving the capability already requires exponential numbers of queries to access the density matrix. See further detailed discussions in <ref type="bibr" target="#b36">[37]</ref>. In summary, the pursuit of identifying classical analogs for quantum machine learning applications presents a fascinating avenue for exploration. Investigating dequantization enables the identification of the constraints inherent in both quantum and classical machine learning, and aids in delineating the distinctions between quantum and classical algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Harrow-Hassidim-Lloyd algorithm</head><p>In this section, we will delve into the intricacies of the HHL algorithm, as detailed in <ref type="bibr" target="#b57">[58]</ref>. The fundamental setup remains consistent:</p><formula xml:id="formula_27">A |xâ© = |bâ© , (<label>12</label></formula><formula xml:id="formula_28">)</formula><p>where A is an N Ã N Hermitian matrix, and |xâ© and |bâ© are normalized vectors. We assume that A is Hermitian which does not compromise the generality of the algorithm, as the space can always be expanded to make it true. For |u i â© the eigen vectors of A, we can decompose A and |bâ©, such that</p><formula xml:id="formula_29">|xâ© = A -1 |bâ© = N -1 i,j=0 Î» -1 i |u i â©â¨u i |b j |u j â© = N -1 i,j=0 Î» -1 i b j Î´ ij |u i â© = N -1 i=0 Î» -1 i b i |u i â© . (<label>13</label></formula><formula xml:id="formula_30">)</formula><p>Now, let's delve into the HHL algorithm circuit, which step by step accomplishes what we've discussed in Eqn. <ref type="bibr" target="#b12">(13)</ref>. We'll track the evolution of qubit states as follows. With the entire process divided into 5 stages <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b10">11]</ref>, we begin with the following initialization:</p><formula xml:id="formula_31">|Ï 0 â© = |0â© ân b |0â© ân l |0â© .</formula><p>The goal is to encode the information of |bâ© in the first register: |0â© ân b and encode Î» j in the second register: |0â© ân l . These can be done with a unitary operator U b and quantum phase estimation which determines the values of Î» j and |u j â© : |Ï 2 â© = N -1 j=0 b j |u j â© |Î» j â© |0â© . The key step is to rotate the third register qubit with an angle with a control on the clock register and do a post-selection on the third register of obtaining |1â©:</p><formula xml:id="formula_32">|Ï 3 â© = N -1 j=0 b j |u j â© |Î» j â© 1 - C 2 Î» 2 j |0â© + C Î» j |1â© post-select -----â |Ï 4 â© = N -1 j=0 b j |u j â© |Î» j â© C Î» j |1â© ,<label>(14)</label></formula><p>where constant C is the normalization factor. If we obtain |0â© , hen we will have to repeat the above procedure until we obtain the desired result. Now we have our desired Î» -1 j , so we can apply the inverse of the quantum phase estimation procedure and return to our initialized second register and we have the following identification:</p><formula xml:id="formula_33">|Ï 5 â© = C N -1 j=0 b j Î» -1 j |u j â© |0â© ân l |1â© = C |xâ© |0â© ân l |1â© . (<label>15</label></formula><formula xml:id="formula_34">)</formula><p>The state output of the first register is our desired solution state or vector. The whole post-selection process is for us to be sure that the state in the first register is now proportional to the solution vector, and from there, we can complete our algorithm. For a more detailed discussion of the HHL algorithm, please refer to the original paper <ref type="bibr" target="#b57">[58]</ref>. The HHL algorithm takes O((log N ) 2 ) quantum steps to output |xâ©, compared with O(N log N ) steps required to find the vector x using the best-known method on a classical computer. HHL does achieve a significant speedup, and so does the quantum SVM compared to its classical counterpart.</p><p>Before we become overly enthusiastic about this algorithm and its broad applications, it's important to note the following caveats, which can be crucial in practice <ref type="bibr" target="#b0">[1]</ref>.</p><p>(i) HHL can handle various types of information. However, when dealing with classical information, it's essential to efficiently load the vector b = (b 1 , . . . , b n ) into the quantum computer's memory. This process involves transforming:</p><formula xml:id="formula_35">b â |bâ© = N -1 i=0 b i |u i â© ,<label>(16)</label></formula><p>must occur rapidly. If the preparation of the state |bâ© requires exponential steps, the significant speedup gained by HHL in subsequent steps might be negated. Theoretically, this might be achieved through quantum random access memory (QRAM), which will be discussed in section 3.4. Nevertheless, it is crucial that b is reasonably uniform. For evident reasons, this challenge is referred to as the input problem <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18]</ref>.</p><p>(ii) The quantum computer must also have the capability to apply unitary transformations of the form e -iAt for various values of t. If the matrix A is sparse-meaning it contains at most s nonzero entries per row, where s âª n-and if there exists a quantum random access memory (QRAM) that efficiently stores, for each i, the locations and values of row i's nonzero entries, then it is known that one can apply e -iAt in a time that grows nearly linearly with s.</p><p>(iii) The matrix A not only needs to be invertible but also robustly invertible, or "wellconditioned." Otherwise, the significant speedup provided by the algorithm may be lost.</p><p>(iv) Finally, there's the output problem, which is the converse of the input problem <ref type="bibr" target="#b17">[18]</ref>. The challenge of encoding classical information into quantum states also extends to reading the output quantum state |xâ© into classical information x when HHL is finished. Learning the value of any specific entry x i by measurement will, in general, require repeating the algorithm roughly N times, negating the significant speedup.</p><p>To summarize, HHL is an algorithm designed to solve a system of linear equations approximately in logarithmic time. It serves as a template for other quantum algorithms, as long as one can address and mitigate the various caveats associated with its practical implementation <ref type="bibr" target="#b0">[1]</ref>. If these challenges are properly handled, HHL can find applications in various real-world scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Large scale machine learning models in fault tolerant era</head><p>There are trials about applications of the HHL algorithm and their implementation, particularly at a large scale, in Quantum Machine Learning (QML) programs. One observation is that, the mathematical description of the gradient descent program involves solving a set of difference equations, which, in the continuous limit, transforms into ordinary differential equations (ODEs).</p><p>The paper <ref type="bibr" target="#b89">[90]</ref> introduces a technique known as Carleman linearization, demonstrating that non-linear ODEs can be linearized into an infinite set of linear ODEs that can be truncated to a chosen level of approximation. This allows the approximate solution of challenging non-linear ODEs by solving the easier linearized versions. The authors establish that if the original ODEs are non-linear and dissipative, then the error resulting from the truncation in Carleman linearization can be controlled. This implies that a non-linear, dissipative system can be efficiently linearized.</p><p>In the realm of quantum computing, the HHL algorithm is known to efficiently solve linear ODEs, as expressed in Eqn. <ref type="bibr" target="#b11">(12)</ref>, providing a significant speedup compared to classical algorithms. Consequently, the combination of Carleman linearization and the HHL algorithm holds the promise of yielding a significantly efficient algorithm for solving non-linear ODEs in comparison to classical algorithms.</p><p>Dissipativeness plays a crucial role in various machine learning tasks. Many machine learning processes, including gradient descent, exhibit dissipative behavior. Treating gradient descent as dynamics reveals that it operates as an open first-order system outside the scope of Lagrangian mechanics <ref type="bibr" target="#b88">[89]</ref>. Biological processes in the brain also exemplify the significance of dissipation, where forgetting becomes essential for making room to remember new information <ref type="bibr" target="#b88">[89]</ref>.</p><p>The findings of <ref type="bibr" target="#b88">[89]</ref> suggest the potential for an efficient algorithm to solve stochastic gradient descent. Generalizing the techniques for differential equations to ordinary difference equations, it is observed that in the learning process, the Hessian eigenvalues characterize the degree of dissipation. Towards the end of training, there are roughly equal numbers of positive and negative eigenvalues, signifying comparable dissipative and non-dissipative modes. However, at the beginning of training, the number of dissipative modes significantly exceeds the number of non-dissipative modes, creating highly asymmetric Hessian eigenvalues. This phase is recognized as highly dissipative, consistent with the intuition that the system learns rapidly in the initial stages. The ODE solver described earlier is applicable during this phase, enabling the solution of machine learning tasks. Towards the end of training, when positive and negative eigenvalues become comparable, the algorithm may not be suitable for solving ODEs in general. An exception is when approaching a local minimum, where the Hessian matrix is positive definite, indicating a dissipative system suitable for the ODE solver. In summary, this quantum algorithm might help machine learning processes significantly, and if the Hessian becomes symmetric towards the end, classical algorithms can be employed for further computation.</p><p>Overcoming the input and output challenges in quantum machine learning is a complex task. While Quantum Random Access Memory (QRAM) is a promising solution for efficient data input, it is still in the developmental stage. Addressing the input challenge in quantum machine learning can be tackled using a classical algorithm known as "pruning". Typically, towards the end of training in many machine learning algorithms, the matrix of training parameters becomes highly sparse, meaning that a significant number of training parameters become zero. This sparsity presents an opportunity to effectively manage the input problem in quantum machine learning.</p><p>Dealing with the output problem involves leveraging the sparsity that often occurs in parameter matrices at the end of training, making it potentially easier to download sparse quantum states to classical computers. Additionally, classical shadow techniques, with their polynomial scaling, provide a method for extracting information from dense quantum states, if we know the sparsity of the matrix. These areas are actively researched, and advancements in quantum computing technologies and algorithms may offer new solutions in the future.</p><p>Indeed, the vision of leveraging quantum algorithms, particularly with large-scale implementations of algorithms like the HHL, holds the promise of addressing the increasing costs associated with classical algorithms. The potential gains in efficiency and computational speed offered by quantum computers could revolutionize machine learning and other computational tasks. However, it's important to emphasize that realizing these advancements requires the implementation of full quantum error correction to ensure fault tolerance. Overcoming the challenges associated with error correction remains a critical aspect of bringing quantum computing applications to fruition. Moreover, some further explorations about machine learning foundations should be given along this line, like improving the algorithms from solving gradient descent to solving the matrix multiplication problems in large-scale classical neural networks for back propagation, where quantum linear algebra techniques or parallel computing from analog photonic devices might be helpful for those tasks <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Quantum random access memory</head><p>Now, let's explore the challenges associated with the "input problem" and the "output problem". Classical data needs to be inputted into a quantum computer before undergoing processing <ref type="bibr" target="#b17">[18]</ref>. Referred to as the 'input problem', this step is generally performed with minimal overhead but can pose a significant bottleneck for certain algorithms. Similarly, the 'output problem' arises when retrieving data after it has been processed on a quantum device. Much like the input problem, the output problem can lead to a substantial operational slowdown.</p><p>In particular, when considering the application of algorithms like HHL, least squares fitting, quantum support vector machines, and related approaches, substantial amounts of classical data might be loaded into a quantum system. This loading process can demand significant time, as acknowledged in the literature <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18]</ref>. While the use of a quantum random access memory (QRAM) <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b55">56]</ref> might, in principle, address this issue, the associated costs might be prohibitive for large-scale data problems <ref type="bibr" target="#b9">[10]</ref>.</p><p>QRAM can be conceptualized as an architecture designed for the implementation of quantum oracles <ref type="bibr" target="#b53">[54]</ref>. Consider a computational problem where the input is represented by a classical data vector x . An oracle, often described as a black box, is a tool that can be interrogated to disclose information about x . Although the oracle reveals details about x upon request, the specific method it employs to obtain this information is not explicitly specified. Oracles can exist in either classical or quantum forms, as illustrated in FIG. <ref type="figure" target="#fig_5">7</ref>. A basic example of a classical oracle is the data-lookup oracle. This type of oracle is activated by providing it with an index i as input, and it subsequently outputs the corresponding vector element x i . A natural extension of this classical data-lookup oracle is the quantum datalookup oracle. In the quantum scenario, both the inputs and outputs of the oracle query are represented as quantum states. The query itself is implemented by a unitary operation, denoted as O (DL) x , which performs the mapping <ref type="bibr" target="#b53">[54]</ref>:</p><formula xml:id="formula_36">O DL) x |iâ© A |bâ© B = |iâ© A |b â x i â© B ,<label>(17)</label></formula><p>where the notation b represents any computational basis state and â denotes addition modulo 2. The superscripts A and B refer to two quantum registers, the state of register A indicates which element to look up, and the query encodes this element into the state of register B . It's important to note that, while the inputs and outputs of the query are quantum, the data being queried is classical. This characteristic makes quantum oracles serve as a bridge between classical data and quantum algorithms <ref type="bibr" target="#b53">[54]</ref>.</p><p>However, merely loading classical data into quantum memory is not sufficient; the process needs to be fast <ref type="bibr" target="#b0">[1]</ref>. QRAM is designed to address this requirement. In QRAM, the quantum state summarizing the vector uses log d qubits, and the QRAM operation involves O(d) operations distributed over O(log d) steps, which can be performed in parallel <ref type="bibr" target="#b17">[18]</ref>.</p><p>For QRAM, a quantum superposition of different addresses |Ï in â© serves as input, and the QRAM produces an entangled state |Ï out â© where each address is correlated with the corresponding memory element <ref type="bibr" target="#b53">[54]</ref>:</p><formula xml:id="formula_37">|Ï in â© = N -1 i=0 Î± i |iâ© A |0â© B QRAM ---â |Ï out â© = N -1 i=0 Î± i |iâ© A |x i â© B , (<label>18</label></formula><formula xml:id="formula_38">)</formula><p>where N is the size of the data vector x, and the superscripts A and B represent "address" and "bus," respectively.</p><p>There are two popular designs for QRAM: fanout QRAM and bucket-brigade QRAM. Their difference primarily lies in how they utilize the address qubit. All QRAM designs consist of quantum routers, which serve to route the input qubit to the right if the router qubit is in state |1â© and to the left if the router qubit is in state |0â© . In fanout QRAM, all router qubits are first flipped according to the address qubit. For example, if we want to query the information stored at site i = 5 , the address qubits will be in the computational basis: |5â© = |1â© |0â© |1â© . Then, we need a QRAM with a depth of 3 and flip all the router qubits with a CNOT gate controlled by the address qubits, as illustrated in the figure below. Then we can route the bus qubit, and since we stored classical information at x i , it is possible for us to copy it to the bus qubit and then route it all the way out before we initialize the QRAM for future use.</p><p>The bucket-brigade QRAM is a bit different in the first stage. We don't flip all the router qubits in the layer corresponding to the address qubits. Instead, we route the address qubits into the QRAM one by one, with the router qubits initialized at some state |wâ© . Since we route in the address qubits in order, we naturally carve out the path that will lead to the information stored in x 5 .</p><p>There are debates about whether QRAM is actually practical since it is time-saving but also hardware-consuming. Recently, there are several different QRAM designs that are hardware-efficient. One example is developed by the authors of <ref type="bibr" target="#b54">[55]</ref>. They made use of circuit quantum acoustodynamic (cQAD) systems <ref type="bibr" target="#b102">[103,</ref><ref type="bibr" target="#b50">51]</ref> and constructed quantum gates by applying external drives with different frequencies.</p><p>Furthermore, due to its logarithmic depth nature, when QRAM is stored with a large number of data, the speed for querying it will ultimately be bounded by the speed of light. The problem is how many qubits QRAM can store before we hit the boundary set by locality. This problem is addressed in <ref type="bibr" target="#b128">[129]</ref>, where the authors considered locality and found that some 2D or 3D QRAM designs can handle up to 10 20 qubits before hitting the constraint line. This might be already a sufficient number of qubits to perform machine learning training programs. As an result, QRAM might be still reasonable to build in the future.</p><p>Although it looks like that QRAM might be implementable, it is also important that there is no definitive evidence or proof in the hardware especially in the large scale up to date. So whether we can achieve exponential speed ups that some quantum machine learning programs promises might be still unknown and controversial. On the other hand, for some of the QML programs, one can go around QRAM by implementing a quantum subroutine which prepares the quantum states that encodes classical information <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Statistical learning theory</head><p>In this section, our aim is to approach a quantum counterpart to statistical learning theory, initiating a systematic framework for delving into the fundamentals of quantum machine learning.</p><p>A crucial aspect intertwined with statistical learning theory is shadow tomography, addressing a challenge rooted in the distinctive nature of quantum measurements-destructiveness. When concluding a Quantum Machine Learning (QML) program and obtaining a quantum state, extracting classical information becomes a non-trivial endeavor. The challenge arises from the inevitable collapse of the state during measurement, limiting access to the original state. Working with a single copy of an unknown quantum state, denoted as Ï, poses an inherent difficulty, as clever strategies cannot approximate a classical description of Ï through direct measurement. The overarching task of reconstructing a description of a D-dimensional quantum mixed state Ï, given multiple copies of Ï, falls under the domain of quantum state tomography <ref type="bibr" target="#b1">[2]</ref>. On the other hand, works such as <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref> studied statistical complexity in the context of quantum machine learning, which also closely relates to this topic.</p><p>One significant development inspired by shadow tomography is known as classical shadow. As discussed earlier in section 2.1.3, this approach holds promise for addressing the output or downloading problem. Classical shadow infers the output state Ï by performing random measurements, averaging the obtained classical data, and then inverting the results to retrieve the quantum state. This method extensively leverages basics of probability theory to control errors, making it an efficient quantum-to-classical data converter <ref type="bibr" target="#b40">[41]</ref>. Utilizing classical shadow, one can devise classical machine learning algorithms that exhibit only polynomial differences with full fault-tolerant QML programs, particularly when focusing on average error <ref type="bibr" target="#b65">[66]</ref>. Moreover, this approach holds significant applications in QML for quantum data or quantum simulators, especially when a readout is required at the end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Shadow tomography</head><p>Shadow tomography was a proposal first came up with by Scott Aaronson couple of years ago <ref type="bibr" target="#b1">[2]</ref>. In this final section, we will review some key points of it and also a little about its recent developments.</p><p>The foundation of tomography lies in the well-known fact of the destructive nature of measurements in quantum mechanics. When a quantum state or qubit, expressed as Î± |0â© + Î² |1â©, undergoes a measurement, it collapses into either |0â© or |1â© with probabilities Î± 2 and Î² 2 , respectively. Regardless of the outcome, the original state is lost and impossible to recover, a consequence of the No-Cloning Theorem, which prohibits the direct copying of quantum information.</p><p>The complexity increases significantly when dealing with n qubits. For a pure state of n qubits, obtaining an approximate description requires dealing with 2 n complex numbers. This exponential growth poses a challenge, as it would necessitate exponential classical bits to represent n qubits. Even for a relatively modest system of 1000 qubits, it would require 2 1000 complex numbers for an approximate description. To put this into perspective, this exceeds the total number of atoms in the observable universe, estimated to be around 10 80 . This realization, first acknowledged in the 1980s, played a crucial role in the conceptualization of quantum computing by visionaries like Richard Feynman <ref type="bibr" target="#b44">[45]</ref> and others. But again measurement will yield at most n bits.</p><p>The quantum state tomography challenge involves a machine capable of generating nqubit quantum states and producing identical copies of a specified state. Focusing on a mixed quantum state represented by a D Ã D density matrix, denoted as Ï, the goal is to gain insights into this density matrix. The key question is to determine the minimum number of copies of the state Ï necessary to effectively tackle this challenge. The answer to this question is approximately O(D 2 ) copies of Ï, which was established in 2016 <ref type="bibr" target="#b103">[104]</ref>. This implies that the number of required copies scales polynomially with D, the dimension of the Hilbert space, which is still exponentially large. For instance, learning about 100 qubits would necessitate around 2 200 copies of the state, an impractical and astronomically large number. Consequently, the feasibility of quantum state tomography becomes increasingly limited as the number of qubits grows, and one of the world records stands at about 10 qubits <ref type="bibr" target="#b117">[118]</ref>, involving millions of measurement settings. This underscores the significant challenges and limitations in quantum state tomography for larger quantum systems.</p><p>The concept of shadow tomography, introduced by Scott Aaronson <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, is motivated by the following scenario. We are provided with an unknown D-dimensional mixed state Ï and a set of observables, O 1 , . . . , O M . Assuming these observables can only take two values, such as yes or no, and considering that these measurements fully characterize the state, we aim to recover the "shadow" cast by Ï on the measurements O 1 , . . . , O M . The term "shadow tomography" was suggested by Steve Flammia, emphasizing our goal of retrieving the "shadow" rather than the entire density matrix of Ï. The objective is to determine the minimum number of states Ï needed to estimate the expectation value Pr[O i ] = Tr(O i Ï) for all these observables.</p><p>Our intuition suggests that approximately O(D 2 ) copies would be adequate. We can bypass the entire shadow tomography setup and simply obtain a well-approximated version of the state Ï. Once we possess the state, accurately determining any expectation values becomes feasible. Furthermore, it seems intuitive that having roughly O(M ) copies of the state should enable straightforward shadow tomography. By conducting measurements on all M observables, we can derive the expectation values. Although the state is lost after each measurement, the availability of numerous copies remains. The latter will be practical if M is small, which means that we only care a small number of measurements or observables. But in many cases, both D and M are enormous. So the crucial question revolves around whether there exist a systematic way of accomplishing shadow tomography can be accomplished with a time complexity of poly(log D, log M ) .</p><p>In 2018, it was demonstrated in <ref type="bibr" target="#b1">[2]</ref> that a protocol exists capable of achieving shadow tomography with a time complexity of poly(log D, log M ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 4.1. Shadow Tomography Theorem</head><p>Shadow tomography is solvable using only Ã log 4 M â¢ log D/Îµ 4 copies of the state Ï , where the Ã hides a higher order factor. The procedure is fully explicit.</p><p>In simpler terms, this protocol estimates the acceptance probability of all measurements, denoted as O 1 , . . . , O M , with an additive error of Â±Îµ, utilizing only approximately Ã log 4 M â¢ log D/Îµ 4 copies of Ï. While it's acknowledged that this is not the most efficient method and there is room for improvement, this protocol marked a significant milestone by demonstrating the theoretical feasibility of shadow tomography.</p><p>The implications of Theorem 4.1 include the following:</p><p>(i) For an n-qubit state |Ïâ©, by measuring approximately n O (1) copies of |Ïâ©, one can understand its behavior on every quantum circuit with at most p(n) gates, for any fixed polynomial p.</p><p>(ii) Given any n O(1) -qubit quantum program Ï, having n O(1) copies of Ï allows us to estimate its acceptance probability on every n-bit input x.</p><p>To comprehend the workings of shadow tomography, a key concept is "gentle measurement" <ref type="bibr" target="#b3">[4]</ref>. If a measurement of a mixed state Ï yields a certain outcome with a probability greater than or equal to 1 -Îµ, then after the measurement, there exists a state Ï â² that is â Îµ-close to Ï in trace distance. In simpler terms, if a state is close to an eigenstate of some observable, it is highly likely that the state will essentially collapse into that eigenstate, which isn't much different from the original state before the measurement occurred. An even stronger statement holds: applying M such measurements in succession, each accepting with a probability greater than or equal to 1 -2M â Îµ, ensures that the error grows linearly. Thus, if a sequence of measurements is applied, and each one does not significantly damage Ï, the cumulative effect of the entire session (assuming not too many measurements, i.e., small M ) will also not significantly damage Ï.</p><p>The concept of gentle measurement is often paired with amplification. If one has many identical copies of a state Ï, and the measurement on one copy yields a certain outcome with a 90 percent probability, then with k copies of the state, an amplified measurement can be applied. This involves coherently measuring k copies of Ï and taking a majority to reduce the error to 1/ exp k. Therefore, one can use amplification initially to reduce Îµ or the probability of a bad measurement to an exponentially small value with respect to k, the number of copies measured. Subsequently, gentle measurement can be employed, ensuring that the damage to the state Ï each time a measurement is applied is only of an exponentially small amount.</p><p>One obvious question might be why gentle measurement does not solve our problem of shadow tomography immediately. Gentle measurement only provides a solution under a special case known as a promise gap. The gentle measurement will give us an answer under the following circumstance: given measurements O 1 , . . . , O M and real numbers C 1 , . . . , C M , and being promised that Pr[O i accepts Ï] is either at least C i or at most C i -Îµ for each i, we can decide for each i using only O (log M/Îµ 2 ) copies of Ï. This provides a good zone for gentle measurements to figure out which side of the two outcome measurements our state is close to, allowing gentle measurement to work. The problem arises when we are in the intermediate zone:</p><formula xml:id="formula_39">C i -Îµ â¥ Pr[O i accepts Ï] â¥ C i .</formula><p>In this case, we will not be able to use this trick and accomplish shadow tomography. In other words, when there's no promise, we can never rule out that we're on the knife-edge between acceptance and rejection, making measuring Ï dangerous, since measurement there will not be gentle and destroy our state. And because our objective limits our copies of Ï to only log M , we can't afford to destroy that many copies of the state.</p><p>The whole point of shadow tomography is to address this problem <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. The actual proof of Theorem 4.1 involves a combination of several tricks. The first one was intended to solve a different yet similar problem. Imagine Alice, who knows the state Ï, needs to send its information or description to Bob with respect to its behavior on measurements of observables O 1 , . . . , O M , which we call E 1 , . . . , E M . In contrast to shadow tomography, Alice does know the state at the beginning, but she has to send the information about the measurements in much fewer bits.</p><p>The following program will solve this problem, resembling a machine learning program. Initially, since Bob knows absolutely nothing, he will take a guess, and let's set it to the maximally entangled state: Ï 0 . Then Alice helps Bob improve by repeatedly telling him a measurement with respect to an observable O i(t) on which Bob's current guess Ï t-1 badly fails. Bob lets Ï t be the state obtained by starting from Ï t-1 , then performing the measurement of O i(t) and postselecting on getting the right outcome. After a few rounds, Bob has improved his state. To clarify, Bob is not trying to learn Ï at all but only Ï's behavior. He might end up with a state that is very far away in terms of trace distance from Ï yet still improves with respect to all the measurements that we care about. So the extreme situation is that Bob would guess randomly and obtain a very different state, yet this state has nothing to do with the measurements to improve upon. Then Bob is done on day one. The key point is for boosting weights type reasons; this process must converge after T = O(log D) iterations, at some state Ï T that behaves like Ï in terms of E 1 , . . . , E M , even if it's far from Ï in trace distance.</p><p>Can we use this postselection learning protocol to solve the problem of shadow tomography? Unfortunately, it's still not enough by itself. Here, we relied on Alice to know the state Ï, and to know which measurement to be used that is best fit for postselection and updating Bob's guess. However, in the shadow tomography situation, there is no Alice. There is no one who knows the state and can tell you useful measurements to condition on. Rather, you just have these copies of a Ï, and we have to figure it out for ourselves.</p><p>Another protocol to be combined with the previous one is called the Quantum OR Bound <ref type="bibr" target="#b58">[59]</ref>. Theorem 4.2. Quantum OR Bound</p><p>Let Ï be an unknown mixed state, and let E 1 , . . . , E M be known 2-outcome measurements. Suppose we are promised that either (i) there exists an i such that Pr[E i accepts Ï] â¥ C ; or else</p><formula xml:id="formula_40">(ii) Pr[E i accepts Ï] â¤ C -Îµ , for all i â [M ] .</formula><p>Then we can decide which, with high probability, given only O (log M/Îµ 2 ) copies of Ï . So what's new about shadow tomography is the combination of two protocols, postselection learning and the Quantum OR Bound. Scott Aaronson <ref type="bibr" target="#b1">[2]</ref> found that you can use the Quantum OR Bound protocol as a subroutine to repeatedly search for informative measurements. Again, you start with the maximally mixed state and use the quantum OR bound repeatedly to search for measurements that can best improve your guess, round by round, to shape it into the one that has a similar outcome in terms of measurements with the target state Ï. Putting everything together, one will end up with Theorem 4.1.</p><p>The result in Theorem 4.1 is not the upper or lower bound; it simply shows that shadow tomography can be done in log M steps. Nowadays, the best lower bound people can prove is O(log M/Îµ 2 ), which holds even if we are trying to learn a classical distribution <ref type="bibr" target="#b3">[4]</ref>. So it is still unclear whether we need quantum Hilbert dimension D in Theorem 4.1. In <ref type="bibr" target="#b2">[3]</ref>, the authors were able to improve upon the log M dependence using a brand-new connection between gentle measurement and differential privacy. The sample complexity they have achieved is</p><formula xml:id="formula_41">k = O log 2 M â¢ log 2 D/Îµ 8 .</formula><p>Inspired by shadow tomography, <ref type="bibr" target="#b65">[66]</ref> introduced the classical shadow protocol, as discussed in section 2.1.3. Thus, quantum machine learning is a rapidly developing field that encompasses various topics in physics and computer science. Although sub-fields may appear distinct, they all fall under the umbrella of quantum machine learning, influencing and potentially finding applications in one another. As a result, as Scott Aaronson states at the end of his paper <ref type="bibr" target="#b0">[1]</ref>, despite decades of research in quantum computing, researchers still marvel at the fact that the laws of quantum physics enable us to solve classical problems significantly faster than today's computers seem capable of. Therefore, it should perhaps not surprise us that, in machine learning and elsewhere, unlocking the full potential of quantum speedups requires significant effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Classical shadow formalism and random measurements</head><p>Drawing inspiration from the principles of shadow tomography, the classical shadow formalism has emerged as an intriguing topic with the potential to serve as an efficient quantum-classical information converter. A series of works, such as <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b40">41]</ref>, have contributed to establishing a rigorous framework for reasoning about the randomized measurement paradigm, a key component of classical shadow. These works not only delve into the conceptual aspects but also provide methods to derive error bounds for quantum information extraction based on randomized measurements, leveraging probability theory.</p><p>The challenges associated with the quantum-classical information interface, particularly in the context of NISQ algorithms (discussed in sections 2.1 and 2.2), as well as in the FTQC era for quantum machine learning algorithms (explored in section 3.3.1), highlight the necessity of efficient readout mechanisms. Researchers are actively addressing the need for reliable ways to input and extract information from quantum systems to classical ones, as the success of quantum machine learning programs relies on overcoming these challenges. If the process of loading classical data into a quantum computer or transforming quantum data into classical form takes an significant amount of time, the promised speed-ups of quantum algorithms become impractical. Therefore, not only is it crucial to find methods for transforming classical data into quantum form and vice versa, but the efficiency of these processes, including achieving significant speed-up, is paramount, given the exponential growth of Hilbert space degrees of freedom.</p><p>The most direct and comprehensive solution to the input problem is Quantum Random Access Memory (QRAM), as detailed in section 3.4. Additionally, alternative techniques like pruning, discussed in section 3.3.1, offer potential solutions to circumvent the pressing requirement for QRAM. Classical shadow, see also section 2.1.3, on the other hand, is focused on addressing the output problem. In this scenario, we possess a quantum state that encapsulates information trained by our Quantum Machine Learning (QML) program, and the goal is to decode this quantum state into classical information for straightforward interpretation.</p><p>To present this challenge in a broader context, the task is to efficiently estimate the expectation values of multiple structured observables. Specifically, the aim is to estimate the expectation value of various individual terms in Hamiltonians, where these terms share a well-defined structure, such as being Pauli operators. The proposed strategy for addressing this challenge involves diverting attention from the intricate details of the terms and instead uniformly sampling Pauli measurements. In simpler terms, the goal is to estimate the expectation values of Pauli observables, with the selection of the Pauli basis for each qubit being determined randomly during the measurement process <ref type="bibr" target="#b40">[41]</ref>.</p><p>This concept can be grasped intuitively through the lens of the infinite monkey theorem <ref type="bibr" target="#b42">[43]</ref>. The theorem posits that a monkey randomly hitting keys on a typewriter for an infinite amount of time will almost certainly type any given text, including the complete works of William Shakespeare, and will likely produce every possible finite text an infinite number of times. Let's apply this idea to predicting an arbitrary low-weight Pauli observable, represented by the purple blocks in Fig. <ref type="figure" target="#fig_7">9</ref>. The white blocks signify identity matrices, which are not of primary concern. The crucial aspect is the presence of three specific Pauli operators adjacent to each other in Fig. <ref type="figure" target="#fig_7">9</ref>. Now, if we randomly assign Pauli measurements to each qubit, we are free to choose any Pauli measurements for the white blocks on the left side of Fig. <ref type="figure" target="#fig_7">9</ref>. However, for the purple blocks, we must use the same Pauli measurements as on the left, or else we won't gain meaningful information about the statistics. To achieve this, random sampling is employed. Importantly, the performance is not adversely affected, as the probability of obtaining such a low-weight Pauli string is exponentially small, but this exponentiation is in the weight of the Pauli, not in the number of qubits <ref type="bibr" target="#b42">[43]</ref>. Additionally, if single-shot measurements are considered, there will be an oversampling factor. The crucial aspect is that, since everything is done randomly, an effective union bound can be applied to estimate numerous low-weight Pauli observables. The union bound scales logarithmically with the number of terms. Consequently, if one randomly samples each Pauli measurement, the expected total number of measurements required to predict L low-weight observables with accuracy Ïµ each is only logarithmic in L, thanks to the union bound <ref type="bibr" target="#b40">[41]</ref>.</p><p>To formally understand the classical shadow formalism, first we construct a quantum channel which transforms the quantum data into the classical data. We start with an unknown m qubit quantum state Ï and do a certain random unitary rotation: U , for example an independent single qubit Clifford rotation. Then we do a computational basis measurement on all of them. Since we did measurement at last, so the output of this channel is actually, honest to god, classical information. This, in Fig. <ref type="figure" target="#fig_8">10</ref>, means that U â  |bâ©â¨b|U although written in quantum language, is classical data. Hence, altogether, what this channel does is to transform the quantum state we got from the quantum computer and mapped it into classical information which we will do further computation. The subsequent step involves averaging the random unitary sampling (through an integral over U ), depending on the chosen ensemble, and also averaging over the computational basis outcomes (by summing over b) as per Born's rule. If the ensemble is well-behaved, such as Haar random, then the result after the averaging step can be efficiently computed. Moreover, since the result is classical information rather than quantum, it can be easily inverted to obtain the state Ï. Another example may be found in <ref type="bibr" target="#b22">[23]</ref>, where the authors consider classical shadows with unitary ensembles that are invariant under multiplication by Pauli operators. Consequently, the state Ï is obtained by performing random measurements to acquire classical data, taking average, and then inverting the result to retrieve the state. The lingering question pertains to the convergence speed of this program to the desired expectation value. Drawing inspiration from shadow tomography, the authors of <ref type="bibr" target="#b61">[62]</ref> demonstrated that the number of required snapshots or single measurements in this program scales logarithmically with the number of terms needed to predict: N â³ log (L) max j ||O j || 2 shadow /Ïµ 2 , where O j is the observable to be measured, and Ïµ denotes the desired accuracy.</p><p>In 2021, the authors of <ref type="bibr" target="#b118">[119]</ref> conducted an experimental implementation of classical shadow, demonstrating its superiority over maximum likelihood in the low sampling regime. This framework's applicability extends to the prediction of observable polynomials, as discussed in <ref type="bibr" target="#b40">[41]</ref>. The strategy involves expressing polynomials as linear combinations of tensor products and substituting the tensor products with independent shadows, enhancing efficiency in probing entanglements in many-body systems. Notably, this method exhibits robustness in the presence of noise, leveraging random unitaries as detailed in <ref type="bibr" target="#b29">[30]</ref>. The authors of <ref type="bibr" target="#b74">[75]</ref> propose an error-mitigated classical shadow estimation scheme. This result complements <ref type="bibr" target="#b29">[30]</ref>. <ref type="bibr" target="#b134">[135]</ref> introduced an error-mitigated fermionic classical shadow scheme. Additionally, <ref type="bibr" target="#b64">[65]</ref> explores techniques for derandomizing the procedure. In classical computer science, there exists a standard approach to transform a probabilistic argument into a deterministic strategy, maintaining comparable effectiveness without reliance on randomness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Machine learning with classical shadow</head><p>In summary, classical shadows serve as an efficient quantum-to-classical converter, enabling the extraction of classical information from quantum states. This information can be used to predict observable expectation values. When considering the Variational Quantum Eigensolver (VQE) in a classical context, it resembles a kernel method. The process involves initiating with parameters that define the circuit, creating a map in a high-dimensional space. These parameters are then used to map to a state generated by the circuit, constructing an objective function with the Hamiltonian to acquire classical information. Moreover, classical shadows have demonstrated significant performance gains for VQE <ref type="bibr" target="#b40">[41]</ref>, prompting exploration into their potential implementation for more sophisticated machine learning programs.</p><p>Consider the problem of predicting ground state properties, where we assume a family of parameterized Hamiltonians, denoted as H(x), with x being a classical input characterizing the Hamiltonian (e.g., Heisenberg Hamiltonian with x representing couplings). The goal is to learn how to predict ground state properties, such as observable expectation values, for ground states associated with Hamiltonians that were not part of the training data.</p><p>Classically, this problem is challenging. However, leveraging quantum training data and classical shadow measurements simplifies the task. Here's how the process unfolds:</p><p>(i) Learning Phase:</p><p>-Random input parameters are sampled, and the associated ground states are prepared in the laboratory.</p><p>-Classical shadow measurements are performed on these ground states for randomly chosen single qubits.</p><p>-The training data comprises classical inputs (x) associated with classical shadow singleshot measurements of the corresponding ground states.</p><p>-The goal is to train a classical kernel method using these classical shadows.</p><p>(ii) Prediction Phase:</p><p>-In this phase, a Fourier-type kernel function is employed to convolve all the classical shadows observed during the learning phase.</p><p>-This convolution provides an approximation of the ground state for Hamiltonians not directly observed.</p><p>The central concept involves using classical shadows as a connection between quantum training data and classical predictions. This approach facilitates the learning of ground state properties for Hamiltonians that were not part of the initial training set. The goal is to establish an efficient representation for future Hamiltonians, enabling the computation of observable expectation values and making predictions. This program has been demonstrated to be effective. In <ref type="bibr" target="#b67">[68]</ref>, the authors established that for a small average case prediction error (averaged over all possible inputs), a scenario common in machine learning, the required amount of training data is not extensive. Instead, it scales quasi-polynomially in the number of inputs, not the number of qubits.</p><p>In the study conducted by <ref type="bibr" target="#b65">[66]</ref>, the authors delved deeper into the efficacy of this method. They utilized a quantum device to generate data, employed classical shadows to effectively utilize the quantum data, and then applied classical machine learning algorithms for training. They compared this approach (classical machine learning with quantum data leading to classical shadows) to a hypothetical full-scale quantum machine learning protocol. The latter runs on a quantum computer and has coherent access to training data through QRAM. This is the most powerful program that we can envision in the future of QML. The results indicated that, when focusing on average error, there is no significant separation between quantum and classical training data size in terms of sample complexity. However, for worst-case prediction error, <ref type="bibr" target="#b65">[66]</ref> presented concrete examples demonstrating an exponential separation in complexity. In the research presented in <ref type="bibr" target="#b66">[67]</ref>, the authors explore analogous approaches to learning. They investigate how classical and quantum agents, given their distinct methods of receiving, processing, and storing information, differ in efficiency when aiming to characterize a physical system or state Ï. The study demonstrates that quantum agents can achieve exponential advantages in experiments, particularly in terms of the number of queries required to obtain Ï.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Quantum machine learning for quantum data and quantum simulators</head><p>The most immediate application of quantum machine learning lies in handling quantum data <ref type="bibr" target="#b17">[18]</ref>, i.e., the states produced by quantum systems and processes. Traditional quantum machine learning algorithms, as discussed earlier, identify patterns in classical data by transforming it into quantum states and manipulating those states using basic quantum linear algebra operations. These same algorithms can be directly employed on quantum states of light and matter to uncover inherent features and patterns. The quantum methods of analysis often prove to be more efficient and insightful than classical approaches when dealing with data obtained from quantum systems.</p><p>For instance, in the case of multiple copies of a system represented by an N Ã N density matrix, quantum principal component analysis can determine eigenvalues and reveal corresponding eigenvectors in a time complexity of O (log 2 N ) 2 . This stands in contrast to the O(N 2 ) measurements required for classical devices to perform tomography on the density matrix and the O(N 2 ) operations needed for classical PCA. This quantum analysis of quantum data can be efficiently conducted on the relatively modest-scale quantum computers expected to be available in the coming years. As mentioned before, <ref type="bibr" target="#b66">[67]</ref> also demonstrated the quantum advantages of learning a physical state Ï through a quantum agent for example quantum sensor or simulator discussed above.</p><p>Quantum simulators serve as powerful tools for analyzing quantum dynamics. These are essentially "quantum analog computers" capable of emulating the dynamics of specific quantum systems. Quantum simulators can be specialized devices designed for simulating particular classes of quantum systems or general-purpose quantum computers. The approach involves connecting a trusted quantum simulator to an unknown system, adjusting the simulator's model to counteract the unknown dynamics, and efficiently learning the dynamics of the unknown system using approximate Bayesian inference <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b131">132,</ref><ref type="bibr" target="#b132">133]</ref>. This significantly reduces the number of measurements required for simulation, offering an exponential improvement.</p><p>Notably, the universal quantum emulator algorithm <ref type="bibr" target="#b95">[96]</ref> enables the reconstruction of quantum dynamics, and the quantum Boltzmann training algorithm <ref type="bibr" target="#b17">[18]</ref> allows for the reconstruction of states with a time complexity logarithmic in the dimension of the Hilbert space. This is significantly faster than reconstructing dynamics through classical tomography.</p><p>While using a quantum computer to characterize a quantum system <ref type="bibr" target="#b131">[132,</ref><ref type="bibr" target="#b132">133]</ref> or input states for quantum PCA poses technical challenges, as it doesn't require QRAM, it holds promise for near-term applications of quantum machine learning <ref type="bibr" target="#b131">[132,</ref><ref type="bibr" target="#b132">133,</ref><ref type="bibr" target="#b17">18]</ref>, offering the potential for significant speedups in device characterization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and discussion</head><p>This review highlights that both current NISQ-era quantum devices and future fully faulttolerant quantum computers (FTQC) hold significant promise for applications in machine learning and data analysis <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b86">87,</ref><ref type="bibr" target="#b88">89]</ref>. Over the past decade, quantum computing has witnessed notable advancements in applications, experimental validations, and theoretical findings. The quantum computation field, especially in NISQ applications, has seen an almost exponential growth in the number of research papers. Various factors contribute to this trend, including substantial enhancements in quantum hardware <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b66">67]</ref>. Given that quantum computing is a relatively young scientific discipline, there is ample opportunity for groundbreaking research and discoveries. The presence of theoretical, practical, and experimental challenges, many of which are addressed in this review, further underscores the motivation for an open-source approach in the field.</p><p>As mentioned in <ref type="bibr" target="#b16">[17]</ref>, we expect experimental pursuit in the NISQ era would focus on the design of quantum hardware with a larger number of qubits, and gates with lower error rates capable of executing deeper circuits. Along the way, one of the goals is to demonstrate quantum advantage for practical use cases. If the NISQ paradigm is not powerful enough to exhibit any quantum advantage, theoretical pursuits would be required to understand its limitations. The prime direction of the NISQ and near-term era is to engineer the best possible solution with the limited quantum resources available. The tools and techniques invented during this period could be valuable in the fault-tolerant era as well. To conduct a successful demonstration of quantum advantage, the right blend of the two crucial components: hardware and algorithms designs, is required <ref type="bibr" target="#b16">[17]</ref>. First, hardware development is the key. The design of quantum computers with more qubits, lesser error rates, longer coherence times, and more connectivity between the qubits will be one of the top priorities in the NISQ era. Intensive research in new qubits developments, quantum optimal control and material discovery will be indispensable for both universal programmable quantum computers or special purpose ones. Secondly, to harness the potential of noisy but powerful quantum devices, we expect breakthroughs on the algorithm frontier. Algorithms with realistic assumptions, as the ones mentioned in <ref type="bibr" target="#b16">[17]</ref>, regarding device capabilities will be favored. To lessen the effect of noise, progress towards the design of error suppression, mitigation and correction methods is expected.</p><p>While QML has been proposed as a potential avenue for achieving scientific value in the near term using NISQ devices, questions arise regarding its applicability in the future <ref type="bibr" target="#b26">[27]</ref>. Researchers envision two distinct post-NISQ eras. The first, termed "partial error corrected," assumes that quantum computers will possess a sufficient number of physical qubits (a few hundred) and low error rates, allowing for a small number of fully error-corrected logical qubits. In this era, users can allocate qubits between error-corrected and non-error-corrected subsets. The subsequent era, labeled the "fault-tolerant era," will emerge when quantum hardware features a large number of error-corrected qubits. In this era, algorithms like those discussed in section 3.3.1 could notably enhance the scalability and sustainability of classical large-scale machine learning models. Notably, works such as <ref type="bibr" target="#b89">[90]</ref> offer solid theoretical assurances and intersections with cutting-edge classical machine learning research. This approach diverges from the variational quantum algorithms mindset, exemplified by <ref type="bibr" target="#b86">[87]</ref>, by aiming to enhance classical machine learning through a key quantum step that acts as a bottleneck for classical training. Developments in shadow tomography and related fields <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b65">66]</ref> demonstrate the potential for systematically analyzing QML and gaining a deeper understanding of how quantum speedup is achieved. As demonstrated experimentally in <ref type="bibr" target="#b66">[67]</ref>, with quantum technology such as quantum sensor, quantum memory, and quantum computer, our ability to learn about the physical world might be exponentially improved. Hence, there is confidence that in the future, researchers will have a much more robust understanding of how quantum computing achieves speedup and can develop more powerful applications for machine learning problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. VQA in 4 parts.</figDesc><graphic coords="7,92.74,461.92,400.26,255.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. A basic illustration of VQA circuits.</figDesc><graphic coords="11,153.89,538.06,277.96,80.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Circuits for quantum phase estimation.</figDesc><graphic coords="21,181.69,478.72,222.36,91.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. A simple illustration of principle component analysis (PCA).</figDesc><graphic coords="22,226.16,553.83,133.42,76.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Circuits for HHL algorithm [11].</figDesc><graphic coords="25,137.22,509.28,311.31,98.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Classical and quantum data-lookup oracles [54].</figDesc><graphic coords="29,92.74,356.64,400.26,54.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. The left figure is a picturesque illustration of fanout QRAM [54] to retrieve information stored at i = 5 . On the other hand, the right figure is a picturesque illustration of bucket-brigade QRAM [54] to retrieve information stored at i = 5 .</figDesc><graphic coords="30,153.89,362.17,277.96,76.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. A picturesque illustration of the infinite monkey theorem applied to randomized measurements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. A quantum to classical channel.</figDesc><graphic coords="37,137.22,483.02,311.31,105.20" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Figure3. Demonstration of the evolution of the loss function in the continuous limit<ref type="bibr" target="#b86">[87]</ref>. The right diagram depicts the closed-form solution when the QNTK remains constant. In contrast, the left diagram illustrates a scenario where the QNTK is nonlinear but nearly constant. In this case, representation learning is achieved, and the gradient descent equation can be addressed perturbatively.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>dec 2020. doi: 10.1088/2632-2153/abcb50. URL https://doi.org/10.1088% 2F2632-2153%2Fabcb50.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>We thank <rs type="person">Hsin-Yuan Huang</rs> and <rs type="person">Kanav Setia</rs> for helpful discussions. JL is supported in part by <rs type="funder">International Business Machines (IBM) Quantum</rs> through the <rs type="institution">Chicago Quantum Exchange</rs>, and the <rs type="funder">Pritzker School of Molecular Engineering</rs> at the <rs type="institution">University of Chicago through AFOSR MURI</rs> (<rs type="grantNumber">FA9550-21-1-0209</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_2jnqaDn">
					<idno type="grant-number">FA9550-21-1-0209</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Read the fine print</title>
		<author>
			<persName><forename type="first">S</forename><surname>Aaronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="291" to="293" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Shadow tomography of quantum states</title>
		<author>
			<persName><forename type="first">S</forename><surname>Aaronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th annual ACM SIGACT symposium on theory of computing</title>
		<meeting>the 50th annual ACM SIGACT symposium on theory of computing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="325" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Shadow tomography of quantum states</title>
		<author>
			<persName><forename type="first">S</forename><surname>Aaronson</surname></persName>
		</author>
		<idno type="DOI">10.1137/18M120275X</idno>
		<ptr target="https://doi.org/10.1137/18M120275X" />
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Gentle measurement of quantum states and differential privacy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Aaronson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Rothblum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Filtering variational quantum algorithms for combinatorial optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Amaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Modica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rosenkranz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fiorentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Benedetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lubasch</surname></persName>
		</author>
		<idno type="DOI">10.1088/2058-9565/ac3e54</idno>
		<ptr target="http://dx.doi.org/10.1088/2058-9565/ac" />
	</analytic>
	<monogr>
		<title level="j">Quantum Science and Technology</title>
		<idno type="ISSN">2058-9565</idno>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">54</biblScope>
			<date type="published" when="2022-01">Jan. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Natural evolutionary strategies for variational quantum computation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Degroote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<idno type="DOI">10.1088/2632-2153/abf3ac</idno>
		<ptr target="https://doi.org/10.1088%2F2632-2153%2Fabf3ac" />
	</analytic>
	<monogr>
		<title level="j">Machine Learning: Science and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">45012</biblScope>
			<date type="published" when="2021-07">jul 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Junipr: a framework for unsupervised machine learning in particle physics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Feige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Frye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The European Physical Journal C</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Effect of barren plateaus on gradient-free optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arrasmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Czarnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<idno type="DOI">10.22331/q-2021-10-05-558</idno>
		<ptr target="http://dx.doi.org/10.22331/q-2021-10-05-558" />
	</analytic>
	<monogr>
		<title level="j">Quantum</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">558</biblScope>
			<date type="published" when="2021-10">Oct. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Equivalence of quantum barren plateaus to cost concentration and narrow gorges</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arrasmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<idno type="DOI">10.1088/2058-9565/ac7d06</idno>
		<ptr target="http://dx.doi.org/10.1088/2058-9565/ac7d06" />
	</analytic>
	<monogr>
		<title level="j">Quantum Science and Technology</title>
		<idno type="ISSN">2058-9565</idno>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">45015</biblScope>
			<date type="published" when="2022-08">Aug. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the robustness of bucket brigade quantum ram</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arunachalam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gheorghiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jochym-O'connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mosca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<idno type="DOI">10.1088/1367-2630/17/12/123010</idno>
		<ptr target="http://dx.doi.org/10.1088/1367-2630/17/12/123010" />
	</analytic>
	<monogr>
		<title level="j">New Journal of Physics</title>
		<idno type="ISSN">1367-2630</idno>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">123010</biblScope>
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Step-by-step hhl algorithm walkthrough to enhance the understanding of critical quantum computing concepts</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J M J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Wong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Classical algorithms and quantum limitations for maximum cut on high-girth graphs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marwaha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.05900</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Improving variational quantum optimization using cvar</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Barkoutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nannicini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tavernelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Woerner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">256</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">An optoacoustic field-programmable perceptron for recurrent neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Englund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Stiller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.01543</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A generative modeling approach for benchmarking and training shallow quantum circuits</title>
		<author>
			<persName><forename type="first">M</forename><surname>Benedetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Garcia-Pintos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Perdomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Leyton-Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perdomo-Ortiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">npj Quantum Information</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hardware-efficient variational quantum algorithms for time evolution</title>
		<author>
			<persName><forename type="first">M</forename><surname>Benedetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fiorentini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lubasch</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevResearch.3.033083</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevResearch.3.033083" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Research</title>
		<idno type="ISSN">2643- 1564</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2021-07">July 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Noisy intermediate-scale quantum (nisq) algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bharti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cervera-Lierta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Kyaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Haug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alperin-Lea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Degroote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Heimonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Kottmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Menke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.08448</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Quantum machine learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Biamonte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wittek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pancotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rebentrost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">549</biblScope>
			<biblScope unit="issue">7671</biblScope>
			<biblScope unit="page" from="195" to="202" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A semi-agnostic ansatz with variable structure for variational quantum algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bilkis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Verdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<idno type="DOI">10.1007/s42484-023-00132-1</idno>
		<ptr target="http://dx.doi.org/10.1007/s42484-023-00132-1" />
	</analytic>
	<monogr>
		<title level="j">Quantum Machine Intelligence</title>
		<idno type="ISSN">2524-4914</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Training variational quantum algorithms is np-hard</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bittel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kliesch</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.127.120502</idno>
		<ptr target="https://link.aps.org/doi/10.1103/PhysRevLett.127.120502" />
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page">120502</biblScope>
			<date type="published" when="2021-09">Sep 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Statistical complexity of quantum circuits</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevA.105.062431</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevA.105.062431" />
	</analytic>
	<monogr>
		<title level="j">Physical Review A</title>
		<idno type="ISSN">2469-9934</idno>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2022-06">June 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Effects of quantum resources and noise on the statistical complexity of quantum circuits</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1088/2058-9565/acb56a</idno>
		<ptr target="http://dx.doi.org/10.1088/2058-9565/acb56a" />
	</analytic>
	<monogr>
		<title level="j">Quantum Science and Technology</title>
		<idno type="ISSN">2058-9565</idno>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">25013</biblScope>
			<date type="published" when="2023-02">Feb. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Classical shadows with pauliinvariant unitary ensembles</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaffe</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41534-023-00801-w</idno>
		<ptr target="http://dx.doi.org/10.1038/s41534-023-00801-w" />
	</analytic>
	<monogr>
		<title level="m">npj Quantum Information</title>
		<imprint>
			<date type="published" when="2024-01">Jan. 2024</date>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The battle of clean and dirty qubits in the era of partial error correction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bultrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Czarnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<idno type="DOI">10.22331/q-2023-07-13-1060</idno>
		<ptr target="http://dx.doi.org/10.22331/q-2023-07-13-1060" />
	</analytic>
	<monogr>
		<title level="j">Quantum</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">1060</biblScope>
			<date type="published" when="2023-07">July 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cost function dependent barren plateaus in shallow parametrized quantum circuits</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Volkoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-021-21728-w</idno>
		<ptr target="http://dx.doi.org/10.1038/s41467-021-21728-w" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<idno type="ISSN">2041-1723</idno>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021-03">Mar. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Variational quantum state eigensolver. npj Quantum Information</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arrasmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">113</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Challenges and opportunities in quantum machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Verdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Computational Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="567" to="576" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Barren plateaus in quantum tensor network optimization. Quantum</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cervero MartÃ­n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Plekhanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lubasch</surname></persName>
		</author>
		<idno type="DOI">10.22331/q-2023-04-13-974</idno>
		<ptr target="http://dx.doi.org/10.22331/q-2023-04-13-974" />
		<imprint>
			<date type="published" when="2023-04">Apr. 2023</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">974</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">An introduction to error-correcting codes: From classical to quantum</title>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Robust shadow estimation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Flammia</surname></persName>
		</author>
		<idno type="DOI">10.1103/PRXQuantum.2.030348</idno>
		<ptr target="http://dx.doi.org/10.1103/PRXQuantum.2.030348" />
	</analytic>
	<monogr>
		<title level="j">PRX Quantum</title>
		<idno type="ISSN">2691-3399</idno>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2021-09">Sept. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Information perspective to probabilistic modeling: Boltzmann machines versus born machines</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">583</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sampling-based sublinear low-rank matrix arithmetic framework for dequantizing quantum machine learning</title>
		<author>
			<persName><forename type="first">N.-H</forename><surname>Chia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>GilyÃ©n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3357713.3384314</idno>
		<ptr target="http://dx.doi.org/10.1145/3357713.3384314" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, STOC &apos;20</title>
		<meeting>the 52nd Annual ACM SIGACT Symposium on Theory of Computing, STOC &apos;20</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020-06">June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">On lazy training in differentiable programming</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chizat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oyallon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Quantum machine learning: a classical perspective</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ciliberto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herbster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Ialongo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rocchetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Severini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wossnig</surname></persName>
		</author>
		<idno type="DOI">10.1098/rspa.2017.0551</idno>
		<ptr target="http://dx.doi.org/10.1098/rspa.2017.0551" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<idno type="ISSN">1471-2946</idno>
		<imprint>
			<biblScope unit="volume">474</biblScope>
			<date type="published" when="2018">2209. 20170551. Jan. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Machine learning of noise-resilient quantum circuits</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarovar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<idno type="DOI">10.1103/PRXQuantum.2.010324</idno>
		<ptr target="http://dx.doi.org/10.1103/PRXQuantum.2.010324" />
	</analytic>
	<monogr>
		<title level="j">PRX Quantum</title>
		<idno type="ISSN">2691-3399</idno>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021-02">Feb. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Chaos, complexity, and random matrices</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cotler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hunter-Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yoshida</surname></persName>
		</author>
		<idno type="DOI">10.1007/JHEP11(2017)048</idno>
		<ptr target="http://dx.doi.org/10.1007/JHEP11" />
	</analytic>
	<monogr>
		<title level="j">Journal of High Energy Physics</title>
		<idno type="ISSN">1029- 8479</idno>
		<imprint>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="2017-11">2017. Nov. 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Revisiting dequantization and quantum advantage in learning tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cotler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mcclean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.00811</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Error mitigation with clifford quantum-circuit data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Czarnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arrasmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<idno type="DOI">10.22331/q-2021-11-26-592</idno>
		<ptr target="http://dx.doi.org/10.22331/q-2021-11-26-592" />
	</analytic>
	<monogr>
		<title level="j">Quantum</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">592</biblScope>
			<date type="published" when="2021-11">Nov. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Tight bounds on the convergence of noisy random circuits to the uniform distribution</title>
		<author>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niroula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shtanko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Gorshkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fefferman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Gullans</surname></persName>
		</author>
		<idno type="DOI">10.1103/PRXQuantum.3.040329</idno>
		<ptr target="http://dx.doi.org/10.1103/PRXQuantum.3.040329" />
	</analytic>
	<monogr>
		<title level="j">PRX Quantum</title>
		<idno type="ISSN">2691-3399</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2022-12">Dec. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">A non-review of quantum machine learning: trends and explorations</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dunjko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wittek</surname></persName>
		</author>
		<idno type="DOI">10.22331/qv-2020-03-17-32</idno>
		<imprint/>
	</monogr>
	<note>Quantum Views, 4:32, 03 2020</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The randomized measurement toolbox</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Flammia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kueng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Preskill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vermersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zoller</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42254-022-00535-2</idno>
		<ptr target="http://dx.doi.org/10.1038/s42254-022-00535-2" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Physics</title>
		<idno type="ISSN">2522-5820</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="24" />
			<date type="published" when="2022-12">Dec. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Hybrid quantum-classical algorithms and quantum error mitigation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Endo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Physical Society of Japan</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">32001</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Flammia</surname></persName>
		</author>
		<title level="m">Scalable bayesian hamiltonian learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Farhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goldstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gutmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.4028</idno>
		<title level="m">A quantum approximate optimization algorithm</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Feynman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Allen</surname></persName>
		</author>
		<ptr target="https://books.google.com.tw/books?id=-olQAAAAMAAJ" />
		<title level="m">Lectures On Computation. Advanced book program. Basic Books, 1996. ISBN 9780201489910</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Quantum observables for continuous control of the quantum approximate optimization algorithm via reinforcement learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Garcia-Saez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics</title>
		<author>
			<persName><forename type="first">A</forename><surname>GilyÃ©n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wiebe</surname></persName>
		</author>
		<idno type="DOI">10.1145/3313276.3316366</idno>
		<ptr target="http://dx.doi.org/10.1145/3313276.3316366" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, STOC &apos;19</title>
		<meeting>the 51st Annual ACM SIGACT Symposium on Theory of Computing, STOC &apos;19</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-06">June 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Robust online hamiltonian learning</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Granade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ferrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Cory</surname></persName>
		</author>
		<idno type="DOI">10.1088/1367-2630/14/10/103013</idno>
		<ptr target="http://dx.doi.org/10.1088/1367-2630/14/10/103013" />
	</analytic>
	<monogr>
		<title level="j">New Journal of Physics</title>
		<idno type="ISSN">1367-2630</idno>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">103013</biblScope>
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An adaptive variational algorithm for exact molecular simulations on a quantum computer</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Grimsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Economou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Mayhall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3007</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A fast quantum mechanical algorithm for database search</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Grover</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Propagating phonons coupled to an artificial atom</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Gustafsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aref</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Kockum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>EkstrÃ¶m</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Delsing</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1257219</idno>
		<ptr target="http://dx.doi.org/10.1126/science.1257219" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<idno type="ISSN">1095-9203</idno>
		<imprint>
			<biblScope unit="volume">346</biblScope>
			<biblScope unit="issue">6206</biblScope>
			<biblScope unit="page" from="207" to="211" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Quantum computing with trapped ions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Haffner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Roos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Blatt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.physrep.2008.09.003</idno>
		<ptr target="https://doi.org/10.1016%2Fj.physrep.2008.09.003" />
	</analytic>
	<monogr>
		<title level="j">Physics Reports</title>
		<imprint>
			<biblScope unit="volume">469</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="155" to="203" />
			<date type="published" when="2008-12">dec 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Quantifying fermionic nonlinearity of quantum circuits</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hakkaku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mitarai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mizukami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fujii</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevResearch.4.043100</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevResearch.4.043100" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Research</title>
		<idno type="ISSN">2643-1564</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2022-11">Nov. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Hann</surname></persName>
		</author>
		<title level="m">Practicality of Quantum Random Access Memory</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
		<respStmt>
			<orgName>Yale University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Hardware-efficient quantum random access memory with hybrid quantum acoustic systems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Hann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Girvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.123.250501</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevLett.123.250501" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<idno type="ISSN">1079-7114</idno>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">25</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Hardware-efficient quantum random access memory with hybrid quantum acoustic systems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Hann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Girvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page">250501</biblScope>
			<date type="published" when="2019-12">Dec 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Low-depth gradient measurements can improve convergence in variational hybrid quantum-classical algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Harrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Napp</surname></persName>
		</author>
		<idno type="DOI">10.1103/physrevlett.126.140502</idno>
		<ptr target="https://doi.org/10.1103%2Fphysrevlett.126.140502" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">14</biblScope>
			<date type="published" when="2021-04">apr 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Quantum algorithm for linear systems of equations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Harrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hassidim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review letters</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page">150502</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Sequential measurements, disturbance and property testing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Harrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>-Y. Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Montanaro</surname></persName>
		</author>
		<idno type="DOI">10.1137/1.9781611974782.105</idno>
		<ptr target="http://dx.doi.org/10.1137/1.9781611974782.105" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2017-01">Jan. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Connecting ansatz expressibility to gradient magnitudes and barren plateaus</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<idno type="DOI">10.1103/PRXQuantum.3.010313</idno>
		<ptr target="http://dx.doi.org/10.1103/PRXQuantum.3.010313" />
	</analytic>
	<monogr>
		<title level="j">PRX Quantum</title>
		<idno type="ISSN">2691-3399</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2022-01">Jan. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Near-term quantum algorithms for linear systems of equations</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bharti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rebentrost</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1909.07344</idno>
		<idno type="arXiv">arXiv:1909.07344</idno>
		<imprint>
			<date type="published" when="2019-09">Sept. 2019</date>
		</imprint>
	</monogr>
	<note>arXiv e-prints, art</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Predicting many properties of a quantum system from very few measurements</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kueng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Preskill</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41567-020-0932-7</idno>
		<idno>1038% 2Fs41567-020-0932-7</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1050" to="1057" />
			<date type="published" when="2020-06">jun 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Predicting many properties of a quantum system from very few measurements</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kueng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Preskill</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41567-020-0932-7</idno>
		<ptr target="http://dx.doi.org/10.1038/s41567-020-0932-7" />
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<idno type="ISSN">1745-2481</idno>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1050" to="1057" />
			<date type="published" when="2020-06">June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Power of data in quantum machine learning</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Broughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohseni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Babbush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boixo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mcclean</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-021-22539-9</idno>
		<idno>1038%2Fs41467-021-22539-9</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021-05">may 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Efficient estimation of pauli observables by derandomization</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kueng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Preskill</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.127.030503</idno>
		<ptr target="https://link.aps.org/doi/10.1103/PhysRevLett.127.030503" />
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page">30503</biblScope>
			<date type="published" when="2021-07">Jul 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Information-theoretic bounds on quantum advantage in machine learning</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kueng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Preskill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page">190505</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Quantum advantage in learning from experiments</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Broughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cotler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohseni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Babbush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kueng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Preskill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<biblScope unit="issue">6598</biblScope>
			<biblScope unit="page" from="1182" to="1186" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Provably efficient machine learning for quantum many-body problems</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kueng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Torlai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Preskill</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.abk3333</idno>
		<ptr target="http://dx.doi.org/10.1126/science.abk3333" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<idno type="ISSN">1095-9203</idno>
		<imprint>
			<biblScope unit="volume">377</biblScope>
			<biblScope unit="issue">6613</biblScope>
			<date type="published" when="2022-09">Sept. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Non-convex optimization for machine learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kar</surname></persName>
		</author>
		<idno type="DOI">10.1561/2200000058</idno>
		<ptr target="http://dx.doi.org/10.1561/2200000058" />
	</analytic>
	<monogr>
		<title level="j">Foundations and TrendsÂ® in Machine Learning</title>
		<idno type="ISSN">1935-8245</idno>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="142" to="336" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">On nonconvex optimization for machine learning: Gradients, stochasticity, and saddle points</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Netrapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Hardware-efficient variational quantum eigensolver for small molecules and quantum magnets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kandala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mezzacapo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Temme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Gambetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">549</biblScope>
			<biblScope unit="issue">7671</biblScope>
			<biblScope unit="page" from="242" to="246" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Quantum recommendation systems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kerenidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prakash</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Learning unitaries by gradient descent</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Maity</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Quantum simulation of electronic structure with linear depth and connectivity</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Kivlichan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcclean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gidney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>-L. Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Babbush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review letters</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">110501</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Classical shadows with noise. Quantum, 6:776</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grewal</surname></persName>
		</author>
		<idno type="DOI">10.22331/q-2022-08-16-776</idno>
		<ptr target="http://dx.doi.org/10.22331/q-2022-08-16-776" />
		<imprint>
			<date type="published" when="2022-08">Aug. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Quantum computer-aided design of quantum optics hardware</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Kottmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krenn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Kyaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alperin-Lea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantum Science and Technology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">35010</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A quantum engineer&apos;s guide to superconducting qubits</title>
		<author>
			<persName><forename type="first">P</forename><surname>Krantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kjaergaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Orlando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gustavsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Oliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied physics reviews</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Computer-inspired quantum experiments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krenn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeilinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Physics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="649" to="661" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Theory of overparametrization in quantum neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Larocca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Garcia-Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<idno type="DOI">10.1038/s43588-023-00467-6</idno>
		<ptr target="http://dx.doi.org/10.1038/s43588-023-00467-6" />
	</analytic>
	<monogr>
		<title level="j">Nature Computational Science</title>
		<idno type="ISSN">2662-8457</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="542" to="551" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Robust data encodings for quantum classifiers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Larose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coyle</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevA.102.032420</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevA.102.032420" />
	</analytic>
	<monogr>
		<title level="j">Physical Review A</title>
		<idno type="ISSN">2469-9934</idno>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2020-09">Sept. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Variational quantum state diagonalization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Larose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tikku</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>O'neel-Judy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41534-019-0167-6</idno>
		<ptr target="http://dx.doi.org/10.1038/s41534-019-0167-6" />
	</analytic>
	<monogr>
		<title level="m">npj Quantum Information</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Generalized unitary coupled cluster wave functions for quantum computation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Huggins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Head-Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Whaley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical theory and computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="311" to="324" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Quantum optimization with a novel gibbs objective function and ansatz architecture search</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Coram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leichenauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">23074</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Spectral form factors and late time quantum chaos</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.98.086026</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevD.98.086026" />
	</analytic>
	<monogr>
		<title level="j">Physical Review D</title>
		<idno type="ISSN">2470-0029</idno>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018-10">Oct. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Scrambling and decoding the charged quantum information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevResearch.2.043164</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevResearch.2.043164" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Research</title>
		<idno type="ISSN">2643-1564</idno>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2020-10">Oct. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Laziness, barren plateau, and noise in machine learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Representation learning via quantum neural tangent kernels</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tacchino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Glick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mezzacapo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PRX Quantum</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">30323</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Noise can be helpful for variational quantum algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wilde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Mele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eisert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.06723</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Towards provably efficient quantum algorithms for large-scale machine-learning models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Alexeev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eisert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.03428</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Efficient quantum algorithm for dissipative nonlinear differential equations</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Ã</forename><surname>Kolden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Krovi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Loureiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Trivisa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Childs</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2026805118</idno>
		<ptr target="http://dx.doi.org/10.1073/pnas.2026805118" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<idno type="ISSN">1091-6490</idno>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">35</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Universal quantum simulators</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="issue">5278</biblScope>
			<biblScope unit="page" from="1073" to="1078" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Quantum algorithms for supervised and unsupervised machine learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohseni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rebentrost</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Quantum principal component analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohseni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rebentrost</surname></persName>
		</author>
		<idno type="DOI">10.1038/nphys3029</idno>
		<ptr target="http://dx.doi.org/10.1038/nphys3029" />
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<idno type="ISSN">1745-2481</idno>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="631" to="633" />
			<date type="published" when="2014-07">July 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Variational quantum algorithms for nonlinear problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lubasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moinier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kiffner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jaksch</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevA.101.010301</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevA.101.010301" />
	</analytic>
	<monogr>
		<title level="j">Physical Review A</title>
		<idno type="ISSN">2469-9934</idno>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020-01">Jan. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">O</forename><surname>Marrero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>KieferovÃ¡</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wiebe</surname></persName>
		</author>
		<title level="m">Entanglement induced barren plateaus</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Universal quantum emulator</title>
		<author>
			<persName><forename type="first">I</forename><surname>Marvian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">The theory of variational hybrid quantum-classical algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mcclean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Babbush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Journal of Physics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">23023</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Barren plateaus in quantum neural network training landscapes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mcclean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boixo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Smelyanskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Babbush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neven</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-018-07090-4</idno>
		<ptr target="http://dx.doi.org/10.1038/s41467-018-07090-4" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<idno type="ISSN">2041-1723</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018-11">Nov. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Methodology for replacing indirect measurements with direct measurements</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mitarai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fujii</surname></persName>
		</author>
		<idno type="DOI">10.1103/physrevresearch.1.013006</idno>
		<ptr target="https://doi.org/10.1103%2Fphysrevresearch.1.013006" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019-08">aug 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Quantum optimization using variational algorithms on near-term quantum devices</title>
		<author>
			<persName><forename type="first">N</forename><surname>Moll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barkoutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Egger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Filipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fuhrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Gambetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ganzhorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantum Science and Technology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">30503</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Sequential minimal optimization for quantum-classical hybrid algorithms</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Nakanishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Todo</surname></persName>
		</author>
		<idno type="DOI">10.1103/physrevresearch.2.043158</idno>
		<ptr target="https://doi.org/10.1103%2Fphysrevresearch.2.043158" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2020-10">oct 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">L</forename><surname>Chuang</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9780511976667</idno>
		<title level="m">Quantum Computation and Quantum Information: 10th Anniversary Edition</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Quantum ground state and single-phonon control of a mechanical resonator</title>
		<author>
			<persName><forename type="first">A</forename><surname>O'connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hofheinz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ansmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Bialczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lenander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lucero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neeley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Martinis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cleland</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature08967</idno>
		<ptr target="https://doi.org/10.1038/nature08967" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<idno type="ISSN">0028-0836</idno>
		<imprint>
			<biblScope unit="volume">464</biblScope>
			<biblScope unit="issue">7289</biblScope>
			<biblScope unit="page" from="697" to="703" />
			<date type="published" when="2010-04">April 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Donnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<title level="m">Efficient quantum tomography</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Structure optimization for parameterized quantum circuits</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ostaszewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Benedetti</surname></persName>
		</author>
		<idno type="DOI">10.22331/q-2021-01-28-391</idno>
		<ptr target="https://doi.org/10.22331%2Fq-2021-01-28-391" />
	</analytic>
	<monogr>
		<title level="j">Quantum</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">391</biblScope>
			<date type="published" when="2021-01">jan 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Entanglement devised barren plateau mitigation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Yelin</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevResearch.3.033090</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevResearch.3.033090" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Research</title>
		<idno type="ISSN">2643-1564</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2021-07">July 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Data re-uploading for a universal quantum classifier</title>
		<author>
			<persName><forename type="first">A</forename><surname>PÃ©rez-Salinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cervera-Lierta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gil-Fuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Latorre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">226</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">A variational eigenvalue solver on a photonic quantum processor</title>
		<author>
			<persName><forename type="first">A</forename><surname>Peruzzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcclean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shadbolt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Love</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>O'brien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4213</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">Sequential minimal optimization: A fast algorithm for training support vector machines</title>
		<author>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
		<idno>MSR-TR-98-14</idno>
		<imprint>
			<date type="published" when="1998-04">April 1998</date>
			<publisher>Microsoft</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Quantum computing in the nisq era and beyond</title>
		<author>
			<persName><forename type="first">J</forename><surname>Preskill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">79</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Chaos and complexity by design</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yoshida</surname></persName>
		</author>
		<idno type="DOI">10.1007/JHEP04(2017)121</idno>
		<ptr target="http://dx.doi.org/10.1007/JHEP04(2017)121" />
	</analytic>
	<monogr>
		<title level="j">Journal of High Energy Physics</title>
		<idno type="ISSN">1029-8479</idno>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2017-04">2017. Apr. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main">The principles of deep learning theory</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yaida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hanin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Quantum error correction: an introductory guide</title>
		<author>
			<persName><forename type="first">J</forename><surname>Roffe</surname></persName>
		</author>
		<idno type="DOI">10.1080/00107514.2019.1667078</idno>
		<ptr target="http://dx.doi.org/10.1080/00107514.2019.1667078" />
	</analytic>
	<monogr>
		<title level="j">Contemporary Physics</title>
		<idno type="ISSN">1366-5812</idno>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="226" to="245" />
			<date type="published" when="2019-07">July 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Modern Quantum Mechanics. Quantum physics, quantum information and quantum computation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Sakurai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Napolitano</surname></persName>
		</author>
		<idno type="DOI">10.1017/9781108587280</idno>
		<imprint>
			<date type="published" when="2020">10 2020</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Noise resilience of variational quantum compiling</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khatri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<idno type="DOI">10.1088/1367-2630/ab784c</idno>
		<ptr target="http://dx.doi.org/10.1088/1367-2630/ab784c" />
	</analytic>
	<monogr>
		<title level="j">New Journal of Physics</title>
		<idno type="ISSN">1367- 2630</idno>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">43006</biblScope>
			<date type="published" when="2020-04">Apr. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Trainability of dissipative perceptronbased quantum neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.128.180505</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevLett.128.180505" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<idno type="ISSN">1079-7114</idno>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">18</biblScope>
			<date type="published" when="2022-05">May 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Algorithms for quantum computation: discrete logarithms and factoring</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shor</surname></persName>
		</author>
		<idno type="DOI">10.1109/SFCS.1994.365700</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings 35th Annual Symposium on Foundations of Computer Science</title>
		<meeting>35th Annual Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="124" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">10-qubit entanglement and parallel logic operations with a superconducting circuit</title>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>-P. Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-B</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-W</forename><surname>Pan</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.119.180511</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevLett.119.180511" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<idno type="ISSN">1079-7114</idno>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">18</biblScope>
			<date type="published" when="2017-11">Nov. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Experimental estimation of quantum state properties from classical shadows</title>
		<author>
			<persName><forename type="first">G</forename><surname>Struchalin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Zagorovskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kovlakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Straupe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kulik</surname></persName>
		</author>
		<idno type="DOI">10.1103/PRXQuantum.2.010307</idno>
		<ptr target="https://link.aps.org/doi/10.1103/PRXQuantum.2.010307" />
	</analytic>
	<monogr>
		<title level="j">PRX Quantum</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">10307</biblScope>
			<date type="published" when="2021-01">Jan 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Generalized Trotter&apos;s formula and systematic approximants of exponential operators and inner derivations with applications to many-body problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Suzuki</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF01609348</idno>
	</analytic>
	<monogr>
		<title level="j">Communications in Mathematical Physics</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="190" />
			<date type="published" when="1976-06">June 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">A quantum-inspired classical algorithm for recommendation systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st annual ACM SIGACT symposium on theory of computing</title>
		<meeting>the 51st annual ACM SIGACT symposium on theory of computing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="217" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.127.060503</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevLett.127.060503" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<idno type="ISSN">1079-7114</idno>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2021-08">Aug. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">New perspectives on unitary coupled-cluster theory</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Taube</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Bartlett</surname></persName>
		</author>
		<idno type="DOI">10.1002/qua.21198</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Quantum Chemistry</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="3393" to="3401" />
			<date type="published" when="2006-01">Jan. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Error mitigation for short-depth quantum circuits</title>
		<author>
			<persName><forename type="first">K</forename><surname>Temme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bravyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Gambetta</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.119.180509</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevLett.119.180509" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<idno type="ISSN">1079-7114</idno>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">18</biblScope>
			<date type="published" when="2017-11">Nov. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">On barren plateaus and cost function locality in variational quantum algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Uvarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Biamonte</surname></persName>
		</author>
		<idno type="DOI">10.1088/1751-8121/abfac7</idno>
		<ptr target="http://dx.doi.org/10.1088/1751-8121/abfac7" />
	</analytic>
	<monogr>
		<title level="j">Journal of Physics A: Mathematical and Theoretical</title>
		<idno type="ISSN">1751-8121</idno>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page">245301</biblScope>
			<date type="published" when="2021-05">May 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Learning to learn with quantum neural networks via classical neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Verdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Broughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Mcclean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Babbush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohseni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Can error mitigation improve trainability of noisy variational quantum algorithms?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Czarnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arrasmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Noiseinduced barren plateaus in variational quantum algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fontana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cincio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Coles</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-021-27045-6</idno>
		<ptr target="http://dx.doi.org/10.1038/s41467-021-27045-6" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<idno type="ISSN">2041-1723</idno>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021-11">Nov. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Alexeev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.13460</idno>
		<title level="m">Fundamental causal bounds of quantum random access memories</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Reinforcementlearning-assisted quantum optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Wauters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Panizon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Mbeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Santoro</surname></persName>
		</author>
		<idno type="DOI">10.1103/physrevresearch.2.033446</idno>
		<ptr target="https://doi.org/10.1103%2Fphysrevresearch.2.033446" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2020-09">sep 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Progress towards practical quantum variational algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Hastings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Troyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review A</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">42303</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Hamiltonian learning and certification using quantum resources</title>
		<author>
			<persName><forename type="first">N</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Granade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ferrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cory</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.112.190501</idno>
		<ptr target="http://dx.doi.org/10.1103/PhysRevLett.112.190501" />
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<idno type="ISSN">1079-7114</idno>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">19</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Quantum bootstrapping via compressed quantum hamiltonian learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Granade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Cory</surname></persName>
		</author>
		<idno type="DOI">10.1088/1367-2630/17/2/022005</idno>
		<ptr target="http://dx.doi.org/10.1088/1367-2630/17/2/022005" />
	</analytic>
	<monogr>
		<title level="j">New Journal of Physics</title>
		<idno type="ISSN">1367-2630</idno>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">22005</biblScope>
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Glasmachers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<title level="m">Natural evolution strategies</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">Error-mitigated fermionic classical shadows on noisy quantum devices</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Koh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Policy gradient based quantum approximate optimization algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bukov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">From transistor to trapped-ion computers for quantum chemistry</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mezzacapo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcclean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lamata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Solano</surname></persName>
		</author>
		<idno type="DOI">10.1038/srep03589</idno>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2014</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Dynamical phase transition in quantum neural networks with large depth</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhuang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.18144</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Natural evolution strategies and variational monte carlo</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carleo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stokes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Veerapaneni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning: Science and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="02L" to="T3" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
